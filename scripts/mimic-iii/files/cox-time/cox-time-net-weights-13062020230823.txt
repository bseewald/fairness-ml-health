Weights: 
net.embeddings.embeddings.0.weight tensor([[-0.0476,  0.0140],
        [-0.0878,  0.2404],
        [-0.1539,  0.2001],
        [ 0.0133, -0.2246]])
net.embeddings.embeddings.1.weight tensor([[ 0.0216,  0.1437],
        [-0.0504,  0.2157],
        [-0.2465, -0.0585],
        [ 0.0028,  0.0818],
        [ 0.0525, -0.1222]])
net.embeddings.embeddings.2.weight tensor([[-0.1502, -0.1597, -0.0718],
        [ 0.0223, -0.0372, -0.0498],
        [ 0.3273,  0.2298, -0.0695],
        [-0.1386,  0.0260, -0.1375],
        [-0.1405, -0.0954,  0.0924],
        [ 0.0267,  0.0217, -0.0877]])
net.embeddings.embeddings.3.weight tensor([[ 0.0189,  0.2140],
        [-0.0364, -0.3259],
        [-0.0020,  0.0953],
        [ 0.3502, -0.1440]])
net.embeddings.embeddings.4.weight tensor([[-0.2038,  0.1987],
        [-0.0530,  0.1724],
        [ 0.1611, -0.0905],
        [ 0.0085,  0.1291]])
net.mlp.net.0.linear.weight tensor([[ 0.1755, -0.1256, -0.1157,  ...,  0.1160,  0.0032, -0.1650],
        [ 0.0446, -0.2822,  0.0358,  ..., -0.1154, -0.1443,  0.2916],
        [-0.0724,  0.0530, -0.0153,  ...,  0.0428,  0.1091, -0.1727],
        ...,
        [-0.0376, -0.1123,  0.1712,  ...,  0.0961,  0.0738, -0.1376],
        [ 0.0499,  0.0389,  0.1750,  ..., -0.0453, -0.1828, -0.0604],
        [-0.0822,  0.0579,  0.1081,  ...,  0.0894, -0.1384,  0.0078]])
net.mlp.net.0.linear.bias tensor([-4.1884e-02, -8.8408e-02,  2.8627e-02, -8.9202e-02,  7.8202e-02,
         8.5088e-02, -4.3266e-02, -7.0424e-02, -1.1397e-02,  4.0246e-02,
        -8.6911e-02,  4.3517e-03,  3.7612e-02,  3.8672e-02, -6.1031e-02,
        -4.6145e-03, -2.8537e-02, -6.4092e-02, -6.1801e-03, -1.1575e-01,
        -6.2061e-02,  3.2497e-02,  4.8864e-02, -1.2810e-01,  9.8061e-02,
        -3.1633e-02, -7.4213e-02,  8.6944e-02,  1.7911e-02,  5.3893e-02,
         1.0469e-02, -5.5381e-02, -5.8389e-02,  5.7703e-02,  7.0850e-02,
        -5.6539e-02, -3.5667e-02, -1.7408e-02,  6.6287e-02, -6.8278e-02,
        -5.4851e-02, -3.4781e-02, -9.9562e-02,  5.5838e-02, -1.1080e-02,
         9.5486e-02, -5.8970e-02, -4.5801e-02, -2.9705e-02,  9.4472e-03,
         1.2047e-02,  5.3902e-02, -3.2870e-02, -1.2067e-03,  4.7424e-02,
         1.0035e-01, -4.2513e-02,  1.3092e-01, -3.0176e-02,  6.8474e-02,
        -1.0111e-03,  1.1637e-01, -1.9227e-02, -4.3569e-02, -4.2700e-02,
        -8.2006e-02, -2.9410e-02, -2.3634e-02, -5.7341e-02,  6.4690e-02,
         4.4016e-02,  3.8093e-02, -1.5217e-02,  2.9380e-02, -3.4637e-02,
        -5.2501e-02, -2.9535e-02,  4.1726e-02, -1.1670e-02, -7.6422e-03,
        -7.5565e-02,  3.7995e-02,  2.2015e-02, -5.7228e-02, -6.3607e-02,
        -5.8921e-02,  4.3948e-02,  1.4300e-02,  1.1624e-01, -4.0378e-02,
        -8.0791e-02, -4.1616e-02,  5.3770e-02, -1.5580e-02,  2.3081e-02,
        -1.7339e-02,  5.8670e-02,  1.1047e-02, -5.1918e-03, -1.1041e-01,
         3.9736e-02, -2.5094e-02,  4.8377e-03,  4.5945e-02, -1.1941e-01,
         1.1264e-01,  8.8030e-02,  1.2855e-02, -4.5107e-02,  6.5363e-02,
        -8.5722e-02, -5.1619e-02,  1.6330e-02, -1.0716e-01,  5.4941e-02,
         3.3025e-02,  3.8607e-04, -1.0619e-01,  2.5994e-02,  5.9787e-02,
         2.9056e-02, -5.8139e-02,  5.4732e-03, -4.8082e-02, -7.8593e-02,
         5.8679e-02,  3.2807e-02, -8.0797e-02,  5.0464e-02, -5.9917e-02,
        -3.0978e-02,  9.4603e-02,  1.4546e-02,  2.2505e-02, -1.8803e-02,
        -4.8153e-02,  3.2233e-02, -7.1966e-02,  7.2381e-05,  4.4838e-02,
         6.1785e-03,  4.2331e-02, -1.3285e-02, -3.3906e-02, -4.6551e-03,
        -5.7051e-02, -5.3412e-02, -7.7298e-02,  6.3047e-02,  1.5609e-02,
        -2.3111e-02,  4.5783e-02,  4.2289e-02,  4.4846e-02, -5.3770e-02,
         1.8872e-02,  2.7955e-02, -3.9132e-02,  7.9709e-02,  6.3418e-02,
        -2.5201e-02, -9.4925e-02,  5.6304e-02,  9.2022e-03, -8.8943e-02,
         5.3152e-02, -4.1616e-02,  6.6979e-03,  8.4760e-02,  1.8631e-02,
         4.4584e-02,  3.7960e-03, -4.2698e-02, -5.9612e-02, -1.3986e-03,
        -5.6951e-02, -9.5291e-03,  3.5782e-02, -3.5942e-02,  6.9718e-02,
        -6.4956e-03,  2.8077e-02,  3.0788e-02, -1.5927e-02,  8.4083e-02,
         4.9608e-02, -5.3647e-02,  7.8364e-02, -2.2588e-03,  1.0865e-02,
        -2.0706e-02,  1.3924e-02,  8.4636e-02,  3.0026e-02,  1.2473e-02,
        -7.1303e-02, -2.8309e-02, -8.9986e-02, -7.9846e-02, -1.1937e-02,
         5.9166e-02,  3.5301e-02,  5.5631e-02,  1.4206e-02,  8.6836e-02,
         1.0531e-01, -1.7632e-02,  4.4188e-02,  9.2105e-02,  1.3485e-02,
         1.8773e-03, -7.5753e-02,  8.9101e-02,  2.3976e-02, -1.0809e-02,
         7.0572e-02, -3.2028e-02, -6.2278e-02,  5.5328e-02,  1.5677e-02,
        -4.3910e-02,  5.9977e-02, -2.7883e-02,  6.6084e-03,  5.4411e-02,
         1.9133e-02, -5.1843e-02,  4.8628e-02, -1.2730e-01, -2.4701e-02,
         7.7951e-02, -8.5130e-02,  3.3613e-02, -4.5716e-03, -2.0032e-02,
        -8.9324e-02,  1.2978e-02, -6.7660e-02, -1.1045e-01,  6.5922e-02,
         7.0058e-02,  7.7192e-02, -5.9772e-02, -3.0340e-02, -2.4098e-02,
        -4.0730e-02,  1.0634e-01,  2.1906e-02,  4.6352e-02, -3.7267e-02,
         1.3880e-02,  3.4221e-02, -6.8950e-02,  4.0141e-02,  2.9108e-02,
         1.0370e-02])
net.mlp.net.0.batch_norm.weight tensor([0.2994, 0.3344, 0.2858, 0.3772, 0.3386, 0.2997, 0.3877, 0.3259, 0.3096,
        0.3618, 0.3148, 0.2911, 0.3519, 0.3211, 0.3287, 0.3039, 0.3106, 0.4049,
        0.3487, 0.3818, 0.3435, 0.3032, 0.2660, 0.2908, 0.3145, 0.3097, 0.3029,
        0.3230, 0.3898, 0.3684, 0.2863, 0.3927, 0.3136, 0.3457, 0.2877, 0.3159,
        0.3439, 0.2987, 0.3095, 0.3686, 0.3353, 0.3311, 0.3305, 0.2992, 0.3633,
        0.2996, 0.4066, 0.3438, 0.3207, 0.2981, 0.3139, 0.3282, 0.4539, 0.3397,
        0.3617, 0.3155, 0.3347, 0.2692, 0.4064, 0.3046, 0.3952, 0.3137, 0.2779,
        0.3671, 0.3326, 0.2584, 0.3396, 0.3427, 0.4172, 0.3414, 0.3261, 0.3709,
        0.3026, 0.2983, 0.3094, 0.3137, 0.3143, 0.4002, 0.3953, 0.3488, 0.3291,
        0.3072, 0.3428, 0.3633, 0.4058, 0.3018, 0.3181, 0.3487, 0.3151, 0.3702,
        0.3376, 0.3441, 0.3351, 0.3001, 0.3394, 0.3126, 0.2926, 0.3053, 0.3900,
        0.3388, 0.2782, 0.3139, 0.3082, 0.4151, 0.4019, 0.2996, 0.2886, 0.3365,
        0.3129, 0.3616, 0.3190, 0.3950, 0.3339, 0.3402, 0.2800, 0.2916, 0.2847,
        0.3422, 0.3229, 0.3110, 0.3595, 0.3590, 0.3655, 0.3478, 0.2898, 0.4515,
        0.3664, 0.3565, 0.3597, 0.3528, 0.3128, 0.3004, 0.2822, 0.3757, 0.2825,
        0.3527, 0.3647, 0.3256, 0.2748, 0.3150, 0.2851, 0.3345, 0.2735, 0.3529,
        0.3210, 0.3758, 0.3593, 0.2731, 0.4188, 0.3358, 0.4002, 0.3219, 0.3312,
        0.3344, 0.3020, 0.4048, 0.2931, 0.2987, 0.3477, 0.2898, 0.2658, 0.3190,
        0.3233, 0.2770, 0.3006, 0.4188, 0.3806, 0.2827, 0.3176, 0.3292, 0.3211,
        0.3250, 0.3302, 0.3021, 0.3066, 0.3167, 0.3873, 0.3611, 0.3527, 0.3321,
        0.3472, 0.2836, 0.2988, 0.3204, 0.3192, 0.2625, 0.3306, 0.2995, 0.3321,
        0.3149, 0.3962, 0.3045, 0.3832, 0.3089, 0.2946, 0.3218, 0.3106, 0.2802,
        0.3148, 0.3525, 0.3281, 0.3076, 0.3436, 0.2987, 0.4111, 0.3454, 0.3877,
        0.3883, 0.3133, 0.4045, 0.3779, 0.3356, 0.3219, 0.3235, 0.3894, 0.3062,
        0.3223, 0.3009, 0.3024, 0.3512, 0.3422, 0.3042, 0.3183, 0.3556, 0.3239,
        0.3775, 0.3843, 0.3381, 0.3397, 0.3220, 0.2220, 0.3194, 0.3737, 0.2778,
        0.3446, 0.3479, 0.3630, 0.3139, 0.2877, 0.2724, 0.2528, 0.3829, 0.3048,
        0.4057, 0.3546, 0.4119, 0.3550, 0.3256, 0.3231, 0.2845, 0.3394, 0.3572,
        0.3881, 0.3255, 0.3024, 0.3743])
net.mlp.net.0.batch_norm.bias tensor([ 5.8401e-03, -4.2696e-02, -2.5221e-02,  2.6234e-02, -2.0421e-02,
        -1.3324e-02,  8.2696e-02,  5.1737e-02,  3.2380e-02,  2.6988e-02,
        -2.1118e-02,  2.5984e-02,  6.6488e-03,  1.4475e-02, -5.0056e-02,
         5.1127e-02,  9.3665e-03,  3.8644e-02, -2.3070e-02,  3.5346e-03,
         3.6575e-02,  5.4840e-02,  1.5079e-02,  4.3878e-03,  7.1882e-02,
         7.2040e-04,  1.6104e-02, -1.0259e-02,  4.0990e-02, -2.1196e-02,
         1.3176e-02, -3.9086e-02, -3.6120e-02,  3.3910e-02,  3.5740e-02,
        -2.0860e-02,  7.3735e-04, -1.5534e-02,  3.4995e-02, -7.3033e-03,
        -5.2320e-03, -6.5646e-02,  7.2595e-02, -1.2728e-01, -3.7491e-02,
         4.4438e-02, -3.8429e-02, -1.2797e-02, -4.1658e-02, -3.3407e-02,
        -8.5451e-03, -1.1866e-02,  7.5854e-02, -2.9694e-02,  7.2696e-03,
        -3.6057e-02,  9.2424e-03,  7.5607e-02, -3.4488e-02, -4.3008e-02,
        -3.3681e-02,  2.0257e-02,  1.3893e-02,  2.5822e-02,  4.4478e-02,
         5.0530e-02,  3.2066e-02,  1.6445e-02, -2.9024e-02, -5.4231e-03,
        -4.4954e-02, -2.4304e-02,  9.1902e-03,  1.2201e-02, -1.3502e-02,
         2.4048e-02, -1.6205e-02,  1.5971e-02,  5.3260e-02,  3.2109e-02,
        -1.8991e-02,  6.6377e-02,  2.1621e-02, -2.2041e-02, -2.6837e-03,
         7.2684e-02, -6.5077e-02,  4.2519e-02,  3.7527e-03, -5.4266e-02,
        -5.4050e-03, -5.6665e-03, -2.0580e-04,  7.8655e-02, -7.0740e-03,
        -3.9208e-02, -5.8795e-02, -7.3285e-02,  4.7511e-02,  1.5721e-02,
        -1.1905e-03, -1.5566e-05,  1.0203e-02,  2.7363e-03,  4.7859e-02,
        -2.5660e-03,  9.8115e-03, -4.4137e-03, -7.0759e-02,  3.2171e-02,
         2.5717e-02,  1.6532e-02,  6.3145e-02,  3.6292e-02,  3.3963e-02,
        -9.0026e-03, -1.9055e-02, -4.1957e-03,  1.1464e-02, -1.2702e-02,
         5.6509e-02,  7.7541e-02, -3.4651e-03, -3.2082e-03, -4.9223e-03,
         2.5262e-02, -4.3668e-02, -1.4020e-02, -1.5124e-02,  4.8768e-02,
        -2.7904e-02,  2.2748e-02, -3.1664e-02,  3.0911e-03, -5.3440e-02,
        -1.3144e-02, -1.0710e-01,  4.6026e-03, -1.0524e-02,  2.9471e-02,
        -1.0731e-02, -1.6320e-02, -3.4482e-02, -7.4918e-03, -4.4981e-02,
        -9.1795e-02, -2.1558e-04, -1.9884e-02,  2.2854e-02, -6.9074e-02,
        -7.2297e-03, -3.5971e-02, -1.7847e-02,  1.3814e-02, -2.6340e-02,
         3.8080e-02,  5.5710e-02,  6.6436e-03, -1.2185e-03,  3.6350e-02,
         2.7729e-02, -1.4463e-02, -5.0320e-02,  4.6812e-02,  3.6086e-02,
         5.3468e-02, -2.7000e-02,  1.2980e-02, -2.7121e-02,  3.1009e-04,
        -3.2122e-02,  4.3747e-02, -1.1021e-02,  3.2812e-02,  1.1506e-02,
         4.2438e-02,  1.1203e-02,  7.1567e-03, -1.7821e-02,  1.6875e-02,
        -3.0393e-02,  2.4487e-02,  2.6039e-02, -2.9196e-02, -3.6513e-03,
        -4.6091e-02, -1.0340e-02,  3.2172e-02, -1.0676e-02,  2.8299e-02,
        -5.3623e-03, -8.3460e-03, -9.5661e-02, -3.2825e-02, -6.7990e-03,
         6.5909e-04, -9.5757e-03, -4.5473e-02,  3.8833e-02,  1.8851e-02,
         7.8782e-02,  1.2685e-02, -2.6911e-02,  3.4328e-02,  6.6294e-03,
         3.5417e-02,  4.5444e-02,  3.4947e-02, -2.1138e-02,  3.6267e-02,
         2.3219e-03,  1.9095e-02, -3.0913e-03, -2.2172e-03, -5.3597e-02,
         5.6702e-02,  3.7203e-02,  2.8779e-02,  4.5662e-02, -7.5017e-03,
        -2.0283e-02,  2.4718e-02,  1.7621e-02, -3.5315e-03,  1.9237e-03,
         1.7620e-02,  4.0838e-02,  1.0556e-02, -1.4720e-02,  3.2348e-02,
         1.2798e-02,  9.3851e-03, -3.7456e-02,  3.8652e-02, -2.3144e-02,
        -1.8599e-03, -5.2618e-02,  6.1937e-02, -3.0922e-02, -1.1625e-02,
         2.5603e-03, -1.4125e-02,  2.3333e-02, -6.9101e-02,  5.3951e-02,
         3.6775e-02,  1.9786e-02, -9.6977e-03, -2.7467e-02,  2.3577e-02,
         4.8662e-02,  6.6828e-02,  3.0671e-02,  2.4170e-03, -2.4184e-02,
        -2.5464e-02])
net.mlp.net.0.batch_norm.running_mean tensor([6.2613e-02, 8.8277e-02, 1.4225e-02, 1.6826e-02, 1.5678e-01, 1.8107e-01,
        9.7706e-04, 4.3045e-02, 1.7023e-02, 2.1247e-01, 4.5862e-02, 1.1060e-02,
        8.2074e-02, 4.1179e-01, 4.5326e-02, 5.0262e-02, 3.9074e-02, 1.0348e-01,
        2.1329e-02, 1.6740e-02, 1.4059e-03, 1.3489e-02, 1.4854e-01, 4.8467e-05,
        2.9110e-01, 3.9188e-02, 2.5836e-03, 3.0721e-01, 1.4680e-03, 6.8744e-03,
        5.3976e-02, 3.3562e-02, 3.1232e-01, 3.0932e-01, 1.2539e-01, 7.6913e-03,
        2.8060e-01, 7.7636e-02, 1.0090e-01, 1.7620e-02, 7.2805e-03, 3.5040e-02,
        1.3699e-01, 4.7445e-01, 8.9943e-02, 6.6218e-02, 9.3201e-03, 1.7432e-01,
        1.8440e-01, 2.5716e-01, 6.1243e-02, 1.4988e-01, 3.4187e-04, 1.0299e-01,
        2.1639e-01, 4.5414e-01, 6.3363e-02, 4.1746e-01, 1.2126e-03, 1.2204e-01,
        1.3957e-01, 4.8664e-01, 6.4353e-02, 1.1574e-02, 1.3318e-03, 5.9997e-02,
        1.3412e-01, 5.3938e-03, 7.9373e-02, 1.2364e-01, 1.8974e-02, 1.3145e-01,
        8.9362e-02, 1.1716e-01, 5.2114e-02, 2.0996e-01, 6.7487e-02, 3.9623e-03,
        1.6807e-02, 2.3754e-01, 7.6071e-02, 3.9150e-01, 3.3746e-02, 1.3901e-01,
        1.0382e-02, 6.7905e-02, 4.9207e-01, 7.2670e-02, 3.2860e-01, 6.6022e-03,
        1.9268e-02, 8.1667e-02, 2.2738e-01, 7.9801e-02, 1.7204e-01, 1.4003e-02,
        2.3243e-01, 1.4895e-01, 1.2809e-02, 3.0793e-02, 6.1105e-02, 3.2868e-02,
        2.2717e-01, 9.0163e-02, 1.2354e-02, 3.6549e-01, 1.1973e-02, 4.1100e-02,
        6.5613e-02, 9.5498e-02, 1.4883e-02, 3.0027e-02, 1.5958e-01, 3.3396e-02,
        1.8326e-03, 1.0501e-01, 6.7560e-02, 7.4073e-03, 8.3287e-02, 2.9491e-02,
        1.6364e-01, 1.5505e-01, 5.9288e-02, 1.1281e-02, 6.4315e-02, 7.2150e-04,
        2.5220e-01, 3.5974e-02, 1.7314e-01, 2.0776e-03, 1.8552e-01, 2.3952e-01,
        7.0454e-04, 5.4968e-03, 1.9469e-01, 2.0370e-02, 1.2136e-01, 1.7877e-02,
        1.1444e-01, 9.4813e-02, 7.0287e-02, 8.7550e-02, 1.5532e-01, 8.8126e-02,
        2.2196e-02, 7.7467e-03, 2.4334e-02, 2.3104e-01, 3.0551e-03, 1.2523e-02,
        1.1342e-02, 1.7729e-02, 2.4400e-02, 1.0010e-01, 4.6236e-02, 3.9795e-04,
        7.7387e-02, 8.1179e-02, 1.7309e-02, 2.3762e-01, 2.0222e-02, 4.3819e-04,
        1.1951e-01, 1.2316e-01, 5.5793e-02, 4.6425e-04, 2.7159e-02, 1.8975e-01,
        1.0499e-01, 3.7061e-01, 8.8264e-02, 1.1220e-02, 2.3471e-01, 3.7959e-01,
        7.9762e-02, 1.3379e-01, 2.8856e-03, 4.2941e-01, 4.4347e-03, 2.7390e-01,
        6.8564e-02, 4.4630e-01, 1.4333e-01, 2.8023e-02, 1.2433e-02, 1.0970e-01,
        3.4374e-04, 1.5969e-01, 6.0155e-03, 2.0982e-01, 1.8907e-01, 1.5889e-01,
        1.0751e-01, 7.6645e-02, 2.6725e-02, 6.3289e-02, 2.2791e-01, 5.7949e-01,
        4.3818e-03, 1.0858e-01, 8.3681e-02, 4.5499e-02, 1.0551e-01, 1.7719e-01,
        2.7576e-03, 3.4803e-01, 8.9416e-03, 3.5192e-03, 3.8939e-01, 1.0245e-02,
        1.2129e-02, 1.7049e-02, 2.1147e-01, 1.6520e-01, 2.5996e-01, 1.0179e-01,
        1.0518e-01, 1.8543e-03, 1.2947e-01, 2.9991e-01, 2.2252e-02, 2.3922e-01,
        2.1721e-01, 1.3840e-02, 1.5808e-01, 1.9092e-02, 2.8468e-02, 1.4726e-01,
        5.1828e-03, 6.9197e-03, 3.6687e-01, 4.9618e-03, 5.5204e-02, 6.6176e-02,
        1.2065e-01, 8.9858e-03, 1.7080e-01, 2.5529e-01, 1.1378e-01, 1.4840e-01,
        1.7936e-01, 2.2626e-01, 1.0690e-02, 1.6151e-02, 7.8494e-03, 6.0729e-02,
        3.0626e-01, 2.9566e-01, 2.4617e-03, 4.0389e-02, 2.1101e-02, 1.6550e-02,
        4.7856e-02, 2.5603e-01, 1.2148e-01, 7.7357e-03])
net.mlp.net.0.batch_norm.running_var tensor([0.0101, 0.0099, 0.0028, 0.0047, 0.0246, 0.0212, 0.0014, 0.0194, 0.0038,
        0.0186, 0.0094, 0.0030, 0.0139, 0.0303, 0.0173, 0.0118, 0.0084, 0.0185,
        0.0036, 0.0060, 0.0015, 0.0030, 0.0246, 0.0013, 0.0210, 0.0103, 0.0016,
        0.0449, 0.0016, 0.0023, 0.0121, 0.0046, 0.0202, 0.0289, 0.0778, 0.0022,
        0.0146, 0.0139, 0.0110, 0.0026, 0.0025, 0.0057, 0.0243, 0.0488, 0.0066,
        0.0066, 0.0019, 0.0248, 0.0136, 0.0329, 0.0081, 0.0184, 0.0013, 0.0137,
        0.0341, 0.0323, 0.0117, 0.0209, 0.0014, 0.0171, 0.0137, 0.0295, 0.0256,
        0.0029, 0.0014, 0.0459, 0.0231, 0.0035, 0.0113, 0.0163, 0.0035, 0.0162,
        0.0146, 0.0110, 0.0071, 0.0162, 0.0088, 0.0017, 0.0030, 0.0097, 0.0143,
        0.1051, 0.0043, 0.0178, 0.0023, 0.0602, 0.0276, 0.0111, 0.0317, 0.0022,
        0.0031, 0.0302, 0.0387, 0.0098, 0.0146, 0.0027, 0.0329, 0.0220, 0.0033,
        0.0106, 0.0075, 0.0053, 0.0141, 0.0111, 0.0035, 0.0159, 0.0031, 0.0080,
        0.0081, 0.0076, 0.0087, 0.0094, 0.0370, 0.0066, 0.0015, 0.0118, 0.0089,
        0.0020, 0.0140, 0.0202, 0.0382, 0.0152, 0.0071, 0.0032, 0.0079, 0.0014,
        0.0296, 0.0057, 0.0210, 0.0014, 0.0153, 0.0226, 0.0014, 0.0019, 0.0336,
        0.0033, 0.0075, 0.0044, 0.0455, 0.0089, 0.0260, 0.0262, 0.0305, 0.0077,
        0.0045, 0.0027, 0.0047, 0.0348, 0.0016, 0.0028, 0.0029, 0.0033, 0.0041,
        0.0142, 0.0079, 0.0013, 0.0841, 0.0180, 0.0028, 0.0213, 0.0036, 0.0014,
        0.0190, 0.0475, 0.0419, 0.0014, 0.0043, 0.0189, 0.0167, 0.0434, 0.0138,
        0.0031, 0.0380, 0.0385, 0.0214, 0.0647, 0.0016, 0.0436, 0.0018, 0.0496,
        0.0108, 0.0323, 0.0137, 0.0157, 0.0024, 0.0183, 0.0013, 0.0327, 0.0025,
        0.1654, 0.0205, 0.0154, 0.0096, 0.0089, 0.0049, 0.0074, 0.0233, 0.0640,
        0.0024, 0.0140, 0.0363, 0.0081, 0.0675, 0.0914, 0.0015, 0.0304, 0.0026,
        0.0023, 0.0184, 0.0024, 0.0025, 0.0027, 0.0185, 0.0410, 0.0295, 0.0768,
        0.0439, 0.0020, 0.0172, 0.0164, 0.0050, 0.0155, 0.0323, 0.0029, 0.0186,
        0.0139, 0.0048, 0.0194, 0.0019, 0.0027, 0.0290, 0.0021, 0.0087, 0.0478,
        0.0220, 0.0032, 0.0382, 0.1224, 0.0160, 0.0239, 0.0935, 0.0413, 0.0030,
        0.0027, 0.0030, 0.0081, 0.0101, 0.0177, 0.0015, 0.0064, 0.0079, 0.0053,
        0.0070, 0.0401, 0.0230, 0.0025])
net.mlp.net.0.batch_norm.num_batches_tracked tensor(63)
net.mlp.net.1.linear.weight tensor([[ 0.0701, -0.0457, -0.0100,  ..., -0.0638,  0.0462,  0.0177],
        [-0.0615,  0.0059,  0.0215,  ..., -0.0092,  0.0276, -0.0053],
        [ 0.0457,  0.0154,  0.0421,  ...,  0.0370, -0.0653, -0.0485],
        ...,
        [-0.0135,  0.0602,  0.0257,  ...,  0.0066,  0.0119, -0.0353],
        [ 0.0052,  0.0392,  0.0047,  ..., -0.0540, -0.0434,  0.0173],
        [-0.0070,  0.0245,  0.0189,  ...,  0.0719,  0.0706,  0.0344]])
net.mlp.net.1.linear.bias tensor([-3.9843e-02, -2.7394e-02, -3.0551e-02, -2.9215e-02, -5.8009e-02,
        -2.0013e-03, -1.1277e-02, -3.2351e-02,  1.4931e-02, -3.3369e-02,
        -1.4358e-02,  1.5716e-02,  1.7274e-02,  3.5906e-02, -1.0856e-01,
         2.7174e-02, -9.5953e-02, -8.3307e-02, -2.4727e-02, -2.3908e-02,
         6.7373e-02, -2.7687e-02, -3.4045e-02, -3.8897e-03, -4.7621e-02,
        -4.9107e-02, -5.1498e-02,  5.4705e-02,  5.3775e-04, -2.6578e-02,
        -2.8133e-02, -7.3591e-02, -5.1799e-03,  3.5988e-05,  2.3470e-02,
        -4.4277e-03, -2.0043e-02, -4.8023e-02, -9.4546e-02,  2.0467e-02,
        -1.3397e-02,  3.2231e-03, -2.6620e-02, -3.7276e-02, -2.7732e-02,
        -2.2204e-02, -1.3797e-03,  1.4613e-02, -6.6793e-02, -8.3319e-02,
        -5.2932e-02,  2.3142e-02, -3.3794e-02, -3.2161e-02,  6.0332e-02,
        -3.4791e-02, -3.2622e-02, -2.3293e-02, -7.0008e-02,  8.6077e-03,
        -2.6884e-02,  5.2840e-02,  3.5407e-02, -3.0398e-02, -2.8503e-02,
        -4.4569e-02, -7.5097e-03, -7.6872e-02, -5.3838e-02, -4.9170e-02,
        -2.7065e-03, -3.3332e-02,  2.0935e-02, -6.3023e-02, -1.9230e-02,
         1.7485e-02, -5.4702e-02,  3.8365e-02, -3.6779e-02,  2.2061e-02,
        -7.4092e-02, -4.2227e-02, -2.0244e-02, -1.6932e-02, -1.8021e-02,
         2.1324e-02,  3.5348e-03, -6.1759e-02, -4.6739e-02, -7.3826e-02,
         3.9681e-02, -3.9065e-02,  3.0898e-02, -5.3151e-02,  5.7558e-02,
        -9.5023e-02,  4.2803e-03, -4.5346e-03,  1.9724e-02,  2.1917e-02,
        -3.1818e-02, -6.3809e-02, -2.3894e-02, -6.2116e-02,  6.1949e-02,
         6.9666e-03,  3.7750e-03, -3.5087e-02,  2.8725e-02, -1.1871e-02,
        -9.5732e-03, -1.9462e-02, -9.0670e-03,  2.0106e-02,  2.0614e-02,
        -2.3547e-02, -2.1492e-02,  1.8801e-02, -2.1405e-02, -6.4059e-02,
         8.4429e-03, -1.4757e-02, -3.6285e-02, -2.5527e-02,  3.3456e-02,
        -1.7918e-02, -9.0989e-04, -3.4796e-02, -1.2391e-02, -1.0336e-01,
         9.2936e-03, -5.1927e-03, -6.2820e-02, -5.5972e-02,  1.3783e-02,
        -4.5068e-02, -3.0949e-02, -1.9753e-02,  4.4538e-02,  1.6105e-02,
         2.4335e-02,  3.5756e-02, -1.3809e-02,  1.0219e-02,  5.6531e-02,
        -1.4917e-02, -6.5493e-02,  4.1507e-02,  1.0736e-02, -3.8328e-02,
        -9.0025e-02,  2.6482e-02, -2.6973e-02,  1.8007e-03, -2.3992e-02,
        -4.4914e-02, -1.3086e-02,  2.2578e-02, -3.5685e-02, -2.9452e-02,
        -7.6489e-02, -5.8352e-02, -7.5333e-02,  2.6292e-03,  5.6420e-02,
         5.4039e-02, -3.4794e-02, -2.2655e-02,  3.2301e-03, -2.0689e-02,
         5.4249e-02,  1.7651e-02, -2.2781e-02, -3.5218e-02, -2.0401e-02,
         8.6583e-03, -1.5265e-02, -2.8097e-02,  3.0999e-02, -2.2659e-02,
        -4.2330e-02, -1.2610e-02, -2.1032e-02,  1.3515e-02, -3.8922e-02,
         2.7824e-02,  9.1146e-03, -8.9965e-02,  2.8542e-02, -3.5975e-02,
        -8.3755e-03,  3.4141e-02, -2.3531e-02,  1.7196e-02, -2.5997e-02,
         3.6402e-02, -8.1874e-03, -1.6967e-02, -5.7660e-02, -4.8326e-02,
        -5.2961e-02,  1.2387e-02, -5.3224e-02, -2.9384e-02, -1.9715e-02,
        -1.3442e-02,  2.7300e-02, -2.0911e-02,  3.2748e-03, -9.4052e-02,
        -2.9705e-03, -3.2854e-02,  7.9652e-03,  2.3354e-02, -1.1633e-02,
         8.5871e-03, -1.4823e-02, -4.5055e-02, -6.5095e-02,  2.8351e-02,
        -6.6186e-02, -1.9646e-02,  3.6614e-02, -6.3006e-03,  5.3201e-04,
        -3.8798e-02, -5.6135e-02, -6.3880e-02, -8.6075e-02, -3.9597e-02,
        -4.7941e-02, -3.4457e-02, -1.5307e-02, -2.1466e-02, -1.0975e-02,
        -6.3874e-02,  3.3302e-02,  1.8378e-02, -6.0183e-03,  3.8008e-03,
         1.7095e-02, -4.0170e-02, -5.4993e-02, -2.5718e-02,  6.4464e-03,
        -2.1896e-02, -4.7366e-02,  1.4369e-02, -5.9984e-03, -1.6238e-02,
        -5.9135e-04, -2.0866e-02, -9.7989e-03, -7.8187e-02, -5.4747e-02,
        -6.6158e-02])
net.mlp.net.1.batch_norm.weight tensor([0.3206, 0.3002, 0.3225, 0.3132, 0.3059, 0.3960, 0.2894, 0.3486, 0.3192,
        0.3268, 0.3377, 0.3394, 0.3654, 0.3206, 0.3336, 0.3895, 0.3073, 0.3540,
        0.3157, 0.3181, 0.3255, 0.4022, 0.3486, 0.3213, 0.3087, 0.3549, 0.3947,
        0.3297, 0.3426, 0.3260, 0.3561, 0.3227, 0.3166, 0.3426, 0.2897, 0.2759,
        0.3830, 0.3268, 0.3093, 0.2950, 0.3239, 0.3065, 0.3601, 0.3756, 0.3158,
        0.2981, 0.2894, 0.3112, 0.3956, 0.3435, 0.3479, 0.3158, 0.3469, 0.3360,
        0.3489, 0.3279, 0.3669, 0.3073, 0.3347, 0.2994, 0.3109, 0.3448, 0.3561,
        0.2946, 0.3397, 0.3460, 0.3556, 0.3398, 0.3093, 0.3356, 0.3191, 0.3360,
        0.3236, 0.3671, 0.3700, 0.3555, 0.3240, 0.3518, 0.3275, 0.3455, 0.3390,
        0.3011, 0.3661, 0.3234, 0.3943, 0.3713, 0.3304, 0.3727, 0.3113, 0.3370,
        0.3015, 0.3278, 0.2705, 0.3140, 0.3338, 0.3119, 0.3916, 0.3358, 0.3456,
        0.3093, 0.3270, 0.3151, 0.3576, 0.3761, 0.3484, 0.3519, 0.3486, 0.3047,
        0.4080, 0.3263, 0.3043, 0.3347, 0.3311, 0.3170, 0.3195, 0.3318, 0.3529,
        0.3183, 0.3206, 0.3889, 0.3767, 0.2519, 0.3286, 0.3474, 0.3738, 0.3300,
        0.3340, 0.3889, 0.3440, 0.3272, 0.3583, 0.3233, 0.2929, 0.3059, 0.3639,
        0.3152, 0.3004, 0.3260, 0.3699, 0.3524, 0.2808, 0.3401, 0.3415, 0.3596,
        0.3478, 0.3109, 0.3563, 0.2846, 0.3783, 0.3191, 0.4115, 0.3215, 0.3099,
        0.2872, 0.3272, 0.3515, 0.3070, 0.3455, 0.2955, 0.3593, 0.2831, 0.3601,
        0.3700, 0.3047, 0.3324, 0.3255, 0.3760, 0.3186, 0.3652, 0.2972, 0.3466,
        0.3751, 0.2802, 0.3150, 0.3630, 0.2907, 0.3145, 0.3304, 0.2975, 0.3894,
        0.3530, 0.3388, 0.3383, 0.2710, 0.2942, 0.3629, 0.3676, 0.3712, 0.3398,
        0.3392, 0.3588, 0.3207, 0.3650, 0.3272, 0.2889, 0.3314, 0.3823, 0.3626,
        0.3289, 0.3290, 0.4091, 0.3440, 0.3463, 0.3555, 0.3340, 0.3915, 0.3571,
        0.3163, 0.3189, 0.3612, 0.3779, 0.3683, 0.3549, 0.3618, 0.3262, 0.3149,
        0.3075, 0.3347, 0.3503, 0.3224, 0.3325, 0.3631, 0.3472, 0.3408, 0.3475,
        0.3699, 0.3605, 0.3145, 0.3454, 0.3191, 0.3162, 0.3312, 0.3180, 0.3233,
        0.3030, 0.3541, 0.2892, 0.3581, 0.3559, 0.2762, 0.3262, 0.3463, 0.3679,
        0.3405, 0.4216, 0.3704, 0.3373, 0.3265, 0.3304, 0.3368, 0.3819, 0.3007,
        0.2783, 0.3387, 0.3525, 0.3919])
net.mlp.net.1.batch_norm.bias tensor([ 0.0123,  0.0288,  0.0087,  0.0035,  0.0001,  0.0046,  0.0318,  0.0069,
         0.0145, -0.0249,  0.0233,  0.0135, -0.0131,  0.0016, -0.0024,  0.0059,
        -0.0196,  0.0331,  0.0101,  0.0075,  0.0235,  0.0398, -0.0233,  0.0429,
        -0.0441, -0.0078, -0.0687, -0.0003,  0.0369,  0.0627, -0.0067,  0.0084,
        -0.0035,  0.0451,  0.0189,  0.0090, -0.0231,  0.0361, -0.0106, -0.0238,
         0.0354,  0.0220,  0.0155, -0.0536, -0.0286,  0.0208,  0.0138,  0.0010,
        -0.0035, -0.0529,  0.0072,  0.0395, -0.0525,  0.0397,  0.0135, -0.0041,
        -0.0104,  0.0340,  0.0023,  0.0398,  0.0080,  0.0400,  0.0530,  0.0074,
        -0.0132, -0.0163, -0.0140, -0.0275,  0.0111, -0.0358, -0.0183, -0.0329,
        -0.0045, -0.0286,  0.0368,  0.0571,  0.0033, -0.0046, -0.0132,  0.0249,
        -0.0176, -0.0331,  0.0683, -0.0079,  0.0409,  0.0018,  0.0592,  0.0241,
        -0.0486, -0.0150, -0.0231, -0.0301, -0.0124,  0.0113,  0.0097, -0.0005,
         0.0250,  0.0061,  0.0048, -0.0072, -0.0304, -0.0021,  0.0021, -0.0199,
        -0.0143, -0.0196,  0.0079, -0.0258, -0.0173, -0.0069,  0.0201, -0.0299,
        -0.0210, -0.0571, -0.0520,  0.0258,  0.0299, -0.0553,  0.0022, -0.0069,
        -0.0062,  0.0260, -0.0220, -0.0187, -0.0605, -0.0118, -0.0475, -0.0048,
        -0.0317, -0.0098,  0.0053,  0.0290, -0.0405,  0.0205,  0.0103, -0.0064,
         0.0496, -0.0059, -0.0162,  0.0172, -0.0069,  0.0281, -0.0353, -0.0132,
         0.0091,  0.0029,  0.0215,  0.0074, -0.0083,  0.0039, -0.0491, -0.0211,
         0.0481, -0.0382,  0.0057, -0.0158,  0.0028,  0.0113,  0.0493,  0.0700,
        -0.0221,  0.0074, -0.0529,  0.0112,  0.0329,  0.0142,  0.0020,  0.0341,
        -0.0043, -0.0161,  0.0244, -0.0276,  0.0270,  0.0363,  0.0044, -0.0237,
        -0.0464, -0.0148, -0.0222, -0.0299,  0.0165, -0.0541, -0.0080, -0.0232,
        -0.0277,  0.0379, -0.0468, -0.0069, -0.0218, -0.0354, -0.0530, -0.0186,
         0.0067, -0.0453,  0.0192,  0.0204,  0.0357, -0.0369,  0.0020,  0.0011,
         0.0466,  0.0003, -0.0099, -0.0451, -0.0490,  0.0119, -0.0275,  0.0382,
        -0.0363, -0.0716,  0.0240,  0.0517, -0.0307, -0.0333, -0.0340, -0.0007,
        -0.0083, -0.0620,  0.0132, -0.0633,  0.0173,  0.0430, -0.0692,  0.0030,
         0.0289,  0.0325, -0.0591,  0.0111,  0.0025, -0.0155, -0.0667,  0.0060,
        -0.0128,  0.0410, -0.0114, -0.0467,  0.0038, -0.0494,  0.0720, -0.0680,
        -0.0140, -0.0176,  0.0079, -0.0090,  0.0537,  0.0351, -0.0143,  0.0009,
         0.0153, -0.0024,  0.0576,  0.0430, -0.0317, -0.0025,  0.0220, -0.0441])
net.mlp.net.1.batch_norm.running_mean tensor([0.2211, 0.2079, 0.1666, 0.2300, 0.1130, 0.2152, 0.2588, 0.1894, 0.1977,
        0.1203, 0.2619, 0.2221, 0.2010, 0.1805, 0.1997, 0.2497, 0.1942, 0.1324,
        0.2180, 0.1585, 0.2389, 0.1732, 0.1367, 0.1942, 0.2166, 0.2538, 0.1119,
        0.2317, 0.2612, 0.1735, 0.1540, 0.1699, 0.1957, 0.1969, 0.1845, 0.1583,
        0.1951, 0.1818, 0.1652, 0.1996, 0.2115, 0.2236, 0.2061, 0.1357, 0.2287,
        0.1781, 0.2120, 0.2371, 0.1525, 0.1726, 0.1184, 0.2241, 0.1809, 0.2352,
        0.2784, 0.1431, 0.1600, 0.1676, 0.1796, 0.1717, 0.2740, 0.2125, 0.2278,
        0.1792, 0.1986, 0.1973, 0.1950, 0.1463, 0.1584, 0.2281, 0.2106, 0.1795,
        0.1932, 0.1653, 0.1815, 0.1993, 0.1836, 0.2082, 0.2505, 0.2758, 0.1674,
        0.1918, 0.2182, 0.1731, 0.1542, 0.2254, 0.2270, 0.1249, 0.1808, 0.1829,
        0.2288, 0.1596, 0.2576, 0.1507, 0.1806, 0.1201, 0.2351, 0.1458, 0.2272,
        0.2555, 0.1804, 0.1441, 0.2035, 0.1580, 0.2604, 0.2416, 0.1595, 0.2115,
        0.2262, 0.1741, 0.1375, 0.2557, 0.2092, 0.2537, 0.2499, 0.1986, 0.1247,
        0.2447, 0.1691, 0.1112, 0.2873, 0.1722, 0.1767, 0.2439, 0.2291, 0.1927,
        0.2589, 0.1793, 0.2037, 0.1718, 0.2165, 0.2924, 0.1452, 0.1849, 0.2117,
        0.1175, 0.1838, 0.2382, 0.2010, 0.2447, 0.1953, 0.2233, 0.1525, 0.2265,
        0.2912, 0.1838, 0.2062, 0.2472, 0.2313, 0.2557, 0.1060, 0.1560, 0.1449,
        0.2554, 0.2657, 0.1458, 0.2573, 0.2410, 0.2149, 0.2240, 0.0911, 0.2052,
        0.1860, 0.1714, 0.2021, 0.2116, 0.2594, 0.1604, 0.2566, 0.1713, 0.2673,
        0.1890, 0.1811, 0.2173, 0.1347, 0.1719, 0.2340, 0.2091, 0.2881, 0.1882,
        0.2348, 0.1685, 0.1957, 0.2739, 0.2281, 0.2478, 0.2593, 0.1489, 0.2942,
        0.1250, 0.1838, 0.1928, 0.2238, 0.1939, 0.2866, 0.2338, 0.2289, 0.2172,
        0.1690, 0.1898, 0.2110, 0.1718, 0.1462, 0.1419, 0.1985, 0.1873, 0.2329,
        0.2472, 0.2174, 0.1472, 0.1813, 0.2082, 0.2343, 0.2186, 0.2489, 0.1441,
        0.1957, 0.1503, 0.1714, 0.2152, 0.2338, 0.2476, 0.2551, 0.2047, 0.2300,
        0.2298, 0.1294, 0.0993, 0.1227, 0.1991, 0.1608, 0.1431, 0.2220, 0.1808,
        0.2777, 0.1776, 0.2437, 0.1824, 0.1791, 0.1894, 0.2002, 0.2158, 0.2149,
        0.1535, 0.2274, 0.1571, 0.1685, 0.2019, 0.2415, 0.2167, 0.2195, 0.2054,
        0.2521, 0.1496, 0.1557, 0.1385])
net.mlp.net.1.batch_norm.running_var tensor([0.4406, 0.1951, 0.1239, 0.1137, 0.0542, 0.1233, 0.3318, 0.0958, 0.0786,
        0.1343, 0.1413, 0.2027, 0.1496, 0.0689, 0.1068, 0.2420, 0.1544, 0.1308,
        0.0985, 0.1847, 0.1026, 0.0720, 0.0658, 0.1114, 0.4046, 0.6311, 0.0589,
        0.0748, 0.2676, 0.1030, 0.0657, 0.1144, 0.0979, 0.0859, 0.0737, 0.0680,
        0.1183, 0.0928, 0.1735, 0.0965, 0.0999, 0.2910, 0.1128, 0.0462, 0.1161,
        0.0997, 0.0872, 0.1182, 0.0873, 0.0961, 0.0649, 0.0993, 0.1770, 0.1409,
        0.1404, 0.0666, 0.1039, 0.1804, 0.0754, 0.0568, 0.3177, 0.0837, 0.1104,
        0.0958, 0.0670, 0.3749, 0.0925, 0.0629, 0.0642, 0.1731, 0.0792, 0.0883,
        0.1069, 0.0825, 0.0840, 0.1201, 0.0909, 0.0782, 0.1261, 0.1489, 0.1529,
        0.0797, 0.0903, 0.1315, 0.0492, 0.1227, 0.1175, 0.0687, 0.0802, 0.0928,
        0.0680, 0.0459, 0.1345, 0.0836, 0.0618, 0.0727, 0.0956, 0.0727, 0.1114,
        0.5264, 0.0786, 0.0596, 0.1320, 0.0831, 0.1563, 0.1437, 0.0532, 0.1153,
        0.1010, 0.0809, 0.0585, 0.2262, 0.1448, 0.1357, 0.2790, 0.0994, 0.0477,
        0.1188, 0.0691, 0.0394, 0.2830, 0.1978, 0.0868, 0.1576, 0.1409, 0.2798,
        0.1371, 0.1495, 0.1188, 0.2093, 0.1160, 0.1202, 0.0979, 0.1125, 0.1520,
        0.0634, 0.1717, 0.3832, 0.0750, 0.1848, 0.0926, 0.0720, 0.0578, 0.2989,
        0.1059, 0.2555, 0.1707, 0.2263, 0.1218, 0.1965, 0.0398, 0.1287, 0.0610,
        0.1279, 0.1214, 0.2150, 0.2563, 0.1071, 0.0994, 0.0975, 0.0543, 0.0884,
        0.1460, 0.0771, 0.0954, 0.0845, 0.3672, 0.0886, 0.1269, 0.0792, 0.1223,
        0.1001, 0.0786, 0.3002, 0.0581, 0.1732, 0.0923, 0.6217, 0.2406, 0.0871,
        0.1165, 0.0709, 0.0962, 0.3347, 0.2959, 0.1449, 0.3047, 0.0719, 0.1080,
        0.0692, 0.1172, 0.0838, 0.4241, 0.0988, 0.6039, 0.1122, 0.1324, 0.1282,
        0.2028, 0.1073, 0.0965, 0.0551, 0.0909, 0.2103, 0.1357, 0.1234, 0.1259,
        0.1455, 0.0917, 0.0790, 0.0884, 0.1102, 0.2596, 0.1020, 0.2667, 0.0705,
        0.0824, 0.1127, 0.0845, 0.0726, 0.4307, 0.1072, 0.0749, 0.1142, 0.1225,
        0.1420, 0.0578, 0.0410, 0.0486, 0.3021, 0.0813, 0.0659, 0.3192, 0.2069,
        0.3793, 0.1157, 0.1072, 0.0904, 0.1655, 0.0777, 0.0990, 0.0954, 0.1290,
        0.0708, 0.1328, 0.0783, 0.1646, 0.0947, 0.0920, 0.1536, 0.1037, 0.1165,
        0.5215, 0.1522, 0.1094, 0.0925])
net.mlp.net.1.batch_norm.num_batches_tracked tensor(63)
net.mlp.net.2.linear.weight tensor([[ 0.0199,  0.0433, -0.0141,  ...,  0.0407, -0.0971,  0.0113],
        [ 0.0388, -0.0425,  0.0186,  ..., -0.0295, -0.0045,  0.0213],
        [-0.0233, -0.0051,  0.0040,  ...,  0.0535,  0.0284, -0.0604],
        ...,
        [ 0.0448, -0.0165,  0.0403,  ...,  0.0317, -0.0284, -0.0182],
        [-0.0258, -0.0801,  0.0190,  ...,  0.0284,  0.0219, -0.0240],
        [ 0.0327,  0.0233,  0.0090,  ...,  0.0093,  0.0243,  0.0327]])
net.mlp.net.2.linear.bias tensor([-0.0426, -0.0104,  0.0064, -0.0222, -0.0258, -0.0172, -0.0183,  0.0671,
        -0.0342, -0.0182,  0.0275,  0.0401,  0.0630, -0.0265, -0.0251, -0.0155,
         0.0650,  0.0452, -0.0020, -0.0130, -0.0428,  0.0051,  0.0342,  0.0153,
        -0.0268,  0.0596,  0.0487,  0.0338,  0.0306, -0.0146, -0.0024, -0.0169,
         0.0465, -0.0095,  0.0510, -0.0521,  0.0360, -0.0018, -0.0058, -0.0054,
         0.0039, -0.0863,  0.0016,  0.0296,  0.0030,  0.0075,  0.0045,  0.0195,
        -0.0392,  0.0290,  0.0282, -0.0709,  0.0037, -0.0031, -0.0437, -0.0145,
        -0.0362,  0.0051, -0.0282,  0.0086, -0.0330, -0.0279, -0.0141,  0.0655,
         0.0793,  0.0058,  0.0440, -0.0059, -0.0737, -0.0008, -0.0179, -0.0281,
        -0.0377,  0.0011, -0.0448,  0.0340, -0.0294, -0.0530,  0.0331,  0.0070,
         0.0045,  0.0096, -0.0248, -0.0509,  0.0138,  0.0017, -0.0303, -0.0479,
         0.0230,  0.0085, -0.0301,  0.0317,  0.0033,  0.0108,  0.0031,  0.0109,
        -0.0047,  0.0259,  0.0260,  0.0554, -0.0464,  0.0136, -0.0202, -0.0188,
        -0.0173,  0.0853, -0.0228, -0.0223, -0.0463,  0.0301,  0.0349,  0.0588,
         0.0663,  0.0115, -0.0310,  0.0086,  0.0271,  0.0053, -0.0381, -0.0523,
        -0.0241, -0.0024,  0.0127, -0.0592,  0.0119, -0.0474, -0.0168,  0.0057,
        -0.0256,  0.0170, -0.0337,  0.0127, -0.0386, -0.0501,  0.0043, -0.0636,
         0.0116, -0.0229,  0.0073,  0.0306, -0.0102, -0.0314, -0.0307,  0.0417,
        -0.0097,  0.0391,  0.0366,  0.0222,  0.0371,  0.0089,  0.0525,  0.0266,
         0.0316, -0.0567,  0.0676, -0.0575,  0.0249,  0.0130,  0.0116, -0.0097,
         0.0456, -0.0666,  0.0211,  0.0145, -0.0206,  0.0046,  0.0090, -0.0013,
         0.0081,  0.0336, -0.0318, -0.0261,  0.0019, -0.0361,  0.0372, -0.0177,
        -0.0232, -0.0023,  0.0165, -0.0021,  0.0307,  0.0008,  0.0491, -0.0399,
         0.0133,  0.0521, -0.0180,  0.0402,  0.0290, -0.0184, -0.0381, -0.0290,
        -0.0804, -0.0159, -0.0186, -0.0323,  0.0151,  0.0175, -0.0412, -0.0492,
         0.0243, -0.0921, -0.0243, -0.0145,  0.0725,  0.0239,  0.0164,  0.0414,
        -0.0710, -0.0662,  0.0375,  0.0278,  0.0306, -0.0678,  0.0670, -0.0153,
         0.0557, -0.0137, -0.0111, -0.0620,  0.0103, -0.0042, -0.0112, -0.0061,
        -0.0068, -0.0309, -0.0073,  0.0028, -0.0091, -0.0041,  0.0063, -0.0122,
        -0.0199,  0.0127,  0.0290, -0.0238,  0.0180, -0.0134,  0.0607, -0.0070,
         0.0010,  0.0686,  0.0162, -0.0070, -0.0473, -0.0351, -0.0095, -0.0184,
         0.0023, -0.0044, -0.0359,  0.0071, -0.0351, -0.0304, -0.0251, -0.0122])
net.mlp.net.2.batch_norm.weight tensor([0.3944, 0.3209, 0.3862, 0.3547, 0.3458, 0.2908, 0.2865, 0.3314, 0.3021,
        0.3295, 0.3389, 0.2838, 0.3244, 0.3271, 0.3128, 0.3224, 0.3805, 0.3206,
        0.3146, 0.3378, 0.2837, 0.3350, 0.3520, 0.3118, 0.3414, 0.3303, 0.3070,
        0.3627, 0.3930, 0.2924, 0.3776, 0.3219, 0.2917, 0.3685, 0.2516, 0.3319,
        0.3088, 0.3427, 0.3312, 0.3147, 0.3210, 0.2994, 0.3163, 0.3618, 0.3201,
        0.3253, 0.2921, 0.2994, 0.3342, 0.3684, 0.3470, 0.3322, 0.3468, 0.3222,
        0.3067, 0.3097, 0.3650, 0.3036, 0.3529, 0.3366, 0.3610, 0.3359, 0.3645,
        0.3545, 0.3467, 0.2966, 0.2590, 0.3162, 0.3300, 0.3649, 0.3068, 0.3540,
        0.3360, 0.3415, 0.3045, 0.3712, 0.3634, 0.4077, 0.3103, 0.3291, 0.3477,
        0.4009, 0.3451, 0.3151, 0.3369, 0.3559, 0.3484, 0.3045, 0.3214, 0.3164,
        0.3450, 0.3321, 0.2792, 0.3820, 0.3235, 0.2951, 0.3331, 0.3419, 0.3754,
        0.3678, 0.3412, 0.3566, 0.3158, 0.3377, 0.3376, 0.3122, 0.3624, 0.3156,
        0.3274, 0.3501, 0.2712, 0.3443, 0.3423, 0.3459, 0.3217, 0.3196, 0.3143,
        0.3263, 0.3127, 0.3312, 0.2897, 0.3779, 0.3547, 0.3449, 0.3103, 0.3348,
        0.3329, 0.3988, 0.3220, 0.3147, 0.3503, 0.3438, 0.3381, 0.3284, 0.3356,
        0.3121, 0.3081, 0.3516, 0.3204, 0.2900, 0.3589, 0.3146, 0.3334, 0.3643,
        0.3280, 0.3526, 0.3623, 0.3422, 0.2927, 0.3388, 0.3268, 0.3288, 0.3330,
        0.3467, 0.3195, 0.3976, 0.3581, 0.2978, 0.3589, 0.3159, 0.3476, 0.3372,
        0.3704, 0.3608, 0.3708, 0.3541, 0.3271, 0.3866, 0.3751, 0.3096, 0.3312,
        0.3248, 0.3622, 0.3444, 0.3808, 0.3128, 0.3097, 0.3710, 0.3386, 0.3153,
        0.3850, 0.3080, 0.3951, 0.3573, 0.3445, 0.3368, 0.3903, 0.3306, 0.3681,
        0.3809, 0.3465, 0.3069, 0.3235, 0.3070, 0.3202, 0.3343, 0.3549, 0.3819,
        0.3182, 0.3620, 0.3123, 0.3471, 0.3358, 0.3359, 0.3653, 0.3800, 0.3314,
        0.3308, 0.3503, 0.3839, 0.3233, 0.3151, 0.3441, 0.3688, 0.4032, 0.3208,
        0.3571, 0.3170, 0.2731, 0.3212, 0.3194, 0.3415, 0.2671, 0.3479, 0.3361,
        0.3282, 0.3594, 0.3069, 0.2881, 0.3719, 0.3531, 0.3451, 0.2810, 0.3508,
        0.3676, 0.3314, 0.3782, 0.3391, 0.3556, 0.3234, 0.3151, 0.3641, 0.3236,
        0.3157, 0.3828, 0.3470, 0.3752, 0.3367, 0.3188, 0.3808, 0.3637, 0.3235,
        0.3384, 0.3189, 0.3024, 0.3433])
net.mlp.net.2.batch_norm.bias tensor([-1.2663e-02,  1.9098e-02, -4.6692e-02,  5.7226e-02,  1.2837e-02,
        -1.3254e-02,  2.1546e-02, -3.6015e-02,  2.5005e-02, -2.0124e-02,
         6.6044e-02, -3.6223e-02,  1.8230e-02,  1.2338e-02,  1.4119e-02,
        -3.2384e-02, -4.8812e-02,  2.1146e-03,  1.8373e-02,  1.3998e-02,
         4.6455e-02,  6.8613e-03, -4.5501e-02, -6.4803e-03,  2.2289e-02,
        -5.4400e-02, -1.7883e-02,  1.5799e-02, -2.6477e-02, -2.6125e-02,
        -2.6495e-02,  7.0791e-02,  7.5870e-04, -2.5995e-04,  1.1971e-02,
        -1.0312e-02,  2.1476e-02, -1.5290e-03, -1.8668e-02,  2.7406e-02,
        -1.0526e-02,  1.8141e-03,  1.0907e-02, -6.5111e-03, -1.5324e-02,
        -4.4711e-03, -2.6737e-03,  3.0648e-02,  7.8859e-03,  4.2448e-02,
        -4.4920e-03,  5.5743e-03, -1.8243e-02, -4.0970e-02, -9.0728e-04,
         4.0428e-02, -9.7262e-03, -1.0798e-02, -2.5193e-02, -1.6676e-02,
        -9.0794e-03, -2.3699e-02,  2.5194e-02, -3.8052e-02,  8.8475e-02,
        -2.6286e-02, -3.3616e-02, -2.0267e-03, -6.4434e-03, -1.9632e-02,
         4.8102e-03, -8.9768e-03, -7.4675e-02, -2.4598e-02,  2.9472e-02,
         5.5263e-03, -1.3642e-02, -4.3675e-02, -8.3998e-03, -1.9826e-03,
         2.4366e-02,  3.6355e-02, -7.6903e-03, -4.0442e-02,  4.6277e-03,
         7.8723e-03,  4.0990e-02,  1.9866e-02, -7.1899e-02,  1.7434e-02,
        -5.8604e-03, -2.7888e-02, -1.9699e-03, -8.4429e-03,  3.1374e-02,
        -2.1671e-03, -2.2993e-02, -3.0777e-02, -8.4380e-03, -4.4915e-03,
        -1.8951e-02,  2.0476e-02,  5.4474e-04,  1.1334e-02,  2.2320e-02,
        -1.8357e-02, -4.3335e-02, -4.5645e-04, -5.6592e-02, -2.7607e-03,
         1.3331e-02, -1.2136e-02, -5.5710e-02, -1.9428e-02,  2.3132e-02,
         1.2074e-02, -2.6326e-02,  2.7021e-02,  1.8192e-02, -5.5072e-02,
         1.5722e-02,  8.8124e-03, -2.5147e-02, -8.6768e-02, -2.1668e-02,
         9.7010e-03,  1.0262e-02,  2.8699e-02, -2.6022e-02,  7.7849e-03,
         3.9693e-03,  6.4410e-02, -3.0709e-02, -1.9981e-02, -1.2808e-02,
         4.1235e-02,  2.6729e-02, -2.1700e-02,  1.9203e-02, -1.7910e-02,
        -6.7448e-02, -1.7506e-03,  2.0592e-02,  1.3546e-02,  1.5253e-02,
        -2.2869e-02, -2.4865e-02, -1.0667e-02, -1.4758e-02, -6.5931e-02,
         1.3091e-02, -2.2957e-02,  7.6353e-03, -6.6862e-05,  4.7413e-02,
        -4.0787e-02, -4.7753e-02,  4.1001e-02,  2.3494e-02, -7.8117e-03,
        -4.8541e-02,  3.3680e-02,  4.6483e-02,  4.5846e-03,  1.7126e-02,
        -5.0467e-02,  5.7481e-03, -1.1779e-02,  7.8871e-03, -2.6095e-02,
         1.8665e-02, -8.2085e-02,  5.1883e-04,  3.2285e-02,  1.9981e-02,
        -2.6849e-02, -4.4724e-03, -4.2893e-02,  7.3370e-03, -2.5578e-02,
        -5.5382e-02,  2.6955e-02,  7.4457e-03,  2.1178e-02, -3.8811e-02,
         3.9867e-02, -4.7833e-03, -8.1429e-03,  5.1202e-02, -5.3226e-02,
        -8.4064e-03, -3.1210e-02,  6.2988e-03, -1.9982e-02, -3.0767e-02,
         1.3806e-02,  3.6035e-02, -3.0676e-02,  4.4847e-03, -2.4323e-02,
         5.7151e-02, -3.6414e-03, -2.9919e-03,  3.2938e-02, -4.2872e-02,
         2.2436e-02, -1.6218e-02, -3.8818e-02, -6.5733e-02, -6.0165e-03,
         2.7859e-02,  2.1285e-02,  2.2140e-02, -5.7815e-02,  2.6286e-02,
        -5.8613e-03,  4.5434e-02, -3.1416e-02,  2.9835e-02, -1.2300e-02,
        -2.3712e-02,  1.3579e-02,  3.3985e-02,  7.4278e-03,  4.8608e-02,
        -2.7651e-02, -5.0489e-02,  2.8854e-02,  8.3049e-03, -1.9824e-02,
         3.6014e-04, -1.3672e-02, -7.2951e-03,  1.8245e-02, -1.7651e-03,
         1.6549e-02, -2.1971e-02,  2.7745e-03, -1.4764e-02, -3.0895e-02,
         1.1957e-02,  4.1355e-02,  1.4437e-03, -2.4335e-02, -6.8963e-04,
        -5.6519e-03, -2.2308e-02, -2.3047e-02, -3.0507e-02,  3.4272e-02,
         6.2109e-03, -2.6067e-02, -1.4305e-02, -3.8041e-03, -4.2721e-02,
        -2.7690e-02])
net.mlp.net.2.batch_norm.running_mean tensor([0.1857, 0.1652, 0.2288, 0.2338, 0.1508, 0.2284, 0.1508, 0.2054, 0.1940,
        0.1618, 0.1870, 0.2118, 0.1654, 0.1690, 0.1801, 0.1156, 0.2221, 0.2636,
        0.2232, 0.1704, 0.1670, 0.1576, 0.3297, 0.2201, 0.1660, 0.2997, 0.2546,
        0.2432, 0.1599, 0.1672, 0.2450, 0.1421, 0.2119, 0.2362, 0.2242, 0.1926,
        0.2456, 0.2284, 0.2064, 0.1301, 0.1466, 0.1343, 0.2019, 0.2771, 0.2204,
        0.1926, 0.1919, 0.1813, 0.2544, 0.2231, 0.2642, 0.1863, 0.2163, 0.2038,
        0.1585, 0.1686, 0.2342, 0.1526, 0.2008, 0.1845, 0.2424, 0.1408, 0.2795,
        0.3148, 0.3009, 0.1466, 0.1572, 0.1082, 0.1333, 0.2405, 0.1724, 0.2073,
        0.1490, 0.1908, 0.1351, 0.2776, 0.1720, 0.2219, 0.2203, 0.1857, 0.2090,
        0.3138, 0.1726, 0.1828, 0.2408, 0.2394, 0.1578, 0.1383, 0.2751, 0.1633,
        0.1603, 0.2607, 0.1893, 0.2370, 0.2408, 0.2266, 0.1832, 0.1839, 0.2162,
        0.2083, 0.1354, 0.2455, 0.1630, 0.1403, 0.2114, 0.1936, 0.1481, 0.1482,
        0.1364, 0.2443, 0.2619, 0.2238, 0.1942, 0.2186, 0.2150, 0.1712, 0.1863,
        0.2205, 0.2063, 0.1340, 0.2177, 0.2026, 0.2723, 0.1954, 0.2396, 0.1390,
        0.2234, 0.2407, 0.1806, 0.2013, 0.1839, 0.2830, 0.1823, 0.2410, 0.1561,
        0.0963, 0.1810, 0.1987, 0.1980, 0.1661, 0.2146, 0.2486, 0.2530, 0.2278,
        0.1999, 0.2803, 0.3363, 0.2210, 0.1838, 0.2173, 0.2712, 0.2075, 0.3034,
        0.2733, 0.2514, 0.1982, 0.2544, 0.1894, 0.2094, 0.1643, 0.2655, 0.1641,
        0.1849, 0.3096, 0.2529, 0.2117, 0.2269, 0.2631, 0.1547, 0.2353, 0.1631,
        0.1326, 0.2565, 0.1579, 0.2897, 0.1938, 0.1936, 0.2210, 0.2233, 0.1893,
        0.3065, 0.2136, 0.2972, 0.1967, 0.1911, 0.3412, 0.2148, 0.2374, 0.2687,
        0.2514, 0.1600, 0.1767, 0.1614, 0.2080, 0.2594, 0.1664, 0.2084, 0.2867,
        0.1295, 0.1626, 0.2032, 0.1248, 0.1529, 0.2105, 0.2934, 0.2197, 0.1929,
        0.2973, 0.2606, 0.1936, 0.1901, 0.1995, 0.2146, 0.1640, 0.2699, 0.1275,
        0.2855, 0.1452, 0.2012, 0.1519, 0.1295, 0.2098, 0.2145, 0.2018, 0.2313,
        0.1918, 0.2075, 0.2489, 0.2136, 0.1912, 0.2265, 0.2729, 0.1377, 0.2379,
        0.2954, 0.1650, 0.3011, 0.2383, 0.2100, 0.1653, 0.1633, 0.2873, 0.1388,
        0.1936, 0.1573, 0.1834, 0.2582, 0.2200, 0.1964, 0.2661, 0.1613, 0.2071,
        0.2228, 0.1397, 0.1224, 0.2103])
net.mlp.net.2.batch_norm.running_var tensor([0.0705, 0.1049, 0.2141, 0.2330, 0.0878, 0.1665, 0.0843, 0.1068, 0.1612,
        0.1343, 0.0709, 0.1365, 0.0692, 0.3742, 0.2997, 0.1019, 0.1006, 0.0824,
        0.1341, 0.0830, 0.0981, 0.1093, 0.3349, 0.0912, 0.0670, 0.2593, 0.1365,
        0.1515, 0.0735, 0.2297, 0.1587, 0.0775, 0.0765, 0.1750, 0.0778, 0.1013,
        0.0896, 0.3370, 0.0695, 0.0811, 0.1258, 0.2266, 0.2479, 0.1941, 0.1192,
        0.0685, 0.0696, 0.0968, 0.1735, 0.1010, 0.1953, 0.2607, 0.0879, 0.0883,
        0.2963, 0.0704, 0.1242, 0.0628, 0.1075, 0.0836, 0.2036, 0.0495, 0.1883,
        0.2799, 0.1466, 0.0944, 0.1889, 0.0388, 0.0885, 0.1766, 0.0584, 0.2345,
        0.1982, 0.1229, 0.1562, 0.2390, 0.1152, 0.1319, 0.0870, 0.1060, 0.1780,
        0.2497, 0.1563, 0.2642, 0.1404, 0.1076, 0.0706, 0.1260, 0.1875, 0.0765,
        0.0744, 0.1563, 0.1757, 0.1873, 0.2364, 0.2367, 0.1706, 0.2740, 0.2185,
        0.1243, 0.1129, 0.2382, 0.3145, 0.0454, 0.2814, 0.0794, 0.1432, 0.0943,
        0.0552, 0.0831, 0.1068, 0.0656, 0.0786, 0.1370, 0.0953, 0.0913, 0.0559,
        0.1304, 0.0911, 0.1914, 0.1658, 0.0712, 0.2426, 0.4487, 0.1210, 0.0659,
        0.1329, 0.3028, 0.0754, 0.0893, 0.1152, 0.2246, 0.1788, 0.3016, 0.2525,
        0.0799, 0.0636, 0.3823, 0.0844, 0.0940, 0.1174, 0.1217, 0.1560, 0.1230,
        0.0979, 0.1149, 0.2592, 0.0912, 0.0499, 0.1444, 0.1809, 0.2625, 0.3393,
        0.2193, 0.0967, 0.1758, 0.2467, 0.0810, 0.2149, 0.0466, 0.0909, 0.1405,
        0.1466, 0.2883, 0.1805, 0.3326, 0.3052, 0.1421, 0.0619, 0.0968, 0.0845,
        0.1485, 0.1917, 0.2312, 0.1561, 0.3124, 0.2810, 0.0983, 0.1566, 0.0666,
        0.2817, 0.3882, 0.1474, 0.1674, 0.1243, 0.1987, 0.1271, 0.1098, 0.1542,
        0.2812, 0.0798, 0.1091, 0.0749, 0.1715, 0.1826, 0.0870, 0.1183, 0.2878,
        0.0829, 0.1538, 0.0800, 0.0535, 0.1678, 0.1179, 0.2836, 0.2725, 0.1726,
        0.1869, 0.2354, 0.0839, 0.0812, 0.0826, 0.1513, 0.1169, 0.1782, 0.0517,
        0.2526, 0.0661, 0.0888, 0.0564, 0.0585, 0.1156, 0.0818, 0.1758, 0.1495,
        0.2352, 0.1378, 0.1750, 0.0983, 0.1082, 0.1216, 0.3025, 0.0383, 0.1470,
        0.1855, 0.3151, 0.3703, 0.2058, 0.0728, 0.1657, 0.0818, 0.1313, 0.0503,
        0.2160, 0.1407, 0.1581, 0.1982, 0.1235, 0.0747, 0.1251, 0.3645, 0.4058,
        0.4627, 0.2700, 0.0520, 0.1681])
net.mlp.net.2.batch_norm.num_batches_tracked tensor(63)
net.mlp.net.3.linear.weight tensor([[ 0.0212,  0.0149,  0.0308,  ..., -0.0447, -0.0158, -0.0268],
        [ 0.0279,  0.0272, -0.0171,  ..., -0.0166,  0.0126, -0.0260],
        [ 0.0273,  0.0355, -0.0097,  ..., -0.0182,  0.0233,  0.0318],
        ...,
        [ 0.0590,  0.0125, -0.0186,  ..., -0.0563, -0.0174,  0.0125],
        [ 0.0177,  0.0246,  0.0792,  ..., -0.0048,  0.0571,  0.0435],
        [ 0.0511,  0.0839,  0.0021,  ...,  0.0603, -0.0686, -0.0046]])
net.mlp.net.3.linear.bias tensor([-3.1043e-02,  1.0750e-04, -1.2229e-02, -2.6353e-02, -4.2297e-02,
         5.8098e-02, -2.1971e-02,  6.3427e-03,  9.3117e-03, -3.6830e-03,
        -3.3564e-02,  6.0286e-02,  7.7905e-03, -1.3384e-02,  1.5570e-02,
        -1.6020e-02, -3.9324e-02, -2.8130e-02,  3.1680e-02, -4.7604e-04,
        -4.7432e-02,  1.0154e-02, -4.7209e-05, -6.9297e-02,  4.5581e-02,
        -5.7771e-02,  5.7497e-02, -6.6069e-02, -3.3874e-02,  7.7318e-02,
        -2.3344e-02, -2.0918e-02, -2.7519e-02,  9.7568e-03,  3.8624e-03,
         1.2547e-02,  3.7405e-02,  9.3108e-03,  5.9590e-02, -1.3681e-02,
        -2.3111e-02,  1.1119e-03,  2.0781e-02,  5.0384e-02, -1.1882e-04,
        -5.6365e-03, -6.0071e-02, -2.1347e-02, -5.8543e-02,  3.0282e-02,
        -2.5123e-02, -2.7569e-02, -6.9757e-03,  1.4243e-02,  1.9573e-02,
        -6.3325e-02,  4.0332e-03,  4.2468e-03,  3.1008e-02, -4.2627e-03,
        -2.2826e-02, -1.3755e-02, -1.5350e-02,  4.7189e-02, -1.3786e-02,
         5.7668e-02, -7.7864e-03, -2.8445e-03, -5.7764e-02,  1.2370e-02,
        -4.2387e-02, -4.0125e-02,  4.6350e-02,  3.0594e-02, -1.8368e-02,
        -1.6793e-02,  2.8431e-02,  7.3276e-03,  8.2438e-03,  2.8253e-03,
        -6.7355e-02, -7.1557e-02,  1.4545e-02,  1.1745e-02, -5.5883e-03,
         5.5991e-02,  2.9632e-02,  2.7558e-02, -3.1077e-02, -3.9741e-03,
         1.6546e-02, -3.2290e-02, -3.3924e-02, -1.0267e-01, -4.5352e-02,
         3.3298e-02,  1.5706e-02, -1.7375e-02,  3.0605e-02, -2.6219e-02,
        -1.0150e-02,  2.3943e-02, -7.4383e-03, -3.2589e-03, -5.4425e-03,
        -9.2251e-03, -5.8489e-02,  3.5496e-02, -1.1868e-02,  4.8090e-02,
        -3.3333e-02, -3.8884e-03,  8.6159e-03,  3.7797e-04,  2.3372e-02,
        -4.6161e-02, -5.8412e-02,  6.0589e-02,  4.7481e-02,  1.3046e-02,
         4.7974e-02, -2.3584e-02,  6.2878e-02, -9.2829e-03, -2.6984e-02,
        -1.0076e-01, -3.2367e-02, -2.7423e-02,  3.6584e-02,  4.3299e-02,
        -6.9054e-02, -1.9256e-02,  3.7927e-02,  1.7480e-02,  4.9516e-02,
        -3.4635e-03, -3.3916e-02,  3.6782e-02,  2.4451e-02,  1.3716e-02,
        -5.3028e-02, -6.1227e-03, -2.2234e-02,  4.2741e-03, -3.2297e-02,
         1.6594e-03,  3.8093e-03,  3.5035e-02,  3.4720e-03, -5.4969e-03,
        -4.4420e-02, -1.3481e-02,  1.8693e-02, -1.8546e-02,  9.8690e-03,
        -5.3909e-02, -7.3331e-03, -7.3231e-03, -2.6681e-02, -6.9475e-02,
        -2.8306e-02, -4.2600e-02, -1.2390e-02, -3.0958e-02, -2.4474e-02,
        -2.7900e-02, -7.2127e-02,  1.0611e-02,  2.0097e-02,  8.4003e-03,
        -7.9048e-03,  1.2927e-02, -3.9202e-02,  1.4310e-02,  2.8294e-02,
         8.1348e-03, -3.0844e-03, -3.0333e-02,  3.8655e-02, -5.4155e-02,
         1.6952e-02,  1.2060e-02,  1.9647e-02,  3.7425e-03, -1.4663e-02,
        -2.6839e-02,  3.9064e-04, -4.1181e-02,  4.3077e-02,  4.6596e-03,
        -2.6506e-03, -2.7851e-04, -2.3742e-02, -4.8892e-02,  2.2549e-02,
        -3.3621e-02, -2.3395e-02,  2.9780e-02,  1.8623e-02, -3.7730e-03,
        -5.5295e-03,  9.0389e-02, -4.5037e-02,  3.5474e-02,  2.1398e-03,
         1.5437e-02,  6.3477e-02, -4.4660e-02,  1.1082e-02, -8.2185e-02,
        -2.5379e-02, -6.8618e-03, -3.1384e-02, -2.2602e-02, -7.3537e-02,
        -2.7741e-02,  3.2199e-02,  4.7101e-02, -2.8535e-02,  4.4380e-02,
         5.8869e-02, -3.2112e-02, -1.7685e-02, -4.1307e-03,  5.2671e-03,
         1.9772e-02,  4.8690e-02, -6.1498e-02,  2.1956e-02,  2.3489e-03,
         1.5186e-02,  3.5910e-03,  1.2981e-02, -1.3648e-03, -4.5465e-03,
        -3.5806e-03,  7.9238e-03, -2.6256e-02,  1.6967e-02,  4.9964e-03,
        -1.0294e-02, -5.5306e-02,  4.8045e-02,  3.2066e-02, -1.1694e-02,
         1.7522e-02, -1.9317e-02, -2.5266e-02, -4.2445e-02, -9.1035e-02,
         3.4930e-02, -9.4075e-03,  2.4813e-02, -5.4264e-03,  4.4237e-02,
         6.3347e-02])
net.mlp.net.3.batch_norm.weight tensor([0.3070, 0.2916, 0.2942, 0.3698, 0.3600, 0.3118, 0.2795, 0.3328, 0.3070,
        0.2996, 0.3222, 0.3489, 0.2461, 0.3136, 0.3332, 0.3077, 0.2917, 0.3145,
        0.3292, 0.3052, 0.3515, 0.3314, 0.3344, 0.2686, 0.3363, 0.3221, 0.3070,
        0.3070, 0.3312, 0.3179, 0.3635, 0.2742, 0.2873, 0.2868, 0.3179, 0.3009,
        0.3327, 0.3019, 0.3397, 0.3089, 0.3436, 0.2930, 0.3411, 0.2958, 0.3385,
        0.2985, 0.2926, 0.3066, 0.3035, 0.3643, 0.3105, 0.3099, 0.3369, 0.3036,
        0.3260, 0.2835, 0.3035, 0.3287, 0.3306, 0.3125, 0.3057, 0.2883, 0.3446,
        0.3083, 0.3144, 0.3130, 0.3108, 0.3376, 0.2904, 0.3748, 0.2992, 0.3071,
        0.2941, 0.3330, 0.2978, 0.3132, 0.3706, 0.3138, 0.3433, 0.3661, 0.3217,
        0.3300, 0.3493, 0.3265, 0.2945, 0.3134, 0.3477, 0.3446, 0.2856, 0.3513,
        0.3482, 0.2590, 0.3198, 0.3048, 0.3023, 0.2875, 0.3503, 0.2825, 0.3262,
        0.3358, 0.3045, 0.3106, 0.2988, 0.2816, 0.3428, 0.3169, 0.3005, 0.3553,
        0.3430, 0.3662, 0.3285, 0.2899, 0.3000, 0.3016, 0.3331, 0.3116, 0.3222,
        0.3538, 0.2960, 0.3587, 0.3470, 0.3127, 0.3472, 0.3284, 0.3152, 0.3092,
        0.2813, 0.3242, 0.3158, 0.3329, 0.2763, 0.2724, 0.3057, 0.3558, 0.3549,
        0.2770, 0.3022, 0.3045, 0.3388, 0.2753, 0.3111, 0.3118, 0.2911, 0.3037,
        0.3273, 0.3040, 0.3682, 0.3120, 0.3027, 0.2890, 0.3177, 0.2947, 0.2767,
        0.2816, 0.3179, 0.3290, 0.3219, 0.3379, 0.3034, 0.3007, 0.3081, 0.3450,
        0.3078, 0.3491, 0.3253, 0.3003, 0.2311, 0.3034, 0.3371, 0.2903, 0.3064,
        0.3053, 0.2883, 0.3168, 0.2800, 0.3329, 0.3255, 0.3199, 0.3040, 0.2978,
        0.3426, 0.3186, 0.3126, 0.2775, 0.2699, 0.2814, 0.2974, 0.3008, 0.3320,
        0.3313, 0.2958, 0.3383, 0.2956, 0.3243, 0.3227, 0.3296, 0.2846, 0.3092,
        0.2933, 0.3455, 0.2681, 0.3306, 0.2629, 0.3098, 0.3130, 0.3176, 0.3246,
        0.2833, 0.3609, 0.2987, 0.3990, 0.3245, 0.2997, 0.3038, 0.3177, 0.3255,
        0.3224, 0.3330, 0.3138, 0.3444, 0.3581, 0.3132, 0.3185, 0.3193, 0.3119,
        0.3430, 0.3547, 0.2688, 0.3471, 0.3113, 0.2986, 0.3358, 0.2848, 0.2879,
        0.3549, 0.3355, 0.3515, 0.3171, 0.3149, 0.3423, 0.2915, 0.3170, 0.3516,
        0.3055, 0.2914, 0.3153, 0.2857, 0.3433, 0.3686, 0.3140, 0.3723, 0.3543,
        0.3232, 0.3110, 0.3361, 0.3324])
net.mlp.net.3.batch_norm.bias tensor([-0.0315,  0.0054, -0.0241, -0.0679,  0.0170,  0.0157,  0.0480, -0.0563,
        -0.0171,  0.0089,  0.0144,  0.0179, -0.0257, -0.0069,  0.0116,  0.0161,
        -0.0584, -0.0068,  0.0096,  0.0493, -0.0711, -0.0342, -0.0324,  0.0384,
        -0.0367,  0.0208, -0.0674,  0.0040,  0.0446,  0.1006, -0.0270, -0.0134,
         0.0289,  0.0410, -0.0060,  0.0151,  0.0114,  0.0324,  0.0475, -0.0562,
        -0.0127,  0.0053, -0.0434, -0.0257, -0.0235, -0.0361, -0.0172,  0.0631,
         0.0031,  0.0013,  0.0343, -0.0332, -0.0329,  0.0122, -0.0327,  0.0301,
        -0.0282,  0.0063,  0.0113,  0.0968,  0.0631,  0.0065, -0.0558,  0.0154,
        -0.0031,  0.0124, -0.0114, -0.0593, -0.0679,  0.0274, -0.0253, -0.0067,
        -0.0060,  0.0017, -0.0421,  0.0225, -0.0135, -0.0295,  0.0552, -0.0338,
        -0.0234, -0.0062, -0.0173, -0.0466, -0.0258,  0.0337,  0.0721, -0.0121,
        -0.0148,  0.0286,  0.0252,  0.0281,  0.0127,  0.0585,  0.0134, -0.0349,
        -0.0235,  0.0636,  0.0176,  0.0191,  0.0022,  0.0093, -0.0062, -0.0078,
        -0.0020,  0.0428,  0.0280,  0.0059, -0.0386, -0.0547, -0.0223,  0.0113,
        -0.0271,  0.0331,  0.0507,  0.0710,  0.0100,  0.0348, -0.0139, -0.0309,
        -0.0147, -0.0674, -0.0209, -0.0608,  0.0150,  0.0066,  0.0199, -0.0135,
         0.0070,  0.0199,  0.0131,  0.0014,  0.0532, -0.0398, -0.0216,  0.0170,
         0.0320,  0.0208,  0.0733, -0.0015, -0.0527,  0.0212, -0.0389, -0.0327,
        -0.0329,  0.0126,  0.0029,  0.0031, -0.0059,  0.0016,  0.0309, -0.0042,
         0.0105,  0.0174, -0.0469,  0.0287, -0.0002,  0.0491,  0.0411,  0.0871,
        -0.0312, -0.0106, -0.0307, -0.0295, -0.0259, -0.0005,  0.0238,  0.0234,
         0.0318,  0.0305,  0.0378, -0.0244,  0.0308, -0.0234,  0.0195, -0.0503,
         0.0388, -0.0159,  0.0871, -0.0029,  0.0053, -0.0086, -0.0019, -0.0227,
        -0.0151,  0.0099, -0.0149,  0.0002,  0.0120, -0.0293,  0.0098, -0.0027,
         0.0240, -0.0090,  0.0218,  0.0145, -0.0026, -0.0521, -0.0309, -0.0863,
         0.0137,  0.0371, -0.1094, -0.0193,  0.0188, -0.0129,  0.0400,  0.0085,
         0.0409,  0.0507, -0.0088, -0.0838, -0.0107, -0.0018,  0.0367,  0.0306,
        -0.0586, -0.0001,  0.0313, -0.0010, -0.0576,  0.0033, -0.0080, -0.0327,
        -0.0483,  0.0424, -0.0057,  0.0520, -0.0185, -0.0353, -0.0309, -0.0596,
         0.0859, -0.0337, -0.0479,  0.0037, -0.0075, -0.0255, -0.0416,  0.0430,
         0.0353, -0.0368, -0.0307,  0.0147,  0.0111,  0.0026, -0.0316, -0.0070,
        -0.0099,  0.0791, -0.0068, -0.0213,  0.0116, -0.0192,  0.0092, -0.0485])
net.mlp.net.3.batch_norm.running_mean tensor([0.2220, 0.1792, 0.1443, 0.2221, 0.1968, 0.3132, 0.1427, 0.2912, 0.2003,
        0.2261, 0.1534, 0.2921, 0.2184, 0.1347, 0.3379, 0.1884, 0.0803, 0.1778,
        0.2956, 0.2172, 0.1479, 0.2965, 0.1983, 0.3143, 0.3024, 0.1220, 0.4133,
        0.0633, 0.3527, 0.3486, 0.2283, 0.1622, 0.2221, 0.2212, 0.2079, 0.2650,
        0.2997, 0.2173, 0.3119, 0.1674, 0.2472, 0.1246, 0.2809, 0.2638, 0.3351,
        0.1096, 0.1722, 0.2656, 0.1613, 0.2773, 0.2165, 0.1117, 0.1774, 0.1639,
        0.3188, 0.1542, 0.1105, 0.2500, 0.2636, 0.2889, 0.1229, 0.1619, 0.2691,
        0.2519, 0.2255, 0.2128, 0.2575, 0.3603, 0.1705, 0.3778, 0.1535, 0.2765,
        0.2839, 0.2081, 0.1599, 0.1835, 0.2891, 0.2055, 0.3300, 0.2718, 0.1647,
        0.1449, 0.3307, 0.2200, 0.2589, 0.2895, 0.2990, 0.2453, 0.1884, 0.2614,
        0.3189, 0.2088, 0.1627, 0.2187, 0.1875, 0.3735, 0.3065, 0.2316, 0.2750,
        0.2435, 0.2916, 0.2068, 0.2151, 0.1848, 0.2380, 0.1786, 0.1103, 0.2316,
        0.2563, 0.3513, 0.2329, 0.1430, 0.1920, 0.2380, 0.2443, 0.1200, 0.1556,
        0.3715, 0.2228, 0.2585, 0.2798, 0.3414, 0.3396, 0.2410, 0.2268, 0.1860,
        0.1839, 0.1473, 0.2244, 0.3672, 0.1346, 0.2168, 0.2719, 0.2975, 0.4060,
        0.3792, 0.1925, 0.2045, 0.3107, 0.2076, 0.1796, 0.1361, 0.2019, 0.2657,
        0.2166, 0.1637, 0.2595, 0.2847, 0.1568, 0.2294, 0.1078, 0.1417, 0.1850,
        0.2253, 0.1860, 0.1913, 0.2772, 0.1904, 0.1898, 0.2489, 0.1667, 0.2462,
        0.2526, 0.3148, 0.1781, 0.1306, 0.2134, 0.1414, 0.3049, 0.2462, 0.1505,
        0.2454, 0.1413, 0.2348, 0.1932, 0.2940, 0.2355, 0.1541, 0.2617, 0.2268,
        0.2101, 0.2813, 0.2167, 0.1855, 0.1990, 0.1708, 0.2141, 0.1850, 0.3545,
        0.2996, 0.1697, 0.2554, 0.1963, 0.1585, 0.2404, 0.2689, 0.2517, 0.2543,
        0.1823, 0.2190, 0.1597, 0.2700, 0.2283, 0.2062, 0.2347, 0.2851, 0.3458,
        0.1484, 0.3499, 0.1707, 0.3304, 0.3765, 0.1968, 0.2172, 0.1388, 0.1845,
        0.2923, 0.2738, 0.1620, 0.2722, 0.3235, 0.3206, 0.2108, 0.1437, 0.1318,
        0.2751, 0.3154, 0.2137, 0.3129, 0.3394, 0.3036, 0.2387, 0.1671, 0.2666,
        0.2701, 0.3434, 0.2543, 0.1900, 0.1993, 0.2720, 0.2805, 0.1925, 0.3518,
        0.3513, 0.2107, 0.2567, 0.1782, 0.2354, 0.2362, 0.1184, 0.3952, 0.2552,
        0.2777, 0.1166, 0.2747, 0.4128])
net.mlp.net.3.batch_norm.running_var tensor([0.1816, 0.0435, 0.2383, 0.1513, 0.3044, 0.2052, 0.2122, 0.3488, 0.0758,
        0.1907, 0.1892, 0.1722, 0.0620, 0.1264, 0.4770, 0.1945, 0.1079, 0.3248,
        0.1936, 0.2414, 0.0716, 0.3281, 0.2246, 0.7757, 0.4291, 0.0940, 0.1591,
        0.0163, 0.2790, 0.2964, 0.1014, 0.0893, 0.5089, 0.0728, 0.0878, 0.1044,
        0.1518, 0.2876, 0.4661, 0.3146, 0.2072, 0.0911, 0.2224, 0.0696, 0.1753,
        0.1242, 0.2748, 0.3007, 0.1624, 0.2322, 0.2358, 0.0499, 0.1053, 0.0641,
        0.1818, 0.3512, 0.0367, 0.2052, 0.2713, 0.2330, 0.0979, 0.2066, 0.3826,
        0.0776, 0.3567, 0.1247, 0.1805, 0.3723, 0.2180, 0.4134, 0.2014, 0.5038,
        0.1406, 0.1812, 0.1460, 0.0916, 0.1844, 0.0693, 0.2484, 0.1801, 0.3915,
        0.1364, 0.3276, 0.1246, 0.3819, 0.2845, 0.2211, 0.3136, 0.0698, 0.2380,
        0.3225, 0.1425, 0.1317, 0.5495, 0.2617, 0.7765, 0.2958, 0.1684, 0.2117,
        0.2241, 0.3930, 0.0551, 0.1201, 0.2413, 0.2323, 0.2590, 0.1279, 0.1507,
        0.3995, 0.2400, 0.2337, 0.1768, 0.2577, 0.2620, 0.1712, 0.1808, 0.0956,
        0.2674, 0.0783, 0.2407, 0.1675, 0.4180, 0.1647, 0.2969, 0.2580, 0.3189,
        0.3876, 0.3404, 0.1810, 0.1978, 0.2728, 0.1941, 0.1480, 0.2819, 0.3456,
        0.4432, 0.1352, 0.1283, 0.2667, 0.0546, 0.3426, 0.0531, 0.1203, 0.1893,
        0.3482, 0.0486, 0.3719, 0.1972, 0.0455, 0.2068, 0.2170, 0.2074, 0.1842,
        0.3706, 0.0972, 0.0925, 0.2965, 0.1261, 0.2444, 0.4024, 0.0964, 0.4329,
        0.4454, 0.3800, 0.2818, 0.0370, 0.1076, 0.0481, 0.2192, 0.1323, 0.1023,
        0.1435, 0.2765, 0.1068, 0.0598, 0.2144, 0.1128, 0.2351, 0.1370, 0.0856,
        0.1452, 0.1334, 0.1435, 0.2409, 0.0646, 0.3006, 0.0794, 0.2062, 0.2306,
        0.2652, 0.1632, 0.1777, 0.4647, 0.1528, 0.2978, 0.4318, 0.1571, 0.1221,
        0.0541, 0.2264, 0.1440, 0.1774, 0.2770, 0.2167, 0.1414, 0.2119, 0.2275,
        0.1819, 0.3692, 0.3284, 0.4762, 0.3066, 0.0948, 0.3453, 0.0580, 0.1069,
        0.1781, 0.1157, 0.2331, 0.1728, 0.3947, 0.2453, 0.4401, 0.1350, 0.2805,
        0.1836, 0.2558, 0.5575, 0.4049, 0.2284, 0.2181, 0.2153, 0.0687, 0.6295,
        0.3321, 0.2022, 0.1150, 0.2333, 0.2058, 0.2218, 0.2729, 0.2858, 0.2770,
        0.3930, 0.1497, 0.2569, 0.3951, 0.4577, 0.2834, 0.0412, 0.2132, 0.5408,
        0.1611, 0.0491, 0.3526, 0.2104])
net.mlp.net.3.batch_norm.num_batches_tracked tensor(63)
net.mlp.net.4.weight tensor([[-0.0167, -0.0027,  0.0023, -0.0529, -0.0347, -0.0134,  0.0050, -0.0213,
          0.0079, -0.0068, -0.0160, -0.0381, -0.0030, -0.0051, -0.0183, -0.0191,
         -0.0040, -0.0088, -0.0202, -0.0037,  0.0419, -0.0173, -0.0286, -0.0009,
         -0.0273, -0.0189,  0.0277, -0.0102,  0.0285, -0.0278,  0.0444,  0.0117,
         -0.0089,  0.0082, -0.0180,  0.0162,  0.0254, -0.0076, -0.0388, -0.0157,
          0.0275,  0.0076,  0.0290,  0.0176,  0.0202, -0.0076, -0.0010, -0.0154,
         -0.0114, -0.0452, -0.0231, -0.0136, -0.0249, -0.0198, -0.0171, -0.0031,
          0.0017, -0.0244, -0.0194,  0.0190, -0.0072, -0.0022,  0.0306,  0.0205,
         -0.0179, -0.0141,  0.0052, -0.0264, -0.0224, -0.0451,  0.0042, -0.0159,
          0.0076, -0.0205, -0.0099,  0.0170, -0.0509, -0.0152, -0.0359, -0.0354,
         -0.0264, -0.0270,  0.0400,  0.0234,  0.0083, -0.0180, -0.0362, -0.0342,
          0.0078, -0.0391, -0.0310,  0.0032,  0.0179, -0.0081, -0.0155, -0.0078,
          0.0322, -0.0193, -0.0237,  0.0232, -0.0160,  0.0144, -0.0128, -0.0024,
         -0.0231, -0.0160, -0.0054, -0.0349, -0.0312, -0.0334,  0.0220, -0.0089,
         -0.0027, -0.0211, -0.0239, -0.0280,  0.0166, -0.0362, -0.0211, -0.0436,
         -0.0376,  0.0166,  0.0311, -0.0223, -0.0245, -0.0129, -0.0082,  0.0202,
         -0.0324,  0.0286, -0.0137,  0.0143, -0.0183,  0.0368, -0.0265, -0.0063,
          0.0080, -0.0096, -0.0262, -0.0011, -0.0342, -0.0209,  0.0064,  0.0167,
          0.0160,  0.0223, -0.0485,  0.0077, -0.0051,  0.0034, -0.0011, -0.0141,
         -0.0052,  0.0162,  0.0199,  0.0155,  0.0160, -0.0278, -0.0039, -0.0102,
         -0.0151, -0.0378, -0.0068,  0.0330, -0.0257,  0.0014,  0.0001,  0.0028,
          0.0269, -0.0095, -0.0215, -0.0169,  0.0015,  0.0126, -0.0066,  0.0281,
         -0.0218, -0.0111,  0.0137,  0.0150, -0.0319,  0.0196, -0.0121,  0.0053,
         -0.0075,  0.0041, -0.0146, -0.0041, -0.0317,  0.0202, -0.0030,  0.0236,
         -0.0190, -0.0249, -0.0158, -0.0203,  0.0105, -0.0186,  0.0027, -0.0212,
         -0.0095, -0.0271,  0.0112, -0.0050,  0.0232, -0.0136, -0.0255, -0.0064,
          0.0499,  0.0170, -0.0620,  0.0305, -0.0012, -0.0015,  0.0234, -0.0195,
          0.0274, -0.0322, -0.0080, -0.0302, -0.0383,  0.0094,  0.0037, -0.0080,
         -0.0025, -0.0336,  0.0368,  0.0034, -0.0344,  0.0193,  0.0166,  0.0217,
          0.0037,  0.0074, -0.0392,  0.0362,  0.0431, -0.0142, -0.0058,  0.0321,
         -0.0147, -0.0191, -0.0299, -0.0145,  0.0140, -0.0151, -0.0115, -0.0236,
          0.0412,  0.0201,  0.0558, -0.0312, -0.0173,  0.0018, -0.0217,  0.0293]])
