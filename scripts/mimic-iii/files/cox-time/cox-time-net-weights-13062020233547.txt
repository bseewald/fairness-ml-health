Weights: 
net.embeddings.embeddings.0.weight tensor([[-0.1189,  0.4064],
        [-0.3524, -0.3674],
        [ 0.1577,  0.3612],
        [-0.0519,  0.2017]])
net.embeddings.embeddings.1.weight tensor([[ 0.1187,  0.4123],
        [-0.0346, -0.0786],
        [ 0.2663, -0.1168],
        [-0.4420,  0.4687],
        [ 0.0201,  0.0442]])
net.embeddings.embeddings.2.weight tensor([[ 0.1420,  0.1858, -0.0796],
        [-0.0165, -0.0241, -0.2779],
        [ 0.2315, -0.1512,  0.3340],
        [-0.0105,  0.3629,  0.1471],
        [ 0.1699, -0.0980,  0.2739],
        [-0.0483,  0.1940,  0.2533]])
net.embeddings.embeddings.3.weight tensor([[-0.1017,  0.4371],
        [ 0.3165,  0.3755],
        [-0.1175, -0.3368],
        [-0.2684, -0.0209]])
net.embeddings.embeddings.4.weight tensor([[-0.3903, -0.4160],
        [-0.4249, -0.2593],
        [ 0.2900,  0.3288],
        [-0.2678,  0.0933]])
net.mlp.net.0.linear.weight tensor([[-0.3136,  0.0510, -0.0024,  ...,  0.2028,  0.0937, -0.3935],
        [ 0.0540,  0.4967,  0.1095,  ...,  0.2265, -0.1488, -0.2216],
        [-0.3035, -0.2263, -0.6410,  ..., -0.1614, -0.3281, -0.1093],
        ...,
        [ 0.2087, -0.2093, -0.2339,  ..., -0.1065, -0.5363,  0.0426],
        [-0.1429,  0.1574, -0.0253,  ..., -0.1115,  0.1026,  0.2755],
        [ 0.2083, -0.4502,  0.1274,  ...,  0.1874, -0.0569,  0.0605]])
net.mlp.net.0.linear.bias tensor([-0.0466,  0.0006,  0.1120,  0.1373,  0.2191,  0.0516,  0.1156,  0.0898,
        -0.0387, -0.0519,  0.1823,  0.0018,  0.0460, -0.0973, -0.0816,  0.0334,
         0.0733,  0.0148,  0.1123,  0.0688,  0.0856,  0.1669, -0.0802, -0.1695,
        -0.0619,  0.0868, -0.0578,  0.1231, -0.1060,  0.0571,  0.0734, -0.0056,
        -0.1304, -0.1279,  0.0157, -0.0867, -0.0307,  0.0088,  0.1268,  0.0812,
         0.1043, -0.0513, -0.0110, -0.0445,  0.0612, -0.0758, -0.1347, -0.0042,
        -0.1145,  0.0517, -0.0812,  0.0492, -0.1792, -0.1207, -0.0611, -0.1198,
        -0.0230, -0.0401, -0.1217, -0.0423, -0.0760,  0.0777,  0.0789,  0.0591,
        -0.0544, -0.1311, -0.1333,  0.1764, -0.1302,  0.1216,  0.0439, -0.0957,
        -0.0047,  0.0543, -0.0642, -0.0880,  0.0985,  0.1276, -0.0359, -0.0588,
        -0.0794, -0.1569,  0.0003, -0.0658, -0.0387,  0.0073,  0.1981,  0.0521,
         0.0190,  0.0176, -0.0140, -0.0009,  0.0891, -0.0685,  0.0433,  0.1271,
        -0.0311, -0.1257, -0.0742,  0.0671,  0.1172,  0.1485,  0.1208,  0.0536,
         0.1348,  0.0415, -0.0891,  0.1355,  0.1269,  0.1130, -0.0652, -0.1135,
        -0.0482,  0.0059, -0.0345,  0.0367, -0.0068, -0.1126, -0.0602,  0.0994,
        -0.0041, -0.0753,  0.0499,  0.0633,  0.0896,  0.2096,  0.0810, -0.0765,
        -0.0493, -0.0493,  0.0313, -0.0654,  0.0591,  0.0608,  0.0835, -0.0315,
         0.0242,  0.0782, -0.0040,  0.0153,  0.1240, -0.0704, -0.1877, -0.1216,
        -0.1773, -0.0803,  0.1330, -0.1507, -0.0950,  0.0088, -0.1299, -0.0453,
         0.1187,  0.0877,  0.0292,  0.2012,  0.0014,  0.0107, -0.0072, -0.0470,
         0.0828, -0.0342, -0.0347,  0.0889,  0.0908, -0.0081, -0.1283, -0.0408,
        -0.1810,  0.1076,  0.0890, -0.0380, -0.1103, -0.1533,  0.0110, -0.1168,
         0.0743, -0.0818,  0.1396, -0.0767, -0.0597, -0.0060,  0.0004,  0.0975,
        -0.1180,  0.0815,  0.1457,  0.1178,  0.1398, -0.0941, -0.0524, -0.0991,
         0.1412,  0.0031,  0.1224, -0.1023, -0.0395,  0.0834, -0.0007, -0.0205,
         0.0080,  0.0972,  0.0583, -0.1517,  0.0552, -0.0044,  0.1048,  0.1185,
         0.0574, -0.1149, -0.1862,  0.1351,  0.0507, -0.0669, -0.1168, -0.0087,
        -0.0572, -0.0062, -0.1901,  0.0696, -0.0454,  0.1386, -0.1013,  0.0393,
         0.0998, -0.1433,  0.0379,  0.0630,  0.0221, -0.1565, -0.1157,  0.0121,
         0.0525, -0.0642,  0.1319,  0.2171,  0.1089,  0.0409,  0.0291,  0.1020,
        -0.0370,  0.0318, -0.0454, -0.0492,  0.0852, -0.0383,  0.0884, -0.1527,
        -0.0086,  0.1317, -0.0048, -0.1073,  0.1524, -0.0239,  0.0681, -0.1281])
net.mlp.net.0.batch_norm.weight tensor([0.7110, 0.6388, 0.6823, 0.7754, 0.7639, 0.6431, 0.6208, 0.6187, 0.7902,
        0.6629, 0.6594, 0.7216, 0.7171, 0.6508, 0.7060, 0.7483, 0.6734, 0.7351,
        0.7357, 0.7161, 0.6444, 0.6695, 0.7617, 0.6633, 0.7812, 0.6458, 0.7156,
        0.6593, 0.6995, 0.7098, 0.6259, 0.6564, 0.6724, 0.6199, 0.7942, 0.7057,
        0.6930, 0.7978, 0.6907, 0.7370, 0.6846, 0.6728, 0.7227, 0.7178, 0.6266,
        0.7365, 0.6886, 0.6928, 0.6800, 0.6837, 0.6168, 0.6411, 0.6915, 0.6740,
        0.6217, 0.6488, 0.6393, 0.7744, 0.6952, 0.6430, 0.7143, 0.6660, 0.7184,
        0.6547, 0.7034, 0.6241, 0.7139, 0.7246, 0.6363, 0.6779, 0.6575, 0.7511,
        0.7690, 0.6640, 0.6802, 0.6295, 0.7221, 0.7508, 0.6419, 0.7081, 0.7372,
        0.6994, 0.6911, 0.6806, 0.7297, 0.6279, 0.7220, 0.6098, 0.7333, 0.7157,
        0.6594, 0.6381, 0.6262, 0.6907, 0.6258, 0.6284, 0.7460, 0.6117, 0.7317,
        0.6965, 0.6407, 0.6213, 0.6862, 0.7238, 0.7079, 0.7212, 0.6803, 0.6705,
        0.6601, 0.6455, 0.6809, 0.6604, 0.7274, 0.6145, 0.7694, 0.6833, 0.7076,
        0.7746, 0.7201, 0.7401, 0.6406, 0.6549, 0.7075, 0.7070, 0.7238, 0.6162,
        0.6802, 0.6511, 0.7331, 0.7058, 0.7224, 0.7052, 0.6270, 0.6930, 0.7129,
        0.7554, 0.7346, 0.6815, 0.6421, 0.7287, 0.6706, 0.6246, 0.7657, 0.6648,
        0.6315, 0.6628, 0.7407, 0.6979, 0.6575, 0.6911, 0.7782, 0.7095, 0.6655,
        0.6823, 0.7033, 0.6900, 0.6412, 0.6211, 0.7048, 0.7215, 0.6161, 0.7341,
        0.6313, 0.5922, 0.6337, 0.6033, 0.6411, 0.7274, 0.7143, 0.6356, 0.6006,
        0.6081, 0.6368, 0.7018, 0.6574, 0.6617, 0.6944, 0.7269, 0.6410, 0.6727,
        0.7319, 0.6957, 0.7397, 0.7191, 0.6650, 0.7357, 0.7057, 0.6513, 0.7463,
        0.7136, 0.6078, 0.6636, 0.6697, 0.6934, 0.6628, 0.6811, 0.6084, 0.6958,
        0.7428, 0.7036, 0.6449, 0.6442, 0.6086, 0.6808, 0.6901, 0.6460, 0.7137,
        0.6992, 0.7028, 0.7066, 0.7082, 0.7257, 0.6473, 0.6674, 0.7166, 0.5981,
        0.6946, 0.7088, 0.6647, 0.7035, 0.7254, 0.7692, 0.7018, 0.7214, 0.5979,
        0.6905, 0.6689, 0.6906, 0.7184, 0.6600, 0.6931, 0.5936, 0.6781, 0.6551,
        0.7618, 0.7338, 0.6353, 0.6514, 0.7378, 0.6761, 0.6986, 0.7440, 0.6601,
        0.6836, 0.6066, 0.6933, 0.6255, 0.7281, 0.6623, 0.7074, 0.6430, 0.6992,
        0.6317, 0.7138, 0.6760, 0.6941])
net.mlp.net.0.batch_norm.bias tensor([ 0.0600,  0.0443, -0.0878, -0.0057,  0.0324, -0.0165, -0.0134,  0.0268,
        -0.0551,  0.0041, -0.0158, -0.0317, -0.0368,  0.0275, -0.0102,  0.0025,
         0.0402,  0.0174, -0.0724, -0.0803, -0.0098,  0.0034, -0.0573, -0.0729,
        -0.0647,  0.0368,  0.0744, -0.0337, -0.0582, -0.0301, -0.0001, -0.0204,
        -0.0510, -0.0147,  0.0355, -0.0235, -0.0290, -0.0709, -0.0105, -0.0197,
        -0.0223,  0.0747, -0.0677, -0.0835,  0.0313, -0.0272,  0.0248,  0.0827,
        -0.0471,  0.0056,  0.0125, -0.0545,  0.0424,  0.0258, -0.0553, -0.0467,
         0.0672,  0.0295,  0.0111, -0.0683, -0.0634,  0.0060,  0.0135, -0.0381,
        -0.0276, -0.0391, -0.0944,  0.0654,  0.0072,  0.0344,  0.0138, -0.0602,
        -0.0159, -0.0450,  0.0446,  0.0537, -0.0399,  0.0426,  0.0017, -0.0175,
        -0.0276,  0.0642,  0.0301,  0.0712, -0.0379, -0.0402, -0.0087,  0.0085,
         0.0409, -0.0341, -0.0302,  0.0352,  0.0153, -0.0301,  0.0893, -0.0349,
        -0.0325,  0.0126, -0.0479,  0.0108, -0.0253,  0.0065, -0.0608,  0.0703,
        -0.0072,  0.0196,  0.0380, -0.1019, -0.0175, -0.0104, -0.0766, -0.0203,
         0.0739, -0.0551,  0.0478, -0.0233, -0.0424, -0.0530, -0.0101, -0.0228,
         0.0426, -0.0673, -0.0503, -0.0189, -0.0412, -0.0240,  0.0094, -0.0242,
        -0.0772, -0.0372,  0.0364,  0.0148,  0.0277, -0.0743, -0.0210, -0.0095,
        -0.0388,  0.0005,  0.0020, -0.0516,  0.0104, -0.0954, -0.0441, -0.0261,
        -0.0005, -0.0123, -0.0812, -0.0345,  0.0844,  0.0077, -0.0349, -0.0707,
         0.0097,  0.0691,  0.0255, -0.0141, -0.0032,  0.0224, -0.0075,  0.0290,
        -0.0563,  0.0608, -0.0905,  0.0598, -0.0288,  0.0330,  0.0162, -0.0377,
         0.0121, -0.0017, -0.0054,  0.0065,  0.0227, -0.0697,  0.0326,  0.0815,
         0.0454,  0.0149,  0.0065, -0.0496,  0.0230,  0.0022, -0.0023, -0.0641,
        -0.0436, -0.0904, -0.0691,  0.0443,  0.0839, -0.0389, -0.0596, -0.0014,
        -0.0281,  0.0424, -0.0180,  0.0286, -0.0006, -0.0037,  0.0138,  0.0151,
         0.0279,  0.0110, -0.0257, -0.0075,  0.0015, -0.0717, -0.0013, -0.0124,
         0.0107,  0.0655,  0.0223,  0.0283, -0.0398, -0.0057,  0.0682, -0.0054,
        -0.0224, -0.0228, -0.0037,  0.0036, -0.0674,  0.0902,  0.0497,  0.0867,
        -0.0661, -0.0807, -0.0520,  0.0876, -0.0159,  0.0106, -0.0129, -0.0644,
         0.0124,  0.0515,  0.0194, -0.0369,  0.0259,  0.0492,  0.0177, -0.0289,
        -0.0087,  0.0026,  0.0082, -0.0226,  0.0919,  0.0164,  0.0578,  0.0548,
         0.0249, -0.0708, -0.0475,  0.0108, -0.0352, -0.0022,  0.0442,  0.0068])
net.mlp.net.0.batch_norm.running_mean tensor([1.2285e-01, 5.2599e-02, 3.4525e-02, 4.9888e-01, 7.2778e-01, 9.6155e-02,
        9.0522e-01, 4.6705e-01, 1.8502e-03, 1.7279e-01, 4.7985e-01, 6.7644e-02,
        2.6183e-01, 2.8245e-01, 6.2961e-02, 4.3764e-02, 1.9743e-01, 4.6746e-03,
        2.1158e-01, 5.2978e-01, 1.6010e-01, 4.5971e-01, 4.7031e-01, 4.1679e-02,
        1.6375e-01, 5.9086e-01, 3.3856e-01, 5.3289e-01, 9.4505e-02, 3.9237e-01,
        1.6970e-01, 1.2757e-04, 3.7000e-04, 3.5604e-01, 3.7184e-02, 5.6107e-01,
        3.3572e-01, 2.4913e-03, 3.1396e-01, 8.6652e-02, 6.9531e-01, 2.6021e-01,
        6.4986e-01, 7.8555e-03, 7.6825e-02, 7.1461e-02, 6.5531e-02, 4.7241e-01,
        6.7761e-03, 7.8020e-02, 3.5384e-02, 1.0749e-01, 3.1010e-03, 6.2040e-04,
        3.2707e-01, 3.0893e-01, 1.8667e-01, 2.0641e-01, 1.1799e-01, 1.6397e-01,
        3.4838e-01, 1.4741e-01, 7.4100e-01, 3.3867e-01, 6.1199e-02, 4.2940e-02,
        5.5436e-02, 3.6304e-01, 3.0372e-02, 3.1687e-01, 1.0447e-01, 2.2565e-01,
        4.8902e-02, 2.1579e-01, 3.9709e-02, 4.1271e-02, 3.9237e-01, 7.3105e-02,
        8.0043e-02, 4.8419e-01, 6.5934e-02, 3.7322e-02, 1.5481e-01, 7.7695e-02,
        2.2572e-02, 1.2182e-01, 7.8868e-01, 8.0485e-02, 2.2462e-03, 1.3432e-01,
        5.8004e-01, 1.3024e-01, 4.3727e-01, 1.3673e-01, 4.3869e-01, 2.7621e-01,
        1.1040e-01, 2.9214e-02, 3.5121e-01, 4.0688e-03, 6.1101e-01, 3.8537e-01,
        9.1740e-01, 1.0143e-01, 7.5772e-01, 2.0740e-01, 3.5441e-01, 1.5617e-01,
        5.8040e-01, 5.5146e-01, 1.6149e-02, 3.3787e-02, 8.9581e-02, 3.1512e-01,
        3.1427e-02, 5.4108e-02, 3.9819e-02, 4.9155e-04, 2.3371e-01, 9.2926e-01,
        1.4853e-02, 3.7619e-01, 7.8707e-02, 2.3075e-01, 2.2991e-02, 4.1165e-01,
        5.1954e-01, 1.3591e-01, 1.0224e-01, 4.2943e-01, 2.0630e-01, 1.4802e-01,
        1.8254e-01, 5.9053e-02, 5.8431e-01, 3.0090e-01, 3.4424e-01, 1.5522e-01,
        2.3149e-01, 2.1403e-01, 1.8719e-01, 1.2601e-01, 1.1339e-01, 2.9432e-02,
        1.3537e-01, 5.9488e-02, 3.5134e-02, 4.0331e-02, 2.6433e-01, 1.4008e-01,
        2.2828e-02, 5.9112e-04, 1.9846e-01, 5.4427e-01, 1.2031e-01, 7.6682e-01,
        1.5947e-05, 9.0430e-02, 6.0871e-01, 6.2904e-02, 2.8487e-01, 7.8536e-01,
        3.7407e-02, 6.2759e-02, 9.1893e-01, 2.1410e-01, 9.5910e-02, 2.6130e-01,
        4.2370e-02, 4.2865e-02, 1.6054e-01, 4.2846e-01, 5.1798e-01, 1.5538e-01,
        2.4730e-01, 6.5766e-02, 6.0053e-01, 1.1233e-01, 5.5274e-01, 1.8483e-01,
        1.8849e-01, 1.6674e-01, 6.8046e-01, 3.0971e-01, 4.1244e-01, 2.4080e-02,
        3.6350e-01, 4.7576e-03, 1.2287e-01, 4.9930e-02, 1.1735e-01, 2.1769e-01,
        3.4941e-01, 4.5891e-02, 3.6119e-01, 6.1063e-03, 2.5132e-01, 5.0575e-01,
        4.4630e-01, 1.1899e-01, 3.2163e-01, 7.6381e-02, 3.1894e-01, 5.0180e-02,
        2.3451e-01, 3.1007e-01, 1.8125e-01, 4.3442e-01, 8.8229e-02, 1.9855e-01,
        1.3130e-01, 5.3948e-02, 1.6981e-01, 7.1389e-03, 3.5817e-02, 4.4923e-03,
        2.1056e-02, 2.7735e-01, 2.3982e-01, 4.5070e-01, 1.7344e-01, 4.3739e-02,
        1.8411e-02, 7.7953e-01, 4.1204e-01, 5.0010e-02, 6.7103e-02, 6.6153e-02,
        9.5487e-02, 1.7114e-02, 3.3011e-01, 5.1712e-01, 1.4174e-01, 3.0285e-01,
        1.5624e-01, 9.0400e-01, 3.8916e-01, 3.9015e-02, 1.2898e-01, 4.6377e-01,
        8.1441e-02, 4.1770e-02, 7.2575e-02, 1.5576e-01, 1.4365e-01, 1.6652e-01,
        2.3520e-01, 1.7129e-02, 1.7124e-02, 5.2757e-02, 1.9728e-01, 4.5995e-02,
        9.4082e-02, 5.0481e-02, 2.0148e-01, 4.8814e-02])
net.mlp.net.0.batch_norm.running_var tensor([6.1464e-02, 1.2030e-02, 1.1448e-02, 7.4075e-02, 3.4982e-01, 2.3598e-02,
        2.4816e-01, 6.1184e-02, 7.6050e-04, 5.9821e-02, 5.9285e-02, 1.5203e-01,
        1.0967e-01, 6.4647e-02, 3.1413e-02, 7.9630e-03, 7.6073e-02, 1.5230e-03,
        4.1046e-02, 1.8085e-01, 2.6906e-02, 4.2921e-02, 9.6123e-02, 8.2024e-02,
        3.9780e-02, 1.9722e-01, 5.9800e-02, 2.5229e-01, 1.8868e-01, 5.1498e-02,
        3.2663e-02, 1.6160e-04, 2.0197e-04, 1.0108e-01, 3.6497e-02, 1.5761e-01,
        8.2655e-02, 7.2555e-04, 8.0763e-02, 4.1620e-02, 1.3946e-01, 6.6621e-02,
        1.1537e-01, 2.3357e-03, 3.8334e-02, 9.8948e-03, 4.6970e-02, 1.0604e-01,
        1.9117e-03, 2.7394e-02, 1.2355e-02, 2.2673e-02, 1.3472e-03, 2.3005e-04,
        7.5715e-02, 5.6960e-02, 2.5385e-02, 4.2451e-02, 4.3641e-02, 5.0304e-02,
        4.5048e-02, 7.5283e-02, 1.8901e-01, 7.9862e-02, 7.5611e-03, 1.2354e-02,
        1.3597e-02, 1.1316e-01, 1.2599e-02, 8.6552e-02, 5.8357e-02, 3.5300e-02,
        8.4355e-03, 5.1087e-02, 7.7901e-03, 2.2405e-02, 1.7640e-01, 1.2990e-02,
        5.9683e-02, 1.8322e-01, 6.2411e-02, 5.0338e-02, 1.2570e-01, 1.9625e-02,
        5.3812e-03, 1.9153e-02, 2.2094e-01, 4.0790e-02, 5.8223e-04, 2.5105e-02,
        6.9886e-02, 9.8997e-02, 1.1570e-01, 3.2857e-02, 2.6860e-01, 6.5778e-02,
        1.9436e-02, 1.6840e-02, 9.5641e-02, 1.0094e-03, 5.7928e-02, 1.3645e-01,
        1.6951e-01, 7.3058e-02, 1.6907e-01, 4.1399e-02, 1.6379e-01, 1.8051e-01,
        1.0432e-01, 7.8920e-02, 5.5609e-03, 1.3898e-02, 1.0369e-01, 6.5408e-02,
        7.1587e-03, 4.0837e-02, 4.8339e-02, 2.3732e-04, 1.4485e-01, 3.0732e-01,
        2.5596e-03, 5.4600e-02, 1.1394e-01, 8.8410e-02, 5.6212e-03, 3.6794e-02,
        1.2488e-01, 2.9178e-02, 6.7391e-02, 4.9393e-02, 6.4434e-02, 2.5875e-02,
        3.1659e-02, 7.2679e-03, 2.9179e-01, 5.8366e-02, 8.6726e-02, 2.6349e-01,
        6.2583e-02, 4.5049e-02, 5.7706e-02, 3.4060e-02, 2.9436e-02, 6.0307e-03,
        3.4301e-02, 4.0953e-02, 3.6159e-02, 1.5887e-02, 3.1049e-02, 4.0305e-02,
        4.5566e-03, 2.0759e-04, 4.2714e-02, 7.2460e-02, 3.3513e-02, 9.3069e-02,
        1.4472e-04, 2.8972e-02, 7.0020e-02, 1.6097e-02, 4.5264e-02, 2.1990e-01,
        9.9243e-03, 2.1354e-02, 1.9990e-01, 1.6936e-01, 5.9674e-02, 1.0322e-01,
        5.9400e-02, 1.4083e-02, 2.8301e-01, 2.7861e-01, 1.1279e-01, 6.6402e-02,
        9.6026e-02, 1.5362e-02, 7.5614e-02, 7.1099e-02, 1.2194e-01, 3.1226e-02,
        5.4955e-02, 8.9459e-02, 1.4392e-01, 4.2793e-02, 6.8211e-02, 4.9335e-03,
        3.4360e-01, 1.1973e-03, 2.9421e-02, 1.3317e-02, 4.8656e-02, 3.7146e-02,
        5.4582e-02, 1.2783e-02, 5.8720e-02, 1.4138e-03, 6.9947e-02, 7.7403e-02,
        1.8273e-01, 3.9593e-02, 8.2330e-02, 1.9606e-02, 1.4402e-01, 9.3075e-03,
        4.7078e-02, 5.5859e-02, 2.8681e-02, 1.2128e-01, 1.1518e-01, 7.1470e-02,
        3.9370e-02, 4.5122e-02, 8.0715e-02, 1.7997e-03, 2.2205e-02, 1.3418e-03,
        4.2088e-03, 7.7770e-02, 4.2111e-02, 1.3229e-01, 2.0209e-01, 9.5808e-03,
        4.1430e-03, 6.3813e-02, 2.8473e-01, 1.9708e-02, 4.0989e-02, 2.9155e-02,
        1.6713e-02, 1.2454e-02, 9.2358e-02, 2.0194e-01, 4.0723e-02, 1.6617e-01,
        3.3788e-02, 1.0955e-01, 6.2646e-02, 8.9799e-03, 3.3615e-02, 6.9848e-02,
        1.5200e-02, 1.4917e-02, 3.6481e-02, 7.6706e-02, 4.2086e-02, 2.9745e-02,
        2.4415e-01, 4.6845e-03, 3.1612e-03, 1.2220e-02, 1.3735e-01, 1.4642e-02,
        1.1371e-01, 1.6331e-02, 1.8986e-02, 1.2627e-02])
net.mlp.net.0.batch_norm.num_batches_tracked tensor(84)
net.mlp.net.1.linear.weight tensor([[-0.0069,  0.0650,  0.0807,  ...,  0.0387,  0.0361, -0.1021],
        [ 0.0193, -0.0184,  0.0172,  ..., -0.1096,  0.0081,  0.0634],
        [ 0.0961,  0.0643, -0.0314,  ..., -0.0190, -0.1089,  0.0928],
        ...,
        [ 0.0320, -0.0830, -0.0112,  ..., -0.0297, -0.0239, -0.0056],
        [-0.0558,  0.0234, -0.1076,  ...,  0.0342,  0.0210,  0.0906],
        [ 0.0324,  0.0275, -0.0386,  ...,  0.0199, -0.0472, -0.1589]])
net.mlp.net.1.linear.bias tensor([-5.7760e-02, -4.5081e-02, -2.1171e-02, -1.0332e-02,  2.3396e-02,
        -3.3574e-02, -5.5334e-02, -3.8543e-02, -1.4141e-02,  7.0777e-02,
        -3.9826e-02,  2.3825e-02,  2.2390e-02, -9.0867e-02,  6.4019e-02,
        -1.3344e-02,  3.1365e-02,  1.6299e-02, -5.2019e-02, -5.8992e-02,
         9.0525e-03,  5.0189e-02, -2.0365e-02, -2.2081e-02,  1.7288e-02,
        -4.0696e-03,  2.1843e-02,  1.4461e-02, -8.9622e-02,  2.5662e-02,
        -7.5462e-02,  6.6302e-02, -3.3918e-02, -1.3144e-02,  1.2151e-01,
        -1.3711e-03,  2.8727e-02, -8.8629e-02,  7.7708e-04,  1.6812e-02,
         2.0170e-02, -2.2962e-02,  2.5596e-02,  9.4756e-03,  2.6651e-02,
         2.2136e-02,  6.7495e-02,  4.1333e-03, -2.6299e-04, -6.4644e-02,
         4.1725e-02, -2.4363e-02, -2.2653e-02,  1.7271e-02,  1.4328e-02,
         5.7470e-02, -5.8935e-02,  3.6025e-02, -1.2180e-01, -6.0812e-02,
         2.5791e-02,  6.9195e-02, -3.0440e-02, -1.9829e-03, -2.9115e-02,
        -4.2707e-02, -3.8705e-02,  5.6106e-02,  8.4569e-02, -2.9085e-02,
        -8.1664e-03, -3.4151e-02, -3.5598e-02, -7.2208e-02,  8.5387e-03,
         1.8976e-02, -5.5411e-02, -1.0273e-02, -2.9800e-02,  1.6112e-02,
        -1.3776e-02, -6.5542e-02, -3.3356e-02, -6.1183e-02, -7.2411e-02,
         4.5241e-03,  5.0483e-02, -6.9541e-02, -1.2141e-02,  4.4734e-03,
        -3.6068e-02, -1.1132e-01,  1.3062e-02,  8.5243e-02, -1.9896e-02,
        -4.7479e-02,  6.3662e-03, -4.2145e-02, -4.2702e-02, -9.5387e-02,
         1.2880e-01,  9.3273e-02,  2.5839e-02, -2.0654e-02, -3.8807e-02,
        -6.5664e-02, -3.9606e-02,  5.2370e-02,  5.6018e-02, -4.3215e-03,
        -3.3589e-02,  7.9083e-03,  2.5219e-02, -4.3645e-02,  1.2311e-01,
         1.9092e-02, -6.7090e-02, -2.7145e-02, -1.0461e-01,  6.7840e-02,
        -3.4265e-02, -5.8397e-02,  2.6595e-02, -2.4602e-02,  4.5203e-02,
        -8.5932e-02, -4.4652e-02, -9.2355e-02,  2.7658e-02,  1.3942e-02,
         4.2940e-03, -4.2462e-02, -1.7240e-02, -7.3828e-02,  6.0225e-03,
         1.9035e-02,  1.3798e-02, -3.1770e-02,  1.8115e-02,  2.4428e-02,
        -5.3708e-02,  2.2737e-02,  3.8950e-02, -4.9634e-02, -7.5266e-02,
        -3.9488e-03,  1.3297e-01, -4.4407e-03,  6.4830e-02, -1.2457e-02,
         2.7170e-02, -5.1596e-02, -2.7235e-02, -1.0137e-01, -3.5656e-02,
         8.8354e-03, -1.1638e-02,  8.7127e-02,  2.3915e-02, -6.4368e-02,
        -3.7633e-03,  6.9056e-02, -5.8298e-02, -1.1835e-01, -1.0648e-01,
        -3.3707e-02,  2.2537e-02, -1.8126e-02, -8.5592e-02,  3.2893e-03,
        -6.4789e-02,  3.5819e-02, -3.0931e-02, -9.8267e-02,  3.1713e-02,
        -2.8975e-03, -2.0742e-02, -1.1181e-02, -2.6018e-02, -6.9783e-02,
        -7.5247e-02, -3.8342e-02, -2.6975e-03,  3.0202e-02,  1.5223e-02,
        -3.0756e-02,  3.9292e-02, -6.7168e-03, -5.4769e-02,  8.5341e-02,
         9.1875e-02,  5.0466e-02,  2.1514e-02,  1.7863e-02,  2.3453e-03,
         3.2440e-02,  3.1386e-02,  1.3403e-02, -5.1757e-02, -1.7606e-02,
         6.4729e-02, -4.5818e-02,  1.9009e-02,  2.5603e-02,  2.1305e-02,
         1.1619e-02, -8.2165e-02,  5.3895e-02, -7.2389e-03,  2.4383e-06,
         2.6757e-02,  2.5818e-03,  3.5276e-02, -1.2325e-02, -2.5874e-02,
        -4.3593e-02, -6.3570e-02, -7.7113e-04,  4.9179e-02, -3.1840e-04,
        -7.6604e-04,  6.0678e-02,  3.1603e-02,  8.4814e-02, -1.3371e-02,
         2.3199e-02, -7.9537e-03, -6.4579e-03, -1.6562e-02, -5.7899e-02,
        -5.2774e-02,  4.3579e-02,  5.2620e-03, -1.6055e-02, -2.1169e-02,
        -3.4289e-02,  3.2722e-02,  3.7735e-02, -4.9943e-03, -2.3980e-02,
        -3.8444e-02,  5.2537e-02, -1.4310e-02,  5.8966e-03, -3.4934e-02,
         3.8623e-02, -5.3210e-02,  8.6538e-02,  1.0147e-01, -7.0060e-02,
        -5.5783e-02,  1.2754e-02,  2.1384e-03, -3.8556e-02, -8.7654e-03,
         3.5245e-02])
net.mlp.net.1.batch_norm.weight tensor([0.5973, 0.6336, 0.7070, 0.6235, 0.6705, 0.6456, 0.6877, 0.6842, 0.6311,
        0.7458, 0.6789, 0.6168, 0.6418, 0.6834, 0.7794, 0.5990, 0.7086, 0.6655,
        0.6406, 0.6550, 0.6680, 0.7252, 0.6853, 0.7252, 0.7566, 0.6802, 0.6824,
        0.6667, 0.7046, 0.7317, 0.7684, 0.6935, 0.6177, 0.7566, 0.7392, 0.6875,
        0.6123, 0.7076, 0.6310, 0.6673, 0.7199, 0.6699, 0.7099, 0.6704, 0.6534,
        0.6962, 0.6700, 0.6556, 0.6936, 0.6094, 0.7474, 0.6817, 0.6198, 0.7070,
        0.6366, 0.7398, 0.6439, 0.7159, 0.6685, 0.7593, 0.6539, 0.7360, 0.6814,
        0.6304, 0.6841, 0.6811, 0.7358, 0.7156, 0.5937, 0.6433, 0.7683, 0.6444,
        0.7434, 0.7038, 0.6401, 0.6506, 0.6379, 0.6279, 0.7171, 0.6473, 0.6917,
        0.6226, 0.7211, 0.6839, 0.6871, 0.5999, 0.6777, 0.7335, 0.6854, 0.6455,
        0.6945, 0.6887, 0.7591, 0.6703, 0.5735, 0.6505, 0.6562, 0.7206, 0.7094,
        0.6569, 0.6994, 0.7297, 0.7814, 0.6903, 0.6878, 0.6919, 0.6627, 0.7632,
        0.6720, 0.7267, 0.6330, 0.6671, 0.6199, 0.6765, 0.7397, 0.6636, 0.6600,
        0.7423, 0.7558, 0.7383, 0.6897, 0.7209, 0.6535, 0.6876, 0.6492, 0.6860,
        0.7096, 0.7133, 0.7270, 0.6685, 0.6187, 0.5868, 0.7819, 0.6308, 0.7197,
        0.7428, 0.6664, 0.7436, 0.6067, 0.7744, 0.7543, 0.7047, 0.6231, 0.6643,
        0.7355, 0.6976, 0.6905, 0.6835, 0.6376, 0.6841, 0.5999, 0.6749, 0.6986,
        0.6463, 0.7072, 0.7349, 0.7026, 0.7536, 0.6667, 0.5878, 0.7170, 0.6777,
        0.7169, 0.7053, 0.7142, 0.6121, 0.6449, 0.6480, 0.5785, 0.6939, 0.5923,
        0.7381, 0.6704, 0.7490, 0.6949, 0.7164, 0.6575, 0.6751, 0.6874, 0.6184,
        0.7013, 0.6745, 0.7503, 0.7403, 0.5847, 0.6202, 0.6702, 0.6840, 0.7062,
        0.6761, 0.6414, 0.6892, 0.6515, 0.6402, 0.6079, 0.6881, 0.7136, 0.6842,
        0.6942, 0.7357, 0.6709, 0.6826, 0.7950, 0.6733, 0.7563, 0.7071, 0.6814,
        0.6592, 0.6981, 0.7106, 0.7324, 0.6921, 0.6488, 0.6624, 0.6797, 0.6398,
        0.6959, 0.6444, 0.6976, 0.7253, 0.6339, 0.6457, 0.7746, 0.6653, 0.6573,
        0.7294, 0.6804, 0.6193, 0.7355, 0.6638, 0.5844, 0.6870, 0.7005, 0.7563,
        0.5960, 0.6498, 0.6397, 0.6539, 0.7614, 0.6806, 0.7100, 0.6504, 0.6925,
        0.6261, 0.6733, 0.6995, 0.6391, 0.8081, 0.6486, 0.7051, 0.6504, 0.6845,
        0.7776, 0.6592, 0.6759, 0.6272])
net.mlp.net.1.batch_norm.bias tensor([ 4.2289e-02, -9.8075e-02,  8.0316e-05,  1.4807e-02, -2.1663e-02,
        -2.2405e-02,  1.0845e-02, -5.7303e-02, -3.4912e-02,  4.8088e-02,
         7.1027e-03, -3.8780e-02, -2.6374e-02,  8.2257e-02,  1.9470e-02,
         8.9061e-02,  1.2771e-02, -5.2398e-02, -1.9988e-02, -1.8853e-02,
         1.0649e-02, -6.9773e-02, -6.8578e-02, -2.2405e-03,  7.0467e-03,
        -2.8442e-02, -1.8069e-03,  2.4300e-02,  1.6590e-02, -4.6542e-03,
        -3.2099e-02, -3.5532e-02,  1.8870e-02,  1.0514e-01, -5.3970e-02,
        -3.0601e-02, -3.9287e-03,  9.4533e-03, -1.7414e-02, -3.5672e-03,
         4.2309e-02,  1.3130e-03,  1.9050e-02,  5.1815e-02, -2.5428e-02,
        -4.8495e-02,  5.7924e-02,  1.2553e-02,  9.3318e-04,  1.5675e-03,
         2.5693e-02, -1.7750e-02,  7.1983e-02, -2.8002e-02, -8.6452e-03,
        -3.0759e-02,  8.6421e-03, -1.7604e-02, -7.6316e-02, -9.2675e-02,
         2.9736e-02,  7.5714e-02,  4.8406e-02,  6.4266e-02,  4.3640e-02,
        -3.9301e-02,  8.2494e-02,  4.8329e-02,  5.9366e-02, -5.1272e-02,
        -5.2554e-02, -2.4395e-02,  1.5982e-02, -1.9936e-02,  7.1773e-02,
        -3.3539e-02,  3.7847e-02, -3.4960e-02,  1.6658e-02,  1.0983e-02,
        -7.3800e-03, -5.7634e-02, -3.4209e-02, -7.1741e-02,  2.8732e-02,
         4.7995e-03,  2.3398e-02,  1.6572e-02,  5.1735e-02, -8.4397e-02,
         1.8531e-02, -1.3761e-02, -2.3278e-02,  6.1538e-02, -8.2581e-03,
        -4.3666e-02, -4.4727e-03,  1.7439e-02,  6.9172e-02,  1.0375e-01,
         3.1946e-02, -5.6448e-02,  4.9361e-02, -1.3016e-02,  6.5260e-03,
         4.9220e-02,  1.6835e-02, -4.9698e-02,  3.9552e-02, -3.9412e-02,
         4.8294e-02, -3.0538e-02, -6.4954e-02,  4.2390e-02,  7.6940e-02,
         3.9769e-02, -3.5473e-02,  6.0103e-02, -1.0506e-02, -2.9111e-02,
         2.0571e-02, -1.5787e-02,  5.5373e-02,  2.6818e-02,  2.4220e-02,
         1.0010e-02,  4.8607e-02, -9.3776e-02, -9.6119e-03, -8.9163e-02,
         6.4045e-02, -3.8877e-02,  3.7959e-02,  2.3526e-02, -4.6441e-02,
        -2.8560e-02,  3.2532e-03,  6.5907e-03,  6.6727e-02, -3.5441e-02,
         4.0480e-02, -1.0526e-02,  2.8118e-02, -1.1385e-01,  1.8590e-02,
        -2.3875e-02,  3.6978e-02, -4.8880e-03,  3.1819e-02,  3.4743e-03,
         6.5748e-02,  1.6627e-02,  2.8420e-03, -7.4527e-02,  1.6158e-02,
        -2.3105e-02,  8.1764e-02,  3.3180e-02, -9.1167e-03, -1.0781e-02,
        -2.8582e-02, -1.5241e-02, -1.0688e-02,  9.8588e-03, -3.3620e-02,
        -5.6046e-02, -2.4290e-02,  3.8192e-02,  5.9403e-02,  2.4877e-02,
        -9.0599e-03,  7.2744e-02, -2.6937e-02,  2.7270e-02,  5.9593e-02,
        -1.4719e-02,  5.6739e-02, -2.0341e-02,  1.3569e-03, -3.9125e-02,
         1.4139e-02, -4.5005e-02,  4.8832e-02, -4.3268e-02,  5.0595e-02,
         6.2373e-02,  3.6551e-02, -5.4614e-02, -6.5996e-02,  5.2855e-02,
        -3.9454e-02, -8.3196e-03, -1.6927e-02,  2.7680e-02, -1.9646e-02,
         1.1293e-02, -6.1621e-02, -1.7040e-02,  3.2828e-03,  3.9502e-02,
         7.5484e-02,  4.4190e-03, -2.4758e-02, -2.0867e-02,  6.2351e-02,
         1.8061e-02,  4.1594e-02, -5.8862e-02, -1.1979e-02,  4.6653e-02,
         7.6138e-02, -4.8150e-02, -6.3948e-02,  3.0753e-02, -2.7236e-02,
        -7.9860e-03,  6.2498e-02, -2.3178e-02, -2.2565e-02,  1.8150e-02,
        -5.6562e-02, -2.0374e-03, -1.4516e-02,  7.2035e-03,  5.9444e-02,
        -1.9645e-02,  1.3084e-02, -1.2565e-02, -1.5092e-02, -3.1196e-02,
         3.4393e-02,  4.5656e-03,  4.2485e-04, -3.1064e-02, -2.0086e-02,
        -2.9281e-02,  3.9103e-02,  3.0042e-04,  1.6197e-02, -1.2475e-02,
         2.3885e-02, -2.2467e-02,  2.2336e-02,  6.8153e-02,  3.7310e-02,
        -1.7676e-02,  3.5675e-02,  3.5361e-02, -4.0072e-02,  3.6060e-02,
         3.8652e-02,  1.0448e-01,  8.8355e-03, -6.2568e-02, -7.4676e-04,
         4.5718e-03])
net.mlp.net.1.batch_norm.running_mean tensor([0.4925, 0.7822, 0.5547, 0.5371, 0.5922, 0.5427, 0.5336, 0.5309, 0.6523,
        0.5612, 0.6394, 0.4989, 0.6153, 0.4174, 0.5436, 0.6572, 0.5357, 0.4950,
        0.6704, 0.6287, 0.4910, 0.8365, 0.5578, 0.6770, 0.6225, 0.5337, 0.6496,
        0.7227, 0.6347, 0.5745, 0.4174, 0.5724, 0.8623, 0.4834, 0.5970, 0.5903,
        0.6436, 0.6869, 0.6429, 0.6721, 0.5298, 0.3533, 0.6655, 0.6722, 0.5407,
        0.6771, 0.8182, 0.6210, 0.6386, 0.5750, 0.7333, 0.7059, 0.4134, 0.5427,
        0.6218, 0.6883, 0.5481, 0.5026, 0.5408, 0.6872, 0.5041, 0.5136, 0.6308,
        0.6524, 0.6658, 0.5361, 0.4874, 0.8229, 0.6606, 0.5498, 0.5544, 0.5652,
        0.4879, 0.5792, 0.5030, 0.4537, 0.5564, 0.5767, 0.6047, 0.5797, 0.5170,
        0.5493, 0.4536, 0.4919, 0.4570, 0.7442, 0.6737, 0.5855, 0.7222, 0.7323,
        0.5847, 0.3906, 0.5684, 0.7671, 0.5369, 0.6847, 0.6254, 0.7719, 0.4634,
        0.5248, 0.6296, 0.7350, 0.4633, 0.7467, 0.6919, 0.5592, 0.4383, 0.6900,
        0.6729, 0.5908, 0.4925, 0.6606, 0.5839, 0.5487, 0.5475, 0.4403, 0.5362,
        0.6086, 0.4738, 0.6086, 0.5321, 0.5549, 0.6453, 0.5129, 0.8085, 0.3337,
        0.5452, 0.5761, 0.5631, 0.6305, 0.6087, 0.6372, 0.6258, 0.5515, 0.5817,
        0.6613, 0.5232, 0.7182, 0.4629, 0.5496, 0.6193, 0.6645, 0.6705, 0.5730,
        0.5824, 0.4582, 0.7498, 0.5530, 0.6117, 0.7183, 0.6658, 0.6386, 0.6256,
        0.5525, 0.6456, 0.5532, 0.4869, 0.6986, 0.6481, 0.5497, 0.6434, 0.6149,
        0.4864, 0.4752, 0.6368, 0.5634, 0.5397, 0.5961, 0.5372, 0.4055, 0.5556,
        0.6351, 0.4259, 0.4456, 0.7052, 0.6358, 0.5513, 0.4410, 0.4920, 0.4269,
        0.5189, 0.5580, 0.5894, 0.7007, 0.5564, 0.5640, 0.8173, 0.4695, 0.5640,
        0.8242, 0.8274, 0.7165, 0.5927, 0.6909, 0.7019, 0.6563, 0.8278, 0.4904,
        0.4497, 0.7025, 0.7551, 0.6256, 0.4095, 0.6073, 0.6458, 0.5993, 0.4685,
        0.5818, 0.4625, 0.6250, 0.6171, 0.5258, 0.4733, 0.6466, 0.5012, 0.4502,
        0.6175, 0.3824, 0.4208, 0.6737, 0.6438, 0.5083, 0.6189, 0.7086, 0.4863,
        0.6025, 0.5637, 0.4206, 0.4167, 0.4965, 0.5169, 0.5708, 0.5108, 0.6115,
        0.6695, 0.5497, 0.3806, 0.6601, 0.6174, 0.4800, 0.4910, 0.7747, 0.7626,
        0.6313, 0.3991, 0.7817, 0.5840, 0.6459, 0.9152, 0.5039, 0.5597, 0.6153,
        0.4897, 0.4144, 0.5925, 0.6592])
net.mlp.net.1.batch_norm.running_var tensor([0.8432, 1.1774, 0.9854, 0.5350, 0.8271, 0.7063, 0.4588, 0.6783, 1.5356,
        1.2558, 1.1087, 0.3695, 1.5258, 0.5638, 1.3534, 2.9044, 1.6957, 0.5487,
        1.1195, 3.5727, 1.4571, 1.1200, 1.0404, 0.8929, 1.6758, 0.8903, 0.7226,
        0.7784, 1.1328, 0.8119, 0.5744, 1.4172, 1.1669, 0.6266, 0.6981, 0.7965,
        1.2788, 2.2955, 1.0157, 0.8874, 0.7465, 0.4377, 0.7658, 1.3132, 1.4714,
        0.7477, 2.7169, 0.8454, 0.8526, 0.7859, 1.5434, 1.2484, 1.0067, 0.4429,
        1.8570, 0.7443, 1.8210, 0.7912, 0.6861, 0.8792, 1.2108, 0.5465, 3.4062,
        0.8230, 1.3816, 0.5986, 1.1145, 1.3520, 1.1175, 1.7991, 0.6276, 2.0811,
        0.7509, 0.8865, 0.5350, 0.4380, 3.0105, 1.6286, 1.0113, 0.6682, 0.4664,
        0.8068, 0.7438, 1.3830, 0.6830, 1.4977, 0.8715, 0.8274, 2.4688, 1.0075,
        0.8537, 0.9034, 0.6830, 0.9510, 2.2681, 4.6544, 2.3771, 3.9407, 1.1061,
        0.6802, 0.8834, 1.8147, 0.5890, 4.5754, 1.0265, 0.9635, 0.9833, 0.7907,
        0.8741, 0.8513, 0.7265, 2.1220, 0.7637, 1.2430, 0.7621, 0.3848, 0.6438,
        0.7315, 1.7829, 2.7575, 0.9370, 2.2548, 0.8772, 1.0764, 0.9694, 1.0277,
        2.6156, 0.9357, 0.8458, 0.8354, 1.9549, 3.3485, 1.0359, 1.0331, 1.6654,
        3.3959, 0.5916, 3.0607, 0.6798, 0.7269, 0.8293, 3.6239, 3.0529, 1.3191,
        1.9180, 1.7071, 1.1998, 1.1920, 0.6844, 2.9911, 1.4575, 0.8780, 1.1504,
        0.6612, 1.4963, 0.8211, 0.8082, 0.8461, 2.5180, 0.9019, 0.8223, 1.7494,
        0.8599, 0.6567, 2.8968, 0.6830, 1.5257, 1.4085, 0.7229, 0.4705, 1.7594,
        0.6522, 1.2800, 0.6410, 1.0860, 1.1745, 0.7715, 0.5949, 1.4900, 1.2058,
        1.0190, 2.6992, 0.6986, 0.8918, 2.3118, 0.7003, 1.2716, 0.4348, 0.7579,
        1.3396, 1.2720, 0.6944, 0.9272, 2.1283, 1.1670, 1.7028, 1.3858, 1.1011,
        1.5238, 1.0827, 1.4425, 0.7958, 0.4536, 0.7962, 0.7664, 2.1758, 2.1922,
        0.8118, 0.7315, 3.8136, 0.7316, 0.6343, 0.7504, 1.7346, 0.6789, 0.8521,
        0.9468, 0.7298, 0.5112, 0.8121, 0.9129, 2.0955, 1.3363, 1.3179, 0.6450,
        0.7831, 0.6297, 0.4930, 0.5158, 0.6988, 0.6255, 0.7457, 0.7219, 0.9904,
        3.6147, 0.8041, 0.5288, 0.9280, 3.6769, 0.5384, 0.8590, 0.9696, 3.0476,
        2.1836, 0.4106, 1.6406, 2.4854, 1.0830, 2.3914, 0.7690, 1.4891, 3.0309,
        0.8809, 0.4268, 0.6584, 1.3310])
net.mlp.net.1.batch_norm.num_batches_tracked tensor(84)
net.mlp.net.2.linear.weight tensor([[ 0.1046,  0.1163,  0.0424,  ...,  0.0189,  0.0363, -0.1064],
        [ 0.0843, -0.0791,  0.0932,  ..., -0.0176, -0.0657,  0.1245],
        [-0.0279, -0.0962,  0.0111,  ...,  0.0255, -0.0477, -0.0322],
        ...,
        [ 0.0158,  0.0299,  0.1633,  ..., -0.0029,  0.0528,  0.0372],
        [ 0.0122,  0.0262,  0.0469,  ..., -0.0647,  0.0380,  0.0028],
        [-0.0700,  0.0571,  0.0767,  ...,  0.0221,  0.0466,  0.0257]])
net.mlp.net.2.linear.bias tensor([ 0.0051, -0.0511, -0.0864, -0.0426, -0.0221,  0.0437,  0.0316, -0.0326,
         0.0637,  0.0395, -0.1405,  0.0585,  0.0538,  0.0057, -0.0221, -0.0977,
         0.0011, -0.0183, -0.0271, -0.0490,  0.0207,  0.0661, -0.0083, -0.0606,
         0.0758, -0.0776,  0.0177, -0.0510, -0.0292, -0.0525, -0.0137, -0.0482,
         0.0559,  0.0147, -0.0114, -0.0401, -0.0202, -0.0204, -0.0510,  0.0768,
        -0.0686,  0.0612,  0.0819, -0.0622, -0.0471, -0.0658, -0.0418,  0.0009,
        -0.0061,  0.0626, -0.0162, -0.0800, -0.0290,  0.0321, -0.0043, -0.0812,
         0.0653,  0.0214,  0.0719, -0.0428,  0.0072,  0.0310, -0.0421,  0.0128,
        -0.0100,  0.0569,  0.0386,  0.0127,  0.0967,  0.0057, -0.0183, -0.0110,
        -0.0613, -0.0594,  0.0552, -0.0030,  0.0231,  0.0808, -0.0043,  0.0218,
         0.0736,  0.0837, -0.0743,  0.0691,  0.0132,  0.0758, -0.0424,  0.0367,
        -0.0052,  0.0264,  0.1055,  0.0199, -0.0016,  0.0044,  0.0334, -0.0359,
        -0.0400, -0.0080, -0.0720,  0.0644, -0.0452, -0.0823, -0.0187,  0.0416,
        -0.0270,  0.0148, -0.0108,  0.0156,  0.0060, -0.0314,  0.0281,  0.1278,
        -0.0244,  0.1495,  0.0542, -0.1287, -0.0560,  0.1265, -0.0078,  0.0218,
        -0.0823,  0.0407, -0.0423,  0.0290,  0.0979, -0.0177,  0.0809,  0.0140,
         0.0196, -0.0026, -0.0919, -0.0441,  0.0112,  0.0451, -0.1008,  0.0376,
         0.0481, -0.1200, -0.0137, -0.0561,  0.0342, -0.0988, -0.0064, -0.0098,
         0.0154,  0.0171, -0.0441, -0.0020, -0.1068,  0.0820, -0.0351, -0.0488,
         0.0031, -0.0364,  0.0189,  0.0409,  0.0657,  0.0385, -0.0500, -0.0312,
        -0.0361, -0.0367,  0.0049,  0.0031,  0.0473, -0.0671,  0.0302,  0.0481,
         0.0198,  0.0317, -0.0616,  0.0114,  0.0324,  0.0436,  0.1590, -0.0121,
        -0.0184,  0.0467, -0.0037,  0.0649, -0.0890,  0.0550,  0.0469, -0.0236,
        -0.0186,  0.0554,  0.0254, -0.0680, -0.0136,  0.0157,  0.0337, -0.0457,
        -0.0016,  0.0101,  0.0375,  0.0270, -0.0043, -0.0108,  0.0112, -0.0672,
        -0.0733, -0.0353, -0.0517, -0.0586, -0.0160, -0.0192,  0.0023, -0.0722,
         0.0475,  0.0573,  0.0581, -0.0254,  0.0209, -0.0613, -0.0271, -0.0050,
         0.0495,  0.0340, -0.0788,  0.0589, -0.0513, -0.0323,  0.0392, -0.0079,
         0.0435,  0.0442,  0.0287,  0.0371,  0.0032, -0.0886,  0.0334,  0.0366,
        -0.0458,  0.0121,  0.0122, -0.0007, -0.0040,  0.0994, -0.0351, -0.0294,
        -0.0232,  0.0712,  0.0133,  0.0662, -0.0251, -0.0250,  0.0400,  0.0269,
         0.0035,  0.0198, -0.0660,  0.0596, -0.0866, -0.0407,  0.0630, -0.0336])
net.mlp.net.2.batch_norm.weight tensor([0.6744, 0.6732, 0.6867, 0.7059, 0.7270, 0.6821, 0.7071, 0.6873, 0.6271,
        0.7005, 0.7111, 0.6695, 0.6488, 0.6899, 0.7259, 0.7275, 0.6509, 0.7031,
        0.7088, 0.7202, 0.6444, 0.7009, 0.7114, 0.6375, 0.7577, 0.7214, 0.7374,
        0.6536, 0.7208, 0.6757, 0.7038, 0.6249, 0.6820, 0.6448, 0.7150, 0.7113,
        0.7303, 0.6078, 0.6455, 0.6998, 0.6862, 0.7247, 0.7094, 0.5999, 0.6598,
        0.6304, 0.6499, 0.7406, 0.6747, 0.6682, 0.6574, 0.6311, 0.6458, 0.7400,
        0.7479, 0.6062, 0.6833, 0.6805, 0.6571, 0.6405, 0.7442, 0.7485, 0.7370,
        0.7258, 0.6456, 0.7259, 0.7569, 0.6667, 0.7265, 0.6578, 0.6819, 0.7215,
        0.6744, 0.7032, 0.6949, 0.7187, 0.6864, 0.7111, 0.7116, 0.6709, 0.6987,
        0.6281, 0.6789, 0.6598, 0.6830, 0.7097, 0.5834, 0.6768, 0.6077, 0.5648,
        0.6739, 0.6959, 0.6995, 0.6998, 0.6449, 0.6481, 0.7093, 0.6585, 0.6883,
        0.6674, 0.6701, 0.6960, 0.6909, 0.6050, 0.6285, 0.6207, 0.6968, 0.7123,
        0.7053, 0.6849, 0.6783, 0.6547, 0.6785, 0.6509, 0.6670, 0.7163, 0.7020,
        0.6741, 0.7649, 0.6752, 0.7134, 0.7201, 0.6722, 0.6844, 0.6377, 0.6422,
        0.6943, 0.6212, 0.6573, 0.7049, 0.7009, 0.7621, 0.6191, 0.6595, 0.6852,
        0.7418, 0.7119, 0.6711, 0.6597, 0.6972, 0.7267, 0.6390, 0.6919, 0.6987,
        0.6429, 0.7344, 0.6589, 0.6464, 0.6388, 0.6995, 0.6345, 0.6582, 0.6279,
        0.6847, 0.7138, 0.6176, 0.6863, 0.6802, 0.6826, 0.7166, 0.6803, 0.6937,
        0.6887, 0.7412, 0.7351, 0.7369, 0.6767, 0.7201, 0.6711, 0.6566, 0.6850,
        0.6605, 0.6693, 0.6543, 0.6286, 0.7050, 0.6785, 0.7037, 0.7122, 0.7644,
        0.6184, 0.6452, 0.6966, 0.7182, 0.6316, 0.6210, 0.6581, 0.7253, 0.6229,
        0.6210, 0.6828, 0.6758, 0.6496, 0.6349, 0.6660, 0.6938, 0.6650, 0.6668,
        0.7458, 0.5997, 0.6806, 0.7025, 0.6922, 0.7135, 0.7199, 0.6576, 0.6318,
        0.7453, 0.7178, 0.7090, 0.6383, 0.6300, 0.6923, 0.6855, 0.6686, 0.7031,
        0.6944, 0.6255, 0.7088, 0.6755, 0.6996, 0.7188, 0.6451, 0.6424, 0.6393,
        0.6677, 0.6727, 0.6353, 0.6862, 0.7062, 0.7058, 0.6591, 0.7248, 0.6950,
        0.6691, 0.7602, 0.7090, 0.6184, 0.6086, 0.7336, 0.6807, 0.7261, 0.7494,
        0.7017, 0.7216, 0.7359, 0.6785, 0.7081, 0.6597, 0.6476, 0.6525, 0.6866,
        0.6792, 0.6769, 0.7453, 0.6898])
net.mlp.net.2.batch_norm.bias tensor([-0.0564,  0.0325, -0.0910,  0.0194,  0.0786,  0.0224, -0.0460, -0.0304,
         0.0488, -0.0447, -0.0190, -0.0642, -0.0269, -0.0413,  0.0809, -0.0365,
        -0.0482, -0.0208,  0.0457,  0.0228, -0.0929, -0.0299,  0.0434,  0.0114,
        -0.0697, -0.0177,  0.0093, -0.0032,  0.0295,  0.0712, -0.0086,  0.0241,
        -0.0367, -0.0214, -0.0447,  0.0513, -0.0274,  0.0155,  0.0848, -0.0061,
        -0.0148, -0.0335, -0.1213, -0.0048,  0.0143,  0.1228, -0.0026,  0.0571,
         0.0237, -0.0039, -0.0186,  0.0090,  0.0825,  0.0310,  0.0531,  0.0073,
        -0.0280,  0.0760, -0.0813, -0.0292,  0.1004,  0.0155, -0.0336, -0.0543,
         0.0340,  0.0714, -0.0356,  0.0131,  0.0057, -0.0592, -0.0880,  0.0124,
         0.0133,  0.0037,  0.0183, -0.0270,  0.0226, -0.0195, -0.0236, -0.0206,
        -0.0167,  0.0477, -0.0041, -0.0168,  0.0083, -0.0303,  0.0537, -0.0255,
        -0.0484, -0.0139,  0.0417, -0.0047, -0.0453,  0.0186,  0.0342,  0.0683,
        -0.0275, -0.0463,  0.0189, -0.0275, -0.0080,  0.0221,  0.0698, -0.0363,
         0.0436,  0.0156,  0.0054,  0.0522, -0.0030, -0.0045,  0.0630, -0.0983,
         0.0342,  0.0428,  0.0010, -0.0175,  0.0191,  0.0368, -0.0109, -0.0244,
        -0.0140,  0.0375,  0.0013,  0.0135,  0.0396, -0.0021,  0.0426, -0.0755,
        -0.0645, -0.0111, -0.0127, -0.0274, -0.0351,  0.0227, -0.0897, -0.0320,
        -0.0244,  0.0226,  0.0285, -0.0637, -0.0632,  0.0430, -0.0059, -0.0708,
        -0.0760, -0.0302,  0.0258,  0.0317, -0.0182, -0.0603, -0.0536,  0.0698,
         0.0063,  0.0546,  0.0345, -0.0549,  0.0408,  0.0474,  0.0037, -0.0524,
         0.0650,  0.0391, -0.0563, -0.0217, -0.0140,  0.0363,  0.0570,  0.0496,
         0.0084,  0.0504, -0.0823, -0.0511,  0.0342,  0.0302,  0.0493,  0.0435,
         0.0224,  0.0424,  0.0592, -0.0686,  0.0007, -0.0600,  0.0581, -0.0513,
         0.0716,  0.0865,  0.0047, -0.0193,  0.0488,  0.0004,  0.0520, -0.0120,
         0.0163, -0.0917,  0.0711, -0.1359, -0.0091, -0.0289,  0.0127, -0.0081,
         0.0189, -0.0019,  0.0039, -0.0101,  0.0907,  0.0025, -0.0407, -0.0296,
        -0.0704, -0.0886, -0.0429, -0.0060,  0.0245, -0.0105, -0.0223, -0.0154,
        -0.0272,  0.0168,  0.0212,  0.0855, -0.0430,  0.0336, -0.0242,  0.0574,
         0.0616, -0.0214,  0.0107,  0.0010, -0.0121,  0.0332,  0.0054,  0.0097,
        -0.1003,  0.1391, -0.0836, -0.0714,  0.0325,  0.0168, -0.0263,  0.0589,
         0.0433,  0.0664,  0.0297,  0.0056,  0.0583, -0.0221, -0.0232, -0.0078,
        -0.0170, -0.0088, -0.0372, -0.0370, -0.0647,  0.0451, -0.0332,  0.0977])
net.mlp.net.2.batch_norm.running_mean tensor([0.6541, 0.4559, 0.4228, 0.7974, 0.5992, 0.4889, 0.6496, 0.5594, 0.6381,
        0.7495, 0.5820, 0.6119, 0.5878, 0.5563, 0.4940, 0.5077, 0.5165, 0.3743,
        0.6723, 0.5174, 0.5202, 0.3979, 0.4741, 0.4605, 0.5485, 0.3225, 0.6526,
        0.5469, 0.5573, 0.4495, 0.3786, 0.3868, 0.6791, 0.7443, 0.4103, 0.6631,
        0.4478, 0.6203, 0.4057, 0.5706, 0.3293, 0.8176, 0.4661, 0.5764, 0.4436,
        0.3990, 0.5974, 0.4535, 0.3664, 0.5897, 0.5814, 0.4030, 0.4261, 0.4720,
        0.6088, 0.6829, 0.8092, 0.5274, 0.6328, 0.5556, 0.5731, 0.6885, 0.4318,
        0.8167, 0.4335, 0.7033, 0.6398, 0.6473, 0.8666, 0.6274, 0.4800, 0.7679,
        0.6019, 0.6108, 0.6302, 0.6367, 0.5085, 0.6888, 0.6938, 0.7563, 0.5518,
        0.6355, 0.4446, 0.5744, 0.6515, 0.6268, 0.4170, 0.6348, 0.7100, 0.3861,
        0.7503, 0.8584, 0.4430, 0.5916, 0.5549, 0.6716, 0.7580, 0.5723, 0.5063,
        0.5834, 0.4946, 0.3352, 0.4930, 0.5711, 0.8566, 0.4384, 0.5549, 0.4728,
        0.6296, 0.2218, 0.6642, 0.5707, 0.5760, 0.7185, 0.5291, 0.5523, 0.4631,
        0.5935, 0.8116, 0.6086, 0.6120, 0.8021, 0.5906, 0.5679, 0.6183, 0.5559,
        0.6549, 0.4743, 0.6133, 0.7098, 0.5427, 0.4916, 0.6673, 0.7888, 0.4004,
        0.4368, 0.6853, 0.5653, 0.5205, 0.5107, 0.6626, 0.4964, 0.6267, 0.6205,
        0.6180, 0.4351, 0.5419, 0.3286, 0.5438, 0.5144, 0.6103, 0.5829, 0.4509,
        0.4884, 0.5557, 0.6368, 0.5001, 0.7830, 0.6918, 0.6049, 0.4715, 0.6096,
        0.5606, 0.5530, 0.4508, 0.7558, 0.5048, 0.4741, 0.6426, 0.5242, 0.6563,
        0.5058, 0.6604, 0.6912, 0.6748, 0.5771, 0.4296, 0.5935, 0.6377, 0.5275,
        0.4282, 0.7063, 0.6012, 0.4092, 0.4667, 0.5424, 0.6070, 0.4469, 0.6400,
        0.5624, 0.7319, 0.5583, 0.6871, 0.6783, 0.4947, 0.5695, 0.6559, 0.4062,
        0.6612, 0.6981, 0.5329, 0.3993, 0.4280, 0.4866, 0.5850, 0.5201, 0.7597,
        0.4713, 0.6517, 0.5073, 0.4589, 0.4888, 0.6408, 0.4992, 0.6629, 0.5249,
        0.6675, 0.5588, 0.4284, 0.7474, 0.4117, 0.5164, 0.5042, 0.3572, 0.5915,
        0.8362, 0.4896, 0.7377, 0.5863, 0.5067, 0.7582, 0.4840, 0.5447, 0.6621,
        0.6356, 0.5041, 0.6900, 1.0464, 0.5976, 0.5504, 0.5626, 0.7448, 0.7328,
        0.5645, 0.6781, 0.9219, 0.5196, 0.6790, 0.5721, 0.5140, 0.3979, 0.5648,
        0.4748, 0.5794, 0.6437, 0.5605])
net.mlp.net.2.batch_norm.running_var tensor([2.1224, 2.3699, 0.5347, 1.5471, 2.8555, 0.5873, 0.7730, 0.6954, 0.7900,
        1.0950, 0.8519, 0.7605, 0.7176, 0.9001, 2.3887, 3.0386, 1.1386, 0.3014,
        2.5406, 1.3960, 0.3942, 0.3375, 0.9033, 0.4430, 1.0338, 0.5719, 0.9462,
        0.8042, 0.9335, 0.9076, 0.4072, 0.7580, 3.2519, 1.3202, 0.7637, 0.9897,
        1.4712, 0.6984, 0.6258, 0.8563, 0.3584, 2.2474, 0.7995, 1.1125, 0.3982,
        0.5447, 0.9596, 0.9722, 0.5047, 0.6758, 1.0478, 0.5586, 0.7258, 0.6027,
        1.9447, 2.4388, 1.7565, 1.0070, 0.8654, 2.1805, 2.2778, 4.3439, 0.5385,
        1.3914, 1.9863, 0.9592, 1.8089, 2.5422, 1.2972, 0.7327, 1.7868, 1.3642,
        0.7801, 1.9402, 0.7602, 1.1511, 1.0796, 1.4665, 1.1662, 1.4285, 0.5064,
        0.7289, 0.4312, 1.9404, 1.1159, 0.8730, 1.4514, 0.7795, 0.9610, 0.6265,
        1.1189, 1.8576, 1.2485, 1.7898, 2.3034, 1.2013, 2.2713, 2.6549, 0.7366,
        0.7751, 0.8716, 0.3325, 1.4661, 0.4226, 1.8452, 1.3578, 2.6228, 0.9492,
        0.9437, 0.2667, 0.8973, 0.5304, 0.7973, 0.8724, 0.6767, 1.2093, 2.9977,
        2.4729, 1.9401, 1.0337, 3.2904, 3.5431, 1.7481, 1.1235, 0.7247, 0.7332,
        0.5904, 1.6459, 1.1873, 2.5507, 2.0524, 1.5266, 1.2057, 1.2015, 0.7067,
        0.3472, 1.2399, 1.9742, 3.2098, 2.3197, 2.2896, 2.7003, 1.1838, 1.0062,
        1.9507, 0.4106, 0.6118, 0.3033, 1.2180, 1.7823, 1.3932, 0.9802, 0.4046,
        1.0541, 0.6553, 1.0270, 0.4783, 1.5016, 0.9817, 1.3637, 0.6748, 0.7690,
        1.2864, 1.6610, 0.7009, 1.0757, 0.9726, 0.5753, 1.1607, 1.3883, 1.3386,
        0.4321, 0.8740, 1.0112, 0.8311, 1.2916, 0.5385, 0.7267, 0.9205, 1.0525,
        0.7225, 1.2826, 1.1927, 0.4215, 1.4666, 0.8479, 1.0811, 1.6568, 0.8187,
        0.6057, 0.8719, 1.2312, 2.8585, 0.8134, 1.1009, 2.5880, 0.7596, 0.5719,
        3.1209, 1.0364, 0.5198, 0.5904, 0.3934, 2.1593, 3.1209, 1.2758, 1.8776,
        0.6280, 1.0426, 0.6531, 0.8188, 2.2929, 0.9951, 1.6297, 1.2899, 1.4700,
        0.9375, 1.6584, 2.0120, 2.6272, 2.0686, 0.7849, 0.8159, 0.4117, 0.5520,
        1.2980, 0.9634, 0.8732, 2.2139, 0.9699, 3.1836, 0.6842, 2.1261, 1.1429,
        1.4139, 1.0003, 1.8026, 1.6463, 1.0001, 0.9622, 0.5880, 1.0278, 2.7991,
        1.0697, 3.8069, 2.4318, 1.3293, 1.0928, 0.5284, 1.6428, 0.7195, 3.6174,
        1.3700, 1.1715, 1.1677, 2.4920])
net.mlp.net.2.batch_norm.num_batches_tracked tensor(84)
net.mlp.net.3.linear.weight tensor([[-0.0029,  0.0814,  0.0613,  ...,  0.0910, -0.0190, -0.0274],
        [-0.0098, -0.0561, -0.0696,  ..., -0.1198, -0.0513,  0.0070],
        [ 0.0019,  0.0022,  0.0989,  ...,  0.0974,  0.0520,  0.0213],
        ...,
        [-0.0505, -0.0120,  0.1047,  ..., -0.1258,  0.1873, -0.1074],
        [-0.0408,  0.0500,  0.0226,  ...,  0.0071,  0.0349, -0.1405],
        [ 0.0087, -0.0174, -0.0945,  ...,  0.0374, -0.0807, -0.0552]])
net.mlp.net.3.linear.bias tensor([-0.0661, -0.0289,  0.0300, -0.0073, -0.0675,  0.0342,  0.0330, -0.0262,
        -0.0134, -0.0624,  0.0414,  0.0247, -0.0624,  0.0002,  0.0262,  0.0292,
        -0.0176, -0.0222,  0.0156, -0.0563, -0.0441,  0.0368, -0.0590, -0.0647,
         0.0128, -0.0349, -0.0104, -0.0202, -0.0843,  0.0213, -0.0182, -0.0440,
        -0.0351, -0.0395, -0.0005,  0.0478,  0.0192, -0.1249,  0.0052, -0.0951,
         0.0469,  0.0040, -0.0094,  0.0017,  0.0592, -0.0455, -0.0865, -0.0329,
         0.0639, -0.0581, -0.0298, -0.0379,  0.0353,  0.0644,  0.0094,  0.0565,
         0.0043,  0.0181,  0.0490,  0.0014, -0.0696, -0.0116, -0.0643,  0.0541,
         0.0724,  0.1366, -0.0079, -0.0451, -0.0020, -0.0239,  0.0676,  0.0491,
         0.0003, -0.0726,  0.0007,  0.0912,  0.0843, -0.0795, -0.0092, -0.0817,
        -0.0380,  0.0358,  0.0351,  0.0237, -0.0304,  0.0282,  0.0045, -0.0708,
        -0.0329, -0.0005, -0.0176,  0.1024,  0.0722, -0.0237, -0.0247, -0.1108,
        -0.0518,  0.0587, -0.0441,  0.0032, -0.1158,  0.0625,  0.0798, -0.0173,
         0.0336,  0.0168, -0.0420,  0.0382, -0.0519, -0.0607, -0.0655,  0.0149,
         0.0298, -0.0454, -0.0608, -0.1219,  0.0598, -0.0187, -0.0671,  0.0060,
         0.0858,  0.0370, -0.0056,  0.0072,  0.0320,  0.0124, -0.0154, -0.0803,
         0.0211,  0.0208, -0.0009,  0.0453,  0.1050, -0.0191, -0.0171, -0.0048,
        -0.0709,  0.0396,  0.0301,  0.0486,  0.0198, -0.0520,  0.0226, -0.1666,
         0.0177, -0.0491,  0.0344,  0.0915, -0.0333, -0.0292,  0.0368, -0.0674,
         0.0024, -0.0043, -0.0099,  0.0699,  0.0481, -0.0515,  0.1130,  0.0306,
         0.0389, -0.0752, -0.0538,  0.0333,  0.0363,  0.0034, -0.0942, -0.0055,
        -0.0441, -0.0651,  0.0459, -0.0950,  0.0319,  0.0722, -0.0061,  0.0561,
        -0.0820, -0.0646, -0.0072, -0.0019,  0.0022, -0.0521,  0.0067, -0.0399,
        -0.0415, -0.0125, -0.0339, -0.0090, -0.0163, -0.0099,  0.0215,  0.0654,
        -0.0236, -0.0626,  0.0013, -0.0437, -0.0303,  0.0327,  0.0179,  0.0061,
         0.0077, -0.0287, -0.1072, -0.0613, -0.0106,  0.0128,  0.0350,  0.0589,
         0.0019,  0.0797,  0.0352,  0.0712,  0.0243,  0.0698, -0.0173,  0.0380,
        -0.0294, -0.0366, -0.1242, -0.0365,  0.0399,  0.0546, -0.0050, -0.0268,
         0.0228,  0.0156,  0.0577,  0.0552, -0.0333,  0.0103,  0.0040, -0.0433,
         0.0357, -0.0034, -0.1038, -0.0265,  0.0176,  0.1485,  0.0171, -0.0590,
         0.0694, -0.0027, -0.0330, -0.0270,  0.0591,  0.0066, -0.0263,  0.0173,
         0.0462,  0.0464, -0.0424,  0.0091, -0.0037, -0.0368, -0.0409, -0.0663])
net.mlp.net.3.batch_norm.weight tensor([0.5739, 0.6306, 0.6754, 0.6580, 0.6068, 0.6165, 0.6292, 0.5874, 0.6214,
        0.7186, 0.6611, 0.7375, 0.6305, 0.7232, 0.6371, 0.7477, 0.6454, 0.6384,
        0.6234, 0.6572, 0.6575, 0.6440, 0.6686, 0.5911, 0.7146, 0.6249, 0.6588,
        0.6683, 0.6439, 0.6503, 0.6937, 0.6313, 0.6896, 0.6607, 0.6035, 0.6511,
        0.6929, 0.6400, 0.6047, 0.6680, 0.6451, 0.5959, 0.6455, 0.6180, 0.7157,
        0.6433, 0.6904, 0.6338, 0.6911, 0.6370, 0.7263, 0.6565, 0.7061, 0.6683,
        0.6546, 0.6744, 0.6486, 0.6184, 0.6704, 0.6449, 0.6637, 0.6763, 0.6627,
        0.6305, 0.6700, 0.6050, 0.6540, 0.6976, 0.6131, 0.6477, 0.6697, 0.6475,
        0.6227, 0.6570, 0.6544, 0.7228, 0.7057, 0.6611, 0.6710, 0.6512, 0.6467,
        0.6521, 0.7179, 0.6509, 0.6723, 0.6260, 0.6419, 0.6274, 0.6994, 0.6559,
        0.6044, 0.6208, 0.6793, 0.6755, 0.7180, 0.7126, 0.6436, 0.6397, 0.6609,
        0.6472, 0.7615, 0.6638, 0.5947, 0.6417, 0.6614, 0.6630, 0.6921, 0.6433,
        0.6347, 0.6548, 0.6494, 0.6306, 0.6252, 0.6957, 0.6932, 0.6598, 0.6344,
        0.6569, 0.6469, 0.6750, 0.6185, 0.6893, 0.6512, 0.6241, 0.6374, 0.6693,
        0.7068, 0.6723, 0.6751, 0.6526, 0.6255, 0.6599, 0.6263, 0.6483, 0.6414,
        0.6396, 0.6572, 0.6717, 0.7047, 0.6337, 0.6729, 0.6369, 0.6484, 0.6525,
        0.6265, 0.6406, 0.6653, 0.6624, 0.6430, 0.6000, 0.7009, 0.7301, 0.6278,
        0.6495, 0.6518, 0.6681, 0.6201, 0.6557, 0.6319, 0.6591, 0.6387, 0.7002,
        0.6259, 0.6486, 0.6135, 0.6636, 0.6722, 0.6709, 0.6507, 0.6365, 0.6891,
        0.6869, 0.6379, 0.6392, 0.6771, 0.7233, 0.6556, 0.6494, 0.6461, 0.6325,
        0.5817, 0.6676, 0.6544, 0.6931, 0.6487, 0.6137, 0.7209, 0.6777, 0.6674,
        0.6458, 0.6237, 0.6522, 0.6730, 0.6821, 0.6752, 0.6560, 0.6227, 0.6147,
        0.6536, 0.6352, 0.6460, 0.7086, 0.5980, 0.7174, 0.6719, 0.6907, 0.6828,
        0.6635, 0.6313, 0.6438, 0.6832, 0.6333, 0.6932, 0.6736, 0.6416, 0.6549,
        0.6953, 0.6052, 0.7078, 0.5858, 0.6553, 0.6430, 0.6462, 0.6625, 0.6367,
        0.6135, 0.6623, 0.6447, 0.6099, 0.6379, 0.6626, 0.6261, 0.6843, 0.6137,
        0.6797, 0.6230, 0.6813, 0.6653, 0.6606, 0.5835, 0.6412, 0.6440, 0.6041,
        0.6677, 0.6236, 0.6499, 0.6377, 0.6287, 0.6542, 0.6648, 0.6171, 0.6707,
        0.6661, 0.6502, 0.6502, 0.6686])
net.mlp.net.3.batch_norm.bias tensor([ 2.2903e-02, -9.8079e-02, -4.9057e-02,  8.0247e-02, -2.0921e-02,
        -2.2399e-02,  4.7812e-02,  5.3015e-02,  4.8060e-02,  3.8162e-02,
        -1.2934e-02,  2.5790e-02,  8.5911e-03, -3.2969e-02,  5.2799e-02,
         8.5450e-02,  1.5190e-02, -8.4535e-05,  6.2444e-03,  8.2711e-02,
        -6.1923e-02, -3.2393e-02,  4.3243e-03,  1.2337e-02,  7.1555e-03,
         6.5878e-02,  4.3599e-03, -4.9687e-03,  6.5256e-02,  7.4658e-02,
         2.6731e-02, -2.6065e-03,  8.2349e-03,  3.9881e-02, -3.0997e-02,
         5.8111e-03,  1.0554e-01, -6.0852e-02, -9.9531e-02,  2.8288e-03,
         2.9695e-02, -3.2559e-02,  2.0087e-02,  1.0828e-02,  5.5621e-02,
        -3.4428e-02,  5.5806e-03, -6.7573e-02, -6.3476e-02, -8.0801e-02,
         1.0136e-01, -3.3531e-02, -3.3013e-02,  2.8664e-02,  5.3202e-02,
        -6.3239e-02, -3.0847e-02,  7.8831e-03,  4.5664e-02,  2.8206e-02,
         3.6747e-02,  1.0650e-02,  5.2502e-02,  3.4088e-03, -1.6858e-03,
         4.3335e-02,  2.5817e-04, -5.0613e-02,  5.5927e-02,  3.3225e-02,
        -2.6182e-03, -3.5532e-02, -4.4986e-02,  7.8343e-03,  3.4807e-03,
         1.1644e-02, -9.0769e-02,  4.4868e-02,  4.0716e-02, -5.1014e-04,
         1.5828e-03, -3.4362e-02, -3.1969e-02,  3.2531e-02, -1.8206e-02,
         4.8473e-02,  2.0757e-02,  1.0538e-02, -1.7689e-02,  9.7801e-03,
         1.1960e-02,  4.8695e-02, -1.4788e-02,  5.9389e-02, -1.3332e-03,
         1.0708e-01,  3.0472e-02, -2.0781e-02, -9.3834e-02,  1.0229e-02,
         8.6011e-02,  4.1258e-02, -5.8476e-02,  3.5098e-04, -1.2802e-02,
         4.4808e-02, -2.4184e-02,  3.1906e-02,  6.1749e-03, -3.6528e-03,
        -4.6647e-03,  5.6861e-02,  5.6424e-02,  1.1171e-02, -1.6191e-02,
        -1.8670e-02, -2.9359e-02, -1.5466e-04, -2.1741e-02, -5.6579e-02,
         1.3809e-02, -7.2906e-02,  1.6055e-02, -2.6683e-02, -6.7378e-02,
        -9.4834e-03, -1.1354e-02,  2.7653e-03,  4.3119e-02,  5.0196e-02,
         4.2616e-03,  2.0523e-02, -4.9271e-02, -6.6984e-02, -5.4312e-02,
        -1.4147e-02, -4.0708e-02, -3.1177e-02,  5.6858e-03,  8.6383e-02,
        -2.1331e-02, -4.9743e-02,  3.7617e-02, -1.1571e-01, -1.6002e-02,
        -2.5846e-02, -1.1281e-02,  2.0185e-02,  4.2588e-02, -1.9222e-02,
         3.0439e-02, -1.9508e-02, -3.8722e-02,  3.9592e-02,  4.2579e-02,
         3.3391e-02,  2.7567e-02, -8.3266e-02, -5.1340e-02, -9.6589e-03,
         2.6442e-02,  3.1554e-02, -9.1207e-03, -1.7715e-02, -1.4858e-02,
         6.3034e-03, -2.0601e-02, -1.7291e-02, -6.8567e-02, -5.7525e-02,
        -8.5679e-02,  5.7613e-02, -5.2704e-03, -4.7683e-02,  8.6033e-03,
        -5.7750e-02,  1.9896e-02,  1.8540e-02, -1.9640e-02,  3.1101e-02,
        -2.5325e-02,  3.8156e-02,  9.5736e-02, -4.7039e-02,  3.0087e-02,
        -9.1714e-03, -2.3746e-02, -2.0855e-02, -3.6751e-03,  2.1256e-02,
         1.0026e-03, -1.8326e-03, -6.9143e-02, -4.4519e-02,  1.3535e-02,
        -8.5065e-02, -3.1746e-02, -7.5103e-03, -5.7521e-02,  6.9849e-02,
        -1.0411e-03, -8.3718e-02, -2.0009e-02, -1.1055e-01, -3.6564e-03,
         1.4815e-04, -2.7413e-03,  3.6219e-02,  2.5223e-03,  4.9221e-04,
         7.8753e-02,  2.3820e-02, -2.2452e-02, -5.2940e-02, -7.3205e-02,
        -5.3230e-03, -4.3164e-02,  6.9854e-02, -1.2792e-02, -5.5181e-02,
        -7.1184e-03,  5.8961e-02, -5.1326e-03, -5.9080e-02, -2.4282e-02,
        -1.0435e-01, -6.1002e-03,  2.9194e-02, -2.9363e-02, -1.5541e-02,
         4.0309e-03,  4.7308e-02, -5.0195e-02,  2.6658e-02, -9.8649e-03,
         1.7522e-02, -4.9637e-03,  1.0047e-02,  5.4300e-03,  7.6574e-02,
         1.9543e-02, -3.1369e-02, -8.1541e-02, -9.3834e-02,  1.4485e-02,
        -1.1923e-03,  3.3539e-02, -5.0409e-02,  7.9413e-02, -4.9371e-02,
         8.9522e-03,  5.6479e-03, -3.8998e-02, -4.8918e-02,  4.9013e-02,
        -7.5748e-02])
net.mlp.net.3.batch_norm.running_mean tensor([0.4379, 0.4235, 0.6326, 0.5553, 0.5072, 0.6150, 0.8255, 0.4099, 0.6137,
        0.6068, 0.5792, 0.9148, 0.3893, 0.6916, 0.4894, 0.6510, 0.3156, 0.4625,
        0.6135, 0.6559, 0.3428, 0.5278, 0.7880, 0.4502, 0.5846, 0.3577, 0.3260,
        0.6061, 0.4870, 0.9264, 0.8200, 0.5772, 0.8041, 0.4056, 0.3651, 0.5958,
        0.5978, 0.6226, 0.7095, 0.3995, 0.4457, 0.6314, 0.5399, 0.6396, 0.5233,
        0.4732, 0.7230, 0.4977, 0.6174, 0.5769, 0.4764, 0.5410, 0.7788, 0.5081,
        0.7385, 0.8162, 0.5164, 0.6501, 0.5363, 0.6135, 0.4040, 0.7533, 0.7925,
        0.5652, 0.7032, 0.4509, 0.3565, 0.6143, 0.6332, 0.4642, 0.4700, 0.7177,
        0.6013, 0.3170, 0.4001, 0.7654, 0.6808, 0.6019, 0.6405, 0.5315, 0.3528,
        0.5819, 0.5679, 0.6425, 0.4654, 0.7428, 0.4874, 0.3913, 0.4443, 0.7647,
        0.4335, 0.6340, 0.6680, 0.5454, 0.6635, 0.7155, 0.3595, 0.5376, 0.4644,
        0.6046, 0.6914, 0.6058, 0.3825, 0.6697, 0.7815, 0.4916, 0.4392, 0.4504,
        0.4959, 0.6655, 0.6322, 0.5152, 0.6790, 0.7970, 0.5947, 0.3952, 0.5306,
        0.4367, 0.4832, 0.5886, 0.8249, 0.9664, 0.4532, 0.5745, 0.6493, 0.7205,
        0.8625, 0.6633, 0.5447, 0.4986, 0.3509, 0.5787, 0.9971, 0.6620, 0.6993,
        0.6493, 0.3962, 0.4951, 0.4661, 0.5031, 0.5970, 0.3616, 0.5897, 0.4213,
        0.4095, 0.5980, 0.5252, 0.9610, 0.4532, 0.4407, 1.0155, 0.6482, 0.5115,
        0.5434, 0.4778, 0.7253, 0.4451, 0.6201, 0.5739, 0.4558, 0.5860, 0.4199,
        0.5110, 0.7861, 0.5660, 0.5843, 0.5026, 0.5569, 0.5410, 0.6327, 0.7234,
        0.5343, 0.4632, 0.5621, 0.6199, 0.6671, 0.4919, 0.5483, 0.5433, 0.4070,
        0.7531, 0.7364, 0.6642, 0.4634, 0.7263, 0.4136, 0.4461, 0.3915, 0.4202,
        0.3475, 0.3725, 0.4453, 0.5154, 0.4933, 0.7092, 0.5437, 0.5783, 0.5282,
        0.6793, 0.3927, 0.4703, 0.9121, 0.6785, 0.6014, 0.5982, 0.4304, 0.7942,
        0.8418, 0.6973, 0.7050, 0.9370, 0.6793, 0.9964, 0.7097, 0.3971, 0.3963,
        0.5913, 0.3631, 0.5648, 0.5283, 0.5136, 0.5994, 0.4934, 0.5500, 0.5768,
        0.5547, 0.7409, 0.4196, 0.6048, 0.4832, 0.8069, 0.4995, 0.6569, 0.4014,
        0.3483, 0.4636, 0.5093, 0.8851, 0.6391, 0.3095, 0.4498, 0.3726, 0.5561,
        0.5567, 0.4830, 0.5698, 0.7352, 0.4750, 0.5381, 0.6242, 0.5588, 0.7154,
        0.4781, 0.3604, 0.6669, 0.4885])
net.mlp.net.3.batch_norm.running_var tensor([0.6453, 1.2875, 3.6066, 1.5026, 0.5421, 0.5924, 0.9876, 1.7151, 0.6878,
        2.9507, 0.7862, 1.3615, 1.5605, 4.7427, 0.6055, 4.4224, 0.4046, 1.3897,
        0.7375, 0.7507, 0.5483, 0.5928, 5.4838, 0.6127, 3.6129, 0.7158, 0.5261,
        1.3524, 1.3443, 1.4424, 1.6545, 2.4199, 4.9193, 0.4027, 0.3654, 0.5782,
        1.6867, 1.1237, 3.9831, 0.7578, 0.4375, 1.5631, 0.5529, 0.7630, 0.8256,
        1.2660, 1.3774, 0.5450, 1.8489, 3.0440, 1.2077, 3.1420, 2.9049, 2.1552,
        0.8803, 3.1586, 0.4852, 4.1858, 1.4025, 0.6295, 2.4293, 4.0931, 3.1195,
        0.5785, 1.7162, 0.4952, 0.4128, 5.2022, 0.5906, 1.5859, 1.1038, 1.0878,
        0.5936, 0.4570, 1.1775, 1.1634, 1.1538, 5.0617, 1.2122, 1.4727, 0.3743,
        2.6236, 0.6808, 1.4611, 1.1430, 2.4087, 0.9651, 1.1339, 0.6442, 1.0356,
        0.8616, 1.7513, 1.2216, 2.8562, 3.7031, 1.2637, 0.2889, 0.4340, 2.1966,
        2.8355, 5.8430, 3.1149, 0.4016, 0.8703, 1.0908, 0.6406, 2.8228, 1.0789,
        3.0193, 1.4889, 1.6228, 1.5683, 1.7229, 1.4305, 1.9105, 1.4440, 1.2070,
        1.3444, 1.0227, 2.5674, 1.0186, 3.9966, 0.4247, 1.0209, 2.6439, 0.6722,
        2.7497, 1.3060, 1.1315, 1.1168, 0.5739, 1.0271, 1.2335, 4.1085, 0.8668,
        0.6850, 1.2207, 2.0124, 0.8045, 1.0833, 1.6738, 0.4128, 0.5081, 1.7124,
        0.4746, 1.3545, 1.2467, 1.3501, 0.8261, 0.7295, 1.8221, 5.2765, 0.5743,
        0.9130, 1.5801, 0.9182, 0.4858, 2.1456, 0.8577, 0.7486, 0.6240, 0.5063,
        1.7129, 0.8191, 1.8746, 3.0118, 1.4527, 2.8758, 0.7796, 3.9387, 1.2244,
        1.3933, 0.4574, 0.6956, 2.0561, 2.4149, 0.4797, 0.7793, 2.0305, 0.7913,
        1.1514, 0.9682, 3.9233, 1.5717, 1.0167, 0.4097, 2.3117, 0.5985, 1.0329,
        0.4203, 1.4489, 1.2325, 1.4627, 2.4369, 3.9082, 1.8683, 2.6534, 1.0559,
        1.0796, 0.8519, 0.6013, 1.5168, 2.4194, 3.9349, 4.3086, 2.1814, 1.7514,
        0.9529, 0.6664, 1.5117, 1.5890, 1.5866, 2.3436, 1.6787, 0.5265, 0.7436,
        2.7758, 1.3604, 3.3888, 0.6482, 0.9586, 0.8614, 0.7545, 1.9157, 4.0697,
        1.2284, 0.9663, 0.8438, 1.1622, 0.5739, 1.0202, 0.9273, 2.0047, 1.6323,
        0.4536, 1.4618, 0.9021, 1.3250, 3.1717, 0.3712, 0.5623, 0.6018, 3.6861,
        1.7759, 0.6925, 1.9863, 0.9105, 0.3495, 0.5269, 0.8497, 2.1821, 3.8661,
        0.4557, 0.6983, 1.6379, 2.6200])
net.mlp.net.3.batch_norm.num_batches_tracked tensor(84)
net.mlp.net.4.weight tensor([[-2.1393e-03,  1.8548e-02,  5.8050e-02, -3.9264e-02, -8.7297e-03,
         -4.4620e-03,  2.8479e-02,  1.4750e-02, -9.6961e-03,  7.1048e-02,
         -2.8290e-02,  6.1511e-02,  3.0915e-02, -6.2616e-02,  2.0107e-02,
         -6.3984e-02, -1.3624e-02,  1.4878e-02, -2.9453e-02, -3.6173e-02,
          1.0047e-02, -1.0183e-02, -4.7287e-02, -1.2774e-02,  5.4371e-02,
         -9.1710e-03, -2.2022e-02, -1.9552e-02, -2.5491e-02,  8.0538e-03,
          3.1577e-02,  1.5771e-02,  4.5950e-02,  1.8564e-02,  4.0015e-03,
          1.0381e-02,  3.8211e-02, -1.0949e-02, -2.9541e-02, -1.8428e-02,
          1.5353e-03,  1.7548e-03,  1.5091e-02, -1.8767e-02, -5.6215e-02,
         -2.2038e-02,  4.5134e-02,  8.3523e-03, -3.5433e-02,  2.7485e-02,
         -6.7720e-02,  3.6219e-02, -5.9474e-02,  2.5283e-02,  2.4675e-02,
         -2.7016e-02, -2.3095e-02,  2.7036e-02, -2.1825e-02,  3.1594e-05,
         -9.6321e-03,  5.9681e-02,  2.8187e-02, -5.5817e-03, -4.3045e-02,
          8.4494e-03,  4.5042e-03, -4.3368e-02,  2.2510e-02,  1.7568e-02,
         -3.8351e-02,  3.7969e-02, -2.3928e-02, -1.4309e-04,  1.1915e-02,
         -7.0582e-02, -5.7506e-02, -4.8173e-02, -3.2271e-02,  3.5657e-02,
          1.7903e-02, -1.4972e-02, -6.4478e-02, -1.3624e-02, -1.4040e-02,
         -4.5382e-04,  2.8844e-02,  1.1475e-02, -5.0548e-02,  2.3459e-02,
          3.4898e-04, -1.0577e-02, -3.7993e-02,  2.6674e-02, -6.1614e-02,
          6.6832e-02, -7.1304e-03, -1.7230e-02,  3.0231e-02, -5.8673e-03,
         -7.4914e-02, -4.7874e-02,  2.9563e-02,  3.1947e-02,  1.4444e-02,
         -3.2011e-02,  5.8455e-02, -2.3104e-02, -1.2956e-02, -2.8562e-02,
         -9.9340e-03, -3.0401e-02, -2.2166e-02,  6.7330e-02, -4.4510e-02,
         -3.0323e-02, -6.5557e-03,  1.7276e-02,  2.2396e-02, -3.5332e-02,
          2.5093e-02, -4.8846e-02,  1.8897e-02, -2.6556e-02, -5.3451e-03,
         -2.8267e-02, -6.2441e-02, -4.1177e-02, -2.9737e-02,  9.7656e-03,
         -2.8320e-02, -3.4783e-02, -2.5736e-02,  3.6076e-02,  6.3033e-03,
         -1.9797e-02,  5.8413e-03, -2.7015e-02, -6.7689e-02, -2.5197e-02,
          3.6696e-02, -3.7032e-03,  2.6082e-03,  4.7589e-02,  9.2648e-03,
         -2.5177e-02, -4.1011e-03,  3.2823e-02,  2.6142e-02,  6.7833e-03,
          5.8548e-02, -7.7783e-02,  2.7000e-04, -3.2832e-03,  3.4995e-03,
         -4.1151e-02, -2.8297e-03, -3.9051e-02,  1.6744e-02,  2.2394e-03,
          4.2005e-04, -3.8199e-02,  2.4008e-02, -2.2918e-02, -2.1009e-02,
          2.4575e-02,  4.3377e-02,  1.6835e-02, -3.4781e-02,  1.0266e-02,
          5.9070e-02, -4.6514e-02, -2.5062e-03, -2.9668e-02, -4.5769e-02,
         -8.1954e-02, -2.9342e-02, -1.0883e-02, -1.8808e-02, -2.2300e-02,
         -4.7271e-03,  3.3535e-02, -1.9604e-02, -4.8287e-02,  1.1864e-03,
          3.5142e-02, -5.5202e-02, -1.0849e-02, -1.6318e-02, -4.0550e-02,
          1.1412e-02, -8.2934e-03, -1.3202e-02,  5.4043e-02,  5.1619e-02,
         -3.8047e-02,  1.2886e-02, -5.2174e-03,  1.5614e-02, -2.9972e-03,
         -1.8548e-02,  6.0689e-02,  2.1902e-02,  6.1412e-02, -5.3694e-02,
         -4.1122e-02, -4.7437e-02,  6.3842e-03, -6.5491e-04,  8.7454e-03,
          4.9183e-02,  2.4653e-02,  5.6601e-02, -3.8095e-02,  1.7685e-04,
          1.6772e-02,  4.6473e-02, -1.7577e-03,  5.8319e-02,  5.4345e-03,
         -1.7391e-02,  1.2364e-03,  2.0306e-02, -1.0718e-02,  1.5791e-02,
          2.3441e-02,  1.3018e-02, -1.6203e-02, -1.0532e-02, -2.6647e-02,
         -4.6354e-04,  1.4107e-02, -4.8157e-02,  1.7616e-03, -3.3153e-02,
          1.5660e-03, -3.2043e-02,  2.9170e-02, -4.6292e-02, -2.2287e-03,
         -2.0068e-02, -2.2981e-02,  1.1348e-02,  3.4951e-02, -1.7466e-02,
         -5.5528e-03, -2.8265e-02, -1.2108e-02,  2.8493e-02,  2.3461e-02,
         -1.5098e-02, -2.5042e-02, -2.3250e-02,  2.7289e-03, -2.0728e-02,
          2.4190e-02]])
