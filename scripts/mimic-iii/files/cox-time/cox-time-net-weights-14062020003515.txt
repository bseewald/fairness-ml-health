Weights: 
net.embeddings.embeddings.0.weight tensor([[ 0.4835, -0.0926],
        [ 0.3808, -0.2013],
        [ 0.1563,  0.0891],
        [ 0.5134, -0.5848]])
net.embeddings.embeddings.1.weight tensor([[-0.2887,  0.1479],
        [-0.2046,  0.5325],
        [ 0.1400, -0.2358],
        [-0.0225, -0.2052],
        [ 0.2292, -0.0242]])
net.embeddings.embeddings.2.weight tensor([[ 0.0354,  0.4297, -0.0863],
        [-0.4460,  0.2318, -0.3367],
        [ 0.2924, -0.2018,  0.0495],
        [-0.0596,  0.2642, -0.2554],
        [ 0.3216,  0.3205, -0.2363],
        [ 0.1893, -0.3835,  0.3186]])
net.embeddings.embeddings.3.weight tensor([[-0.0923,  0.1081],
        [-0.0915, -0.6388],
        [ 0.5670,  0.3360],
        [-0.2792,  0.2449]])
net.embeddings.embeddings.4.weight tensor([[-0.2285,  0.1883],
        [ 0.5266,  0.0708],
        [-0.5955, -0.0029],
        [ 0.2368,  0.1640]])
net.mlp.net.0.linear.weight tensor([[-0.1665,  0.3750, -0.0135,  ..., -0.4332,  0.1059,  0.1267],
        [ 0.0951,  0.1355,  0.1921,  ...,  0.4486,  0.2413,  0.2593],
        [-0.0043, -0.1576, -0.0389,  ..., -0.2163, -0.2987, -0.1962],
        ...,
        [-0.1702,  0.1170, -0.4178,  ..., -0.0348, -0.0324, -0.1244],
        [-0.2431,  0.0484, -0.0892,  ..., -0.5189, -0.0581,  0.2137],
        [-0.1499, -0.0893, -0.0069,  ..., -0.0438,  0.3867, -0.5898]])
net.mlp.net.0.linear.bias tensor([ 0.1267, -0.0147, -0.1954,  0.1124,  0.1789,  0.0504,  0.1607, -0.0788,
         0.2302,  0.0543, -0.0353, -0.0889,  0.0275, -0.1706,  0.0600, -0.0641,
         0.1904,  0.0586,  0.0596, -0.1987,  0.1423, -0.2281, -0.1961,  0.1519,
         0.1223,  0.0178,  0.2011,  0.0106, -0.0289, -0.1943, -0.1015,  0.1368,
        -0.0129,  0.2420,  0.0872, -0.0333,  0.0920, -0.1707, -0.0593, -0.1478,
        -0.0362, -0.1275, -0.0527, -0.0338, -0.0233,  0.0791, -0.2106,  0.1253,
        -0.1128,  0.0424,  0.1840, -0.0182,  0.1404,  0.0174, -0.0382, -0.0726,
         0.1292,  0.1398, -0.1371, -0.0287, -0.2055,  0.0078,  0.1053, -0.0419,
        -0.0192, -0.0712,  0.0477, -0.0520,  0.0105,  0.1571,  0.1048, -0.0535,
         0.0910, -0.0967, -0.1102, -0.1750,  0.0311,  0.0609,  0.0321, -0.1298,
        -0.1363,  0.2052, -0.1745,  0.0060, -0.0140, -0.0015,  0.2415,  0.0091,
         0.1499, -0.0355,  0.0801,  0.0972, -0.0369,  0.1482,  0.0252,  0.0652,
         0.1195, -0.1875,  0.0479, -0.1310, -0.0608, -0.1568, -0.1803, -0.1150,
         0.0303,  0.0584, -0.1223, -0.0292,  0.1554,  0.1851,  0.0671, -0.1468,
         0.1427,  0.1350,  0.0343, -0.2581, -0.0610, -0.0505, -0.1361, -0.0241,
         0.0857, -0.2434, -0.2909, -0.0859, -0.1120,  0.0200, -0.0132,  0.0296,
        -0.1179,  0.1011,  0.0414,  0.1368,  0.2014, -0.0079,  0.0560, -0.0582,
        -0.1589,  0.1685, -0.0428,  0.1521, -0.0711, -0.2237,  0.0633, -0.2482,
         0.1216,  0.1621, -0.1988,  0.0338, -0.1011, -0.0887, -0.1615,  0.0878,
        -0.2352,  0.0720, -0.1590, -0.1752, -0.1365, -0.0423,  0.1582,  0.0738,
        -0.0477,  0.0185,  0.2364,  0.1593, -0.1859,  0.0809, -0.0044, -0.1636,
        -0.1912, -0.2171,  0.0429,  0.1326, -0.1774, -0.1264,  0.1005, -0.1364,
        -0.1926,  0.0203,  0.1572, -0.0447,  0.2107,  0.0898,  0.0609, -0.0379,
        -0.0283, -0.1652,  0.0250, -0.1680, -0.1758,  0.1617,  0.2004, -0.0475,
        -0.1168,  0.0604, -0.0750,  0.2183,  0.0784, -0.2286,  0.0580,  0.0498,
         0.1805,  0.0307,  0.1964,  0.1806,  0.0106,  0.0346,  0.0374,  0.1665,
         0.0078, -0.1322,  0.0466, -0.2405,  0.0395, -0.2123, -0.1505, -0.1812,
        -0.1062, -0.2851,  0.0059, -0.0190,  0.2052,  0.2539, -0.0520, -0.1876,
         0.1328, -0.0150, -0.0970, -0.1978,  0.1074,  0.0412, -0.0116,  0.1533,
        -0.0375,  0.0680, -0.0779,  0.1297, -0.1509,  0.1151,  0.1473,  0.0453,
        -0.1413,  0.0720, -0.1268, -0.0209, -0.0389,  0.0819, -0.0435,  0.1253,
         0.1492, -0.0245, -0.0613, -0.0454,  0.1663,  0.1009, -0.1720, -0.1465])
net.mlp.net.0.batch_norm.weight tensor([0.8528, 0.9186, 0.8258, 0.9468, 1.0698, 0.8625, 0.9031, 0.8451, 0.9246,
        0.8145, 0.9426, 0.9114, 0.8637, 0.8961, 0.9408, 0.9520, 0.9375, 0.8477,
        0.9157, 0.9964, 0.9301, 0.8476, 0.9001, 0.8543, 1.0137, 0.9450, 0.9723,
        1.0033, 0.8751, 0.9880, 1.0037, 0.8466, 0.9198, 0.9392, 0.8374, 0.8827,
        0.9279, 1.0152, 0.9308, 0.8843, 0.8080, 0.8767, 0.9071, 0.8545, 0.9609,
        0.7691, 0.9522, 0.8693, 0.8602, 0.9935, 0.9727, 0.9025, 0.8410, 0.8428,
        0.9279, 0.8319, 0.9696, 0.9403, 0.9363, 0.9238, 0.8840, 0.8747, 0.8520,
        0.9061, 0.8736, 0.9824, 0.8775, 0.9659, 0.9129, 0.9119, 0.7806, 0.8131,
        0.8350, 0.9048, 0.8646, 0.9014, 0.8710, 0.9583, 0.9698, 0.9458, 0.9109,
        0.8475, 0.9535, 0.9363, 0.8969, 0.8821, 0.8366, 0.9052, 0.9732, 0.8716,
        0.9121, 0.9201, 0.8542, 0.9766, 0.8839, 0.8287, 0.9253, 0.9065, 0.9563,
        0.8713, 0.8803, 0.8709, 0.8678, 0.8662, 0.8842, 0.9198, 0.9395, 0.7655,
        0.9309, 0.8479, 0.8675, 0.9043, 0.9166, 0.8343, 0.8614, 0.7854, 0.9722,
        0.9487, 1.0400, 0.8901, 0.9014, 0.8857, 0.9517, 0.9810, 1.0354, 0.9269,
        0.8431, 0.9902, 0.8530, 1.0121, 0.8050, 0.9121, 0.9139, 0.8601, 0.9599,
        0.7634, 0.9270, 0.8591, 0.8674, 0.8414, 0.9202, 0.8775, 0.9047, 0.9592,
        0.7445, 0.9305, 0.9695, 0.8397, 0.8493, 0.8695, 0.9342, 0.8700, 0.8949,
        0.9226, 0.9437, 0.8822, 0.8579, 0.8845, 0.9442, 0.8857, 0.9134, 0.9641,
        0.8829, 0.8827, 0.9189, 0.9994, 0.9553, 0.8441, 0.8806, 0.9006, 0.9806,
        0.8950, 0.9000, 0.9288, 0.9467, 0.9204, 0.8828, 0.8583, 0.8856, 0.7994,
        0.8196, 0.9112, 0.9232, 0.9258, 0.9823, 0.8752, 0.9991, 0.9175, 0.8677,
        0.8395, 0.9303, 0.8756, 0.8722, 0.8957, 0.9425, 0.9084, 0.8833, 1.0477,
        0.8617, 0.9215, 0.9538, 0.8964, 0.9072, 0.8915, 0.8564, 0.9312, 0.9229,
        0.8767, 1.0017, 0.8895, 0.8281, 0.9095, 0.8504, 0.9144, 0.8891, 0.9313,
        0.9122, 0.9191, 0.8452, 0.9754, 0.8731, 0.9248, 0.8575, 0.8595, 0.9737,
        0.9416, 0.8011, 0.8646, 0.8723, 0.8914, 0.9224, 0.8994, 0.9222, 0.9498,
        0.8804, 0.8859, 0.8922, 0.9331, 0.8785, 0.9314, 0.9929, 0.9713, 0.9489,
        0.8924, 0.9826, 0.9768, 0.9309, 0.8996, 0.9086, 0.9815, 0.8141, 0.9367,
        0.8748, 0.8869, 0.8949, 0.8320])
net.mlp.net.0.batch_norm.bias tensor([ 0.0426,  0.0085, -0.0760, -0.0276, -0.0086,  0.0284, -0.0100, -0.0192,
        -0.0398,  0.0896, -0.0038, -0.0275,  0.0565,  0.0412, -0.0276,  0.0222,
         0.0252, -0.0304,  0.0242,  0.0322, -0.0614, -0.0088,  0.1265,  0.0269,
        -0.1287,  0.0079, -0.0542, -0.0509,  0.0296,  0.0468,  0.0137, -0.0031,
        -0.0200,  0.0034,  0.0317,  0.1514,  0.0288, -0.0469,  0.0284, -0.0050,
         0.0876,  0.0393, -0.0932,  0.1178,  0.0475,  0.0513, -0.0567, -0.0265,
        -0.1004, -0.0582,  0.1067, -0.0087,  0.0568,  0.0462,  0.0217,  0.0833,
         0.0318,  0.0325, -0.0719,  0.0595, -0.0964, -0.0533, -0.0297,  0.0296,
         0.0396, -0.0319, -0.0034,  0.0814, -0.0757,  0.0546, -0.0793,  0.0964,
         0.0191, -0.0039, -0.0084, -0.1325,  0.0361, -0.0174,  0.0549,  0.0563,
         0.0981,  0.0231, -0.0545,  0.0753,  0.1492, -0.0738,  0.0926, -0.0490,
        -0.0233, -0.0474, -0.0211, -0.0490,  0.0258,  0.0139, -0.0844,  0.0501,
         0.0553, -0.0774, -0.0309, -0.0025,  0.0437, -0.0331, -0.0328,  0.0013,
        -0.0187, -0.0427,  0.0617, -0.0271, -0.1144,  0.0151,  0.0513,  0.0208,
         0.1039, -0.0667, -0.1434, -0.0811, -0.1119, -0.0859,  0.0249, -0.0131,
         0.0328, -0.0106, -0.0201, -0.0369, -0.0109,  0.0847,  0.0041, -0.1111,
         0.0621,  0.0381,  0.0965, -0.0276,  0.0281,  0.0590,  0.0417, -0.1468,
         0.0419, -0.0707,  0.0142,  0.0115,  0.1590,  0.0769, -0.0687, -0.0466,
         0.0701, -0.0576,  0.0026,  0.0054, -0.0072,  0.0818,  0.0606, -0.0387,
        -0.1278, -0.0513,  0.1101, -0.0929, -0.0288, -0.0738,  0.0534,  0.0767,
         0.0531, -0.0219, -0.0124, -0.1247,  0.0040,  0.0182,  0.0605, -0.0007,
         0.0465,  0.0400, -0.0141,  0.0363,  0.0853,  0.0533,  0.0193,  0.0210,
         0.0294, -0.0706,  0.0454, -0.0057,  0.0503,  0.0145,  0.0403,  0.0477,
        -0.1235, -0.0102, -0.0895, -0.0275,  0.0389, -0.0400,  0.0438,  0.0202,
         0.0228, -0.0926, -0.0782,  0.0363, -0.0391,  0.0098, -0.0592, -0.0456,
         0.0192,  0.0236, -0.0377, -0.0471, -0.0072, -0.0103, -0.1116, -0.1206,
         0.0100, -0.0963,  0.0536, -0.0579, -0.0425, -0.1259, -0.0518,  0.0120,
         0.0972,  0.0120, -0.1282, -0.0412, -0.0338,  0.0343,  0.0282,  0.0073,
         0.1310,  0.0323,  0.0579, -0.0540,  0.0416,  0.0253, -0.0425,  0.0173,
        -0.0039,  0.1187,  0.0466,  0.0658, -0.0724,  0.0196,  0.0865,  0.0463,
        -0.1160, -0.0222,  0.0336,  0.0276,  0.0044, -0.1074,  0.0964, -0.0201,
         0.1301, -0.1195, -0.0560, -0.0961,  0.0312, -0.0016, -0.0177, -0.1788])
net.mlp.net.0.batch_norm.running_mean tensor([2.4416e-01, 5.8592e-02, 6.1367e-01, 2.9942e-02, 2.9007e-01, 2.2051e-01,
        6.7723e-01, 3.9220e-01, 2.8940e-01, 2.1996e-01, 2.6926e-01, 1.5989e-02,
        2.1300e-03, 8.2248e-03, 6.3433e-02, 2.4276e-03, 1.1638e+00, 6.1066e-01,
        2.2246e-01, 8.5203e-03, 6.9407e-02, 5.4656e-02, 1.9876e-02, 1.9556e-01,
        4.2137e-01, 1.9280e-01, 2.4580e-01, 5.8176e-01, 3.6032e-01, 1.7446e-01,
        8.1264e-01, 3.1823e-02, 5.1934e-01, 9.3743e-01, 2.0742e-01, 6.2605e-03,
        2.4311e-02, 2.0751e-03, 1.2675e-01, 4.8184e-02, 3.0469e-01, 2.1870e-01,
        1.5937e-02, 1.5563e-01, 3.5822e-03, 1.1793e-01, 1.7144e-02, 1.7350e-01,
        1.6224e-01, 5.4876e-01, 5.9208e-01, 9.3353e-01, 5.3826e-01, 4.1131e-02,
        6.0376e-01, 4.2394e-02, 4.9338e-03, 1.2076e-01, 1.4801e-01, 5.1446e-02,
        6.1034e-01, 2.7418e-01, 3.0290e-01, 1.4168e-01, 1.9629e-01, 6.3806e-02,
        3.0448e-01, 2.5044e-01, 3.7883e-01, 7.0824e-01, 6.6698e-01, 6.9070e-01,
        3.5007e-02, 7.2587e-01, 1.6717e-01, 6.5672e-02, 2.2473e-01, 9.6985e-02,
        6.7610e-01, 3.7061e-01, 9.6620e-03, 1.4149e-01, 3.8270e-01, 3.3145e-01,
        4.1606e-01, 6.5440e-03, 6.9752e-01, 2.3823e-01, 1.7405e-01, 9.8738e-01,
        2.1200e-01, 1.0604e+00, 6.8979e-01, 7.3557e-01, 6.9825e-01, 8.6535e-01,
        5.7556e-02, 1.6380e-01, 4.7810e-01, 1.8716e-01, 4.7071e-01, 5.6075e-02,
        8.2813e-02, 1.7880e-01, 8.2950e-03, 7.5787e-03, 1.2883e-02, 3.0318e-01,
        7.0795e-01, 5.1633e-01, 9.3310e-02, 1.3490e-01, 3.9271e-01, 4.3334e-02,
        7.4485e-02, 4.1598e-01, 1.6918e-01, 8.6005e-03, 2.0231e-02, 3.7596e-01,
        8.0344e-02, 1.0367e-02, 2.0383e-01, 2.4545e-01, 4.6172e-02, 6.1009e-01,
        3.6406e-01, 3.4478e-01, 3.6876e-01, 1.8206e-03, 7.3224e-01, 2.1501e-01,
        2.1273e-01, 7.7288e-01, 4.6529e-01, 2.0408e-01, 3.1031e-01, 1.9686e-01,
        4.7916e-02, 1.8914e-01, 2.0661e-03, 2.3766e-01, 3.2493e-01, 1.8497e-01,
        4.5422e-01, 1.6327e-01, 2.8724e-01, 2.7768e-01, 4.0295e-02, 6.0934e-02,
        3.3460e-02, 1.2823e-01, 1.4340e-01, 1.5906e-01, 3.8347e-02, 7.5588e-04,
        2.7305e-01, 2.6669e-01, 7.0577e-01, 1.3790e-01, 7.7998e-02, 7.2983e-01,
        5.2736e-01, 5.7530e-01, 3.9109e-01, 6.9659e-01, 4.2683e-01, 2.2829e-01,
        3.2010e-01, 3.0097e-01, 3.1273e-01, 7.0462e-02, 4.6493e-01, 3.8099e-02,
        6.2604e-02, 1.8913e-02, 4.9249e-01, 2.3821e-01, 5.1840e-02, 1.6958e-01,
        1.4264e-01, 1.8104e-01, 2.3051e-03, 3.0869e-01, 9.1394e-01, 1.0768e-01,
        2.4812e-01, 5.5138e-01, 5.2279e-02, 4.8864e-01, 2.2853e-01, 8.4729e-02,
        7.1359e-01, 3.7338e-02, 1.4727e-01, 3.1463e-01, 1.7839e-02, 2.6304e-01,
        6.0953e-02, 1.8280e-01, 1.5069e-02, 2.7639e-02, 1.7191e-01, 4.1787e-02,
        1.2624e+00, 4.0181e-01, 5.2137e-01, 4.3487e-01, 6.1731e-02, 2.6014e-01,
        3.8618e-01, 1.4604e+00, 4.8315e-01, 1.3579e-01, 1.2347e-01, 5.5109e-02,
        1.2873e-01, 4.0933e-05, 8.3834e-01, 4.8334e-01, 6.1302e-02, 1.4581e+00,
        2.7071e-01, 4.2927e-02, 5.1336e-01, 7.6908e-02, 3.3148e-02, 1.0436e-01,
        5.6175e-01, 1.2694e+00, 3.5330e-02, 1.0209e+00, 2.0122e-01, 2.8737e-01,
        6.7528e-02, 4.0871e-01, 1.6315e-01, 4.8714e-01, 1.8539e-01, 1.8175e-01,
        1.4621e-01, 4.9135e-01, 2.7735e-02, 3.2456e-02, 5.7878e-01, 3.0200e-01,
        1.7353e-01, 8.2230e-01, 7.1621e-01, 6.4202e-01, 1.2834e-01, 8.2776e-01,
        1.9589e-01, 8.8862e-02, 9.0063e-02, 3.8829e-02])
net.mlp.net.0.batch_norm.running_var tensor([9.2270e-02, 5.9654e-02, 1.4924e-01, 9.0708e-03, 2.8286e-01, 1.0213e-01,
        2.0837e-01, 7.6960e-02, 1.3424e-01, 1.0502e-01, 1.6755e-01, 8.7808e-03,
        3.2480e-04, 1.8661e-03, 2.0063e-02, 7.0094e-04, 2.0655e-01, 2.2192e-01,
        4.8264e-01, 2.7914e-03, 3.5984e-02, 4.7813e-02, 7.6362e-03, 9.5461e-02,
        6.6140e-01, 3.4890e-01, 2.6457e-01, 2.3124e-01, 1.0302e-01, 1.7071e-01,
        4.8599e-01, 1.1023e-02, 1.6682e-01, 2.4316e-01, 9.7341e-02, 1.6702e-03,
        1.0052e-02, 5.3289e-04, 8.2653e-02, 2.3659e-02, 1.5384e-01, 7.3022e-02,
        6.4551e-03, 4.3237e-02, 1.2975e-03, 4.1183e-02, 7.2413e-03, 1.8780e-01,
        7.2330e-02, 1.4033e-01, 1.7615e-01, 2.5847e-01, 7.2267e-01, 4.5793e-02,
        1.0415e-01, 1.8023e-02, 1.7610e-03, 5.4628e-02, 4.6607e-02, 2.0130e-02,
        5.8511e-01, 1.0614e-01, 2.4582e-01, 1.1642e-01, 5.5132e-02, 2.5635e-02,
        8.1870e-01, 6.2446e-01, 1.1991e-01, 3.1658e-01, 1.1704e-01, 2.0271e-01,
        3.3974e-02, 4.0015e-01, 7.5217e-02, 1.0398e-02, 4.4396e-01, 1.2092e-01,
        1.8238e-01, 7.3028e-01, 1.2848e-03, 3.3059e-02, 2.0184e-01, 7.0902e-01,
        1.4774e-01, 1.5390e-03, 1.0090e-01, 8.2115e-02, 5.6528e-02, 2.6073e-01,
        1.6479e-01, 2.3793e-01, 1.2195e-01, 8.7764e-02, 1.2158e-01, 4.2561e-01,
        2.8282e-02, 5.8895e-02, 1.5460e-01, 8.2567e-02, 1.5822e-01, 1.8208e-02,
        2.0529e-02, 2.1685e-01, 7.4696e-03, 2.7080e-03, 3.3081e-03, 1.2623e-01,
        2.1810e-01, 2.2103e-01, 2.1344e-01, 4.5536e-02, 4.6291e-01, 2.7480e-02,
        2.4861e-02, 1.0801e-01, 3.8981e-02, 1.4974e-03, 6.1993e-03, 1.1612e-01,
        6.2099e-02, 2.0586e-03, 6.0324e-02, 1.0013e-01, 1.2769e-02, 4.6697e-01,
        9.6387e-02, 1.0370e-01, 1.1293e-01, 4.0386e-04, 1.5725e-01, 5.1115e-02,
        7.8232e-02, 1.7328e-01, 4.5423e-01, 7.8678e-02, 2.3032e-01, 9.8693e-02,
        1.7252e-02, 7.0354e-02, 4.2585e-04, 1.9305e-01, 9.3474e-02, 4.6379e-02,
        2.6613e-01, 9.7428e-02, 8.8898e-02, 1.5566e-01, 1.4502e-02, 5.3999e-02,
        4.1416e-02, 2.7363e-02, 4.9472e-02, 1.6303e-01, 1.0092e-02, 2.3534e-04,
        9.7664e-02, 6.6526e-02, 1.3202e-01, 5.0956e-02, 1.9700e-02, 2.3639e-01,
        2.3584e-01, 1.7025e-01, 1.5045e-01, 2.0263e-01, 3.3252e-01, 8.8786e-02,
        1.0327e-01, 3.6189e-01, 5.6021e-02, 2.1178e-02, 2.7895e-01, 6.2743e-02,
        3.4501e-02, 5.7706e-03, 2.9264e-01, 1.3453e-01, 2.8339e-02, 1.9795e-01,
        2.6808e-01, 2.4212e-01, 4.7184e-04, 2.7387e-01, 2.0255e-01, 3.5596e-02,
        8.5588e-02, 2.9633e-01, 5.6329e-02, 8.5932e-02, 3.8347e-02, 3.1064e-02,
        3.5466e-01, 3.0233e-02, 5.4115e-02, 4.9073e-01, 7.8148e-03, 5.9467e-01,
        2.2746e-02, 3.1240e-01, 4.8678e-03, 7.3116e-03, 1.1763e-01, 7.9908e-02,
        2.1347e-01, 2.3239e-01, 1.5839e-01, 5.7204e-02, 5.6366e-02, 7.7658e-01,
        6.2680e-02, 3.4427e-01, 1.8718e-01, 5.7340e-02, 4.6626e-02, 1.5208e-02,
        8.3474e-02, 3.0625e-05, 2.5623e-01, 9.5787e-02, 3.2422e-02, 2.4280e-01,
        8.0478e-02, 1.2992e-02, 6.1932e-01, 2.2600e-02, 2.7993e-02, 5.4390e-02,
        2.3856e-01, 2.1822e-01, 1.0142e-02, 1.9972e-01, 7.0889e-02, 2.4226e-01,
        2.2086e-02, 2.3162e-01, 6.7866e-02, 1.1507e-01, 9.1996e-02, 1.4252e-01,
        6.1189e-02, 1.2941e-01, 8.1042e-03, 3.5720e-02, 4.3994e-01, 6.6791e-01,
        2.6346e-01, 2.3025e-01, 2.4376e-01, 1.5272e-01, 1.4221e-01, 1.5129e-01,
        1.3373e-01, 8.7861e-02, 3.1738e-02, 3.8622e-02])
net.mlp.net.0.batch_norm.num_batches_tracked tensor(100)
net.mlp.net.1.linear.weight tensor([[ 0.0707, -0.0863, -0.0447,  ..., -0.0354,  0.1383, -0.0192],
        [-0.0846,  0.1939, -0.0508,  ...,  0.0958,  0.1323, -0.0809],
        [ 0.0718,  0.0266, -0.0289,  ..., -0.1544, -0.0170, -0.0222],
        ...,
        [-0.0573, -0.0272,  0.1074,  ...,  0.0481, -0.0438, -0.0514],
        [-0.0824,  0.0155,  0.0604,  ...,  0.1224, -0.0832,  0.0567],
        [ 0.1254,  0.0914, -0.0089,  ...,  0.1087,  0.0573,  0.0207]])
net.mlp.net.1.linear.bias tensor([-0.0020, -0.1010, -0.0139, -0.0206, -0.0024, -0.1327,  0.0103,  0.0209,
         0.0106, -0.1246, -0.0811,  0.0013,  0.0049, -0.1040,  0.0011,  0.0744,
        -0.0715, -0.0688, -0.0058,  0.0360,  0.0043,  0.1086, -0.0251,  0.0215,
        -0.1346,  0.0720, -0.1055, -0.1096, -0.0571,  0.1264,  0.0796,  0.0766,
         0.0313,  0.0089,  0.1376, -0.0359, -0.1451,  0.1091, -0.1110, -0.0590,
         0.0659,  0.0933,  0.0485,  0.1534,  0.0279, -0.0572,  0.0094,  0.0434,
        -0.1412,  0.0304, -0.0475, -0.0183,  0.0078,  0.0346, -0.0465, -0.0098,
        -0.0970, -0.0533, -0.0396, -0.0596, -0.1262, -0.0216,  0.0164,  0.0965,
        -0.0435, -0.0630, -0.0033, -0.0046,  0.1059, -0.0955, -0.0185, -0.0420,
         0.0251, -0.1368, -0.0255, -0.0195,  0.0557, -0.0426,  0.0435, -0.0443,
        -0.0373,  0.0543, -0.0677, -0.0234, -0.0489,  0.0042, -0.0256, -0.0703,
        -0.0282, -0.1076,  0.0307,  0.0335, -0.0994,  0.0024, -0.0911, -0.0272,
        -0.0854, -0.1046,  0.0428, -0.0461, -0.0410,  0.0561, -0.0614, -0.0015,
        -0.0087, -0.0029,  0.0057, -0.0232, -0.1183, -0.0326,  0.0154, -0.0841,
         0.0349, -0.0734, -0.0291,  0.1166, -0.0106, -0.0732, -0.0077,  0.0185,
        -0.0164, -0.0042, -0.0428,  0.0720,  0.1413,  0.0299, -0.0584,  0.0987,
         0.0134,  0.0177, -0.0704,  0.0093,  0.0321, -0.1652,  0.0742, -0.1365,
        -0.0330, -0.0426, -0.0753, -0.1045, -0.0278,  0.0493, -0.0194, -0.0183,
        -0.0696,  0.0352,  0.0185,  0.0037, -0.0823,  0.0432, -0.1960, -0.0061,
         0.1153, -0.0088, -0.1068, -0.0026, -0.0523, -0.1522, -0.1030, -0.0629,
        -0.0905, -0.0576,  0.0274,  0.1079,  0.0288,  0.0587,  0.0414,  0.1472,
        -0.0420, -0.1026,  0.0285, -0.0492,  0.0251, -0.1166,  0.0635,  0.0709,
        -0.0692, -0.0047, -0.0311, -0.1129, -0.0662,  0.0337,  0.0690, -0.0376,
        -0.0342,  0.0690,  0.0067, -0.0501, -0.1620, -0.0020,  0.0405,  0.0089,
        -0.0357, -0.1565, -0.0909,  0.0725, -0.0250, -0.0205, -0.0173, -0.1537,
        -0.0160,  0.0017, -0.0401,  0.0798,  0.0468, -0.0482, -0.1116, -0.0943,
         0.0501,  0.0006,  0.0992, -0.1127,  0.0263, -0.0062,  0.0189, -0.1471,
        -0.1248, -0.0233, -0.0945,  0.0563, -0.0946,  0.0442, -0.0008, -0.0180,
         0.0455,  0.0222, -0.0719,  0.0045, -0.0831, -0.0821, -0.0466, -0.0597,
         0.0120, -0.0522,  0.0047,  0.1818, -0.0356, -0.1557, -0.0821,  0.0717,
        -0.0299, -0.0885, -0.0793, -0.0112, -0.1090, -0.1358, -0.0817, -0.0710,
        -0.0676, -0.0574, -0.0034, -0.0836,  0.0027,  0.1239, -0.0552,  0.0180])
net.mlp.net.1.batch_norm.weight tensor([0.8514, 0.8609, 0.8577, 0.7938, 0.8353, 0.8200, 0.8458, 0.8369, 0.7966,
        0.8120, 0.7882, 0.7538, 0.8132, 0.8725, 0.9063, 0.8823, 0.8671, 0.8525,
        0.9019, 0.7543, 0.8730, 0.7724, 0.7596, 0.7927, 0.7623, 0.7461, 0.8364,
        0.8209, 0.8040, 0.8878, 0.8069, 0.7413, 0.7806, 0.7673, 0.7873, 0.8186,
        0.8543, 0.7017, 0.8457, 0.8129, 0.8992, 0.8847, 0.7843, 0.7987, 0.8306,
        0.8243, 0.7910, 0.8134, 0.7028, 0.8477, 0.7904, 0.8487, 0.8554, 0.7955,
        0.8318, 0.7685, 0.9167, 0.7994, 0.8302, 0.8027, 0.8325, 0.8523, 0.8822,
        0.8285, 0.8802, 0.8181, 0.8273, 0.7457, 0.7814, 0.7686, 0.7381, 0.8502,
        0.8205, 0.7870, 0.7628, 0.8547, 0.8494, 0.8456, 0.7936, 0.8265, 0.7671,
        0.7589, 0.8081, 0.7977, 0.8582, 0.7490, 0.8873, 0.8109, 0.8604, 0.7569,
        0.7772, 0.8684, 0.8101, 0.8491, 0.8335, 0.8446, 0.7453, 0.8344, 0.8396,
        0.8321, 0.8844, 0.8093, 0.8539, 0.7897, 0.8133, 0.8501, 0.7522, 0.8604,
        0.8180, 0.6998, 0.9252, 0.8343, 0.7726, 0.7806, 0.7568, 0.8047, 0.8666,
        0.7492, 0.8778, 0.8493, 0.8774, 0.8009, 0.8175, 0.8154, 0.8631, 0.7581,
        0.8223, 0.7811, 0.7627, 0.7227, 0.8257, 0.8058, 0.8448, 0.8046, 0.9039,
        0.7965, 0.8902, 0.8519, 0.8042, 0.7967, 0.8171, 0.7362, 0.7560, 0.8535,
        0.8761, 0.7429, 0.7855, 0.8265, 0.7806, 0.7549, 0.8843, 0.7644, 0.7768,
        0.8487, 0.8130, 0.8558, 0.8329, 0.8621, 0.7779, 0.8202, 0.7820, 0.7863,
        0.7547, 0.7416, 0.8090, 0.8511, 0.8299, 0.7891, 0.8310, 0.8179, 0.7926,
        0.8018, 0.7751, 0.8195, 0.7872, 0.8624, 0.8361, 0.7936, 0.8224, 0.8330,
        0.8024, 0.8017, 0.7722, 0.8658, 0.7396, 0.7948, 0.8696, 0.7664, 0.7894,
        0.7217, 0.7846, 0.8143, 0.7969, 0.7947, 0.7555, 0.8261, 0.8455, 0.8136,
        0.7811, 0.8408, 0.7933, 0.7125, 0.8446, 0.8023, 0.8271, 0.8038, 0.8833,
        0.6872, 0.6689, 0.8014, 0.8967, 0.8145, 0.6853, 0.9122, 0.8125, 0.8439,
        0.7936, 0.7856, 0.7675, 0.8230, 0.7203, 0.7972, 0.8614, 0.8223, 0.8256,
        0.8352, 0.8337, 0.8445, 0.8479, 0.6869, 0.8020, 0.8582, 0.8384, 0.8132,
        0.8106, 0.8099, 0.8768, 0.8805, 0.8620, 0.8613, 0.8547, 0.7283, 0.8230,
        0.7671, 0.8700, 0.7778, 0.8544, 0.8845, 0.8109, 0.9190, 0.7696, 0.8082,
        0.7364, 0.8202, 0.7972, 0.8663])
net.mlp.net.1.batch_norm.bias tensor([-0.0166,  0.0028,  0.0171, -0.0314,  0.0415, -0.0300, -0.0162,  0.0462,
        -0.0204,  0.1104, -0.0276, -0.0852, -0.0272, -0.0443, -0.0435,  0.0769,
         0.0280,  0.0171, -0.0219,  0.0264,  0.0485, -0.0400, -0.0763,  0.0601,
        -0.0280,  0.0605, -0.0024, -0.0287,  0.0103, -0.0795,  0.0247, -0.0242,
         0.0145, -0.0050,  0.0183,  0.1005, -0.0828, -0.0358,  0.1219,  0.0563,
         0.0260, -0.0433, -0.1177, -0.0473,  0.0182, -0.0263, -0.0565,  0.0264,
         0.1796, -0.0012, -0.0734,  0.0332,  0.0030,  0.0592,  0.0236,  0.0051,
         0.0619, -0.0617, -0.0515,  0.0125, -0.0898, -0.0204,  0.0084, -0.0117,
         0.0487, -0.0759, -0.1044,  0.0354, -0.0703, -0.0615,  0.0344, -0.0290,
         0.0905, -0.0823,  0.0271, -0.0138,  0.0439, -0.0412, -0.0296, -0.0998,
        -0.0919,  0.0049,  0.0778,  0.0079,  0.0637, -0.0459,  0.0867,  0.0455,
        -0.0412,  0.0125,  0.0456, -0.0054, -0.0892, -0.0587, -0.0145,  0.0180,
        -0.0829, -0.0817, -0.0442, -0.0539,  0.0564,  0.0434,  0.0202,  0.1259,
        -0.0295,  0.0112,  0.0211, -0.1756,  0.0492, -0.0505,  0.0308, -0.0126,
         0.0200, -0.1516,  0.0219, -0.0345,  0.0540,  0.0789, -0.0348, -0.0051,
        -0.0574, -0.0471, -0.0129,  0.0580, -0.0198,  0.0175,  0.0692, -0.0506,
         0.0382, -0.0320,  0.0261, -0.1565,  0.0469, -0.0645, -0.0050,  0.0834,
         0.0195,  0.0669,  0.0633, -0.0027,  0.0708, -0.0273, -0.0672,  0.0511,
        -0.0460,  0.0936, -0.0151, -0.0148,  0.0487, -0.0597,  0.0358,  0.0131,
        -0.0943,  0.0086, -0.0955, -0.0006, -0.0506, -0.0082, -0.0376,  0.0867,
        -0.0674,  0.1218,  0.1043,  0.0356, -0.0077, -0.0463, -0.0050, -0.0070,
        -0.0364,  0.0380, -0.0015,  0.0759, -0.0387, -0.0821, -0.0051, -0.0370,
         0.0679,  0.0134, -0.0268,  0.0750, -0.0458,  0.0384,  0.0843,  0.0060,
         0.1187,  0.0870,  0.1663,  0.0418, -0.0301, -0.0178,  0.0969, -0.0516,
        -0.0714, -0.0711,  0.0444, -0.0003,  0.0441,  0.0597, -0.0288,  0.0097,
         0.0524,  0.0067,  0.0202,  0.0124, -0.0343,  0.0140,  0.0519, -0.0059,
         0.0581, -0.0366,  0.0642,  0.0330, -0.0250, -0.1487,  0.0712,  0.0701,
         0.1063, -0.0218, -0.0888, -0.0011,  0.0407, -0.0072, -0.0260,  0.0296,
         0.0031, -0.0190,  0.0142, -0.0614,  0.0111, -0.0020, -0.0089,  0.0043,
        -0.0462, -0.0036, -0.0355,  0.0994, -0.0298, -0.1232,  0.0413, -0.0417,
         0.0439, -0.0832, -0.0665,  0.0192, -0.0192, -0.0072,  0.0992,  0.0481,
        -0.0408,  0.0215,  0.0593,  0.0112,  0.0102,  0.0042,  0.0226, -0.0053])
net.mlp.net.1.batch_norm.running_mean tensor([1.3517, 1.2085, 0.9535, 0.9303, 1.5870, 1.1145, 1.1511, 1.3722, 1.3698,
        1.2141, 0.9469, 1.3674, 1.2930, 0.8263, 1.1347, 0.9499, 0.9518, 0.7334,
        0.9291, 1.0502, 1.0101, 1.4576, 1.1641, 1.2537, 1.0146, 1.4463, 0.6004,
        0.8072, 0.9817, 1.1364, 1.6063, 0.9760, 1.4396, 1.0798, 1.3605, 0.8583,
        1.1149, 1.4422, 1.1538, 0.8694, 1.2709, 1.1216, 0.8938, 1.3187, 1.5218,
        1.1220, 1.2044, 1.0549, 0.9841, 1.0437, 1.0133, 1.1736, 0.9096, 1.1145,
        1.1375, 1.1244, 0.9736, 1.3641, 1.3147, 1.1733, 1.2442, 0.9577, 1.2115,
        1.0465, 1.2885, 1.0181, 0.7402, 1.1404, 1.1119, 1.2996, 1.2000, 0.7744,
        0.9210, 1.1342, 1.3042, 1.1438, 1.5794, 1.7443, 1.2679, 1.3720, 1.0131,
        0.9707, 0.9594, 1.1473, 1.0043, 1.3171, 1.3296, 1.0444, 1.2757, 1.2532,
        0.9569, 0.7788, 1.4304, 0.9601, 0.7647, 1.0275, 0.8459, 0.8991, 1.0889,
        1.1035, 0.9788, 1.0763, 1.2502, 1.1526, 1.1302, 1.7815, 1.5257, 1.0655,
        0.8880, 1.3489, 0.8103, 0.9979, 0.8929, 0.8660, 1.0648, 1.2424, 0.7612,
        0.9267, 1.0618, 1.0320, 1.3261, 1.3866, 0.9782, 1.1502, 1.7622, 1.3195,
        0.9461, 1.0740, 1.1533, 1.1451, 0.9134, 1.3164, 1.5094, 0.8852, 1.5694,
        0.9356, 1.1549, 1.2796, 1.1413, 1.1113, 1.0226, 0.9846, 1.2913, 0.9967,
        0.7511, 1.2571, 1.0852, 1.0853, 0.9217, 1.4833, 0.9160, 1.2842, 0.8761,
        1.0349, 0.9193, 1.1692, 0.7088, 1.0244, 1.2116, 0.9616, 0.8928, 0.8414,
        1.4695, 1.6730, 1.4739, 0.9204, 1.5096, 1.3015, 1.1662, 0.9891, 1.2759,
        1.1545, 1.1721, 1.0630, 1.0973, 1.2685, 1.0141, 1.0109, 1.1428, 0.8393,
        1.3041, 1.2885, 1.4297, 0.9022, 1.0620, 1.2689, 1.3923, 1.4224, 0.8624,
        1.0221, 1.3739, 1.3523, 0.9178, 0.8879, 1.0099, 1.1213, 1.0436, 0.7501,
        1.5300, 1.0581, 0.9141, 1.2635, 1.3070, 0.9036, 1.1559, 1.3810, 1.0865,
        1.1155, 1.3966, 1.0143, 1.0477, 0.8123, 1.1622, 1.2753, 1.2060, 1.1727,
        1.1475, 1.1930, 1.1203, 1.0346, 1.4202, 1.2896, 1.0459, 1.0490, 1.3979,
        1.2625, 0.9771, 0.9641, 1.0230, 1.5950, 0.9635, 1.1328, 1.4545, 0.9707,
        1.3777, 1.0300, 1.2593, 0.8263, 1.2012, 1.1221, 1.3227, 0.7637, 1.2686,
        1.1649, 0.9715, 1.0591, 1.5975, 1.2378, 1.1162, 1.0879, 0.8127, 1.1587,
        1.5041, 1.2618, 1.2972, 0.9370])
net.mlp.net.1.batch_norm.running_var tensor([ 5.8401,  8.4054,  1.8726,  3.7271, 16.8502,  7.9957,  1.8606,  6.5517,
         8.4598,  6.8238,  5.6086,  2.6434,  2.6431,  2.6041,  4.1783,  2.2728,
         2.1234,  1.8818,  4.5355,  3.4305,  2.0932,  9.7229, 10.1057,  3.5932,
         2.1805,  2.6909,  1.8622,  1.6976,  6.0799,  2.4166, 14.2128,  1.6136,
         7.7867,  1.9652,  2.6627,  2.6436,  2.1911,  3.8761,  7.7100,  3.2739,
         2.5362,  1.7694,  2.4703,  2.3642, 10.1424,  2.0891,  3.2530,  3.9122,
         3.1008,  1.7558,  2.1650,  8.0434,  4.1860,  8.9683,  2.4521,  2.6768,
         2.5336,  9.8817,  4.1936,  2.2705,  9.9907,  2.0109,  2.7227,  2.0905,
         2.9152,  2.4549,  2.4701,  7.0135,  4.4009,  8.8966,  3.5642,  2.0103,
         2.0875,  7.2856,  7.0287,  2.3405,  3.9498, 17.2134,  2.7268,  7.0320,
         3.2068,  3.0646,  2.4840,  2.4078,  2.7251,  7.4164,  3.6608,  1.7512,
        11.4170,  8.6958,  1.9110,  1.7654,  9.8593,  1.6868,  1.4550,  2.2547,
         3.8826,  1.6075,  3.4706,  2.0390,  2.4791,  2.3377,  2.8245,  3.0253,
         2.7112, 17.8362, 14.3360,  2.3805,  5.4296,  3.1352,  1.7468,  2.7674,
         1.7555,  1.8507,  2.1081,  7.0090,  2.1565,  2.1931,  4.8757,  5.1052,
         8.7041, 12.5426,  2.0615,  2.2153,  3.6681,  3.0550,  3.6661,  1.9737,
         2.2499,  2.0196,  1.6763,  8.2374, 13.0498,  2.8191,  3.1496,  1.8377,
         7.7330,  7.6612,  2.3450,  2.8090,  5.2585,  4.3804,  3.7754,  3.2593,
         3.4877,  2.5547,  2.6716,  5.1975,  2.0323, 14.1446,  1.7538,  6.7532,
         2.3317,  2.7660,  2.1826,  4.1938,  1.5022,  2.7364,  3.0803,  2.1490,
         2.2431,  1.7412,  2.9956,  4.1415,  3.5924,  3.5665,  7.2262,  2.2464,
        11.4979,  2.3117,  2.9815,  6.5822,  4.6041,  2.2067,  1.7325,  2.8793,
         6.4300,  5.2153,  6.4941,  2.1162, 12.8375,  2.6390,  9.1780,  2.6000,
         2.4454,  2.7573,  8.9025,  3.1762,  1.5882,  5.5371,  8.2772,  9.7669,
         3.7687,  2.5312,  5.6416,  2.8146,  4.4736,  0.9260,  9.9454,  3.3764,
         1.7920,  3.0771, 11.1368,  2.7360,  3.3881, 12.8317,  2.6885,  2.0350,
         2.7373,  2.3374,  3.5596,  2.0292,  2.1528,  3.0339,  2.4001,  7.9588,
         8.0686,  3.1493,  2.2636,  2.0817,  3.7947, 10.2295,  1.9248,  2.1692,
         6.5090,  9.1187,  3.1757,  5.8956,  1.8388, 15.1961,  1.9333,  3.4371,
        12.9720,  2.1619,  6.3307,  2.8561,  9.4077,  1.7962,  9.6462,  3.8644,
         8.3777,  1.4155,  3.7529,  4.8334,  6.2309,  9.0984,  4.2064,  4.0502,
        10.4527,  3.0937,  1.4790,  2.0488,  3.3302,  1.9929, 12.1682,  2.8264])
net.mlp.net.1.batch_norm.num_batches_tracked tensor(100)
net.mlp.net.2.weight tensor([[-1.3909e-02,  3.2813e-02,  2.9269e-02, -6.0894e-03,  2.8324e-02,
          1.9712e-02, -6.7967e-04, -2.4767e-02,  8.1040e-04,  3.4125e-02,
         -4.6552e-03,  3.6874e-03,  7.4529e-03, -5.2510e-02, -5.4539e-02,
         -2.9106e-02, -4.3060e-02, -1.9055e-02,  4.6593e-02,  5.4534e-03,
          2.2801e-02,  2.3786e-02,  6.2425e-03, -3.2455e-02,  1.0969e-02,
          2.6269e-02, -1.3181e-02, -1.3546e-02,  1.8161e-02,  6.0125e-02,
          1.0903e-02,  1.5892e-02,  7.6995e-03,  9.1312e-03,  5.5154e-03,
          3.2481e-02,  2.7479e-02,  2.0618e-02, -6.0372e-02, -1.6455e-02,
          6.1235e-02,  3.1614e-02, -1.3135e-02, -2.4966e-02, -1.8668e-02,
          1.4589e-02, -3.5042e-02,  5.2721e-03, -3.6009e-02,  2.2694e-03,
         -8.4735e-03, -1.5158e-02,  6.1700e-03, -3.0253e-03,  1.6999e-02,
          1.6792e-02, -4.6889e-02,  1.9203e-02, -3.6045e-02,  1.1665e-02,
         -3.0394e-02,  3.5525e-02,  4.6594e-02,  2.2562e-02,  5.7583e-02,
         -2.3007e-03,  1.0410e-03, -4.7412e-03, -2.3980e-02, -2.7909e-02,
          1.6351e-02,  2.0064e-02,  1.6575e-02,  5.5343e-03,  4.1138e-03,
          3.2533e-02,  1.1022e-02, -4.1095e-02, -1.9592e-02, -2.4785e-02,
         -3.7359e-02,  1.1747e-02, -3.0389e-02,  1.1060e-02, -5.0905e-02,
          8.6789e-03, -4.0250e-02,  9.2469e-03, -3.0717e-02, -2.2594e-02,
          3.5400e-02,  2.4458e-02,  3.1938e-02,  2.8120e-02, -1.3857e-02,
          3.4826e-02,  2.4722e-03, -3.2109e-02, -3.8416e-03,  2.1049e-02,
         -6.1965e-02,  3.6076e-02,  1.2712e-02, -1.8809e-02, -1.2249e-02,
          2.7315e-02,  3.8563e-03, -4.4721e-02,  1.7352e-02, -1.3607e-03,
         -8.2962e-02, -4.0825e-03, -1.8189e-04,  3.5791e-03,  6.1960e-03,
         -2.3417e-02, -2.4038e-02, -1.4020e-02, -3.5008e-02, -7.2932e-05,
          3.0900e-02, -4.6438e-02,  8.0197e-03, -1.0960e-02,  3.4231e-02,
         -6.2726e-03, -2.5404e-03,  1.8774e-02,  2.3095e-02,  2.2390e-02,
         -9.0465e-03, -3.1540e-03, -9.5738e-03, -1.4071e-02,  6.2963e-02,
          8.6015e-03,  2.6915e-02,  6.8440e-02,  1.3448e-02,  1.3431e-02,
         -1.5786e-03, -1.3265e-02,  1.2512e-02,  2.8184e-02, -2.7458e-02,
         -3.4067e-03, -4.0727e-03, -1.7803e-02,  9.7735e-03,  1.2211e-02,
          5.3767e-02,  1.2571e-02,  1.4489e-02,  1.2709e-02, -4.8418e-03,
         -8.5255e-03, -1.4756e-03, -3.6384e-02, -1.8112e-02, -1.9186e-02,
          6.4911e-03,  1.7096e-02,  1.6460e-02, -1.6000e-02, -2.1925e-03,
          8.7785e-03, -3.2456e-02,  4.2672e-02,  1.2450e-02, -5.7416e-03,
          1.2641e-02, -1.6642e-02, -2.8580e-02, -3.4487e-02, -5.4738e-03,
          2.0926e-02,  2.0657e-02,  2.7353e-02, -1.5277e-03, -2.7225e-02,
         -1.1495e-02,  5.0688e-03, -4.1028e-03,  2.9757e-02,  7.8247e-03,
          1.3643e-02,  4.1492e-03,  2.6102e-03,  2.8171e-02,  1.1313e-02,
          3.6439e-03, -3.4219e-02,  4.1346e-03, -1.1688e-02,  1.5325e-02,
         -3.1133e-02,  2.1732e-03,  1.1582e-02,  4.2435e-03, -2.5931e-02,
          1.7946e-02, -8.4044e-03, -5.8444e-02, -2.9188e-03, -1.9270e-02,
          2.1421e-02, -3.4212e-02, -3.4092e-03, -8.6882e-03, -2.1663e-02,
         -6.6075e-02, -3.6524e-02,  1.0244e-03, -6.2740e-02, -9.4260e-03,
          4.1370e-02, -5.3667e-02, -1.0381e-04,  1.6153e-02, -2.2134e-02,
         -1.7852e-02,  3.0963e-03,  2.0213e-02,  1.6734e-02, -1.7233e-02,
          5.1407e-02,  1.0689e-04,  7.1731e-03,  1.7946e-02,  2.5975e-02,
          1.1730e-02, -6.9201e-05, -4.3343e-02,  8.8254e-04,  1.8517e-02,
          5.9069e-03,  4.5079e-02,  7.8187e-02,  2.6016e-02, -2.5329e-02,
         -3.3154e-02,  1.2889e-02,  1.1032e-02,  1.1134e-03, -6.9989e-02,
         -6.0414e-02,  3.9124e-02, -4.4741e-02,  1.6553e-02, -7.2190e-02,
         -1.3674e-02,  1.2446e-02, -8.6898e-03, -1.4911e-03, -8.5524e-03,
         -4.0241e-02]])
