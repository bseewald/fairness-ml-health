Weights: 
net.embeddings.embeddings.0.weight tensor([[ 0.1882,  0.0242],
        [-0.1218, -0.1002],
        [ 0.0966, -0.0659],
        [-0.0777, -0.2274]])
net.embeddings.embeddings.1.weight tensor([[ 0.1521,  0.0707],
        [-0.0127, -0.3241],
        [ 0.1282, -0.1417],
        [ 0.0169,  0.0262],
        [-0.1618,  0.0376]])
net.embeddings.embeddings.2.weight tensor([[-0.0497, -0.1384,  0.1563],
        [ 0.0585, -0.1697, -0.1415],
        [ 0.0444, -0.0099,  0.0163],
        [-0.0441,  0.2115, -0.0868],
        [ 0.0741,  0.1072, -0.0297],
        [ 0.0648, -0.2203,  0.0984]])
net.embeddings.embeddings.3.weight tensor([[-0.0841, -0.1480],
        [-0.3229,  0.0225],
        [-0.0041, -0.1516],
        [ 0.1518, -0.3959]])
net.embeddings.embeddings.4.weight tensor([[-0.0141,  0.1149],
        [ 0.1526,  0.3331],
        [-0.1433, -0.2256],
        [ 0.1989, -0.0183]])
net.mlp.net.0.linear.weight tensor([[ 0.0115, -0.1331,  0.1157,  ...,  0.2401,  0.1622, -0.0197],
        [ 0.0072,  0.0216,  0.0193,  ...,  0.0375,  0.1858,  0.2592],
        [ 0.0098,  0.1797, -0.1571,  ...,  0.0965,  0.1576,  0.1697],
        ...,
        [ 0.1029, -0.0635, -0.0352,  ...,  0.0037,  0.2993,  0.1953],
        [-0.0669, -0.0569, -0.0951,  ..., -0.0359,  0.1636, -0.0245],
        [-0.1914, -0.0462, -0.1289,  ..., -0.0425,  0.0694,  0.0203]])
net.mlp.net.0.linear.bias tensor([-0.0162,  0.0451,  0.0232,  0.0207, -0.0122, -0.0506, -0.0503,  0.0661,
         0.0710,  0.1368,  0.0215,  0.1365,  0.0101, -0.0189,  0.0064,  0.0735,
         0.0219,  0.0713, -0.0340,  0.0954,  0.0538,  0.0771,  0.0232, -0.0476,
         0.1098,  0.0012,  0.0335, -0.0566, -0.0737,  0.0395,  0.0643,  0.0311,
        -0.0730, -0.1210, -0.0143, -0.0616, -0.0100,  0.1197, -0.0064, -0.0008,
         0.0258, -0.0424,  0.0842,  0.0111, -0.0752,  0.0099, -0.0124,  0.1090,
        -0.0003, -0.0115,  0.0604, -0.0331, -0.0200, -0.0246, -0.0645, -0.0125,
        -0.0858,  0.0631, -0.0465, -0.0345, -0.0105,  0.0281, -0.1003, -0.0186,
         0.0789,  0.0365,  0.0183,  0.1088, -0.1072,  0.0123,  0.0790,  0.0925,
        -0.0161, -0.0977,  0.0635,  0.0575, -0.0771,  0.0007, -0.0934, -0.0808,
        -0.0582, -0.0163, -0.0772,  0.0428, -0.0080, -0.0609,  0.0172, -0.0750,
        -0.0416, -0.0863,  0.0840,  0.1337, -0.0014, -0.0340,  0.0990,  0.0134,
        -0.0949,  0.0520,  0.0427,  0.0084,  0.0572,  0.0322, -0.0057,  0.0521,
        -0.0563, -0.0065,  0.0455, -0.0132,  0.0078,  0.0024,  0.0213,  0.0108,
         0.0325, -0.0812, -0.0546,  0.0529, -0.0233, -0.0937, -0.0631,  0.0380,
        -0.0296, -0.0909, -0.1185,  0.0589, -0.0227,  0.0662,  0.0460, -0.0629,
         0.0229,  0.0594,  0.0770, -0.0517, -0.1225, -0.0302, -0.0317,  0.0265,
         0.0570, -0.0083,  0.0064, -0.0546,  0.0542,  0.0627, -0.0474, -0.0195,
         0.0048,  0.0200, -0.0522,  0.0257,  0.0860, -0.0170, -0.0661,  0.0298,
         0.0716, -0.1234,  0.0157, -0.0703, -0.1230, -0.0045, -0.0386,  0.0998,
         0.1109, -0.0248,  0.1535, -0.0449, -0.1347, -0.0667, -0.0140,  0.0365,
         0.0380, -0.0382,  0.0225,  0.0302,  0.0657,  0.0492,  0.0494,  0.0897,
         0.0156,  0.0385,  0.0791, -0.0096,  0.0506,  0.0834, -0.1539, -0.0123,
         0.0448,  0.0215, -0.0079,  0.0758, -0.0338, -0.0279,  0.0675, -0.1074,
         0.0124, -0.0781, -0.0593, -0.0595, -0.0104,  0.0550,  0.0708,  0.0990,
        -0.0257, -0.0550, -0.0489, -0.0804,  0.0049, -0.0764, -0.0564,  0.0070,
        -0.0167, -0.0201, -0.0262, -0.1384,  0.0770,  0.0361,  0.0743,  0.0248,
         0.0024, -0.0202,  0.0814, -0.0794,  0.0292,  0.0988, -0.0968,  0.1250,
        -0.0541,  0.0982, -0.0676,  0.0081,  0.0306,  0.0863, -0.0427,  0.0690,
         0.1070, -0.0400, -0.0504,  0.0766,  0.0243, -0.0246, -0.0325, -0.0377,
         0.0531,  0.0707, -0.1567, -0.0920, -0.0895,  0.0839,  0.0391, -0.0290,
         0.0253, -0.0934,  0.0699, -0.0233, -0.0939,  0.0691,  0.0116,  0.0548])
net.mlp.net.0.batch_norm.weight tensor([0.4337, 0.3372, 0.3607, 0.4333, 0.4210, 0.3434, 0.3928, 0.3942, 0.3589,
        0.3006, 0.2943, 0.3617, 0.3305, 0.3240, 0.2892, 0.3152, 0.3317, 0.3046,
        0.3283, 0.3642, 0.3574, 0.3442, 0.3178, 0.3112, 0.3734, 0.3848, 0.4036,
        0.3610, 0.3875, 0.3877, 0.3488, 0.3352, 0.3586, 0.4419, 0.3706, 0.3933,
        0.3883, 0.3112, 0.3462, 0.3709, 0.3606, 0.3172, 0.4546, 0.3304, 0.3398,
        0.3681, 0.3370, 0.3270, 0.3604, 0.3956, 0.3184, 0.3290, 0.3353, 0.3903,
        0.4568, 0.3343, 0.3244, 0.3883, 0.2926, 0.3499, 0.3261, 0.3349, 0.3461,
        0.3975, 0.3180, 0.4355, 0.3384, 0.3302, 0.3646, 0.3678, 0.3673, 0.4132,
        0.3056, 0.3344, 0.3638, 0.4192, 0.3634, 0.3736, 0.2702, 0.3393, 0.3329,
        0.3442, 0.4056, 0.2836, 0.3513, 0.3922, 0.3083, 0.3907, 0.2788, 0.3744,
        0.2232, 0.3099, 0.3774, 0.3279, 0.3858, 0.3504, 0.3643, 0.2899, 0.4108,
        0.3041, 0.4479, 0.3194, 0.3578, 0.3909, 0.3935, 0.3533, 0.3969, 0.2718,
        0.3158, 0.2985, 0.3039, 0.3243, 0.3267, 0.3841, 0.4129, 0.3469, 0.3390,
        0.3957, 0.4429, 0.3117, 0.3733, 0.4276, 0.3560, 0.4260, 0.3729, 0.4081,
        0.3874, 0.4003, 0.3464, 0.4023, 0.3610, 0.4207, 0.4731, 0.3307, 0.3666,
        0.4196, 0.3454, 0.4093, 0.3075, 0.3821, 0.4352, 0.3146, 0.3271, 0.4075,
        0.2185, 0.4586, 0.2592, 0.3178, 0.3701, 0.3213, 0.3764, 0.4177, 0.2840,
        0.3225, 0.3312, 0.3045, 0.4146, 0.3197, 0.4644, 0.3408, 0.3604, 0.3468,
        0.2918, 0.3377, 0.4064, 0.3357, 0.4411, 0.3568, 0.4178, 0.4162, 0.4391,
        0.3560, 0.2813, 0.3703, 0.4071, 0.3768, 0.3781, 0.3319, 0.3450, 0.3214,
        0.3873, 0.3559, 0.4065, 0.3587, 0.3777, 0.3238, 0.3049, 0.2676, 0.3395,
        0.4412, 0.3686, 0.3647, 0.4047, 0.4189, 0.3016, 0.4052, 0.4476, 0.3886,
        0.3398, 0.3253, 0.3405, 0.3915, 0.2850, 0.3066, 0.2818, 0.3844, 0.3663,
        0.3526, 0.4326, 0.4080, 0.3446, 0.3432, 0.3454, 0.3368, 0.3756, 0.4252,
        0.3817, 0.4580, 0.3234, 0.3922, 0.3577, 0.3902, 0.4175, 0.4310, 0.3527,
        0.3424, 0.3423, 0.3759, 0.3414, 0.3182, 0.4394, 0.3018, 0.3339, 0.3319,
        0.3479, 0.3689, 0.3171, 0.3267, 0.4802, 0.3914, 0.3538, 0.4232, 0.4172,
        0.4547, 0.3622, 0.3754, 0.3414, 0.4296, 0.3183, 0.3525, 0.3064, 0.3256,
        0.3628, 0.4112, 0.3694, 0.2943])
net.mlp.net.0.batch_norm.bias tensor([-3.1944e-03,  1.7850e-02,  6.9243e-02, -2.5036e-02,  3.9400e-03,
        -3.6600e-02,  5.6515e-02,  1.4902e-01,  5.8679e-02,  3.3352e-02,
        -3.6389e-02,  4.3044e-02,  3.5801e-02, -6.6969e-02,  9.1084e-03,
        -3.4677e-03,  5.8374e-03,  5.5257e-02,  3.3092e-02,  1.3802e-02,
         8.7409e-02,  6.7149e-02,  1.6290e-02, -7.2936e-03,  3.5047e-02,
        -4.7213e-02,  3.6612e-02, -7.7208e-03,  5.8962e-02,  7.7077e-02,
        -3.0847e-02,  1.7155e-02, -3.1589e-02, -3.8542e-03,  5.8471e-02,
         7.9508e-02,  2.3885e-03, -1.4599e-02,  1.9089e-02, -5.1837e-05,
        -2.7398e-03,  5.3160e-02, -1.0388e-01,  1.6575e-02, -1.1026e-01,
        -1.3685e-02,  2.0868e-02, -2.0722e-02, -5.4414e-02, -2.3054e-02,
         6.3868e-02, -8.6710e-03, -2.9922e-02,  4.1744e-02, -3.7953e-02,
         2.6649e-02, -1.3155e-02,  8.7672e-03,  3.8495e-02, -1.8014e-02,
        -2.3883e-02, -3.6124e-02,  4.5162e-04,  5.8399e-03, -4.5689e-02,
         5.6506e-02,  2.0971e-02, -2.4927e-02, -2.2765e-03, -3.8421e-02,
         1.1538e-02,  3.2240e-02, -3.5169e-02,  7.4027e-02, -4.0647e-02,
         3.5381e-02,  4.7582e-04,  6.1681e-02,  1.2939e-02, -5.6598e-02,
        -5.5450e-02, -2.2219e-02, -9.3931e-02, -3.1316e-02,  8.1070e-03,
        -1.0649e-02,  7.1686e-03, -4.8215e-02, -3.9010e-03,  7.3245e-02,
        -2.0722e-02, -1.0171e-03,  1.5407e-02,  1.7929e-02,  1.7560e-02,
         4.2974e-02,  1.8200e-02, -2.4510e-02,  4.0540e-03, -5.3084e-02,
        -2.3081e-02, -4.1186e-02,  4.6295e-02,  4.3415e-02, -4.4782e-02,
        -2.7886e-02, -7.6576e-02, -5.8440e-03,  1.7424e-03,  6.0193e-02,
         4.9519e-02, -2.2585e-02,  7.2788e-02,  2.2201e-02,  2.7007e-02,
         4.5159e-03, -6.6578e-03, -2.6067e-02, -7.4582e-02,  9.9916e-02,
        -2.8122e-02,  1.4883e-02, -3.1259e-02,  2.1712e-02,  3.2949e-02,
        -1.2810e-02,  5.9795e-02,  2.6493e-02, -1.3761e-02,  3.6720e-02,
        -2.3855e-02, -2.8749e-03, -1.1390e-02, -2.7245e-02, -1.1650e-02,
         2.4693e-02,  3.3948e-02, -2.4767e-02, -3.9037e-02, -4.0208e-02,
        -2.0511e-02, -1.0231e-02, -2.6877e-02,  1.4348e-02, -2.4142e-02,
         2.8254e-02,  5.7407e-02,  1.9482e-02, -4.0999e-02, -8.8056e-03,
        -3.6355e-03,  5.9591e-02,  1.1570e-02,  3.4263e-02,  2.1205e-02,
         2.8342e-02, -2.6588e-02, -7.5345e-02,  3.4255e-03, -1.9097e-02,
         7.0142e-05, -1.9406e-02, -4.9842e-02,  2.3989e-03,  5.2928e-02,
         1.9048e-02, -2.1759e-02,  4.0228e-02, -4.7507e-02, -2.9933e-02,
        -5.8903e-02, -5.8868e-02,  3.0882e-02, -1.7460e-02, -2.6159e-02,
         5.8989e-03,  5.1794e-02, -8.4174e-03, -4.4407e-02,  4.6170e-02,
         3.4666e-02,  1.5373e-03,  6.1163e-02,  2.1797e-02, -2.6188e-02,
        -3.9692e-02,  3.3600e-02, -6.4420e-04,  2.2530e-02, -5.5550e-02,
        -2.5709e-02,  3.1581e-02,  7.1368e-03, -3.1333e-02, -2.2248e-02,
        -1.2309e-04,  2.1881e-02, -6.5617e-03, -1.1212e-02, -4.5824e-02,
        -1.1468e-02, -2.5816e-02,  4.3252e-02, -2.9252e-03,  2.4137e-02,
         5.4621e-02,  2.3822e-02, -1.3176e-03,  1.7226e-02, -1.9369e-02,
         6.2421e-03, -3.4788e-02,  2.7226e-03,  3.1226e-02,  2.6592e-02,
        -6.3868e-02,  8.2345e-03, -3.2430e-02, -7.5041e-02,  1.5076e-02,
         3.0871e-02, -3.2266e-02,  1.2214e-01, -5.0096e-02,  1.8938e-02,
        -1.6454e-02,  5.4165e-02, -4.3182e-02,  2.0790e-02,  1.8093e-02,
        -8.5728e-02, -3.4520e-02, -4.3820e-02,  5.3357e-02,  3.9270e-03,
        -8.1254e-03,  7.1555e-02,  4.1698e-02,  1.7048e-03,  2.7939e-02,
        -3.5611e-02,  1.3504e-02, -3.0855e-02, -9.7036e-03,  1.5584e-02,
        -5.7973e-02, -6.6264e-03,  8.6903e-03,  1.2108e-02,  2.1014e-02,
         2.5835e-03, -4.3132e-02,  2.1316e-02,  3.8623e-02,  6.9535e-02,
        -3.8247e-02])
net.mlp.net.0.batch_norm.running_mean tensor([1.8376e-02, 1.9652e-02, 2.2087e-01, 7.1112e-03, 1.2690e-01, 4.0307e-02,
        1.2425e-01, 1.1588e-02, 6.1173e-02, 3.9103e-01, 4.1658e-01, 1.7618e-01,
        6.9329e-02, 1.4691e-02, 6.8904e-02, 1.3475e-01, 7.5595e-02, 9.4856e-02,
        1.9921e-01, 4.7161e-01, 9.5385e-02, 2.1172e-02, 6.6279e-02, 9.6369e-03,
        1.5420e-02, 1.2789e-02, 7.1012e-02, 1.0290e-01, 1.0768e-04, 1.0443e-01,
        1.0134e-01, 4.0075e-01, 1.3938e-04, 2.5402e-03, 1.6675e-04, 2.0159e-02,
        7.2219e-02, 1.3934e-01, 1.9093e-01, 8.0372e-02, 3.4541e-01, 6.6310e-02,
        9.0763e-02, 6.2860e-02, 1.2288e-01, 1.6839e-01, 8.0195e-02, 2.1514e-01,
        2.6454e-01, 3.2070e-01, 1.5322e-01, 3.3705e-02, 1.8831e-01, 4.3680e-02,
        2.4295e-02, 8.7288e-02, 6.3583e-05, 1.4075e-02, 7.2241e-02, 2.1565e-01,
        1.0152e-01, 2.1816e-01, 5.3588e-02, 3.2011e-01, 9.6747e-02, 2.0546e-01,
        1.9752e-01, 3.0513e-01, 5.4591e-04, 4.7305e-04, 3.7834e-02, 4.4682e-01,
        7.3652e-02, 6.9959e-08, 1.3268e-01, 1.1990e-01, 7.6835e-03, 3.3385e-02,
        3.6063e-02, 2.5620e-01, 2.5132e-01, 3.8610e-04, 3.4447e-02, 1.9958e-01,
        4.7709e-02, 4.8213e-02, 3.6490e-01, 1.2763e-01, 1.8737e-03, 3.3044e-04,
        1.7390e-01, 2.3436e-01, 4.0982e-02, 1.2690e-02, 2.2811e-01, 7.7215e-02,
        6.2465e-03, 4.4514e-01, 8.2087e-02, 3.1616e-01, 5.8908e-02, 9.7984e-02,
        3.1891e-01, 2.7794e-02, 2.3559e-01, 1.7747e-01, 2.5256e-01, 2.2326e-01,
        2.2904e-01, 3.7553e-01, 5.0560e-03, 1.2648e-01, 1.5455e-02, 1.7576e-02,
        1.4813e-01, 1.4487e-01, 5.4085e-03, 3.5696e-01, 1.1990e-01, 7.8790e-02,
        6.0702e-02, 4.4887e-02, 6.4339e-06, 1.1920e-01, 1.2845e-03, 4.3363e-01,
        1.3690e-03, 2.4616e-01, 2.8941e-01, 6.7164e-02, 3.5275e-01, 1.0184e-01,
        1.0154e-03, 1.4503e-01, 1.5478e-06, 2.5161e-01, 2.2494e-01, 7.2645e-02,
        2.1832e-02, 3.2310e-02, 2.5667e-01, 1.5119e-01, 1.5308e-01, 1.3831e-02,
        1.7785e-01, 2.0410e-01, 2.1468e-01, 4.3923e-01, 1.8723e-01, 1.0649e-01,
        3.0811e-01, 1.2592e-02, 3.5873e-01, 4.9510e-02, 4.9513e-02, 1.1944e-03,
        1.7408e-03, 9.5851e-02, 2.9204e-02, 2.0005e-01, 1.8906e-01, 6.3599e-02,
        3.0556e-01, 4.7996e-02, 7.6825e-03, 9.9548e-03, 3.3129e-04, 3.9334e-01,
        6.9078e-02, 2.4545e-01, 5.0094e-01, 7.3866e-03, 2.1175e-01, 7.9856e-02,
        1.2442e-02, 1.1791e-01, 4.4288e-01, 4.8570e-02, 2.7300e-01, 2.4887e-01,
        1.9502e-02, 2.2346e-01, 8.4868e-04, 5.6315e-02, 1.2381e-02, 4.4607e-01,
        1.5479e-01, 3.4472e-02, 3.2563e-03, 9.0524e-04, 1.8569e-03, 5.0230e-05,
        4.9211e-02, 8.4455e-02, 1.1625e-01, 5.0332e-03, 2.3875e-01, 2.6781e-01,
        3.0540e-01, 3.4848e-02, 2.2335e-02, 5.4643e-05, 4.3870e-01, 2.7865e-02,
        2.8787e-02, 9.7976e-03, 3.9081e-02, 6.5441e-02, 3.5953e-01, 1.6180e-01,
        1.4044e-07, 5.6385e-05, 3.4960e-01, 9.5464e-02, 2.2520e-01, 6.1626e-03,
        1.3178e-02, 1.0750e-01, 1.2360e-01, 1.5075e-01, 1.6676e-03, 4.2220e-01,
        5.7170e-02, 3.7981e-01, 2.8228e-02, 3.1776e-03, 1.8222e-01, 2.1673e-02,
        3.5058e-01, 2.7421e-01, 2.8654e-02, 8.0149e-02, 2.2899e-01, 1.9872e-01,
        4.0764e-02, 4.0076e-01, 7.6154e-03, 3.3778e-02, 2.7251e-01, 3.0147e-03,
        4.4895e-01, 3.4715e-01, 3.2938e-02, 3.8375e-02, 2.0965e-01, 1.6514e-01,
        9.6487e-02, 1.9284e-03, 3.5682e-01, 1.3844e-01, 1.5477e-01, 8.1098e-02,
        1.6498e-02, 4.0024e-02, 3.5019e-02, 7.2983e-02])
net.mlp.net.0.batch_norm.running_var tensor([1.9880e-03, 3.2032e-03, 5.3222e-02, 9.5541e-04, 1.9642e-02, 7.3801e-03,
        2.4998e-02, 1.2538e-03, 1.1031e-02, 2.6657e-02, 6.2694e-02, 6.9524e-02,
        4.1531e-02, 6.0983e-03, 1.0515e-02, 2.0794e-02, 5.2513e-02, 1.8347e-02,
        6.7017e-02, 2.4464e-02, 5.8382e-02, 4.6455e-03, 9.0655e-03, 4.5075e-03,
        2.3164e-03, 1.7238e-03, 8.3375e-03, 1.8251e-02, 3.8353e-05, 1.0419e-01,
        1.2618e-02, 3.2276e-02, 5.0406e-05, 3.8092e-04, 3.9217e-05, 2.0728e-03,
        1.1728e-02, 1.1892e-02, 3.8214e-02, 2.6064e-02, 2.1585e-02, 1.1341e-02,
        1.2477e-02, 1.2573e-02, 1.6528e-02, 4.7539e-02, 1.3625e-02, 1.3369e-02,
        3.5389e-02, 1.3863e-02, 1.2472e-02, 7.6695e-03, 1.3987e-02, 4.8686e-03,
        4.1854e-03, 5.3765e-02, 3.1389e-05, 1.6734e-03, 1.9788e-02, 1.4979e-02,
        7.6419e-03, 1.4181e-02, 3.3396e-02, 3.0857e-02, 1.0832e-02, 1.6294e-02,
        3.7288e-02, 4.3049e-02, 6.8490e-05, 5.3761e-05, 7.0623e-03, 3.0517e-02,
        1.0684e-02, 2.6562e-05, 9.6065e-03, 2.2257e-02, 1.9642e-03, 1.4929e-02,
        5.1297e-03, 2.4088e-02, 3.5597e-02, 6.0973e-05, 3.5462e-03, 1.9345e-02,
        3.2384e-02, 2.2540e-02, 4.4835e-02, 6.1968e-02, 3.3777e-04, 6.7495e-05,
        3.0281e-02, 2.7273e-02, 5.1719e-03, 3.7391e-03, 2.3239e-02, 1.2302e-02,
        2.9840e-03, 3.3837e-02, 1.1536e-02, 2.6948e-02, 1.0791e-02, 6.8388e-02,
        3.6471e-02, 4.3176e-03, 2.2930e-02, 8.9148e-03, 2.0764e-02, 3.4516e-02,
        1.3974e-02, 2.2482e-02, 1.7405e-03, 5.5063e-02, 7.2931e-03, 1.9405e-03,
        9.7444e-03, 5.7233e-02, 2.1446e-03, 2.8897e-02, 1.2948e-02, 5.9823e-02,
        7.9248e-03, 6.8679e-03, 2.8615e-05, 1.2104e-02, 1.5754e-04, 7.0123e-02,
        1.4611e-04, 1.5103e-02, 3.8730e-02, 5.1755e-02, 2.4828e-02, 7.8165e-03,
        1.2487e-04, 2.0978e-02, 2.6584e-05, 1.9113e-02, 1.5902e-02, 1.2510e-02,
        1.0355e-02, 5.1617e-03, 2.8812e-02, 1.4753e-02, 3.7070e-02, 7.8196e-03,
        3.5190e-02, 2.4704e-02, 2.2125e-02, 3.1893e-02, 2.8254e-02, 1.2444e-02,
        2.7929e-02, 1.4444e-03, 3.8273e-02, 9.5196e-03, 2.0434e-02, 1.2701e-04,
        5.4718e-04, 1.7555e-02, 2.7707e-03, 1.5256e-02, 2.0282e-02, 8.3377e-03,
        2.4857e-02, 4.9370e-03, 4.1980e-03, 3.6947e-03, 6.1692e-05, 7.1340e-02,
        1.2299e-02, 1.7971e-02, 3.1973e-02, 1.3341e-03, 1.6320e-02, 1.1861e-02,
        5.3792e-03, 1.7050e-02, 4.3919e-02, 5.3532e-03, 2.8902e-02, 3.0523e-02,
        2.6019e-03, 5.3326e-02, 3.1507e-04, 9.4490e-03, 1.9978e-03, 6.5313e-02,
        2.2399e-02, 6.0016e-03, 4.1082e-04, 1.0674e-04, 3.2255e-04, 3.1035e-05,
        7.3591e-03, 6.4296e-02, 1.4046e-02, 8.6658e-04, 2.6430e-02, 1.8425e-02,
        2.6713e-02, 5.9941e-03, 2.4502e-03, 3.3678e-05, 9.0286e-02, 1.1281e-02,
        3.5612e-03, 1.0255e-03, 1.4370e-02, 7.2979e-02, 3.2109e-02, 3.5913e-02,
        2.6579e-05, 3.1249e-05, 2.6831e-02, 1.4598e-02, 2.8501e-02, 7.8697e-04,
        5.3184e-03, 9.0489e-03, 1.8662e-02, 6.1380e-02, 2.6868e-04, 2.1162e-02,
        7.7465e-03, 3.2290e-02, 4.0809e-03, 4.6053e-04, 4.3317e-02, 4.1861e-03,
        2.5778e-02, 2.5057e-02, 2.9228e-03, 1.0547e-02, 1.7879e-02, 2.0361e-02,
        5.2757e-03, 5.6075e-02, 1.9983e-03, 1.0079e-02, 2.6620e-02, 4.0167e-04,
        5.6015e-02, 8.8209e-02, 2.8564e-02, 5.3041e-03, 1.9697e-02, 1.1129e-02,
        1.0764e-02, 3.3424e-04, 3.8503e-02, 1.6637e-02, 2.3725e-02, 3.6289e-02,
        1.0899e-02, 6.8530e-03, 1.7819e-02, 1.5585e-02])
net.mlp.net.0.batch_norm.num_batches_tracked tensor(100)
net.mlp.net.1.linear.weight tensor([[ 0.0534,  0.0385,  0.0286,  ..., -0.0097, -0.0131,  0.0160],
        [ 0.0479, -0.0797, -0.0288,  ..., -0.0206, -0.0177, -0.0128],
        [ 0.1086,  0.0009,  0.0314,  ...,  0.0807,  0.0188,  0.0275],
        ...,
        [-0.0416, -0.0572,  0.0064,  ...,  0.0591,  0.0150,  0.0321],
        [ 0.0249, -0.0785,  0.0670,  ..., -0.0060,  0.0099, -0.0243],
        [-0.0584, -0.0215,  0.0411,  ..., -0.0613, -0.0400, -0.0167]])
net.mlp.net.1.linear.bias tensor([-0.0400, -0.0351, -0.0190, -0.0151, -0.0388,  0.0137, -0.0114, -0.0308,
        -0.0554,  0.0551,  0.0399, -0.0749,  0.0195, -0.0254, -0.0662, -0.0998,
        -0.0404,  0.0104, -0.0014,  0.0504,  0.0119,  0.0032, -0.0150,  0.0696,
        -0.0041,  0.0483,  0.0524, -0.0626,  0.0120, -0.0301, -0.0506,  0.0769,
        -0.0869, -0.0450,  0.0386, -0.0086,  0.0613, -0.0681,  0.0620, -0.0904,
        -0.0059,  0.0166, -0.0133, -0.0385, -0.0382,  0.0396,  0.0211, -0.0814,
        -0.0918, -0.0394, -0.0205, -0.0253, -0.0363, -0.0136, -0.0255,  0.0552,
        -0.0572, -0.0100, -0.0451, -0.0051,  0.0370, -0.0573, -0.0389, -0.0722,
         0.0055, -0.0183,  0.1047,  0.0150, -0.0006,  0.0795,  0.0505, -0.0999,
         0.0316,  0.0616,  0.0414, -0.0648, -0.0025,  0.0383,  0.0674, -0.0177,
         0.0505, -0.0598, -0.0533, -0.0585, -0.0750,  0.0545,  0.0684,  0.0511,
        -0.0268, -0.0533,  0.0104, -0.0480,  0.0035,  0.0395, -0.0166,  0.0233,
         0.0556,  0.0706,  0.1101, -0.1088, -0.0785,  0.0132,  0.0138,  0.0227,
        -0.0490, -0.0180,  0.0294,  0.0697,  0.0525,  0.0177, -0.0049, -0.0020,
         0.0434, -0.0257, -0.0497, -0.0387,  0.0675,  0.0271,  0.0697,  0.0249,
         0.0554, -0.0028, -0.0319,  0.0072, -0.0147,  0.0487, -0.0132, -0.0399,
         0.0422, -0.0014, -0.0436,  0.0061, -0.0536, -0.0193,  0.0126, -0.0477,
        -0.0095,  0.0024,  0.0328,  0.0040,  0.0099, -0.0362, -0.0063, -0.0721,
         0.0170, -0.0399,  0.0570, -0.0212, -0.0246, -0.0621, -0.0377,  0.0671,
        -0.0640, -0.0053, -0.0121,  0.0216,  0.1209, -0.0346,  0.0103,  0.0046,
        -0.0829, -0.1037, -0.0140, -0.0516, -0.0467, -0.0041, -0.0415, -0.0535,
         0.0268,  0.0056,  0.0708,  0.0183,  0.0258,  0.0044,  0.0572,  0.1443,
         0.0282,  0.0422, -0.0244, -0.0746,  0.1003,  0.0206, -0.0770, -0.0760,
         0.0668, -0.0169, -0.0006,  0.0467,  0.0107,  0.0773,  0.1062, -0.0093,
         0.0592, -0.0043,  0.0315,  0.0441, -0.0156,  0.1090, -0.0642,  0.0251,
        -0.0170,  0.0161,  0.0532,  0.0170,  0.0154, -0.0434,  0.0128,  0.0286,
        -0.0216,  0.0628,  0.0731,  0.0711,  0.0559, -0.0073,  0.0012,  0.0292,
         0.0120,  0.0139, -0.0881,  0.0334,  0.0028, -0.0332, -0.0204, -0.0332,
        -0.0100, -0.1191,  0.0530,  0.0311,  0.0089,  0.0807,  0.0470, -0.0304,
         0.0221,  0.0710, -0.0596,  0.0698, -0.0535,  0.0473,  0.0076,  0.0361,
        -0.0462, -0.0777, -0.0150, -0.0118,  0.0298,  0.0427,  0.0699, -0.0083,
         0.0429, -0.0436, -0.0765,  0.0389, -0.0171,  0.0193, -0.0143,  0.0153])
net.mlp.net.1.batch_norm.weight tensor([0.2994, 0.3360, 0.2902, 0.2860, 0.3275, 0.3141, 0.3408, 0.3028, 0.2753,
        0.3603, 0.3100, 0.2993, 0.3124, 0.2554, 0.3217, 0.3152, 0.2968, 0.3047,
        0.3532, 0.3137, 0.2922, 0.3018, 0.3086, 0.3696, 0.3587, 0.3559, 0.3153,
        0.2626, 0.2944, 0.2445, 0.3226, 0.3346, 0.3714, 0.3207, 0.3050, 0.3835,
        0.2854, 0.2892, 0.2760, 0.2779, 0.3447, 0.3067, 0.2796, 0.3006, 0.3337,
        0.2956, 0.3776, 0.3705, 0.3612, 0.3252, 0.2986, 0.2427, 0.2607, 0.3942,
        0.2717, 0.3201, 0.3208, 0.2842, 0.3001, 0.3145, 0.3408, 0.3302, 0.3171,
        0.3017, 0.2391, 0.2805, 0.3010, 0.3389, 0.2750, 0.3480, 0.3799, 0.3456,
        0.2875, 0.3470, 0.3259, 0.3051, 0.2760, 0.3535, 0.2666, 0.2853, 0.3263,
        0.3054, 0.3647, 0.2664, 0.3780, 0.2602, 0.3151, 0.3148, 0.2888, 0.2523,
        0.3474, 0.3245, 0.3074, 0.3105, 0.3589, 0.2957, 0.3681, 0.2643, 0.2512,
        0.2515, 0.3383, 0.3316, 0.3039, 0.3121, 0.3089, 0.3059, 0.2859, 0.3203,
        0.2966, 0.2578, 0.3918, 0.3173, 0.3300, 0.3014, 0.3369, 0.2841, 0.3393,
        0.2544, 0.2973, 0.3372, 0.2480, 0.3626, 0.3583, 0.3247, 0.2518, 0.3241,
        0.2983, 0.2888, 0.3004, 0.3672, 0.2875, 0.2563, 0.2429, 0.2779, 0.3689,
        0.3396, 0.2724, 0.3200, 0.3459, 0.3310, 0.2746, 0.2919, 0.3427, 0.3328,
        0.3357, 0.3744, 0.3788, 0.3199, 0.3780, 0.3379, 0.3216, 0.3605, 0.2802,
        0.3352, 0.3343, 0.2894, 0.2824, 0.2816, 0.2994, 0.2864, 0.2886, 0.2987,
        0.3153, 0.3058, 0.3318, 0.3381, 0.3737, 0.2925, 0.3301, 0.3948, 0.3885,
        0.3314, 0.3568, 0.3683, 0.3743, 0.3243, 0.3013, 0.3127, 0.2873, 0.3425,
        0.2828, 0.2959, 0.3855, 0.2806, 0.3302, 0.3214, 0.3369, 0.3774, 0.2725,
        0.3045, 0.2978, 0.3502, 0.3226, 0.3016, 0.3522, 0.4144, 0.3141, 0.3252,
        0.2892, 0.2706, 0.3202, 0.3444, 0.3521, 0.3210, 0.3394, 0.3510, 0.2982,
        0.3375, 0.2794, 0.2907, 0.3119, 0.3020, 0.3691, 0.3348, 0.3441, 0.2925,
        0.2595, 0.3248, 0.3007, 0.2562, 0.3493, 0.3083, 0.3215, 0.3831, 0.3300,
        0.3388, 0.3824, 0.3027, 0.3403, 0.3405, 0.3215, 0.3585, 0.2724, 0.3829,
        0.2889, 0.3049, 0.3308, 0.2880, 0.3250, 0.3147, 0.3484, 0.4106, 0.3250,
        0.2877, 0.3831, 0.3922, 0.4016, 0.3432, 0.3993, 0.3115, 0.2272, 0.3283,
        0.2991, 0.3297, 0.3079, 0.3619])
net.mlp.net.1.batch_norm.bias tensor([ 0.0416,  0.0352, -0.0476, -0.0033, -0.0007,  0.0100, -0.0068, -0.0435,
         0.0014,  0.0332, -0.0003, -0.0112, -0.0316,  0.0313, -0.0757,  0.0320,
         0.0557,  0.0099, -0.0057,  0.0102,  0.0631,  0.0509, -0.0124, -0.0098,
        -0.0102, -0.0121, -0.0234, -0.0153,  0.0395,  0.0028, -0.0133, -0.0440,
         0.0543,  0.0176,  0.0374, -0.0568,  0.0119, -0.0609,  0.0641,  0.0268,
         0.0299, -0.0193, -0.0949, -0.0181,  0.0324, -0.0050,  0.0448, -0.0721,
        -0.0094,  0.0475, -0.0012,  0.0971,  0.0442, -0.0419,  0.0641, -0.0590,
        -0.0623,  0.0071,  0.0295, -0.0611, -0.0262, -0.0491, -0.0042,  0.0066,
        -0.0750, -0.0477, -0.0097, -0.0038, -0.0072,  0.1099, -0.0065,  0.0250,
        -0.0004, -0.0956, -0.0292,  0.0401, -0.0393,  0.0331, -0.0129,  0.0634,
         0.0335, -0.0232, -0.0007, -0.0004,  0.0612, -0.0470, -0.0318, -0.0581,
         0.0344,  0.0363, -0.0778,  0.0091,  0.0577,  0.0679,  0.0897,  0.0432,
         0.0038, -0.0296, -0.0016,  0.0048, -0.0286,  0.0137,  0.0408,  0.0619,
         0.0057,  0.0880, -0.0141,  0.0154, -0.0158, -0.0128,  0.0989,  0.0533,
        -0.0530,  0.0390,  0.0431,  0.0385, -0.0100, -0.0636,  0.0282,  0.0164,
         0.0599, -0.0142,  0.0181, -0.0175,  0.0471,  0.0372,  0.0386,  0.0151,
         0.0715, -0.0119,  0.0012,  0.0368,  0.1019,  0.0237,  0.0372,  0.0269,
        -0.0143, -0.0045,  0.0181,  0.0498,  0.0453,  0.0618, -0.0377, -0.0036,
         0.0230,  0.0081,  0.0312, -0.0009, -0.1199, -0.0308, -0.0451,  0.0934,
        -0.0597, -0.0327,  0.0131, -0.0176, -0.0325,  0.0314,  0.0312,  0.0479,
         0.0061, -0.0013,  0.0321,  0.0473,  0.0004,  0.0139, -0.0234,  0.0496,
         0.0706, -0.0091, -0.0723, -0.0492,  0.0728,  0.0613,  0.0253,  0.0209,
         0.0301,  0.0120,  0.0277, -0.0196, -0.0602, -0.0090, -0.0164, -0.0613,
        -0.0444,  0.0012,  0.0308,  0.0264, -0.0193, -0.0032, -0.0107,  0.0369,
        -0.0291,  0.0079, -0.0087, -0.0016, -0.0224,  0.0649, -0.0182,  0.0604,
        -0.0422, -0.0145,  0.0128,  0.0403,  0.0522,  0.0014,  0.0090, -0.0428,
         0.0083,  0.0939, -0.0027,  0.0402,  0.0477,  0.0206,  0.0224,  0.0075,
        -0.0375,  0.0386, -0.0764,  0.0038, -0.0098,  0.0577, -0.0111, -0.0133,
        -0.0313, -0.0217,  0.0509, -0.0150,  0.0260, -0.0186, -0.0348,  0.0600,
        -0.0097, -0.0877, -0.0434,  0.0338, -0.0618,  0.0104,  0.0347, -0.0552,
        -0.0784, -0.0590,  0.0134,  0.0469, -0.0657,  0.0810, -0.0143, -0.0247,
         0.0036, -0.0144,  0.0818,  0.0261, -0.0355,  0.0263,  0.0859, -0.0052])
net.mlp.net.1.batch_norm.running_mean tensor([0.2462, 0.2591, 0.2301, 0.2605, 0.2559, 0.2555, 0.3176, 0.1994, 0.1410,
        0.3694, 0.3895, 0.2947, 0.2438, 0.2333, 0.2249, 0.2175, 0.2779, 0.2258,
        0.3902, 0.4116, 0.3218, 0.3250, 0.3032, 0.4150, 0.3677, 0.4049, 0.2664,
        0.2484, 0.2964, 0.2461, 0.2194, 0.3880, 0.1456, 0.2626, 0.2604, 0.3637,
        0.2865, 0.1935, 0.2752, 0.3243, 0.3207, 0.2855, 0.1735, 0.2275, 0.3585,
        0.3105, 0.4375, 0.2696, 0.2085, 0.3002, 0.2503, 0.3500, 0.2155, 0.2999,
        0.2283, 0.3833, 0.2202, 0.3148, 0.2108, 0.2801, 0.3009, 0.2956, 0.2792,
        0.2066, 0.2824, 0.2506, 0.3320, 0.2433, 0.2117, 0.4296, 0.4239, 0.2632,
        0.1947, 0.4306, 0.2483, 0.1693, 0.2047, 0.4421, 0.3794, 0.2139, 0.3310,
        0.2517, 0.3651, 0.2586, 0.3672, 0.2701, 0.3010, 0.3133, 0.2895, 0.2844,
        0.3146, 0.3050, 0.2329, 0.2443, 0.2964, 0.2753, 0.4378, 0.2655, 0.2525,
        0.1619, 0.1730, 0.2500, 0.2645, 0.3897, 0.1832, 0.2190, 0.2322, 0.2932,
        0.3100, 0.2579, 0.3186, 0.3248, 0.2427, 0.1792, 0.3572, 0.2429, 0.3600,
        0.2517, 0.2610, 0.3337, 0.3083, 0.2323, 0.2758, 0.2699, 0.2759, 0.2951,
        0.2514, 0.1982, 0.2980, 0.2327, 0.2787, 0.2813, 0.2124, 0.2048, 0.3429,
        0.2382, 0.2632, 0.2498, 0.2285, 0.3335, 0.2849, 0.2297, 0.4010, 0.2561,
        0.3553, 0.2755, 0.3409, 0.1796, 0.2633, 0.1858, 0.3097, 0.3562, 0.3073,
        0.2301, 0.2399, 0.3204, 0.3453, 0.2226, 0.2685, 0.2715, 0.2189, 0.1528,
        0.2184, 0.2206, 0.1897, 0.2059, 0.3380, 0.3041, 0.2759, 0.3858, 0.4787,
        0.2471, 0.3705, 0.4326, 0.4155, 0.3261, 0.2322, 0.3877, 0.2863, 0.3827,
        0.4058, 0.2892, 0.2761, 0.2200, 0.2749, 0.3088, 0.2396, 0.3764, 0.2128,
        0.4081, 0.3125, 0.2772, 0.2530, 0.2949, 0.4142, 0.3387, 0.1888, 0.3457,
        0.1824, 0.3872, 0.2904, 0.3103, 0.2813, 0.2672, 0.3804, 0.2706, 0.3152,
        0.3143, 0.3211, 0.3052, 0.2358, 0.3168, 0.3655, 0.2075, 0.3117, 0.2307,
        0.2233, 0.2367, 0.1979, 0.2352, 0.2198, 0.2732, 0.2859, 0.3042, 0.3179,
        0.3297, 0.4083, 0.2372, 0.3724, 0.3462, 0.2907, 0.2714, 0.2208, 0.4424,
        0.2341, 0.2964, 0.2314, 0.2721, 0.2982, 0.2948, 0.2736, 0.3220, 0.1916,
        0.2457, 0.3283, 0.3168, 0.5688, 0.2825, 0.4926, 0.2859, 0.2220, 0.3646,
        0.1981, 0.2824, 0.2753, 0.3959])
net.mlp.net.1.batch_norm.running_var tensor([0.1747, 0.1502, 0.1924, 0.2231, 0.2353, 0.2838, 0.3229, 0.1226, 0.1065,
        0.2489, 0.2881, 0.3285, 0.1124, 0.1810, 0.1667, 0.1621, 0.7594, 0.1263,
        0.2877, 0.4166, 0.2467, 0.5322, 0.3092, 0.2855, 0.4189, 0.2634, 0.2410,
        0.1650, 0.5777, 0.1817, 0.1377, 0.3556, 0.0895, 0.3065, 0.2276, 0.2477,
        0.2343, 0.1758, 0.4510, 0.3250, 0.2790, 0.5246, 0.1229, 0.2775, 0.2624,
        0.1967, 0.4653, 0.4020, 0.1757, 0.2810, 0.2042, 0.3163, 0.3278, 0.1731,
        0.3558, 0.2433, 0.1986, 0.1792, 0.1715, 0.1966, 0.2287, 0.1828, 0.6053,
        0.2675, 0.3789, 0.1421, 0.1572, 0.1268, 0.2685, 0.3270, 0.4800, 0.6725,
        0.0789, 0.2988, 0.1840, 0.0985, 0.1530, 0.4674, 0.7385, 0.1164, 0.2856,
        0.3994, 0.3208, 0.2649, 0.3673, 0.2203, 0.2043, 0.1919, 0.3258, 0.6310,
        0.4533, 0.6924, 0.2793, 0.4344, 0.2792, 0.2805, 0.3212, 0.2349, 0.1159,
        0.1763, 0.1132, 0.1920, 0.2247, 0.7767, 0.1198, 0.1457, 0.1959, 0.1787,
        0.1521, 0.1561, 0.3333, 0.3265, 0.1247, 0.0937, 0.3809, 0.4581, 0.2198,
        0.1353, 0.1426, 0.3089, 0.1747, 0.1809, 0.1678, 0.2038, 0.5022, 0.1542,
        0.1987, 0.0984, 0.2830, 0.2300, 0.2679, 0.1558, 0.1610, 0.0929, 0.2356,
        0.2601, 0.1810, 0.2514, 0.1459, 0.3430, 0.2376, 0.2149, 0.4456, 0.1856,
        0.3231, 0.2347, 0.2777, 0.0930, 0.2456, 0.2107, 0.2652, 0.2852, 0.5240,
        0.1596, 0.1830, 0.3964, 0.1974, 0.3371, 0.1345, 0.1270, 0.2648, 0.0845,
        0.2162, 0.1783, 0.1117, 0.1372, 0.2100, 0.1842, 0.2579, 0.3906, 0.3778,
        0.1311, 0.4077, 0.4682, 0.4855, 0.2615, 0.1529, 0.3410, 0.7652, 0.4387,
        0.3245, 0.1790, 0.2102, 0.2130, 0.2978, 0.2364, 0.1221, 0.2562, 0.1207,
        0.4972, 0.1771, 0.2371, 0.2341, 0.1671, 0.4248, 0.3439, 0.1009, 0.4803,
        0.1096, 0.3842, 0.1996, 0.1869, 0.2595, 0.2056, 0.3212, 0.2842, 0.2472,
        0.2074, 0.2202, 0.4109, 0.1141, 0.1929, 0.3155, 0.1216, 0.2970, 0.2432,
        0.1093, 0.1677, 0.2256, 0.1312, 0.3199, 0.1551, 0.2705, 0.1979, 0.3228,
        1.0597, 0.4249, 0.4759, 0.2833, 0.3229, 0.2407, 0.2138, 0.1047, 0.4970,
        0.4312, 0.2081, 0.1605, 0.3392, 0.3639, 0.2104, 0.1840, 0.2715, 0.1078,
        0.3213, 0.3007, 0.2844, 0.6274, 0.1709, 0.5873, 0.2049, 0.1426, 0.3549,
        0.1387, 0.2456, 0.2676, 0.2617])
net.mlp.net.1.batch_norm.num_batches_tracked tensor(100)
net.mlp.net.2.weight tensor([[-3.6232e-03, -3.0554e-02, -2.5034e-03, -5.5916e-03,  1.0616e-02,
         -1.1832e-02,  3.3813e-02, -1.3735e-02,  1.6058e-02,  2.2828e-02,
          7.9384e-03,  1.4496e-03, -2.3627e-02, -1.1622e-02, -2.3306e-02,
         -2.2249e-03, -5.6813e-03, -2.9545e-02,  3.9242e-02,  5.3489e-03,
          2.1090e-02, -4.3718e-03,  9.1441e-03,  2.6542e-02, -1.2696e-02,
          4.0391e-02, -5.1475e-03,  2.0622e-02,  1.2401e-02,  8.2186e-03,
         -2.2968e-02, -2.6446e-02,  4.1503e-02, -4.5529e-03,  1.1206e-02,
          4.9115e-02, -3.0852e-04, -1.1526e-02,  1.8581e-02, -7.1350e-04,
         -1.1312e-02, -3.2275e-03, -1.0262e-02, -6.1631e-03,  2.2665e-02,
          7.4128e-03, -2.8831e-02, -4.1182e-02, -2.9011e-02, -1.3943e-02,
         -1.8316e-04,  8.4031e-03,  1.6390e-02,  4.1143e-02, -2.5446e-02,
          4.8498e-03,  1.7855e-02,  3.9055e-03, -2.2825e-02,  1.8625e-02,
         -1.4571e-02,  2.1848e-02, -3.5204e-02, -3.9764e-03, -2.1778e-02,
          4.2910e-03,  2.1738e-02,  4.2253e-02, -8.1737e-03,  3.0273e-02,
         -3.0906e-02,  1.7661e-02,  1.4622e-02,  2.3359e-02, -2.7084e-02,
          2.2695e-02, -1.9952e-02, -2.3051e-02, -9.4293e-03, -5.7390e-03,
         -1.3863e-02,  2.2624e-02,  3.0909e-02, -3.9290e-02, -3.4571e-02,
          1.0959e-02,  1.9776e-02, -2.4770e-02, -1.3271e-02, -1.6460e-02,
         -2.2034e-02, -1.1761e-02,  8.5405e-05, -1.4398e-02, -3.3616e-02,
          8.2656e-03,  3.3437e-02,  1.6370e-03, -1.3199e-02,  1.1768e-02,
          3.7972e-02, -2.0563e-02, -8.9706e-03,  4.2150e-02, -2.5658e-03,
         -6.9644e-03, -1.3177e-02, -1.6558e-02, -1.3021e-02,  2.7681e-05,
         -4.8915e-02,  1.1282e-02,  2.2183e-02,  1.5469e-02, -3.1653e-02,
          6.3002e-03,  2.1483e-02, -2.3087e-03,  1.1135e-02, -2.0222e-02,
         -9.8671e-03, -4.1944e-02,  4.6085e-02, -1.2443e-02,  3.6639e-03,
          3.5454e-02, -1.4958e-02, -4.9787e-04,  2.3851e-02, -3.7415e-02,
         -3.9982e-03, -6.9517e-03, -7.4019e-03,  9.1385e-03,  3.2278e-02,
         -3.4153e-02, -2.1426e-03, -1.4844e-02, -2.8875e-02, -2.7677e-02,
         -4.4580e-03, -4.6960e-03, -3.3315e-02, -2.2057e-02, -2.4132e-02,
         -3.5596e-02, -3.2623e-02,  8.3487e-04,  4.5317e-02,  3.2997e-02,
         -1.7476e-02, -4.1909e-02,  2.9801e-03, -2.2893e-02, -3.2474e-02,
         -1.2910e-02,  1.6217e-02, -6.5213e-03,  7.9547e-03, -3.4648e-03,
          1.3333e-02,  6.8598e-03, -7.1129e-03,  1.1592e-02, -1.1705e-02,
          2.7569e-02,  4.3804e-02,  1.6619e-02,  2.5116e-03, -4.1002e-02,
          3.9581e-02,  1.4097e-02, -3.3302e-02, -3.8389e-02, -2.7500e-02,
         -1.5343e-02, -2.9059e-04, -9.4715e-03, -1.0009e-02, -1.7760e-02,
          1.2229e-03, -1.1391e-02,  3.1074e-02, -7.8065e-03, -2.0481e-02,
         -1.4505e-02, -1.9291e-02,  3.1758e-02, -3.6536e-03, -1.4146e-02,
          1.3358e-02, -2.3472e-02,  3.3149e-03,  6.1053e-03, -2.9661e-02,
         -5.5618e-02,  7.4717e-03, -2.3296e-02,  1.1239e-03,  4.5366e-03,
          1.6665e-02,  2.6784e-02, -2.6545e-02,  4.0959e-03, -4.0495e-02,
         -3.5374e-02,  8.9021e-03,  3.3259e-02, -2.0422e-02, -2.9328e-02,
         -2.0738e-02, -7.9148e-03, -3.5174e-02, -2.0437e-02, -1.8236e-02,
          2.0302e-02, -7.3450e-03,  2.3866e-02,  1.2468e-03, -2.2100e-02,
          2.6353e-02, -8.8883e-03, -1.7214e-02,  3.6579e-02, -8.0133e-03,
          2.0166e-02, -4.2570e-02, -8.7018e-03,  1.1438e-02, -2.3711e-02,
         -6.0958e-03, -5.0191e-02,  5.5038e-03, -3.9893e-02,  1.4056e-02,
          1.0211e-02,  2.8601e-02,  1.9309e-02, -1.4826e-02, -2.9929e-02,
          2.6709e-02, -5.2807e-02, -1.5764e-02,  6.3883e-03, -4.7049e-02,
         -5.2384e-02, -4.6913e-02,  2.2552e-02, -4.9601e-02,  9.2952e-03,
         -1.7326e-02,  5.8757e-03,  1.8618e-02, -1.5458e-03,  2.5515e-02,
          2.4176e-02]])
