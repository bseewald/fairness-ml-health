Weights: 
net.embeddings.embeddings.0.weight tensor([[ 0.1234,  0.1128],
        [ 0.1663,  0.1004],
        [-0.1628, -0.1358],
        [ 0.0020,  0.1210]])
net.embeddings.embeddings.1.weight tensor([[-0.0709, -0.1124],
        [ 0.0315,  0.0657],
        [-0.1598, -0.0965],
        [-0.1596, -0.1054],
        [ 0.0571, -0.0463]])
net.embeddings.embeddings.2.weight tensor([[-0.0743,  0.1005, -0.0803],
        [-0.1148,  0.0356,  0.0956],
        [-0.0614, -0.1170, -0.1366],
        [ 0.0398,  0.0634, -0.0479],
        [-0.1533,  0.0359, -0.0992],
        [-0.0440, -0.1173,  0.0430]])
net.embeddings.embeddings.3.weight tensor([[ 0.1870, -0.0438],
        [-0.0496, -0.0215],
        [ 0.1260,  0.0473],
        [ 0.2744, -0.1809]])
net.embeddings.embeddings.4.weight tensor([[ 0.1125, -0.0556],
        [ 0.0696,  0.2121],
        [-0.1289, -0.0143],
        [ 0.0728,  0.0850]])
net.mlp.net.0.linear.weight tensor([[-0.0251,  0.1129, -0.1461,  ..., -0.1115, -0.0932, -0.0809],
        [-0.0070,  0.0286,  0.1341,  ...,  0.0713, -0.0338, -0.2847],
        [ 0.1060, -0.0446,  0.0194,  ..., -0.1227, -0.0954, -0.1136],
        ...,
        [-0.0019,  0.0219,  0.0396,  ...,  0.1047,  0.0584,  0.0890],
        [ 0.1193, -0.1708,  0.1851,  ...,  0.0274, -0.2159, -0.1630],
        [ 0.0120, -0.0921, -0.0484,  ...,  0.0315,  0.1189,  0.1995]])
net.mlp.net.0.linear.bias tensor([-0.0777,  0.0122, -0.0454, -0.0651, -0.0490, -0.0623, -0.0395,  0.0226,
        -0.0488,  0.0043,  0.0985, -0.0384, -0.0227,  0.0383,  0.0103, -0.0209,
        -0.0042, -0.0637, -0.0537, -0.0309, -0.0180, -0.0373, -0.0255,  0.0357,
        -0.0134, -0.0098, -0.0636, -0.0539, -0.0171, -0.0357, -0.0657,  0.0109,
        -0.0528,  0.0570,  0.0023,  0.0029,  0.0474,  0.0343, -0.0105,  0.0470,
        -0.0369,  0.0740,  0.0300, -0.0233, -0.0542,  0.0026,  0.0225,  0.0121,
        -0.0339, -0.0086, -0.0096, -0.0492, -0.0175, -0.0399,  0.0597, -0.0230,
         0.0464, -0.0205, -0.0199, -0.0324, -0.0585, -0.0249,  0.0419, -0.0521,
        -0.0287,  0.0133,  0.0070,  0.0010, -0.0311,  0.0131, -0.0632,  0.0009,
        -0.0034, -0.0042, -0.0556, -0.0739,  0.0440,  0.0488, -0.0378,  0.0131,
         0.0380,  0.0145,  0.0430,  0.0269, -0.0488, -0.0364,  0.0223,  0.0556,
         0.0565, -0.0456, -0.0031, -0.0480, -0.0342, -0.0491, -0.0454,  0.0691,
         0.0030,  0.0135,  0.0061,  0.0270, -0.0290,  0.0425,  0.0542, -0.0266,
        -0.0037,  0.0030, -0.0754,  0.0406,  0.0033,  0.0006,  0.0126, -0.0381,
         0.0815,  0.0439,  0.0327,  0.0073,  0.0245,  0.0084,  0.0178,  0.0671,
        -0.0508, -0.0166, -0.0202,  0.0495,  0.0107,  0.0045, -0.0542,  0.0068,
         0.0232, -0.0727, -0.0642, -0.0431, -0.0312,  0.0137,  0.0356, -0.0051,
        -0.0258, -0.0651, -0.0155,  0.0304, -0.0165,  0.0290, -0.0368, -0.0548,
        -0.0099,  0.0002, -0.0034,  0.0307, -0.0091,  0.0399,  0.0281,  0.0465,
         0.0516, -0.0389, -0.0352,  0.0278, -0.0368,  0.0737, -0.0635, -0.0179,
         0.0417, -0.0233,  0.0369, -0.0304, -0.0242,  0.0055, -0.0850,  0.0051,
        -0.0539, -0.0407, -0.0198,  0.0505, -0.0666,  0.0600, -0.0307, -0.0115,
        -0.0146, -0.0496, -0.0635,  0.0335,  0.0140,  0.0610, -0.0548,  0.0527,
        -0.0005, -0.0621,  0.0266,  0.0528,  0.0217, -0.0507,  0.0085,  0.0422,
         0.0467, -0.0185,  0.0331,  0.0227,  0.0311, -0.0341,  0.0121,  0.0012,
        -0.0035,  0.0617, -0.0517, -0.0501,  0.0367,  0.0477,  0.0149,  0.0602,
        -0.0574, -0.0045, -0.0515, -0.0520,  0.0752,  0.0656,  0.0640, -0.0475,
         0.0631,  0.0293, -0.0178, -0.0404, -0.0108,  0.0700, -0.0252,  0.0433,
         0.0473,  0.0587, -0.0291, -0.0284, -0.0551, -0.0214, -0.0168, -0.0140,
        -0.0166, -0.0533, -0.0644, -0.0497, -0.0293, -0.0149, -0.0621, -0.0485,
         0.0477,  0.0139, -0.0499,  0.0201,  0.0382, -0.0502, -0.0233,  0.0533,
         0.0319,  0.0163,  0.0003, -0.0146, -0.0540, -0.0166,  0.0178,  0.0047])
net.mlp.net.0.batch_norm.weight tensor([0.2674, 0.2917, 0.3145, 0.2678, 0.3205, 0.2623, 0.2909, 0.2860, 0.2659,
        0.2873, 0.3009, 0.2957, 0.2740, 0.3398, 0.2850, 0.2921, 0.2935, 0.3115,
        0.2796, 0.2979, 0.2878, 0.2649, 0.2826, 0.2845, 0.3079, 0.2871, 0.2748,
        0.2993, 0.2775, 0.2867, 0.2696, 0.2835, 0.2905, 0.2781, 0.2879, 0.2797,
        0.2899, 0.2740, 0.2907, 0.2809, 0.2501, 0.2973, 0.2771, 0.2757, 0.3024,
        0.2772, 0.3028, 0.2721, 0.3061, 0.2918, 0.2817, 0.3153, 0.2878, 0.3191,
        0.2930, 0.2999, 0.2668, 0.2958, 0.3060, 0.2855, 0.2891, 0.2764, 0.2957,
        0.2894, 0.2958, 0.2967, 0.2931, 0.3209, 0.2938, 0.3017, 0.2784, 0.2867,
        0.2898, 0.2776, 0.3281, 0.2707, 0.2829, 0.2775, 0.2791, 0.2592, 0.2819,
        0.3099, 0.2677, 0.2698, 0.2832, 0.2858, 0.2917, 0.2873, 0.2768, 0.2917,
        0.2917, 0.2868, 0.2764, 0.2875, 0.2592, 0.2853, 0.2949, 0.2705, 0.2852,
        0.2746, 0.2890, 0.2887, 0.2964, 0.2740, 0.2728, 0.2923, 0.2815, 0.2846,
        0.2956, 0.2889, 0.2884, 0.2728, 0.3056, 0.2631, 0.2797, 0.2741, 0.2897,
        0.2783, 0.2831, 0.2966, 0.2760, 0.2706, 0.2951, 0.2866, 0.2789, 0.2848,
        0.2738, 0.2721, 0.2791, 0.2886, 0.2721, 0.2685, 0.2862, 0.2801, 0.2965,
        0.2672, 0.2868, 0.2857, 0.2995, 0.3043, 0.2925, 0.2753, 0.2709, 0.2697,
        0.2780, 0.2656, 0.2835, 0.2768, 0.2826, 0.3099, 0.2878, 0.2786, 0.2782,
        0.2880, 0.2843, 0.3201, 0.2903, 0.2921, 0.2746, 0.2881, 0.2906, 0.3036,
        0.3110, 0.2804, 0.2962, 0.2686, 0.3012, 0.2640, 0.2920, 0.2913, 0.2710,
        0.3215, 0.2920, 0.3070, 0.2803, 0.2907, 0.2911, 0.2771, 0.2641, 0.2696,
        0.2900, 0.2796, 0.2849, 0.2976, 0.3267, 0.2785, 0.2918, 0.2928, 0.2876,
        0.2877, 0.2996, 0.2916, 0.3165, 0.2741, 0.3115, 0.2674, 0.2884, 0.2811,
        0.2622, 0.2899, 0.2566, 0.2799, 0.2716, 0.2768, 0.2911, 0.2781, 0.2796,
        0.2755, 0.2857, 0.2865, 0.2635, 0.2903, 0.2695, 0.2732, 0.2797, 0.2709,
        0.2716, 0.2797, 0.2862, 0.2824, 0.2737, 0.2946, 0.2852, 0.2937, 0.2934,
        0.2859, 0.2898, 0.2676, 0.2843, 0.2842, 0.3050, 0.2848, 0.2743, 0.2762,
        0.2849, 0.2885, 0.2938, 0.2720, 0.2718, 0.2930, 0.2765, 0.2723, 0.2831,
        0.2788, 0.2740, 0.2603, 0.2806, 0.2861, 0.2822, 0.2853, 0.2994, 0.3091,
        0.2685, 0.2550, 0.2837, 0.2979])
net.mlp.net.0.batch_norm.bias tensor([ 7.8791e-03, -2.7469e-02, -1.7134e-02,  1.1324e-02, -2.2315e-02,
         1.7410e-02,  6.7092e-03, -1.7644e-02, -4.4623e-03, -2.3134e-02,
         2.0619e-02,  1.4117e-02,  1.0682e-03,  8.3510e-03, -3.0992e-02,
         3.0894e-03,  2.1855e-02,  3.2651e-03,  1.8782e-02,  7.2075e-03,
        -6.8294e-03,  1.1078e-02, -8.7211e-03, -8.1325e-03, -7.6918e-03,
         7.6276e-03,  4.4658e-04,  6.2400e-03,  2.1086e-02,  2.5433e-02,
         4.9532e-03,  1.6408e-02, -8.5716e-03, -4.7365e-03,  1.8710e-02,
         8.0189e-03, -1.0797e-02, -3.7179e-03,  8.4519e-03, -5.4816e-03,
        -1.7524e-02, -1.7343e-02,  2.0300e-02,  1.1796e-02,  6.9337e-03,
        -1.6613e-02, -9.8516e-03, -9.6433e-03,  3.8807e-03,  7.2156e-04,
        -1.8473e-02,  9.8966e-04,  8.7151e-03, -3.4324e-03, -1.1694e-02,
        -3.3345e-02, -1.5644e-02, -5.0786e-03,  1.4231e-02,  2.0855e-03,
        -3.5304e-04,  9.1213e-04,  7.5266e-03, -2.4076e-03, -3.1208e-02,
         1.4236e-02, -1.9996e-03, -1.6079e-02, -2.7998e-02, -8.4914e-03,
         1.6172e-03, -2.2373e-02,  1.3177e-02,  1.4723e-02, -1.1752e-05,
        -1.1705e-02, -3.6322e-03, -9.5786e-03,  9.9984e-03, -1.2020e-02,
        -1.7215e-02, -5.0839e-03,  1.4663e-02, -3.8108e-03, -4.1498e-03,
        -1.2073e-02,  5.8173e-03,  2.8555e-03, -1.7104e-04,  6.7822e-03,
         1.2182e-02, -4.2143e-03,  7.5010e-03,  3.5895e-03, -2.1390e-03,
         2.9903e-02, -2.3711e-02,  1.5417e-02, -8.6556e-03,  9.2454e-04,
         3.2912e-02,  3.7965e-03, -2.3328e-03,  8.8799e-03, -2.8631e-02,
        -1.3264e-02,  1.3718e-02, -1.7869e-03, -5.4936e-03, -1.3801e-02,
        -1.0334e-02,  2.1386e-02,  7.3145e-04, -3.1561e-03, -2.1703e-03,
         1.7959e-02, -1.7229e-02, -2.9108e-03,  1.3135e-03,  1.8320e-02,
        -4.6092e-03,  5.4917e-03, -3.1166e-02,  1.1453e-02, -8.0603e-03,
         2.3305e-02, -2.6017e-03, -7.0518e-03,  6.8769e-03,  5.1916e-03,
        -9.7350e-04,  9.2449e-03,  2.7250e-02, -1.0439e-02, -7.4243e-03,
        -7.4815e-03,  2.4149e-02, -7.4755e-03, -2.9208e-03,  5.7254e-03,
        -1.5003e-02, -2.1752e-02,  7.6406e-03, -2.1512e-02,  1.7729e-02,
        -6.8397e-03, -4.8039e-03, -8.8269e-03,  1.4543e-02, -5.7364e-04,
        -1.5639e-03,  8.6502e-03, -1.5863e-02, -3.4198e-03, -2.4105e-03,
        -1.6310e-02,  8.8177e-03,  1.7009e-02, -1.5577e-02, -2.3656e-03,
         1.3400e-03, -5.8892e-03, -1.3839e-02, -6.3571e-03, -1.1571e-02,
         2.1513e-03,  3.7816e-03, -6.4612e-03, -5.5193e-03,  2.6066e-03,
        -1.8947e-03,  2.6882e-02,  6.8857e-03, -4.9520e-03,  6.0582e-03,
         1.9032e-02, -1.3539e-03, -8.3956e-03,  3.0356e-03, -1.3241e-02,
         8.3322e-03, -3.3991e-02, -1.0377e-04,  2.0369e-02, -5.1057e-03,
         9.6727e-03,  1.7724e-04,  5.5793e-03, -2.1409e-02,  1.1339e-02,
         3.1313e-03,  1.0206e-02, -8.7754e-03,  6.8357e-03, -3.1406e-02,
        -8.1784e-03, -2.3390e-02, -3.5764e-03,  1.1606e-02, -1.1823e-02,
        -2.6305e-02,  1.6785e-03, -9.5581e-04,  7.6027e-03,  1.6370e-02,
         1.0658e-02,  1.6941e-02,  2.7901e-02,  2.5413e-02,  2.6367e-02,
         1.1837e-02, -1.3474e-02,  2.1444e-02, -1.3790e-02, -2.5359e-02,
        -8.0823e-03,  1.3377e-03, -6.0289e-03, -1.3736e-02,  3.3044e-03,
         7.1042e-03, -2.6609e-02,  4.0317e-03,  2.5090e-02,  9.0387e-03,
        -3.1926e-03,  1.1730e-02,  2.5995e-04,  2.4352e-02, -8.3262e-03,
        -5.7956e-03,  6.5870e-03, -1.4884e-03, -1.1804e-02, -5.0196e-03,
        -1.6849e-02,  1.0507e-02,  1.3487e-02, -4.9212e-03, -1.8664e-02,
        -7.3681e-03, -8.0329e-03, -1.0722e-02, -2.2337e-02,  9.3197e-03,
         1.2205e-02,  8.9949e-05, -1.4920e-02, -1.0034e-02, -5.3285e-03,
        -5.3778e-03, -7.6765e-03, -2.8918e-02,  6.7767e-03,  4.2935e-03,
         3.4518e-03])
net.mlp.net.0.batch_norm.running_mean tensor([9.1169e-02, 1.6649e-01, 1.8256e-01, 2.7845e-02, 8.5950e-03, 7.9109e-03,
        1.9701e-01, 7.2607e-03, 1.5254e-01, 4.2586e-29, 2.9020e-01, 3.9990e-04,
        3.3621e-03, 7.6400e-04, 3.1123e-01, 5.8989e-02, 1.2825e-01, 6.1124e-02,
        7.9852e-03, 3.3856e-02, 2.4011e-01, 2.6299e-01, 1.1960e-02, 5.4183e-02,
        2.2831e-01, 1.7752e-04, 7.9708e-05, 6.1551e-04, 3.3028e-04, 1.9386e-01,
        1.9152e-02, 1.1573e-01, 4.4923e-02, 1.5438e-01, 1.9767e-01, 3.2900e-01,
        5.2951e-03, 5.3828e-02, 1.4374e-01, 5.9139e-02, 1.0636e-01, 5.8401e-02,
        4.8383e-02, 9.8669e-03, 1.9690e-02, 7.8279e-02, 2.8299e-02, 1.1504e-01,
        1.2723e-01, 1.2951e-02, 1.9527e-06, 8.2005e-04, 1.1155e-02, 3.3948e-02,
        1.5173e-01, 2.8351e-02, 2.0387e-01, 5.9795e-02, 4.0277e-03, 1.2250e-01,
        3.4394e-03, 5.6031e-02, 6.1898e-02, 1.1111e-03, 1.8479e-03, 8.5908e-03,
        8.3708e-02, 3.1352e-04, 2.4726e-03, 1.9479e-03, 3.7893e-02, 1.8995e-01,
        9.2405e-04, 5.8016e-02, 2.1622e-02, 2.1129e-02, 3.8063e-02, 7.7181e-02,
        7.9254e-02, 4.1600e-02, 9.9241e-02, 9.7429e-02, 1.7730e-01, 6.7387e-02,
        9.8976e-02, 2.0813e-02, 2.0128e-02, 1.8640e-01, 4.3053e-02, 8.3520e-02,
        9.1169e-03, 8.1999e-02, 5.6267e-02, 0.0000e+00, 6.5047e-02, 3.4035e-01,
        1.1859e-01, 1.7337e-01, 1.1888e-01, 1.9135e-02, 6.4697e-02, 1.5383e-01,
        3.8213e-03, 3.0811e-02, 4.4909e-02, 1.9854e-03, 1.4639e-01, 1.5465e-01,
        4.3168e-03, 1.1353e-01, 3.1353e-03, 1.0269e-02, 1.9917e-01, 1.8167e-02,
        1.2173e-01, 9.7651e-02, 1.2653e-01, 9.8057e-02, 1.9776e-01, 1.7584e-01,
        2.7500e-02, 5.4277e-02, 1.1504e-02, 2.8348e-02, 6.3235e-02, 2.3275e-01,
        6.5873e-02, 3.3839e-01, 2.3278e-02, 1.2021e-02, 7.6437e-02, 9.6228e-02,
        1.0831e-01, 5.6356e-02, 1.9619e-02, 2.4869e-01, 2.8454e-03, 3.2026e-03,
        9.5320e-02, 1.1391e-01, 1.1686e-01, 2.2751e-01, 2.7380e-02, 1.5251e-03,
        1.3425e-01, 7.7881e-02, 1.2987e-03, 3.0977e-01, 5.9254e-02, 1.4588e-01,
        6.7816e-03, 1.5249e-02, 4.2282e-02, 2.2847e-02, 9.0696e-02, 1.3464e-04,
        8.7330e-02, 1.5119e-01, 5.3591e-02, 5.4667e-02, 8.3413e-02, 1.2675e-02,
        9.4031e-02, 1.0771e-01, 1.6456e-03, 6.2549e-02, 1.6546e-01, 1.5334e-01,
        2.3052e-02, 1.8657e-01, 1.0375e-02, 5.5868e-02, 8.4304e-02, 7.2275e-02,
        1.6642e-02, 2.2411e-01, 6.3077e-03, 4.9687e-02, 9.4433e-03, 1.9617e-01,
        4.8585e-02, 4.8687e-02, 1.5035e-02, 1.1573e-01, 3.6078e-02, 8.5221e-03,
        7.1444e-02, 5.7954e-02, 1.7327e-01, 2.2180e-02, 5.3143e-02, 1.7650e-01,
        1.4735e-04, 9.5349e-02, 1.9327e-01, 7.7187e-02, 1.2217e-01, 8.6525e-02,
        1.7755e-01, 1.3572e-01, 7.9224e-04, 3.1914e-01, 1.0258e-02, 1.4522e-02,
        4.1310e-02, 1.0189e-01, 8.5605e-02, 2.2895e-01, 1.0204e-01, 3.0391e-02,
        2.5016e-02, 1.8379e-02, 2.4000e-01, 1.7982e-01, 1.6340e-02, 7.3945e-02,
        1.5400e-02, 1.1688e-01, 5.8329e-02, 7.9689e-03, 1.1861e-01, 5.2768e-02,
        1.5697e-03, 1.7088e-01, 1.0665e-02, 1.5449e-01, 1.6996e-01, 1.1683e-01,
        1.5120e-02, 1.4217e-01, 3.6327e-03, 1.0455e-02, 1.0097e-01, 8.2307e-03,
        1.1760e-02, 5.4645e-02, 1.5439e-01, 3.0617e-03, 3.9293e-03, 2.0656e-02,
        1.3114e-01, 9.7878e-02, 1.6251e-02, 6.7051e-02, 1.0776e-01, 7.8628e-02,
        4.1629e-02, 1.6288e-01, 2.1593e-02, 6.4450e-05, 2.5323e-04, 6.5301e-03,
        2.7246e-02, 1.9154e-01, 2.8224e-01, 1.0693e-01])
net.mlp.net.0.batch_norm.running_var tensor([1.2764e-02, 1.0023e-02, 1.2288e-02, 1.4315e-02, 4.4005e-04, 1.6467e-03,
        1.7568e-02, 8.4244e-04, 1.6167e-02, 2.9007e-30, 1.1180e-02, 1.2581e-05,
        4.2672e-04, 5.3946e-05, 2.1123e-02, 7.2818e-03, 1.3244e-02, 6.1957e-03,
        1.4606e-03, 2.0786e-03, 1.8359e-02, 2.1680e-02, 6.9125e-04, 4.2305e-03,
        6.3100e-03, 7.5647e-06, 2.5905e-06, 2.3490e-05, 1.7957e-05, 2.0987e-02,
        2.5456e-03, 4.5052e-02, 3.3810e-03, 9.9977e-03, 1.4443e-02, 1.8771e-02,
        2.9700e-04, 3.9544e-03, 8.8843e-03, 3.4546e-02, 1.7369e-02, 3.2895e-03,
        2.8006e-02, 4.8645e-04, 1.3818e-03, 7.3884e-03, 1.8980e-03, 6.4273e-03,
        1.1153e-02, 1.3440e-03, 3.2942e-08, 4.6773e-05, 7.1750e-04, 2.2713e-03,
        1.2732e-02, 1.8633e-03, 1.4116e-02, 1.7523e-03, 1.9143e-04, 1.2155e-02,
        1.1848e-03, 3.0971e-03, 1.0141e-02, 4.6477e-05, 1.0458e-04, 4.2195e-04,
        7.2885e-03, 8.6779e-05, 1.6076e-04, 1.3622e-04, 7.3986e-03, 1.2144e-02,
        7.5643e-05, 3.1169e-02, 1.5774e-03, 2.2272e-03, 1.7764e-02, 8.5924e-03,
        1.0152e-02, 4.7770e-03, 6.9165e-03, 7.8699e-03, 8.4046e-03, 6.7560e-03,
        3.8575e-02, 6.1474e-03, 3.9707e-03, 1.6624e-02, 2.6951e-03, 7.3553e-03,
        5.0083e-04, 8.6172e-03, 1.0915e-02, 2.7584e-30, 8.9936e-03, 6.8488e-02,
        9.3588e-03, 1.0701e-02, 6.5864e-03, 3.9044e-03, 1.9828e-02, 6.4283e-03,
        4.8696e-04, 3.9054e-03, 9.3133e-03, 1.1198e-04, 8.0726e-03, 1.4104e-02,
        2.1504e-04, 7.7518e-03, 1.4004e-04, 1.9933e-03, 7.0105e-03, 1.4845e-03,
        5.7152e-03, 4.3318e-03, 1.9269e-02, 1.3318e-02, 1.7605e-02, 1.2656e-02,
        1.6123e-03, 2.3252e-02, 9.4192e-04, 3.6081e-03, 6.0483e-03, 2.0269e-02,
        5.7037e-03, 1.2923e-02, 2.6249e-03, 2.0058e-03, 3.5256e-02, 7.2797e-03,
        1.1313e-02, 4.4126e-03, 2.1955e-03, 1.3712e-02, 1.6611e-04, 2.8406e-04,
        5.3619e-03, 1.5558e-02, 1.2390e-02, 1.1373e-02, 8.5122e-03, 7.0245e-05,
        2.1188e-02, 1.1158e-02, 1.1872e-04, 2.0646e-02, 5.0416e-03, 6.5761e-03,
        1.4389e-03, 3.9375e-03, 1.6134e-02, 1.8905e-03, 4.1614e-02, 1.0929e-05,
        6.1828e-02, 4.5226e-03, 4.2868e-03, 2.3476e-03, 1.0866e-02, 1.4989e-03,
        2.0246e-03, 1.5232e-02, 2.0546e-04, 6.4103e-03, 6.2456e-03, 7.9536e-03,
        1.0991e-02, 2.3524e-02, 9.4196e-04, 3.3602e-03, 9.0594e-03, 2.1432e-03,
        2.3617e-03, 5.2450e-02, 6.5431e-04, 7.1942e-03, 6.1674e-04, 1.4171e-02,
        3.1481e-02, 3.4049e-03, 3.9386e-03, 3.3690e-02, 1.3865e-03, 8.9810e-04,
        2.5273e-02, 7.1571e-03, 1.2599e-02, 1.0802e-02, 3.7320e-03, 3.7871e-03,
        7.3195e-06, 7.3866e-03, 2.1635e-02, 9.6842e-03, 7.8878e-03, 8.6667e-03,
        3.8927e-02, 1.3426e-02, 6.1439e-05, 2.7144e-02, 1.5892e-03, 1.2460e-03,
        2.4806e-03, 3.7226e-02, 8.3770e-03, 1.8853e-02, 1.2863e-02, 4.5544e-03,
        1.7402e-03, 1.2967e-03, 1.5389e-02, 1.5873e-02, 1.3111e-03, 1.0450e-02,
        4.0319e-03, 5.4391e-03, 3.6081e-03, 7.3948e-04, 1.0958e-02, 6.2455e-03,
        1.7176e-04, 2.4823e-02, 1.0335e-03, 1.5937e-02, 2.5174e-02, 1.0897e-02,
        9.4933e-04, 9.3127e-03, 1.0673e-03, 2.4813e-03, 4.3001e-02, 5.4330e-04,
        6.8332e-04, 4.0491e-03, 4.7024e-02, 3.0479e-04, 2.0624e-04, 1.4098e-03,
        1.1526e-02, 7.7152e-03, 6.4846e-03, 7.8623e-03, 8.9648e-03, 8.8647e-03,
        3.0633e-03, 1.1940e-02, 1.3967e-03, 1.4025e-06, 1.5485e-05, 3.1298e-04,
        3.1734e-03, 1.6743e-02, 1.8161e-02, 3.5871e-03])
net.mlp.net.0.batch_norm.num_batches_tracked tensor(646)
net.mlp.net.1.linear.weight tensor([[-0.0197, -0.0293, -0.0030,  ..., -0.0084,  0.0222, -0.0175],
        [ 0.0041,  0.0160,  0.0426,  ...,  0.0009,  0.0421,  0.0439],
        [-0.0438,  0.0561, -0.0128,  ...,  0.0116, -0.0059,  0.0009],
        ...,
        [ 0.0017,  0.0216, -0.0054,  ...,  0.0306,  0.0224, -0.0345],
        [ 0.0317,  0.0125, -0.0149,  ...,  0.0017, -0.0018, -0.0003],
        [ 0.0011,  0.0291, -0.0217,  ..., -0.0636,  0.0121, -0.0113]])
net.mlp.net.1.linear.bias tensor([ 1.8076e-02,  6.1220e-04, -1.2994e-02,  5.7048e-03,  9.2434e-03,
        -2.6501e-02, -2.4070e-02,  1.4102e-03, -6.5923e-03,  2.0595e-02,
        -3.7214e-02, -5.7831e-03,  2.1576e-02,  1.2132e-02, -2.4249e-02,
         1.8726e-02, -2.8719e-02, -3.2037e-02, -4.7604e-03, -1.2364e-02,
        -6.0526e-03, -1.8699e-02, -5.1674e-02, -7.8090e-03, -7.7051e-04,
        -1.4857e-02, -6.8390e-03, -1.5438e-02, -2.1731e-02, -2.1176e-02,
         9.4368e-03, -6.0660e-03,  9.5205e-03, -1.9479e-02,  8.0457e-03,
        -2.4825e-02, -1.5999e-02,  1.0787e-02,  3.4070e-02,  9.1742e-03,
        -1.9431e-03,  5.0032e-05, -1.9155e-02,  1.6492e-02, -2.0804e-02,
        -1.3526e-04,  1.8251e-02, -7.8251e-03, -7.4554e-03,  2.9704e-02,
        -2.7565e-02,  2.8188e-02,  2.1142e-02, -1.2216e-02, -4.4331e-03,
        -2.6625e-02, -4.4208e-02, -4.4715e-02,  2.8439e-04,  2.6978e-04,
        -1.3796e-02, -1.1660e-02,  5.0680e-03,  9.1242e-03, -9.9444e-03,
         7.0067e-03,  2.1712e-02, -2.4402e-02, -2.5666e-02,  1.1009e-02,
        -3.1141e-02, -3.4096e-03,  1.4841e-02, -2.1401e-02,  1.9799e-04,
        -3.9204e-02,  2.6441e-02, -4.0104e-02,  9.2196e-03, -8.7258e-03,
        -2.6141e-02, -1.7255e-02, -1.3484e-02,  3.1875e-03, -6.1325e-03,
        -2.3163e-02, -6.1341e-03,  2.2971e-02, -1.1193e-02, -2.3448e-02,
        -1.0260e-02,  3.3790e-04,  3.3013e-02, -5.7211e-03, -1.2258e-03,
        -9.7642e-03, -6.4123e-03, -1.3764e-02, -4.2577e-02, -9.4507e-03,
        -9.9670e-03,  2.6961e-02, -1.4405e-02,  4.5113e-03, -9.3081e-03,
        -1.9442e-02, -1.4069e-02, -2.5872e-02,  2.9475e-02,  2.0863e-02,
         1.9138e-03, -3.2825e-03, -9.6106e-03, -3.7838e-03,  4.5936e-03,
        -3.0495e-02, -9.3387e-03,  5.3667e-03, -3.7029e-02,  1.6905e-02,
        -1.0099e-02, -1.1421e-02, -5.0241e-03,  1.4656e-02, -2.4340e-02,
        -1.5851e-02, -8.7467e-03, -1.8991e-03,  9.3076e-03, -1.2742e-02,
        -5.1050e-03, -1.0736e-03,  1.3548e-02, -1.2574e-02,  1.3915e-02,
        -1.5070e-02,  1.2042e-02,  3.2172e-02, -3.9294e-03, -3.1851e-02,
        -4.8081e-03, -1.7135e-02,  2.1967e-02, -4.2800e-02, -2.9129e-02,
         1.0747e-02, -8.5880e-03,  1.0522e-02, -1.8105e-02,  3.4367e-03,
        -5.3250e-03, -2.2186e-02, -2.2721e-02, -3.1886e-03, -5.0262e-03,
        -7.6626e-03, -1.4244e-02,  1.4710e-02, -1.0836e-02, -2.5730e-02,
        -1.4048e-02,  1.1371e-02,  3.2408e-03, -1.2267e-02, -7.7912e-03,
        -7.8926e-03, -2.4092e-02, -8.4922e-03, -1.3355e-02, -1.7908e-02,
        -1.6502e-02, -3.6486e-02, -6.3008e-03,  1.9831e-02, -1.0569e-02,
        -1.6072e-02, -9.7989e-03,  2.1955e-03, -2.2220e-04,  1.7559e-02,
        -8.6894e-03,  2.5805e-03, -2.6417e-03,  8.7726e-03,  2.0377e-02,
         1.1615e-02, -1.1855e-02,  4.1674e-02,  1.1854e-02, -3.1192e-02,
        -3.9607e-02, -7.2288e-03, -1.3895e-02, -5.1334e-04,  5.1774e-03,
         4.9872e-03, -2.7286e-02,  1.8980e-03, -5.7459e-03, -6.3610e-03,
         3.9646e-03,  2.6801e-02,  6.4066e-03,  1.5281e-02, -3.7385e-03,
        -6.0039e-02,  1.3404e-02, -2.0926e-02,  2.0775e-04, -1.2253e-02,
        -1.8735e-02, -3.2778e-02,  1.4989e-02, -2.6396e-02, -1.1591e-02,
         1.0904e-02,  4.2083e-02, -1.5523e-03,  2.6311e-03,  3.9605e-03,
        -2.5559e-02,  7.7633e-03, -1.7912e-02,  7.4688e-04,  2.6109e-02,
        -2.3285e-02,  1.9016e-02, -1.3508e-02,  5.0046e-03, -7.5391e-03,
         1.6653e-02,  2.5236e-02, -7.1212e-03, -3.0141e-02, -8.5559e-03,
        -2.6308e-02,  6.8245e-03, -4.0265e-02, -1.7824e-02, -4.2212e-03,
        -9.0465e-03,  2.8808e-03,  2.1429e-02, -1.0554e-02, -1.2866e-02,
        -2.1947e-02, -3.0510e-02, -1.4950e-02, -1.5852e-02, -1.3426e-02,
         1.1441e-02, -2.8725e-02, -3.3792e-02,  5.9839e-03,  1.5945e-02,
        -1.7953e-02])
net.mlp.net.1.batch_norm.weight tensor([0.2742, 0.2908, 0.2762, 0.2728, 0.2861, 0.3191, 0.2720, 0.2704, 0.2804,
        0.2681, 0.3032, 0.2803, 0.2901, 0.2753, 0.2824, 0.2754, 0.3060, 0.2668,
        0.2840, 0.2806, 0.3028, 0.2742, 0.3215, 0.2778, 0.2685, 0.2975, 0.2884,
        0.2859, 0.2720, 0.2762, 0.2835, 0.2826, 0.2795, 0.2929, 0.2763, 0.2991,
        0.2900, 0.2729, 0.2750, 0.2675, 0.2910, 0.2997, 0.2694, 0.2930, 0.2735,
        0.2788, 0.2941, 0.3208, 0.3068, 0.2780, 0.3087, 0.2989, 0.3016, 0.2748,
        0.3085, 0.2939, 0.3084, 0.2966, 0.2830, 0.2749, 0.2767, 0.2743, 0.2748,
        0.2697, 0.2861, 0.2859, 0.2810, 0.2839, 0.2882, 0.2828, 0.2906, 0.3044,
        0.2906, 0.2978, 0.2783, 0.3050, 0.2903, 0.3250, 0.2793, 0.3001, 0.3054,
        0.2883, 0.2786, 0.2916, 0.2793, 0.2935, 0.2804, 0.2869, 0.2950, 0.2972,
        0.2922, 0.2894, 0.2886, 0.2885, 0.2760, 0.2836, 0.2760, 0.2815, 0.2919,
        0.2744, 0.3025, 0.2802, 0.2763, 0.2611, 0.2981, 0.2774, 0.2834, 0.2844,
        0.2764, 0.2735, 0.2858, 0.2799, 0.2945, 0.2755, 0.2751, 0.2522, 0.2897,
        0.2822, 0.2875, 0.2992, 0.2803, 0.2821, 0.2724, 0.2766, 0.2804, 0.3017,
        0.2940, 0.2828, 0.2688, 0.2921, 0.2939, 0.2830, 0.2758, 0.2908, 0.2732,
        0.2870, 0.2755, 0.2762, 0.2804, 0.2870, 0.2913, 0.2939, 0.2782, 0.3075,
        0.3105, 0.2776, 0.3041, 0.3144, 0.2855, 0.2841, 0.2770, 0.2727, 0.2843,
        0.2689, 0.3268, 0.2820, 0.2803, 0.2823, 0.2765, 0.2960, 0.2845, 0.2669,
        0.2787, 0.2758, 0.2817, 0.3045, 0.2881, 0.2872, 0.2973, 0.2897, 0.2877,
        0.2948, 0.2975, 0.2730, 0.2785, 0.3083, 0.2813, 0.2959, 0.2731, 0.3012,
        0.2912, 0.2796, 0.2892, 0.2714, 0.2916, 0.2854, 0.2771, 0.2832, 0.2796,
        0.2871, 0.3179, 0.2768, 0.2755, 0.2806, 0.2905, 0.2971, 0.2717, 0.2928,
        0.2850, 0.2805, 0.2913, 0.2887, 0.2721, 0.2625, 0.2737, 0.3039, 0.2767,
        0.2962, 0.2894, 0.3062, 0.2875, 0.2988, 0.2787, 0.3128, 0.2730, 0.2743,
        0.2830, 0.2823, 0.2723, 0.2732, 0.2725, 0.2903, 0.2721, 0.2720, 0.2900,
        0.3072, 0.2680, 0.2793, 0.2842, 0.2704, 0.2782, 0.2772, 0.2788, 0.2991,
        0.2745, 0.2835, 0.2676, 0.3087, 0.3019, 0.2700, 0.2656, 0.2804, 0.2838,
        0.2713, 0.3087, 0.2985, 0.2876, 0.2859, 0.2784, 0.3021, 0.2924, 0.2718,
        0.3064, 0.2901, 0.2919, 0.2789])
net.mlp.net.1.batch_norm.bias tensor([-0.0040, -0.0044, -0.0024,  0.0102, -0.0172,  0.0141, -0.0125, -0.0093,
         0.0135, -0.0056, -0.0124,  0.0030,  0.0098,  0.0051,  0.0008,  0.0081,
         0.0035,  0.0067, -0.0073, -0.0157, -0.0071, -0.0138,  0.0068,  0.0078,
         0.0060,  0.0009, -0.0103, -0.0084, -0.0058,  0.0106, -0.0005, -0.0131,
         0.0118,  0.0015, -0.0109, -0.0015,  0.0082,  0.0090,  0.0007,  0.0089,
        -0.0048, -0.0201,  0.0026,  0.0065, -0.0047,  0.0021, -0.0035,  0.0090,
        -0.0131,  0.0048,  0.0029,  0.0263,  0.0079,  0.0015,  0.0100,  0.0231,
         0.0007,  0.0006,  0.0054, -0.0099, -0.0022,  0.0026, -0.0045, -0.0048,
        -0.0033,  0.0011,  0.0032,  0.0090,  0.0054, -0.0102,  0.0073,  0.0084,
        -0.0026,  0.0046, -0.0070, -0.0206,  0.0066, -0.0016, -0.0150, -0.0068,
         0.0100, -0.0004,  0.0074, -0.0055, -0.0005,  0.0061,  0.0022,  0.0131,
         0.0047,  0.0106,  0.0235, -0.0024,  0.0036, -0.0039,  0.0151, -0.0086,
         0.0077,  0.0103,  0.0009,  0.0007,  0.0200,  0.0068,  0.0006,  0.0044,
        -0.0074, -0.0106, -0.0048, -0.0072, -0.0056, -0.0008,  0.0205,  0.0096,
        -0.0044, -0.0125, -0.0018, -0.0042,  0.0133, -0.0061,  0.0021,  0.0183,
         0.0086, -0.0026, -0.0063, -0.0011, -0.0074,  0.0072, -0.0076, -0.0007,
         0.0056,  0.0122, -0.0081,  0.0194,  0.0097, -0.0005, -0.0016, -0.0071,
        -0.0135,  0.0065, -0.0003,  0.0002, -0.0017,  0.0123, -0.0046, -0.0177,
         0.0036, -0.0030, -0.0046, -0.0213,  0.0184,  0.0092,  0.0204, -0.0031,
         0.0263, -0.0014,  0.0202,  0.0169, -0.0023, -0.0068,  0.0044,  0.0135,
        -0.0105, -0.0186, -0.0067, -0.0059, -0.0026,  0.0227, -0.0062, -0.0066,
         0.0134,  0.0028,  0.0059,  0.0336, -0.0123,  0.0051, -0.0035,  0.0025,
         0.0003,  0.0376,  0.0148, -0.0108,  0.0048,  0.0055, -0.0037,  0.0018,
        -0.0055,  0.0075,  0.0092, -0.0192, -0.0130,  0.0169,  0.0212,  0.0075,
        -0.0200,  0.0124,  0.0064,  0.0226,  0.0012,  0.0238, -0.0071,  0.0060,
         0.0195,  0.0050, -0.0003,  0.0104, -0.0029, -0.0021,  0.0064,  0.0127,
         0.0140,  0.0091, -0.0149, -0.0102, -0.0120, -0.0007,  0.0026, -0.0109,
         0.0049, -0.0084, -0.0091,  0.0030, -0.0026,  0.0075, -0.0030, -0.0034,
        -0.0012,  0.0007,  0.0020,  0.0023,  0.0040,  0.0110,  0.0112,  0.0127,
         0.0005, -0.0028, -0.0084, -0.0078, -0.0011,  0.0033,  0.0126, -0.0087,
         0.0043,  0.0086, -0.0021,  0.0001, -0.0126, -0.0033,  0.0217,  0.0034,
        -0.0149,  0.0241, -0.0004,  0.0030, -0.0123, -0.0066,  0.0119,  0.0012])
net.mlp.net.1.batch_norm.running_mean tensor([0.0836, 0.0883, 0.0765, 0.0861, 0.0882, 0.0750, 0.0715, 0.0706, 0.0683,
        0.0739, 0.1017, 0.0649, 0.0755, 0.0828, 0.0716, 0.0679, 0.0731, 0.0731,
        0.0707, 0.0921, 0.0768, 0.0553, 0.0734, 0.1057, 0.0674, 0.0755, 0.0944,
        0.0841, 0.0626, 0.0723, 0.0740, 0.0885, 0.0652, 0.0691, 0.0697, 0.0735,
        0.0654, 0.0820, 0.0753, 0.0673, 0.0658, 0.1029, 0.0746, 0.0976, 0.0476,
        0.0798, 0.1052, 0.1196, 0.0746, 0.0932, 0.0817, 0.0801, 0.0945, 0.0870,
        0.0831, 0.0621, 0.0731, 0.0596, 0.0980, 0.0680, 0.0663, 0.0555, 0.0757,
        0.0856, 0.0754, 0.1066, 0.0833, 0.0658, 0.0517, 0.0843, 0.0613, 0.0943,
        0.0985, 0.0696, 0.0582, 0.0789, 0.0905, 0.0869, 0.0850, 0.0985, 0.0819,
        0.0782, 0.0917, 0.0737, 0.0727, 0.0886, 0.0689, 0.1190, 0.0924, 0.0787,
        0.0968, 0.0733, 0.0979, 0.0683, 0.0809, 0.0650, 0.0725, 0.0778, 0.0608,
        0.0690, 0.0880, 0.0857, 0.0712, 0.1189, 0.0935, 0.0819, 0.0890, 0.0734,
        0.0830, 0.0810, 0.0804, 0.0654, 0.0598, 0.0792, 0.0742, 0.0700, 0.0663,
        0.0676, 0.0633, 0.0856, 0.0624, 0.0656, 0.0710, 0.0859, 0.0559, 0.0827,
        0.0767, 0.0778, 0.0996, 0.0789, 0.0671, 0.0921, 0.0718, 0.0765, 0.0691,
        0.0790, 0.0843, 0.0998, 0.0771, 0.0740, 0.0816, 0.0875, 0.0830, 0.0695,
        0.0658, 0.1024, 0.0840, 0.1030, 0.0720, 0.0909, 0.0781, 0.0779, 0.0545,
        0.0714, 0.0744, 0.0774, 0.0667, 0.0984, 0.0731, 0.0705, 0.0676, 0.0757,
        0.0741, 0.0680, 0.0940, 0.0868, 0.0832, 0.0729, 0.0624, 0.0728, 0.0677,
        0.0514, 0.0883, 0.0910, 0.0535, 0.0866, 0.0831, 0.1010, 0.0870, 0.1221,
        0.0738, 0.0831, 0.0724, 0.0787, 0.0941, 0.0861, 0.0788, 0.1040, 0.0836,
        0.0780, 0.0588, 0.0522, 0.1205, 0.0921, 0.0756, 0.1000, 0.0608, 0.0947,
        0.0634, 0.0783, 0.0838, 0.0904, 0.0726, 0.1050, 0.0895, 0.0533, 0.0860,
        0.0920, 0.0776, 0.0881, 0.0904, 0.0661, 0.0803, 0.0765, 0.0578, 0.0704,
        0.0965, 0.1092, 0.0924, 0.0702, 0.0571, 0.0842, 0.0663, 0.0642, 0.0862,
        0.0742, 0.0962, 0.0579, 0.0715, 0.0797, 0.0771, 0.1043, 0.0915, 0.0585,
        0.0799, 0.0837, 0.0891, 0.0841, 0.0667, 0.0734, 0.0763, 0.0980, 0.0950,
        0.0631, 0.0770, 0.0747, 0.0554, 0.0654, 0.0629, 0.0924, 0.0955, 0.0826,
        0.0724, 0.0669, 0.0879, 0.0670])
net.mlp.net.1.batch_norm.running_var tensor([0.0296, 0.0174, 0.0148, 0.0159, 0.0144, 0.0168, 0.0296, 0.0115, 0.0123,
        0.0091, 0.0245, 0.0104, 0.0122, 0.0138, 0.0139, 0.0095, 0.0203, 0.0278,
        0.0138, 0.0192, 0.0132, 0.0077, 0.0158, 0.0413, 0.0121, 0.0159, 0.0216,
        0.0181, 0.0173, 0.0141, 0.0108, 0.0177, 0.0127, 0.0161, 0.0103, 0.0172,
        0.0108, 0.0143, 0.0124, 0.0130, 0.0123, 0.0246, 0.0388, 0.0191, 0.0080,
        0.0147, 0.0164, 0.0294, 0.0141, 0.0190, 0.0189, 0.0147, 0.0153, 0.0264,
        0.0180, 0.0108, 0.0156, 0.0107, 0.0393, 0.0096, 0.0143, 0.0082, 0.0117,
        0.0221, 0.0129, 0.0223, 0.0157, 0.0117, 0.0089, 0.0160, 0.0117, 0.0183,
        0.0183, 0.0158, 0.0126, 0.0212, 0.0175, 0.0224, 0.0160, 0.0205, 0.0166,
        0.0152, 0.0377, 0.0127, 0.0122, 0.0200, 0.0112, 0.0238, 0.0183, 0.0182,
        0.0240, 0.0098, 0.0173, 0.0124, 0.0104, 0.0182, 0.0109, 0.0199, 0.0131,
        0.0225, 0.0189, 0.0196, 0.0144, 0.0463, 0.0190, 0.0358, 0.0261, 0.0155,
        0.0129, 0.0114, 0.0135, 0.0127, 0.0098, 0.0340, 0.0207, 0.0123, 0.0127,
        0.0116, 0.0136, 0.0175, 0.0100, 0.0174, 0.0115, 0.0140, 0.0115, 0.0199,
        0.0184, 0.0205, 0.0300, 0.0153, 0.0088, 0.0191, 0.0100, 0.0197, 0.0111,
        0.0123, 0.0139, 0.0205, 0.0129, 0.0159, 0.0147, 0.0193, 0.0121, 0.0134,
        0.0126, 0.0180, 0.0183, 0.0229, 0.0137, 0.0167, 0.0233, 0.0349, 0.0128,
        0.0170, 0.0160, 0.0161, 0.0121, 0.0181, 0.0126, 0.0114, 0.0125, 0.0192,
        0.0121, 0.0111, 0.0405, 0.0194, 0.0179, 0.0146, 0.0096, 0.0189, 0.0161,
        0.0097, 0.0147, 0.0251, 0.0126, 0.0179, 0.0160, 0.0191, 0.0129, 0.0262,
        0.0231, 0.0142, 0.0131, 0.0122, 0.0149, 0.0138, 0.0238, 0.0146, 0.0149,
        0.0244, 0.0133, 0.0118, 0.0615, 0.0195, 0.0174, 0.0188, 0.0096, 0.0187,
        0.0113, 0.0141, 0.0180, 0.0209, 0.0155, 0.0202, 0.0193, 0.0104, 0.0265,
        0.0222, 0.0147, 0.0182, 0.0177, 0.0171, 0.0136, 0.0155, 0.0092, 0.0196,
        0.0169, 0.0246, 0.0282, 0.0091, 0.0091, 0.0129, 0.0132, 0.0086, 0.0149,
        0.0135, 0.0155, 0.0170, 0.0103, 0.0383, 0.0168, 0.0428, 0.0174, 0.0115,
        0.0154, 0.0149, 0.0243, 0.0188, 0.0121, 0.0117, 0.0153, 0.0245, 0.0217,
        0.0092, 0.0142, 0.0145, 0.0180, 0.0114, 0.0122, 0.0185, 0.0178, 0.0273,
        0.0160, 0.0099, 0.0143, 0.0132])
net.mlp.net.1.batch_norm.num_batches_tracked tensor(646)
net.mlp.net.2.weight tensor([[ 3.4182e-03, -1.9075e-02,  3.8846e-03,  3.7470e-03,  9.7612e-03,
         -3.4959e-02, -1.9719e-03, -4.5568e-03, -7.0072e-03, -2.5696e-03,
          2.2047e-02,  1.0245e-02, -1.7479e-02,  2.9619e-03,  1.2933e-02,
         -1.4493e-03, -2.4036e-02, -2.6227e-03, -1.2385e-02,  5.9306e-03,
         -2.3165e-02,  4.8186e-03,  3.2543e-02, -2.6033e-03,  5.4045e-03,
         -1.5387e-02,  1.8962e-02,  1.1661e-02,  9.5496e-04, -5.3674e-03,
          1.0461e-02,  5.3814e-03, -3.6667e-03, -2.0916e-02,  6.2339e-03,
          1.7116e-02,  1.4656e-02, -3.5132e-04, -1.8582e-03,  5.9472e-05,
          2.0600e-02,  1.7237e-02,  7.3296e-04, -1.2608e-02, -2.9339e-03,
         -8.6183e-03,  1.1594e-02,  3.2195e-02,  2.1423e-02, -1.4225e-03,
         -3.1935e-02,  1.4441e-02,  2.6510e-02,  1.5213e-03, -1.9756e-02,
         -1.8145e-02, -2.8843e-02, -1.2916e-02,  1.0534e-02, -2.7755e-03,
         -3.1716e-03, -5.0378e-03,  6.0541e-03, -3.7181e-03,  1.4212e-02,
         -1.0425e-02,  1.1300e-02,  1.2349e-02, -1.0166e-02, -6.9171e-03,
         -1.5582e-02,  2.9098e-02,  1.7608e-02, -1.8673e-02, -9.2154e-03,
         -1.6765e-02, -8.8735e-03, -3.0232e-02,  2.2681e-03,  1.4803e-02,
         -2.1143e-02, -8.2530e-03, -6.9670e-03,  1.2960e-02,  7.4234e-03,
         -1.3724e-02, -5.6693e-03,  9.0289e-03,  7.3118e-03, -1.2195e-02,
         -2.1460e-02,  1.4141e-02,  1.1982e-02,  6.6641e-03,  4.4262e-03,
          7.7578e-03,  6.4872e-03, -5.0805e-03, -9.7656e-03,  3.6987e-03,
         -2.6057e-02, -4.4559e-03,  5.0291e-03, -1.6020e-03, -2.2092e-02,
         -6.3677e-03,  6.6743e-03, -1.8570e-03,  2.9628e-03, -2.2019e-03,
         -1.4073e-02, -6.3440e-03, -2.2399e-02,  6.2668e-03,  6.0301e-03,
         -4.3521e-03, -1.5614e-02,  1.3427e-02, -1.1620e-02, -1.9840e-02,
          1.3445e-02, -7.0664e-03, -7.0902e-04,  3.0175e-03, -7.9285e-03,
         -2.7617e-02,  2.0042e-02,  8.3019e-03, -2.0629e-03,  1.0799e-02,
         -1.1119e-02, -1.1207e-02, -6.0655e-03, -1.5213e-02, -5.4461e-03,
         -1.2159e-02,  6.9914e-03, -5.1959e-03,  1.0217e-02,  7.6483e-03,
         -1.4019e-02, -1.3676e-02, -5.3803e-03, -2.1929e-02,  2.8120e-02,
         -1.8291e-03,  2.4451e-02,  2.6682e-02, -8.9609e-03, -1.4601e-02,
         -6.3216e-03, -1.7015e-03, -9.9311e-03,  3.4505e-03, -3.7546e-02,
         -5.9598e-03,  4.8689e-03, -7.2411e-03,  3.7323e-03,  1.5950e-02,
         -5.0047e-05,  2.2100e-03,  6.4597e-03,  6.9072e-04,  9.3970e-03,
         -1.9833e-02,  1.4830e-02,  1.0790e-02, -1.8107e-02, -1.3892e-02,
         -9.8211e-03, -1.6138e-02,  1.6094e-02,  4.3541e-03,  5.7950e-03,
         -2.9692e-02, -1.0602e-02, -1.3183e-02, -2.1511e-04,  1.6514e-02,
         -1.3178e-02,  6.0846e-03,  1.0232e-02,  1.6084e-03,  1.1675e-02,
          1.3257e-02, -6.3137e-03,  7.1886e-03,  3.2846e-03, -1.0083e-02,
         -2.5194e-02,  4.8572e-03,  4.7507e-03, -8.1948e-03, -1.8137e-02,
         -1.3513e-02, -1.7289e-03, -2.0396e-02, -7.3500e-03,  2.0238e-03,
          1.9678e-02, -1.4301e-02, -2.8262e-03,  3.6336e-03, -6.5108e-03,
         -2.1203e-02, -2.8681e-03, -1.0407e-02, -1.2885e-02,  2.3602e-02,
          1.2666e-02,  1.5271e-02,  6.3230e-03, -2.5488e-02, -5.4596e-03,
         -1.6577e-04, -8.7842e-03,  4.7376e-03,  8.6397e-04, -6.7315e-04,
         -2.9712e-03, -1.0242e-02,  5.6126e-04, -4.5670e-03,  7.9915e-03,
         -2.1032e-02, -3.7949e-04, -8.3197e-03,  1.2251e-02, -2.3488e-03,
         -5.6570e-03, -2.8999e-03,  7.1318e-03,  2.1384e-02, -2.7233e-03,
          1.3324e-02, -1.6274e-03,  2.1319e-02, -1.9099e-02,  3.5711e-04,
          6.9787e-04, -2.6154e-03, -9.7184e-03, -1.1112e-03,  3.1268e-02,
         -1.9494e-02, -1.1423e-02, -9.1035e-03,  7.7143e-03, -1.5662e-02,
          8.7346e-03,  7.8222e-04,  1.8813e-02,  1.0921e-02,  8.8773e-03,
         -6.8308e-03]])
