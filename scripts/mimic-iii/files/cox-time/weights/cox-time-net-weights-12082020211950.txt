Weights: 
net.embeddings.embeddings.0.weight tensor([[ 0.5701,  0.4972],
        [-0.0331, -0.2990],
        [-0.1025, -0.5062],
        [-0.2333,  0.1136]])
net.embeddings.embeddings.1.weight tensor([[-0.1977, -0.5077],
        [-0.6187, -0.5859],
        [ 0.1980,  0.0082],
        [ 0.2452,  0.4093],
        [-0.2549, -0.5115]])
net.embeddings.embeddings.2.weight tensor([[-0.0836,  0.3916,  0.3412],
        [-0.2887, -0.0800, -0.2542],
        [-0.2166, -0.2416, -0.0208],
        [-0.4217, -0.2457, -0.2575],
        [-0.0544, -0.2818,  0.2267],
        [ 0.2088, -0.5275,  0.2786]])
net.embeddings.embeddings.3.weight tensor([[-0.6317, -0.2635],
        [ 0.4090,  0.2632],
        [ 0.3367, -0.4300],
        [-0.4728,  0.0815]])
net.embeddings.embeddings.4.weight tensor([[ 0.2742,  0.0699],
        [-0.6163,  0.6706],
        [-0.1176, -0.1246],
        [ 0.0009,  0.6155]])
net.mlp.net.0.linear.weight tensor([[-0.1037,  0.2390,  0.5990,  ..., -0.2151, -0.1007,  0.2835],
        [ 0.6004,  0.0137, -0.6582,  ...,  0.1169, -0.0807,  0.1191],
        [-0.3154,  0.2404,  0.1333,  ..., -0.1218,  0.1502, -0.7178],
        ...,
        [-0.4663, -0.0876,  0.1892,  ..., -0.7178, -0.3935,  0.3165],
        [-0.1195, -0.9242, -0.7518,  ..., -0.0947,  0.4545,  0.3763],
        [ 0.1684,  0.5888, -0.1193,  ..., -0.3523, -0.1211,  0.1127]])
net.mlp.net.0.linear.bias tensor([ 1.6789e-01, -2.2510e-01, -3.8922e-02, -1.6578e-01,  1.7964e-03,
        -1.1141e-01,  1.5046e-01, -2.0667e-01, -1.6261e-01,  6.8957e-02,
        -1.6392e-01,  2.3110e-02,  8.9392e-02, -1.4919e-01, -1.8396e-01,
        -1.6798e-01, -9.6501e-02, -2.5604e-02,  7.3453e-02, -5.4669e-02,
        -1.6356e-01, -8.6593e-02,  1.0833e-01, -1.5014e-01, -5.6208e-02,
         1.7675e-01, -6.2145e-03, -9.2381e-02, -1.1080e-01, -2.4823e-01,
         1.3162e-02, -3.3779e-02, -3.7012e-02, -1.9369e-01,  2.8206e-02,
         1.9586e-01,  6.6963e-02, -2.0172e-01, -1.1002e-01, -1.7939e-01,
        -1.0498e-01,  6.5299e-02, -3.1140e-02, -4.5034e-02, -4.6339e-02,
        -1.6966e-01,  9.4067e-02, -1.5763e-01,  5.5527e-02,  1.8839e-01,
         2.7306e-01, -2.0643e-01, -1.2452e-01, -1.2053e-02, -2.3784e-01,
        -2.5689e-02,  1.8171e-01,  1.4516e-01, -4.0310e-04, -9.6495e-03,
         7.2999e-02,  1.0834e-01,  9.6947e-03, -1.7364e-01,  1.7710e-01,
         7.0880e-02,  2.7439e-01,  1.3554e-01,  1.1573e-01, -2.6592e-02,
         6.9532e-02,  2.5340e-01, -2.8309e-02,  7.2396e-02,  1.0004e-01,
        -6.7497e-02, -5.8751e-02,  1.3900e-01, -1.1520e-01, -2.1852e-01,
         2.8255e-02,  8.8175e-03,  1.8854e-02,  2.2488e-01,  6.0396e-02,
         1.3402e-01, -9.7748e-02,  1.9860e-01, -1.2338e-01, -8.2344e-02,
         2.1776e-01, -1.4392e-01, -8.8722e-02,  6.7273e-02,  1.0137e-01,
         9.4042e-02,  1.7330e-01, -1.3486e-01,  7.9468e-02, -5.2227e-02,
        -1.6651e-01, -1.1215e-02, -1.0712e-01, -1.2710e-01, -1.4643e-01,
         1.7738e-02, -1.6367e-01,  2.0499e-01, -1.2239e-02,  1.2149e-01,
        -4.5097e-02, -2.4941e-01, -9.5963e-02,  1.3718e-01, -1.3106e-01,
         4.9774e-02,  1.5713e-01,  5.0568e-02, -1.4214e-01,  1.2871e-01,
        -1.3338e-01, -7.2350e-02,  1.9787e-01, -2.8476e-02,  4.6918e-02,
        -1.3659e-01,  1.4018e-01, -1.5998e-01,  1.9868e-01, -1.3473e-01,
        -1.0261e-01, -1.2483e-01, -1.3572e-01, -3.2335e-02,  1.0455e-01,
         2.4955e-01,  1.3898e-01,  1.5225e-01,  2.8261e-02, -7.8025e-03,
         1.3036e-01, -4.9207e-02, -2.1368e-01,  5.5284e-02, -5.6394e-02,
        -1.8339e-01,  8.0083e-02, -2.2056e-01, -3.2694e-02,  8.3840e-02,
        -1.2140e-01,  1.6882e-01, -7.0566e-02, -1.2993e-01,  9.0849e-02,
        -1.4970e-01,  1.4119e-01,  4.8449e-02,  2.5633e-02, -1.8285e-01,
         9.3386e-02,  8.5821e-02, -1.6346e-02, -1.5041e-01, -9.0990e-02,
         1.2907e-01,  7.1823e-03, -1.1269e-01, -1.2004e-01, -1.6946e-01,
        -1.5013e-01,  1.2238e-01, -2.2879e-02, -7.7145e-02, -1.8764e-01,
         5.0715e-02, -8.4528e-03, -2.6358e-02,  1.4358e-01,  1.0184e-01,
         1.4140e-04,  6.8992e-02,  2.2716e-01, -2.2022e-01,  1.2617e-01,
        -2.0440e-01, -9.0854e-02, -1.0034e-01, -7.3724e-02, -1.7009e-01,
        -4.6498e-02,  2.0538e-01,  1.7485e-01, -5.3236e-02,  1.2837e-01,
        -1.3966e-02,  1.9324e-01, -9.6835e-02,  1.4336e-01, -1.0304e-01,
         1.9454e-01,  4.1832e-02, -4.4202e-02,  1.5715e-01, -7.3391e-02,
         2.0801e-01,  5.9167e-02,  2.3830e-01,  1.6287e-01,  1.2321e-01,
         5.3373e-02, -1.2549e-01,  9.8623e-02, -5.8174e-03,  4.5036e-03,
         1.5410e-01,  7.9501e-02, -7.0094e-03, -1.9555e-01, -1.0799e-01,
        -7.3887e-02, -1.2117e-01,  5.3221e-02, -2.3984e-01, -7.2847e-02,
        -1.6104e-01, -6.3409e-02, -1.0834e-02, -7.9931e-02, -2.1875e-01,
        -9.7772e-02,  1.0321e-01, -4.8547e-02, -6.3485e-02,  7.9476e-02,
        -1.5968e-01, -8.0711e-02, -4.0158e-02,  4.4468e-02,  1.1562e-01,
         1.2185e-01,  4.3593e-02, -8.6421e-03,  1.0334e-01,  1.9510e-02,
         1.8990e-01, -1.6812e-01,  3.6710e-02, -1.6631e-01,  2.0807e-01,
        -1.3634e-01, -1.6711e-01,  1.3713e-01,  7.2788e-02,  3.1963e-02,
        -6.7107e-02])
net.mlp.net.0.batch_norm.weight tensor([0.9941, 0.9955, 1.0280, 0.9684, 1.0017, 1.0047, 1.0346, 0.9651, 1.0106,
        1.0354, 0.9305, 1.0116, 0.9365, 0.9495, 0.9740, 0.9757, 0.9888, 0.9883,
        0.9483, 0.9758, 1.0133, 1.0316, 1.0003, 0.9768, 0.9521, 1.0313, 1.0490,
        0.9636, 1.0254, 0.9687, 0.9797, 1.0068, 0.9702, 0.9857, 1.0340, 0.9925,
        1.0050, 0.9320, 0.9750, 1.0566, 0.9590, 1.0329, 0.9838, 0.9175, 0.9522,
        0.9514, 0.9641, 0.9844, 0.9547, 0.9633, 0.9531, 1.0229, 1.0250, 1.0020,
        0.9835, 1.0205, 0.9813, 0.9793, 0.9919, 0.9366, 0.9665, 0.9908, 1.0217,
        0.9726, 0.9518, 0.9679, 0.9675, 0.9917, 0.9678, 0.9767, 0.9910, 0.9432,
        0.9885, 0.9546, 0.9458, 1.0164, 0.9490, 0.9774, 0.9653, 1.0212, 0.9636,
        0.9698, 0.9710, 1.0133, 1.0117, 0.9999, 0.9513, 0.9745, 0.9938, 0.9768,
        0.9342, 1.0036, 0.9970, 1.0182, 0.9839, 0.9912, 0.9709, 0.9192, 1.0360,
        0.9517, 0.9247, 1.0144, 0.9479, 0.9821, 0.9695, 0.9722, 0.9400, 0.9605,
        1.0301, 1.0009, 0.9571, 0.9998, 1.0388, 0.9248, 1.0020, 0.9564, 1.0249,
        0.9677, 0.9584, 0.9824, 1.0511, 1.0003, 1.0039, 0.9693, 0.9984, 1.0393,
        0.9912, 1.0382, 0.9923, 1.0517, 0.9988, 0.9558, 0.9760, 0.9911, 0.9691,
        0.9730, 0.9878, 0.9471, 1.0106, 0.9944, 0.9512, 0.9904, 0.9909, 0.9963,
        0.9453, 1.0223, 1.0253, 0.9315, 1.0287, 0.9996, 0.9450, 0.9494, 1.0354,
        0.9652, 0.9506, 0.9712, 0.9767, 0.9980, 1.0010, 1.0325, 1.0288, 0.9178,
        0.9226, 0.9111, 0.9554, 0.9949, 0.9575, 0.9891, 0.9662, 0.9676, 1.0296,
        0.9706, 1.0067, 0.9934, 0.9650, 0.9374, 0.9878, 1.0376, 1.0274, 1.0275,
        1.0100, 1.0041, 0.9820, 1.0044, 0.9457, 0.9512, 0.9821, 0.9860, 1.0085,
        0.9857, 1.0441, 0.9574, 0.9275, 0.9724, 0.9849, 1.0308, 1.0325, 0.9549,
        0.9231, 1.0291, 0.9510, 1.0017, 0.9269, 0.9831, 1.0048, 1.0114, 0.9999,
        0.9830, 1.0347, 0.9641, 1.0486, 0.9888, 0.9607, 0.9535, 1.0486, 0.9972,
        0.9665, 1.0155, 0.9069, 1.0663, 0.9336, 0.9811, 0.9593, 0.9147, 1.0313,
        1.0086, 1.0337, 0.9508, 0.9931, 1.0140, 1.0402, 0.9502, 1.0455, 0.9866,
        1.0112, 0.9843, 0.9537, 1.0121, 0.9821, 0.9822, 1.0269, 1.0203, 1.0266,
        1.0152, 0.9416, 1.0038, 0.9879, 0.9347, 1.0056, 0.9783, 1.0648, 0.9314,
        1.0040, 0.9684, 0.9545, 1.0023])
net.mlp.net.0.batch_norm.bias tensor([ 1.1850e-02,  3.1366e-02, -1.4527e-02, -4.7281e-02,  2.3358e-02,
         4.8721e-02,  2.5060e-02, -3.6967e-02, -7.0234e-02,  3.7433e-02,
         4.3631e-02, -1.8988e-02,  5.4942e-02,  4.7281e-02,  1.4026e-03,
         8.3748e-03, -8.2832e-03,  4.7581e-02,  3.9719e-02, -2.0459e-02,
         5.2550e-02,  1.1218e-02, -3.7747e-03, -4.8592e-02, -4.1447e-02,
         3.8789e-02,  6.0232e-02, -5.5161e-02,  1.4134e-02, -1.3481e-03,
        -4.3750e-03, -2.7524e-02, -6.1395e-03, -7.7465e-02,  1.6250e-02,
         2.8307e-02,  2.6787e-03,  2.7153e-02,  5.4204e-02, -1.7157e-02,
        -4.2850e-02, -3.5324e-02,  2.0307e-02,  4.2870e-02,  5.4322e-02,
         4.4760e-02, -3.6192e-02, -3.7646e-02,  1.2511e-03, -7.5038e-03,
        -4.0534e-02, -2.7292e-02,  3.0300e-02,  4.5384e-02, -1.5855e-02,
        -3.5622e-02,  2.3498e-02,  2.6918e-02,  9.7868e-03,  3.8722e-02,
         6.5650e-02,  5.7254e-02, -8.1854e-02,  1.2225e-02,  3.4351e-03,
        -6.4805e-02, -8.8996e-03,  3.8975e-02, -7.1856e-02, -3.7985e-03,
        -3.0529e-02,  2.4270e-02, -2.4993e-02,  7.9796e-02, -2.2712e-03,
        -5.8463e-03, -2.9090e-02, -8.0758e-03, -1.3688e-02, -7.2503e-03,
        -8.6410e-03, -3.4146e-02, -5.0759e-02, -2.8709e-02,  3.7511e-02,
         2.8692e-02,  4.0437e-02,  3.6210e-02, -3.8970e-02,  3.6819e-02,
         1.3821e-02, -7.0513e-02,  4.7129e-02, -5.6748e-02, -3.5298e-02,
         9.6340e-03, -2.6199e-02,  5.1454e-02,  1.2893e-02,  4.4676e-02,
         2.4523e-02,  4.0035e-02, -1.9625e-02, -3.9320e-02, -1.4064e-02,
         4.2843e-03,  5.5459e-02, -4.2306e-02,  2.8030e-02,  5.8052e-04,
         4.4868e-02,  2.7695e-02,  2.0191e-02,  2.9959e-02, -3.9006e-02,
         2.4456e-02, -5.9853e-02, -2.7892e-02, -1.8062e-02,  1.3623e-02,
         1.8715e-02, -3.1777e-03, -3.7898e-02, -4.3463e-02,  1.1416e-02,
         1.8776e-02,  1.9588e-02, -2.9656e-03, -4.3509e-02,  3.8604e-03,
        -7.7230e-02,  3.8557e-02,  5.7406e-02, -9.4188e-03, -8.0857e-03,
        -3.3608e-03, -7.3383e-03, -1.7927e-02, -7.0053e-02, -4.6847e-02,
        -3.8888e-02, -2.0799e-03,  3.9135e-02,  3.2957e-02,  5.9889e-03,
        -2.4940e-02, -3.0755e-02,  4.6477e-03, -1.3907e-02, -1.9176e-02,
         4.6688e-02, -3.1695e-02,  5.9662e-02,  1.4677e-02, -4.6615e-02,
         1.5115e-02,  3.7212e-02, -4.9933e-02,  1.0084e-02,  2.3956e-02,
        -1.9676e-02, -1.4865e-03, -1.6006e-02,  1.3207e-02,  5.8046e-03,
         5.6418e-02,  4.8080e-02, -5.7175e-02,  6.4490e-02,  3.7476e-02,
        -2.0014e-02, -4.1443e-02, -2.7744e-02, -4.1972e-02, -9.8398e-03,
        -1.8378e-02,  3.0556e-02, -1.8955e-02,  6.9888e-03, -8.1324e-02,
         2.5692e-02,  3.4048e-02,  1.0818e-02, -8.0486e-02, -1.4226e-02,
        -7.6275e-02,  1.6961e-02,  2.0390e-02, -2.8545e-05, -1.3961e-02,
         3.8071e-02, -2.5365e-03,  4.9578e-02,  4.7668e-02,  4.6165e-02,
         5.7987e-02, -4.5890e-02,  5.9383e-02,  2.9430e-02, -3.0378e-02,
         5.0494e-02,  8.0716e-03, -1.3558e-02, -7.3691e-02, -2.9222e-02,
        -5.1978e-02, -3.7128e-03, -1.1266e-02,  2.5606e-02,  3.1922e-02,
         3.4794e-02, -1.6878e-02,  4.9918e-02, -1.1565e-02, -2.0106e-02,
         3.2185e-02, -1.6196e-02,  3.2095e-02, -1.9221e-03, -3.4183e-02,
         2.6788e-02, -3.8179e-02, -2.0584e-02,  1.7040e-02, -4.7427e-02,
         2.3087e-02,  1.1420e-02,  1.0030e-02,  8.7575e-03, -6.6545e-02,
         7.2852e-02,  1.1022e-02, -7.9190e-02,  1.7354e-02,  2.3062e-02,
        -3.0903e-02, -2.6827e-02, -6.2564e-03, -1.9902e-02,  4.1426e-02,
        -3.0871e-02,  9.4584e-03, -5.3655e-02, -3.7003e-02,  4.6745e-02,
        -2.3275e-02,  1.9727e-02, -2.2207e-02,  3.2468e-02,  6.1203e-02,
         3.0453e-02, -1.0808e-02,  4.3625e-03,  3.1281e-02,  6.7111e-03,
        -7.0402e-03])
net.mlp.net.0.batch_norm.running_mean tensor([3.3164e-01, 4.5081e-01, 1.1275e-02, 4.3181e-01, 3.0724e-01, 3.6920e-01,
        2.6743e-03, 1.5280e-01, 7.4081e-02, 6.9219e-01, 4.0791e-01, 9.1624e-02,
        1.4140e-02, 5.4320e-02, 3.5561e-01, 3.4986e-01, 1.0254e-01, 1.4836e-02,
        7.6802e-01, 4.1640e-01, 2.2962e-01, 1.9316e-01, 8.1220e-02, 6.5281e-01,
        1.7011e-01, 9.6371e-03, 4.4393e-01, 1.4485e-01, 1.5255e-02, 5.6777e-02,
        4.6360e-01, 7.3386e-01, 9.4416e-01, 2.4453e-02, 8.9586e-04, 2.3693e-01,
        2.3786e-01, 2.3626e-01, 1.3655e-01, 3.8841e-01, 2.7544e-01, 7.9786e-02,
        7.5313e-05, 5.0461e-02, 4.6991e-02, 5.3738e-01, 1.3381e-01, 4.6599e-01,
        1.2651e-01, 5.5169e-02, 4.6661e-01, 1.6506e-02, 3.7338e-02, 3.9987e-02,
        1.1311e-01, 3.5604e-01, 2.3837e-01, 6.9648e-01, 1.4559e-01, 3.5140e-01,
        1.1408e-01, 2.0471e-01, 6.7934e-03, 4.0129e-01, 5.3235e-01, 1.9889e-01,
        8.1321e-01, 5.9835e-01, 9.6094e-01, 8.7678e-02, 5.2186e-01, 9.7659e-01,
        5.8757e-02, 2.2728e-01, 2.8799e-03, 4.6418e-02, 9.0522e-01, 3.2232e-03,
        2.0946e-01, 1.7283e-01, 5.5007e-01, 2.9121e-01, 1.7983e-01, 4.8875e-01,
        2.1222e-02, 5.5543e-02, 2.8739e-01, 2.1849e-02, 2.7970e-01, 2.0947e-01,
        4.1993e-01, 6.3652e-03, 2.8686e-02, 2.8489e-02, 5.1600e-03, 1.4248e-01,
        3.4169e-01, 6.2671e-01, 2.3532e-01, 9.3278e-01, 7.7642e-01, 2.0893e-01,
        1.0559e+00, 2.1322e-01, 7.8586e-01, 1.7250e-01, 1.9398e-01, 9.4496e-01,
        5.5208e-01, 3.5805e-01, 6.5597e-01, 5.5966e-02, 8.9986e-04, 1.2715e+00,
        8.8138e-01, 4.0274e-02, 2.6209e-02, 3.0683e-01, 5.9750e-02, 5.8600e-01,
        4.2445e-01, 2.6217e-02, 3.9576e-01, 1.4771e-02, 2.6897e-02, 4.4132e-02,
        5.5734e-01, 1.7312e-02, 1.2529e+00, 2.3359e-02, 1.3689e-01, 2.3602e-01,
        4.1582e-01, 1.0582e-01, 7.7744e-02, 1.3576e-02, 8.4248e-01, 1.1558e-01,
        7.5462e-02, 4.9419e-01, 5.7100e-01, 9.7227e-02, 1.7935e-02, 3.1243e-01,
        4.8296e-01, 3.8294e-01, 6.1928e-02, 1.3181e-03, 5.5759e-02, 8.4188e-02,
        5.4549e-01, 7.8660e-01, 4.5210e-02, 7.4142e-01, 2.1685e-01, 2.8489e-01,
        5.2468e-01, 4.4026e-01, 9.6657e-02, 1.0904e-02, 6.0873e-01, 4.1560e-01,
        3.5374e-02, 1.1421e-01, 3.7493e-02, 1.4080e-01, 2.2613e-02, 8.1674e-01,
        7.0565e-01, 6.9408e-02, 4.6749e-02, 1.2103e+00, 1.2006e-02, 7.6374e-02,
        4.1324e-01, 1.9080e-01, 1.5434e-01, 4.1281e-02, 9.6059e-02, 9.2067e-02,
        2.8591e-02, 1.1272e-01, 3.7826e-01, 2.5751e-01, 1.6420e-01, 2.8535e-01,
        5.6538e-02, 4.5004e-01, 1.6950e-02, 3.1826e-01, 1.7626e-01, 3.1064e-01,
        6.6510e-01, 2.3480e-01, 2.2869e-02, 1.0968e-02, 6.4554e-01, 4.8242e-02,
        8.6985e-01, 1.5092e-02, 5.6513e-01, 3.1746e-01, 1.2794e-01, 6.2751e-01,
        4.1732e-02, 4.0051e-02, 2.1621e-02, 9.4277e-01, 3.6613e-02, 6.4188e-01,
        6.6376e-01, 2.4222e-01, 9.3352e-01, 8.7232e-01, 7.6151e-02, 6.4442e-02,
        2.1588e-01, 1.7598e+00, 2.9163e-01, 2.1560e-02, 7.4045e-02, 7.9322e-01,
        9.3751e-02, 1.3008e-01, 5.7944e-01, 6.6170e-01, 7.3491e-02, 9.0483e-03,
        2.5745e-01, 6.9472e-04, 9.1187e-01, 1.3986e-01, 4.3648e-02, 2.3245e-01,
        3.0452e-01, 1.8224e-01, 5.6277e-02, 8.0103e-02, 4.8354e-01, 1.1325e+00,
        4.4010e-01, 3.4112e-02, 2.4930e-01, 2.2298e-01, 2.4355e-01, 9.3472e-01,
        5.5747e-01, 7.5293e-02, 3.5893e-01, 9.0635e-04, 1.5289e-02, 2.0893e-01,
        2.9909e-01, 3.5104e-02, 1.2876e-01, 8.8080e-02])
net.mlp.net.0.batch_norm.running_var tensor([0.2636, 0.3890, 0.1255, 0.2678, 0.2422, 0.2688, 0.1223, 0.1578, 0.2474,
        0.2631, 0.3309, 0.2882, 0.1253, 0.1446, 0.1840, 0.3208, 0.2400, 0.1251,
        0.2731, 0.2059, 0.2311, 0.1992, 0.1516, 0.3012, 0.1891, 0.1244, 0.2125,
        0.4547, 0.1278, 0.1478, 0.2930, 0.3799, 0.4336, 0.1328, 0.1219, 0.1948,
        0.2552, 0.2238, 0.1556, 0.2009, 0.2558, 0.1545, 0.1216, 0.1397, 0.1333,
        0.3632, 0.1729, 0.3007, 0.1695, 0.1323, 0.2518, 0.1270, 0.1574, 0.1693,
        0.1586, 0.2276, 0.1983, 0.4282, 0.5029, 0.3469, 0.1681, 0.2276, 0.1291,
        0.3563, 0.2930, 0.1566, 0.2694, 0.2110, 0.3306, 0.1544, 0.3832, 0.3739,
        0.1426, 0.1853, 0.1242, 0.2104, 0.3257, 0.1223, 0.2267, 0.4026, 0.2166,
        0.2159, 0.1987, 0.2309, 0.1284, 0.1423, 0.2248, 0.1269, 0.2245, 0.2389,
        0.1925, 0.1281, 0.1519, 0.1364, 0.1229, 0.1673, 0.2981, 0.2527, 0.2454,
        0.3749, 1.7726, 0.4003, 0.4897, 0.1706, 0.8139, 0.1967, 0.1751, 0.4295,
        0.2482, 0.2819, 0.2891, 0.1383, 0.1217, 0.3966, 0.5233, 0.1344, 0.1298,
        0.6540, 0.1858, 0.2319, 0.4191, 0.1288, 0.2409, 0.1265, 0.1283, 0.1335,
        0.7238, 0.1563, 0.3242, 0.1309, 0.1904, 0.2425, 0.2295, 0.1515, 0.2161,
        0.1270, 0.2762, 0.2122, 0.1769, 0.3854, 0.2656, 0.1619, 0.1375, 0.2635,
        0.3107, 0.2352, 0.2155, 0.1219, 0.1789, 0.1502, 0.3126, 0.4457, 0.1711,
        0.3105, 0.2500, 0.2003, 0.6433, 0.2291, 0.1510, 0.1255, 0.4356, 0.2257,
        0.1359, 0.1479, 0.1371, 0.2180, 0.1306, 0.5127, 0.4788, 0.2011, 0.2028,
        0.3317, 0.1262, 0.1530, 0.2365, 0.2064, 0.4056, 0.1474, 0.1628, 0.1523,
        0.1285, 0.2115, 0.3412, 0.1958, 0.1985, 0.2188, 0.1484, 0.9742, 0.1361,
        0.2551, 0.5181, 0.2014, 0.2297, 0.2483, 0.1273, 0.1253, 0.3260, 0.1461,
        0.5299, 0.1257, 0.2186, 0.3406, 0.1447, 0.3747, 0.1435, 0.1332, 0.1342,
        0.5874, 0.1647, 0.2114, 0.3438, 0.2412, 0.3512, 0.3573, 0.1482, 0.1647,
        0.2043, 0.5616, 0.2200, 0.1291, 0.2164, 0.4499, 0.1755, 0.3130, 0.6305,
        0.4244, 0.2453, 0.1242, 0.2170, 0.1218, 0.3844, 0.1817, 0.1383, 0.2164,
        0.2341, 0.2010, 0.1582, 0.1475, 0.2207, 0.3006, 0.2543, 0.1858, 0.3337,
        0.1784, 0.1793, 0.3640, 0.2841, 0.1449, 0.2848, 0.1218, 0.1272, 0.1784,
        0.3298, 0.1345, 0.2255, 0.1521])
net.mlp.net.0.batch_norm.num_batches_tracked tensor(20)
net.mlp.net.1.linear.weight tensor([[-0.1279,  0.1029, -0.0850,  ..., -0.1225, -0.0625, -0.0626],
        [-0.0144, -0.0656,  0.0115,  ...,  0.1046, -0.0348, -0.0864],
        [ 0.0609,  0.1314, -0.1674,  ...,  0.0921, -0.0470, -0.0455],
        ...,
        [-0.0196,  0.0804, -0.0705,  ..., -0.0552, -0.0157,  0.0109],
        [ 0.0587,  0.0356, -0.1094,  ..., -0.1119, -0.0814, -0.1350],
        [ 0.0597,  0.0068,  0.0076,  ..., -0.0794,  0.1641,  0.1246]])
net.mlp.net.1.linear.bias tensor([-0.0110, -0.0119, -0.0567, -0.0622,  0.0379, -0.0016,  0.0449, -0.0530,
         0.0125, -0.0640, -0.0609,  0.0174, -0.0194, -0.0726,  0.0508, -0.0164,
         0.0052, -0.0736,  0.0477, -0.0789, -0.0258, -0.0724, -0.0250, -0.0951,
         0.0297, -0.0025,  0.0351, -0.0444,  0.0241, -0.1119, -0.0437,  0.0403,
        -0.0367, -0.0329,  0.0144, -0.0258, -0.0140, -0.0930, -0.0150, -0.0685,
        -0.0515,  0.0277, -0.0449, -0.0335, -0.0019, -0.0649, -0.0434,  0.0022,
        -0.0273, -0.0382, -0.1383, -0.0105, -0.0571,  0.0108, -0.0094, -0.0075,
        -0.0635,  0.0557, -0.0514, -0.0383, -0.0822,  0.0996,  0.0049,  0.0546,
        -0.0144, -0.0042, -0.0161, -0.0455, -0.0575, -0.0787, -0.1166, -0.0172,
        -0.0424,  0.0335, -0.0356,  0.0121,  0.0091, -0.0440,  0.0190,  0.0497,
         0.0451, -0.0438,  0.0642, -0.0644, -0.0727,  0.0013, -0.0168, -0.0954,
        -0.0443,  0.0810, -0.0555, -0.0229, -0.0469, -0.0379, -0.0181, -0.0406,
        -0.0117,  0.0215, -0.0985,  0.0706, -0.0487,  0.0367, -0.0187, -0.0821,
        -0.0850, -0.0771, -0.0835, -0.0361,  0.0039, -0.0521,  0.0220, -0.0188,
         0.0545,  0.0493, -0.0775,  0.0065, -0.0510, -0.0729, -0.0070, -0.0464,
         0.0045,  0.0107, -0.0698, -0.0151,  0.0496, -0.0136,  0.0278,  0.0097,
        -0.0496, -0.0057,  0.0426, -0.0556, -0.0448, -0.0411, -0.0982, -0.0601,
         0.0022,  0.0343, -0.0315, -0.0005,  0.0120, -0.0196, -0.0514,  0.0443,
        -0.0345, -0.1126,  0.0733, -0.0114,  0.0366, -0.0006,  0.0499, -0.0101,
        -0.0254, -0.0730, -0.0266,  0.0152, -0.0096,  0.0108,  0.0763,  0.0082,
        -0.0289, -0.0462, -0.0461,  0.0656, -0.0261, -0.0039,  0.0086, -0.0851,
        -0.0965, -0.0822,  0.0410, -0.0882, -0.0348, -0.0307,  0.0096, -0.0128,
        -0.0187, -0.0304,  0.0242,  0.0293, -0.0092,  0.0464, -0.0038, -0.0289,
        -0.0797,  0.0148,  0.0389, -0.1013, -0.0407, -0.0591, -0.0229, -0.0558,
        -0.0088, -0.0398,  0.0046,  0.0070,  0.0261,  0.0218, -0.0850, -0.0685,
         0.0031, -0.0100, -0.0447,  0.0113, -0.0098,  0.0323,  0.0332, -0.0350,
         0.0199, -0.0427, -0.0165,  0.0053,  0.0119, -0.0103,  0.0206, -0.0767,
         0.0183, -0.0416, -0.0413, -0.0781,  0.0152,  0.0053, -0.0462, -0.0064,
        -0.0063, -0.0555, -0.0872, -0.0576,  0.0354, -0.0246, -0.0534, -0.0531,
        -0.0786, -0.0408, -0.0289, -0.0270, -0.0239, -0.0086, -0.0028, -0.0365,
        -0.0949, -0.0043, -0.0044,  0.0428,  0.0413,  0.0357,  0.0016, -0.0132,
         0.0552, -0.0443,  0.0106, -0.0481,  0.0655, -0.1257,  0.1030,  0.0933])
net.mlp.net.1.batch_norm.weight tensor([0.9227, 0.9501, 0.9659, 0.9666, 0.9601, 0.9437, 0.9596, 0.9760, 0.9906,
        0.9381, 0.9340, 0.9626, 0.9410, 0.9024, 0.9474, 0.9379, 0.9211, 0.9184,
        0.9373, 0.9526, 0.9645, 0.9441, 0.9484, 0.9639, 0.9492, 0.9508, 0.9830,
        0.9429, 0.9425, 0.9277, 0.9379, 0.9521, 0.9673, 0.9279, 0.9450, 0.9529,
        0.9404, 0.9402, 0.9623, 0.9608, 0.9040, 0.9450, 0.9081, 0.9330, 0.9552,
        0.9241, 0.9401, 0.9249, 0.9503, 0.9159, 0.9646, 0.9660, 0.9493, 0.9552,
        0.9129, 0.9529, 0.9314, 0.9569, 0.9589, 0.9425, 0.9027, 0.9731, 0.9010,
        0.9197, 0.9699, 0.9537, 0.9721, 0.9439, 0.9271, 0.9676, 0.9129, 0.9035,
        0.9780, 1.0007, 0.9763, 0.9593, 0.9424, 0.9041, 0.9145, 0.9621, 0.9253,
        0.9554, 0.9297, 0.9332, 0.9505, 0.9318, 0.9551, 0.9268, 0.9567, 0.8981,
        0.9646, 0.9257, 0.9303, 0.9673, 0.9676, 0.9125, 0.9602, 0.9495, 0.9368,
        0.9218, 0.9458, 0.8886, 0.9258, 0.9761, 0.9491, 0.9783, 0.9345, 0.9476,
        0.9523, 0.9030, 0.9521, 0.9480, 0.9647, 0.9198, 0.9346, 0.9441, 0.9363,
        0.9567, 0.9752, 0.9554, 0.9348, 0.9789, 0.9762, 0.9618, 0.9482, 0.9471,
        0.9334, 0.9489, 0.9621, 0.9491, 0.9504, 0.9464, 0.9605, 0.9421, 0.9388,
        0.9289, 0.9659, 0.9174, 0.9492, 0.9225, 0.9772, 0.9682, 0.9076, 0.9504,
        0.9221, 0.9463, 0.9340, 0.9492, 0.9760, 0.9744, 0.9468, 0.9131, 0.9497,
        0.9232, 0.9380, 0.9217, 0.9214, 0.9365, 0.9448, 0.9749, 0.9394, 0.9518,
        0.9755, 0.9190, 0.9397, 0.9429, 0.9428, 0.9216, 0.9587, 0.9279, 0.8973,
        0.9017, 0.9619, 0.9636, 0.9527, 0.9388, 0.9239, 0.9464, 0.9488, 0.9618,
        0.9573, 0.9068, 0.9488, 0.9851, 0.9102, 0.9113, 0.9487, 0.9481, 0.9701,
        0.9692, 0.9477, 0.9392, 0.9521, 0.9125, 0.9449, 0.9549, 0.9275, 0.9454,
        0.9166, 0.9434, 0.9794, 0.9516, 0.9654, 0.9519, 0.9189, 0.9562, 0.9037,
        0.9564, 0.9128, 0.9473, 0.9671, 0.9832, 0.9178, 0.9756, 0.9521, 0.9341,
        0.9571, 0.9607, 0.9047, 0.9881, 0.9082, 0.9704, 0.9498, 0.9658, 0.9247,
        0.9824, 0.9799, 0.9374, 0.9240, 0.9691, 0.9342, 0.9653, 0.9332, 0.9359,
        0.9591, 0.9386, 0.9189, 0.9362, 0.9028, 0.9893, 0.9425, 0.9113, 0.9223,
        0.9601, 0.9252, 0.9055, 0.9498, 0.9635, 0.9825, 0.9391, 0.9357, 0.9664,
        0.9009, 0.9524, 0.9347, 0.9373])
net.mlp.net.1.batch_norm.bias tensor([ 0.0379, -0.0102,  0.0273,  0.0081, -0.0016, -0.0526, -0.0431,  0.0344,
         0.0682,  0.0169,  0.0378,  0.0061,  0.0330, -0.0026,  0.0121, -0.0220,
        -0.0479,  0.0465,  0.0283,  0.0114, -0.0599,  0.0273,  0.0095,  0.0733,
         0.0029,  0.0213, -0.0267,  0.0291,  0.0078, -0.0030, -0.0502, -0.0306,
        -0.0549,  0.0360,  0.0448, -0.0355, -0.0150, -0.0591, -0.0032, -0.0346,
        -0.0490, -0.0559,  0.0369,  0.0473,  0.0431,  0.0147, -0.0148,  0.0218,
        -0.0318, -0.0013, -0.0023,  0.0394,  0.0112,  0.0323,  0.0225, -0.0499,
         0.0470, -0.0288, -0.0241, -0.0645, -0.0054,  0.0390,  0.0338, -0.0192,
        -0.0036, -0.0328,  0.0031,  0.0505,  0.0495,  0.0097,  0.0142,  0.0016,
         0.0350,  0.0202,  0.0557, -0.0347,  0.0223, -0.0270,  0.0079, -0.0068,
         0.0439, -0.0388,  0.0041, -0.0464, -0.0434,  0.0116,  0.0236, -0.0507,
         0.0331,  0.0114,  0.0397, -0.0342, -0.0195,  0.0191, -0.0390,  0.0327,
         0.0379,  0.0192, -0.0086,  0.0504,  0.0421, -0.0577,  0.0668, -0.0761,
         0.0077,  0.0025,  0.0254,  0.0400, -0.0380, -0.0141,  0.0332,  0.0044,
        -0.0369,  0.0155,  0.0046,  0.0288,  0.0366, -0.0539,  0.0140, -0.0262,
        -0.0265,  0.0357, -0.0381,  0.0040, -0.0374, -0.0082, -0.0465, -0.0054,
         0.0256,  0.0670,  0.0303, -0.0199,  0.0269,  0.0410, -0.0476,  0.0458,
         0.0163, -0.0456, -0.0619, -0.0632,  0.0288, -0.0307,  0.0455,  0.0747,
         0.0217, -0.0391, -0.0019,  0.0277, -0.0103,  0.0255, -0.0228,  0.0358,
         0.0239,  0.0044,  0.0136, -0.0407, -0.0604, -0.0562, -0.0891, -0.0231,
        -0.0330, -0.0205, -0.0642, -0.0161, -0.0070, -0.0234, -0.0451, -0.0610,
        -0.0136,  0.0147,  0.0515,  0.0666, -0.0348, -0.0129,  0.0019, -0.0522,
         0.0254, -0.0410,  0.0060, -0.0230, -0.0468,  0.0148, -0.0525,  0.0645,
         0.0402,  0.0070,  0.0118,  0.0222, -0.0383, -0.0183,  0.0009, -0.0344,
         0.0063, -0.0172, -0.0357, -0.0153,  0.0141, -0.0208, -0.0499,  0.0135,
         0.0383, -0.0369, -0.0369, -0.0601,  0.0338,  0.0528,  0.0114, -0.0418,
         0.0017, -0.0100, -0.0138, -0.0049,  0.0145, -0.0266, -0.0534,  0.0164,
        -0.0578,  0.0138,  0.0380,  0.0040,  0.0177,  0.0219,  0.0174, -0.0104,
         0.0274,  0.0339,  0.0170,  0.0298, -0.0092,  0.0148, -0.0607,  0.0375,
         0.0320, -0.0235, -0.0375, -0.0264,  0.0021, -0.0280,  0.0493,  0.0276,
        -0.0123, -0.0302, -0.0079, -0.0073,  0.0396,  0.0142, -0.0652, -0.0083,
         0.0144,  0.0528, -0.0670,  0.0084,  0.0461, -0.0009,  0.0272, -0.0347])
net.mlp.net.1.batch_norm.running_mean tensor([0.8224, 0.9010, 0.6946, 0.6732, 0.8068, 0.7535, 0.6994, 0.8503, 0.6375,
        0.8392, 0.5975, 0.6299, 0.8045, 0.6205, 0.9895, 0.4962, 0.7205, 0.9526,
        0.6716, 0.4818, 0.6987, 1.0414, 0.6826, 0.7329, 0.6343, 0.6782, 0.9856,
        0.4394, 0.9052, 0.8239, 0.7562, 0.6545, 0.9137, 0.8640, 0.7282, 0.7122,
        0.6427, 0.6703, 0.5637, 0.5107, 0.5721, 0.6917, 0.7418, 0.5455, 0.8821,
        0.7165, 0.8699, 0.6951, 0.7789, 0.7112, 0.7258, 0.6337, 0.6911, 0.6743,
        0.7603, 0.6526, 0.6043, 0.6190, 0.6509, 0.9328, 0.8783, 0.8665, 0.8749,
        0.5708, 0.6984, 0.6001, 0.6474, 0.8729, 0.7823, 0.4656, 0.8185, 0.8585,
        0.6732, 0.6464, 0.6154, 0.6982, 0.9810, 0.5195, 0.7701, 0.8965, 0.9268,
        0.6642, 0.9173, 0.8298, 0.6793, 0.5911, 0.7202, 0.9471, 0.9882, 0.6912,
        0.5623, 0.4399, 0.6279, 0.7169, 0.5888, 0.7488, 0.6752, 0.7824, 0.7592,
        0.7101, 0.7091, 0.7205, 0.8419, 0.6100, 0.5949, 0.8730, 0.6657, 0.7063,
        0.7605, 0.5734, 0.5066, 0.7446, 0.9438, 0.9927, 0.5665, 0.7545, 0.4796,
        0.5499, 0.5544, 0.7825, 0.7504, 0.8673, 0.6906, 0.4686, 0.5321, 0.5812,
        0.7542, 0.8334, 0.6019, 0.6584, 0.7142, 0.6808, 0.7106, 0.5740, 0.6155,
        0.6481, 0.4541, 0.8584, 0.8592, 0.7046, 0.6942, 0.8892, 0.5686, 0.8377,
        0.6874, 0.7325, 0.8653, 0.6449, 0.9682, 0.5738, 0.9244, 1.0310, 0.8261,
        0.5108, 0.8633, 1.0298, 0.8707, 0.6956, 0.6924, 0.6410, 0.5850, 0.5654,
        0.6396, 0.6728, 0.6616, 0.8560, 0.9718, 0.9288, 0.5876, 0.8134, 0.9944,
        0.7479, 0.6136, 0.6046, 0.5183, 0.7090, 0.7631, 0.8632, 0.9466, 0.6388,
        0.7125, 0.6944, 0.5667, 0.8038, 0.6811, 0.7092, 0.8186, 0.5282, 0.7143,
        0.6863, 0.5398, 0.6756, 0.7615, 0.9992, 0.5917, 0.6173, 0.7212, 0.7803,
        0.6934, 0.8324, 0.7593, 0.8991, 0.8291, 0.9658, 0.8083, 0.5361, 0.7875,
        0.5839, 0.9487, 0.6674, 0.8183, 1.0393, 0.7873, 0.6270, 0.8958, 0.7365,
        0.7754, 0.8874, 0.5364, 0.6435, 0.7078, 0.5559, 0.7772, 0.6602, 0.7501,
        0.8120, 0.6224, 0.6996, 0.8308, 0.6685, 0.5409, 0.7480, 0.6181, 0.6767,
        0.5530, 0.7226, 0.5660, 0.7352, 0.7255, 0.8380, 0.5879, 0.7311, 0.7068,
        0.8646, 0.7079, 0.7322, 0.5531, 0.5031, 0.7061, 0.7356, 0.6663, 0.7242,
        0.7030, 0.5755, 1.0188, 0.9586])
net.mlp.net.1.batch_norm.running_var tensor([ 5.7129,  4.7224,  1.1499,  1.4521,  2.0722,  4.0073,  1.3473,  9.4148,
         1.0574,  4.0783,  1.2387,  1.0835,  4.2573,  1.1904,  4.3296,  1.0674,
         1.2696, 10.0593,  1.3159,  1.3752,  1.4165,  2.6382,  1.1162,  1.5869,
         1.1426,  1.0499,  1.8036,  0.6978,  4.3424,  4.3270,  1.7487,  1.1465,
         6.6094,  2.3311,  4.7799,  3.1761,  3.8221,  1.4843,  1.0163,  0.9464,
         3.8077,  1.5587,  2.7563,  2.6113,  1.8542,  1.2806,  7.4165,  3.8436,
         1.5393,  1.5147,  1.5456,  1.0980,  1.0789,  3.5593,  7.8979,  1.0890,
         1.1551,  1.2463,  1.2920,  5.6656,  6.4201,  1.6686,  1.7061,  0.9603,
         1.5149,  1.0309,  2.1607,  1.8035,  4.0226,  0.7476,  8.3825,  5.1822,
         1.3612,  1.0470,  0.8766,  1.3112,  6.7871,  1.2332,  2.6566,  1.7162,
         1.7342,  1.4768,  1.7771,  5.9135,  1.2822,  2.2791,  1.8955,  9.9405,
         2.2168,  1.3197,  1.7147,  0.6542,  0.9999,  3.9985,  1.5811,  2.0965,
         1.4032,  1.8544,  6.4498,  1.5586,  7.5546,  1.2439,  6.7868,  1.1505,
         4.3200,  2.0093,  2.3839,  1.3318,  1.7144,  1.9894,  0.8660,  3.9113,
         1.8254,  4.1627,  3.0196,  1.4029,  1.1721,  1.6524,  0.8533,  6.3469,
         1.2916,  5.2757,  4.6834,  0.8619,  0.8424,  1.1471,  3.7384,  2.4299,
         1.2304,  5.1178,  1.2334,  1.8517,  1.2942,  1.0595,  2.9769,  2.4331,
         1.9156,  1.6431,  6.1644,  1.4339,  1.1261,  1.8947,  1.5762,  4.5025,
         2.5326,  4.8773,  1.7431,  1.3751,  2.5395,  1.3761,  1.8308, 10.8970,
         6.1702,  1.3182,  2.2618,  7.0012,  3.8043,  1.3890,  1.0553,  1.3045,
         0.8840,  1.2007,  1.9066,  0.9200,  1.1443,  1.6178,  8.7145,  8.6035,
         2.7215,  7.7208,  8.0924,  3.3319,  3.2796,  1.9401,  0.8026,  1.6107,
         6.9013,  3.2931,  2.7287,  1.0434,  1.9003,  1.2225,  1.3405,  1.7167,
         2.1663,  3.1608,  1.9534,  1.0907,  1.4691,  1.3014,  0.9970,  1.8312,
         6.6506,  2.1133,  1.5080,  1.0440,  3.2429,  5.1080,  6.4154,  7.4512,
         1.2837,  3.4536,  1.7989,  7.7765,  4.7954,  1.0365,  5.8198,  1.1869,
         9.4464,  1.0308,  1.2477,  2.5110,  6.4014,  1.2328,  4.9228,  4.0902,
         1.4441,  6.9161,  0.9476,  1.4118,  1.3648,  0.8383,  2.3689,  1.3652,
         4.9642,  1.6831,  1.0635,  1.8013,  1.6318,  4.5710,  1.1885,  1.2693,
         1.1020,  1.7912,  1.3692,  4.1233,  1.7822,  1.4178,  1.8463,  1.5159,
         1.9234,  1.4914,  3.8084,  4.9062,  1.0568,  1.1542,  0.9669,  1.1872,
         1.1547,  4.1079,  1.6281,  4.0255,  1.2865,  1.1437,  1.9812,  1.8579])
net.mlp.net.1.batch_norm.num_batches_tracked tensor(20)
net.mlp.net.2.weight tensor([[ 0.0013,  0.0015, -0.0152,  0.0269, -0.0042, -0.0165, -0.0185, -0.0550,
         -0.0573,  0.0021,  0.0144,  0.0132, -0.0255, -0.0137,  0.0166,  0.0307,
         -0.0107,  0.0137, -0.0109, -0.0161, -0.0277,  0.0237, -0.0190, -0.0317,
          0.0290, -0.0336,  0.0505,  0.0097, -0.0250,  0.0052, -0.0140, -0.0282,
         -0.0240, -0.0088,  0.0235, -0.0326,  0.0145,  0.0157,  0.0018, -0.0265,
         -0.0063,  0.0161, -0.0085, -0.0016, -0.0138, -0.0098, -0.0116,  0.0033,
          0.0114,  0.0114, -0.0307, -0.0521,  0.0344, -0.0182, -0.0318,  0.0249,
         -0.0160, -0.0322,  0.0068, -0.0061, -0.0015, -0.0363, -0.0080,  0.0093,
          0.0527,  0.0255, -0.0376,  0.0052,  0.0019, -0.0440, -0.0146,  0.0226,
          0.0606,  0.0571,  0.0215, -0.0330, -0.0159, -0.0072,  0.0071,  0.0242,
          0.0104,  0.0373, -0.0117,  0.0161,  0.0232,  0.0024, -0.0072, -0.0130,
         -0.0185, -0.0013,  0.0198, -0.0014, -0.0036,  0.0185, -0.0341, -0.0149,
          0.0168, -0.0119,  0.0034,  0.0025,  0.0427, -0.0157, -0.0151,  0.0240,
          0.0029,  0.0461, -0.0069,  0.0136, -0.0172, -0.0142,  0.0091,  0.0175,
          0.0189,  0.0231, -0.0041, -0.0305,  0.0156, -0.0480,  0.0351, -0.0152,
          0.0049,  0.0399, -0.0227, -0.0222, -0.0406,  0.0191,  0.0006, -0.0250,
         -0.0292, -0.0078,  0.0213,  0.0186,  0.0117,  0.0072, -0.0180,  0.0230,
          0.0535, -0.0023,  0.0255,  0.0029,  0.0369,  0.0261,  0.0093,  0.0331,
         -0.0089, -0.0063, -0.0054,  0.0188, -0.0470, -0.0425,  0.0145, -0.0054,
         -0.0277,  0.0206, -0.0076, -0.0092, -0.0144,  0.0228,  0.0084, -0.0170,
         -0.0177, -0.0074,  0.0541,  0.0077,  0.0211,  0.0028, -0.0066,  0.0017,
          0.0190, -0.0043,  0.0125,  0.0082, -0.0246,  0.0307, -0.0316, -0.0072,
          0.0096,  0.0088,  0.0109, -0.0276, -0.0366, -0.0079,  0.0148,  0.0439,
         -0.0100,  0.0243, -0.0132, -0.0020, -0.0345,  0.0351, -0.0195,  0.0007,
         -0.0093,  0.0100,  0.0241, -0.0109,  0.0046, -0.0188,  0.0087,  0.0190,
          0.0313,  0.0302, -0.0307, -0.0149, -0.0029, -0.0233,  0.0151, -0.0183,
         -0.0100,  0.0257,  0.0454,  0.0371, -0.0124,  0.0542,  0.0281, -0.0036,
          0.0211,  0.0318,  0.0091, -0.0437, -0.0256,  0.0260,  0.0327,  0.0473,
         -0.0265,  0.0216,  0.0569,  0.0118,  0.0047, -0.0229, -0.0068, -0.0461,
         -0.0265,  0.0038,  0.0221,  0.0010,  0.0242,  0.0301,  0.0062,  0.0369,
         -0.0056, -0.0047,  0.0033, -0.0030,  0.0176, -0.0016,  0.0218, -0.0270,
         -0.0382, -0.0148,  0.0011, -0.0440, -0.0065, -0.0225,  0.0074,  0.0148]])
