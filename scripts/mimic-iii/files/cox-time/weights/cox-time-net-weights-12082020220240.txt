Weights: 
net.embeddings.embeddings.0.weight tensor([[ 0.0546,  0.1090],
        [ 0.0811,  0.0605],
        [ 0.0483,  0.0404],
        [-0.0625,  0.0033]])
net.embeddings.embeddings.1.weight tensor([[-0.0427, -0.0704],
        [ 0.0063, -0.0733],
        [-0.0119, -0.0323],
        [ 0.1007, -0.1029],
        [ 0.0930, -0.0926]])
net.embeddings.embeddings.2.weight tensor([[ 0.0275,  0.0553, -0.0278],
        [-0.0298,  0.0270,  0.0788],
        [ 0.0701, -0.0722, -0.0059],
        [-0.0113,  0.0610, -0.0115],
        [-0.0660, -0.0641, -0.0388],
        [-0.0462, -0.0458, -0.0437]])
net.embeddings.embeddings.3.weight tensor([[-0.0969, -0.0246],
        [ 0.0028,  0.0826],
        [-0.0239, -0.0686],
        [-0.0550, -0.0981]])
net.embeddings.embeddings.4.weight tensor([[ 0.0154, -0.0037],
        [ 0.0838, -0.0492],
        [ 0.0831,  0.0301],
        [-0.0765,  0.0860]])
net.mlp.net.0.linear.weight tensor([[-0.0392, -0.0625, -0.0773,  ..., -0.0004,  0.0746, -0.0277],
        [-0.0480,  0.0334, -0.0319,  ..., -0.0515,  0.0262,  0.0249],
        [ 0.0635, -0.0008, -0.1029,  ...,  0.1239, -0.0220,  0.0439],
        ...,
        [-0.1116, -0.0710, -0.0372,  ..., -0.0109, -0.0874, -0.0337],
        [ 0.0027,  0.0410,  0.0329,  ..., -0.0009, -0.0028, -0.0083],
        [-0.0648, -0.0022,  0.0764,  ...,  0.0237,  0.0809,  0.0868]])
net.mlp.net.0.linear.bias tensor([-0.0213, -0.0224, -0.0292, -0.0200,  0.0099, -0.0353, -0.0083, -0.0119,
         0.0100,  0.0080, -0.0066,  0.0017,  0.0075, -0.0167, -0.0053, -0.0054,
         0.0335, -0.0168,  0.0110, -0.0010,  0.0107,  0.0038, -0.0170, -0.0107,
        -0.0071,  0.0171, -0.0121, -0.0310, -0.0012,  0.0342,  0.0074,  0.0164,
         0.0345,  0.0186, -0.0184,  0.0006, -0.0107,  0.0266, -0.0139,  0.0260,
        -0.0318, -0.0345,  0.0267, -0.0040, -0.0329, -0.0269,  0.0345,  0.0185,
        -0.0153, -0.0124, -0.0273, -0.0059, -0.0113,  0.0184, -0.0241, -0.0237,
        -0.0312, -0.0132,  0.0087, -0.0144, -0.0092,  0.0109,  0.0265,  0.0124,
         0.0036, -0.0331, -0.0271,  0.0198, -0.0364,  0.0108,  0.0117, -0.0320,
         0.0230, -0.0103,  0.0070,  0.0032, -0.0081, -0.0346, -0.0360,  0.0205,
         0.0363,  0.0231,  0.0162,  0.0055, -0.0340,  0.0182, -0.0281,  0.0361,
        -0.0158, -0.0251,  0.0096,  0.0009, -0.0139,  0.0181,  0.0014, -0.0168,
        -0.0155, -0.0325, -0.0338,  0.0193, -0.0082,  0.0209, -0.0087,  0.0319,
        -0.0012, -0.0321,  0.0059, -0.0232,  0.0178, -0.0373,  0.0277, -0.0138,
         0.0335, -0.0262,  0.0006, -0.0222, -0.0123, -0.0243, -0.0221, -0.0151,
         0.0058, -0.0136,  0.0127, -0.0265, -0.0174,  0.0031,  0.0103,  0.0041])
net.mlp.net.0.batch_norm.weight tensor([0.1653, 0.1650, 0.1653, 0.1646, 0.1657, 0.1669, 0.1652, 0.1650, 0.1663,
        0.1651, 0.1649, 0.1639, 0.1641, 0.1640, 0.1640, 0.1652, 0.1667, 0.1654,
        0.1641, 0.1644, 0.1647, 0.1650, 0.1650, 0.1648, 0.1663, 0.1639, 0.1645,
        0.1654, 0.1663, 0.1658, 0.1650, 0.1656, 0.1650, 0.1647, 0.1649, 0.1666,
        0.1659, 0.1637, 0.1648, 0.1638, 0.1649, 0.1653, 0.1654, 0.1667, 0.1642,
        0.1652, 0.1640, 0.1656, 0.1644, 0.1644, 0.1644, 0.1657, 0.1648, 0.1659,
        0.1653, 0.1653, 0.1652, 0.1648, 0.1650, 0.1649, 0.1663, 0.1652, 0.1655,
        0.1657, 0.1653, 0.1657, 0.1651, 0.1664, 0.1649, 0.1646, 0.1655, 0.1659,
        0.1643, 0.1656, 0.1656, 0.1673, 0.1656, 0.1640, 0.1657, 0.1653, 0.1654,
        0.1654, 0.1641, 0.1656, 0.1648, 0.1656, 0.1648, 0.1666, 0.1657, 0.1658,
        0.1657, 0.1659, 0.1651, 0.1661, 0.1656, 0.1639, 0.1650, 0.1646, 0.1651,
        0.1659, 0.1638, 0.1656, 0.1653, 0.1652, 0.1643, 0.1653, 0.1662, 0.1640,
        0.1648, 0.1646, 0.1658, 0.1667, 0.1652, 0.1652, 0.1643, 0.1655, 0.1658,
        0.1646, 0.1641, 0.1653, 0.1651, 0.1658, 0.1657, 0.1655, 0.1651, 0.1657,
        0.1657, 0.1643])
net.mlp.net.0.batch_norm.bias tensor([ 6.1290e-04,  6.0017e-04, -5.5140e-04, -3.7309e-04,  1.3703e-04,
        -6.5827e-05, -4.4264e-04, -5.0377e-04, -6.3483e-04, -9.1702e-04,
        -3.0330e-04, -2.6426e-04,  1.0567e-03,  2.1331e-05, -4.6078e-04,
         8.8312e-05,  4.3862e-05, -9.5084e-04,  8.0158e-04,  2.6886e-05,
        -6.1798e-04,  1.3564e-04,  3.4114e-05,  2.3043e-04, -4.8137e-05,
        -4.4818e-04,  5.6363e-04, -1.9824e-04,  8.0103e-05, -5.5228e-04,
         1.1377e-04, -2.1997e-04, -8.4719e-04, -9.0554e-04, -7.6045e-04,
         6.9947e-06, -6.2588e-04,  9.8596e-04,  1.5574e-04,  7.4972e-04,
         2.7140e-04,  5.5954e-04, -1.3731e-04,  4.8963e-04, -2.3307e-04,
         2.6311e-04,  3.2457e-05, -6.8910e-04,  1.5803e-04,  3.2894e-04,
        -3.9856e-04,  3.7730e-04,  3.8033e-04, -2.7296e-04, -5.0938e-04,
         3.4338e-04, -3.1188e-04, -6.9190e-04, -2.6123e-05,  1.4325e-04,
        -7.5767e-04,  4.1226e-04, -3.1734e-04,  8.9750e-05,  1.1385e-04,
        -1.2329e-03, -4.7338e-04, -4.3523e-04, -1.1695e-04, -2.0792e-04,
         5.7030e-04,  5.8706e-04,  1.0990e-03, -1.8797e-04, -1.9707e-05,
         5.2483e-04, -7.5262e-04,  2.5294e-04,  3.7549e-04, -8.0498e-04,
         1.6695e-04, -5.1907e-04,  1.6199e-04, -1.3410e-03,  8.1496e-04,
         3.3890e-04, -4.4766e-04,  7.6645e-05,  8.2925e-04,  5.3383e-04,
        -3.9589e-04, -6.9701e-05,  3.2072e-05, -2.7247e-04, -2.9545e-04,
         1.1723e-03,  1.3239e-04, -2.2265e-04, -8.0866e-04, -4.9845e-04,
        -6.6164e-04, -4.5329e-04, -4.4881e-04, -8.4852e-04,  4.5675e-05,
         5.0081e-04,  2.0055e-04, -1.5423e-04,  6.5485e-04,  4.9587e-04,
        -2.6097e-04, -7.7640e-04, -1.0587e-03, -9.4796e-06, -1.4363e-04,
         5.2416e-04,  1.8724e-04,  2.2132e-04,  6.4917e-04,  1.0785e-04,
         5.8566e-04, -1.0611e-03, -2.4662e-04,  2.8529e-04,  3.4657e-04,
        -3.4977e-04,  1.1606e-04,  1.1622e-04])
net.mlp.net.0.batch_norm.running_mean tensor([4.5671e-03, 1.9804e-04, 6.7043e-03, 5.2122e-03, 4.2631e-03, 3.7474e-02,
        8.6611e-03, 4.3323e-02, 6.5980e-03, 1.7709e-01, 3.4443e-02, 5.3915e-02,
        2.7067e-02, 1.3681e-03, 5.6772e-02, 3.4951e-02, 8.7457e-04, 7.1669e-11,
        1.3919e-01, 2.9792e-02, 2.5607e-02, 4.1803e-03, 1.0830e-01, 4.7728e-02,
        8.6665e-04, 7.3638e-02, 2.4834e-04, 4.8752e-02, 2.6638e-02, 2.8525e-02,
        1.3939e-03, 1.4693e-01, 5.9303e-03, 4.2294e-02, 4.1420e-02, 3.4914e-02,
        1.1190e-02, 3.3929e-02, 1.2839e-01, 8.4913e-02, 5.2043e-03, 1.0182e-11,
        6.4525e-02, 1.0344e-01, 3.1197e-02, 6.9636e-02, 5.1886e-02, 5.8347e-03,
        1.2231e-01, 1.0954e-02, 1.5034e-03, 3.7421e-02, 9.7633e-02, 1.1329e-02,
        1.4345e-02, 2.9539e-02, 2.0880e-02, 6.8190e-02, 4.4540e-03, 1.4458e-02,
        8.2366e-03, 2.2889e-02, 4.3807e-02, 1.0367e-01, 4.8291e-03, 7.4845e-03,
        2.4218e-02, 1.9449e-02, 3.8291e-02, 6.6071e-02, 4.8198e-02, 4.4287e-02,
        2.7073e-03, 3.4054e-02, 2.4666e-03, 1.7523e-02, 5.4220e-02, 1.9596e-02,
        1.6005e-02, 7.5437e-02, 1.3716e-02, 7.6616e-02, 3.9927e-02, 8.5275e-02,
        1.4199e-03, 8.5305e-02, 1.3410e-02, 5.5108e-02, 6.9124e-02, 3.9198e-03,
        8.7610e-02, 1.1889e-01, 0.0000e+00, 6.9587e-02, 7.2079e-02, 6.6092e-02,
        2.5857e-03, 3.1077e-02, 1.6739e-03, 7.9926e-02, 5.3712e-02, 1.3912e-02,
        1.1313e-01, 3.2752e-02, 4.6223e-02, 2.8994e-02, 4.6667e-02, 9.4798e-02,
        7.0677e-02, 1.3081e-03, 1.5979e-02, 2.2960e-02, 8.1893e-02, 2.0550e-02,
        6.6032e-02, 2.8980e-04, 1.7122e-02, 4.4892e-03, 2.1973e-02, 1.5114e-01,
        1.1363e-02, 1.5996e-02, 5.9586e-03, 7.4810e-03, 2.0703e-01, 3.1262e-05,
        3.1499e-02, 7.3751e-02])
net.mlp.net.0.batch_norm.running_var tensor([6.7537e-04, 4.2933e-06, 3.4267e-04, 2.2901e-04, 2.5304e-04, 1.7858e-03,
        1.1413e-03, 3.9861e-03, 2.5662e-04, 2.5525e-03, 7.2528e-03, 3.4346e-03,
        2.2666e-03, 5.5449e-05, 3.5807e-03, 1.9714e-03, 3.2471e-05, 3.0843e-09,
        2.4347e-03, 1.2587e-03, 1.1925e-03, 1.8775e-04, 4.0001e-03, 1.0561e-02,
        4.3592e-05, 2.8807e-03, 1.2319e-05, 5.0204e-03, 1.3758e-03, 1.0440e-03,
        6.4913e-05, 3.2387e-03, 2.3659e-04, 1.2858e-03, 1.3397e-03, 2.0023e-03,
        3.6179e-03, 2.2999e-03, 4.6036e-03, 4.7977e-03, 1.4380e-03, 3.0840e-09,
        2.2396e-03, 1.5567e-02, 6.4309e-03, 4.1955e-03, 2.6744e-03, 5.3625e-04,
        6.3468e-03, 2.5575e-04, 6.2885e-05, 2.1791e-03, 7.4668e-03, 8.1529e-04,
        4.8352e-03, 1.0003e-03, 2.1061e-03, 2.8146e-03, 1.1810e-04, 8.1914e-04,
        1.4711e-03, 6.3166e-03, 2.5476e-03, 2.8175e-03, 2.3500e-04, 1.8707e-03,
        9.1908e-03, 7.4871e-04, 1.8966e-03, 3.4461e-03, 4.6936e-03, 1.2835e-02,
        1.4693e-04, 1.7100e-02, 4.0732e-04, 8.2650e-04, 2.3671e-02, 2.2468e-03,
        7.9353e-04, 4.5878e-03, 5.6061e-04, 5.0599e-03, 2.4606e-03, 5.7298e-03,
        4.1010e-05, 1.1190e-02, 5.6295e-04, 7.3012e-03, 4.4159e-03, 8.2772e-04,
        1.7168e-02, 9.3820e-03, 3.0839e-09, 7.0048e-03, 3.6032e-03, 2.8287e-03,
        3.3655e-04, 5.2875e-03, 2.1402e-05, 1.4690e-02, 3.4771e-03, 1.2712e-03,
        1.4517e-02, 2.0031e-03, 1.1212e-03, 2.0796e-02, 1.8063e-03, 5.0089e-03,
        7.8226e-03, 1.7951e-04, 5.0288e-04, 1.3284e-03, 2.3956e-03, 3.4820e-03,
        3.3295e-03, 2.2755e-06, 5.3332e-03, 7.6180e-04, 1.4102e-03, 7.0114e-03,
        2.1135e-03, 3.6466e-03, 1.2744e-03, 2.5304e-04, 7.8445e-03, 5.1901e-07,
        1.9315e-03, 4.6943e-03])
net.mlp.net.0.batch_norm.num_batches_tracked tensor(186)
net.mlp.net.1.linear.weight tensor([[-2.3588e-02, -1.7291e-02, -2.8180e-02,  ..., -4.2895e-02,
          2.5854e-02,  3.3077e-02],
        [ 1.9291e-02, -4.5077e-02,  3.4363e-02,  ..., -1.1765e-02,
         -5.9965e-03, -3.4772e-03],
        [-1.1436e-02, -5.4680e-02, -7.2390e-03,  ..., -1.3193e-02,
          4.9709e-02, -3.6255e-02],
        ...,
        [-6.9379e-03, -2.9509e-02, -7.8571e-03,  ...,  4.9159e-03,
         -1.8170e-03,  7.2634e-03],
        [ 6.1697e-05,  4.4126e-02, -2.4892e-02,  ..., -1.3455e-02,
          1.5544e-02,  1.5073e-02],
        [ 5.0523e-03,  7.4751e-03, -2.5821e-02,  ..., -1.7964e-03,
          3.7317e-02,  1.9527e-02]])
net.mlp.net.1.linear.bias tensor([ 8.0253e-03,  9.9158e-03,  1.1898e-03,  7.7736e-03,  9.3741e-03,
        -1.1116e-02, -1.4145e-02,  5.7948e-03, -1.1674e-02,  2.6320e-03,
         5.1798e-03, -8.2023e-04,  1.1994e-02,  6.3136e-03, -9.4980e-03,
         8.3476e-03,  1.1232e-02,  1.3517e-02, -3.2060e-03, -1.1232e-03,
         8.6199e-03, -7.2244e-03,  1.1692e-02, -5.4855e-03, -2.3190e-03,
        -3.2757e-03, -1.1295e-03,  1.1889e-02,  1.4514e-02,  1.4287e-02,
        -8.7422e-03, -9.0726e-03, -1.0572e-02, -4.8548e-04, -1.1866e-02,
         4.6961e-03, -1.0928e-02, -9.0514e-03, -1.2748e-02,  1.0881e-03,
         7.0991e-03,  5.8233e-03, -1.0208e-02,  1.1933e-02,  9.4334e-03,
         7.6439e-03, -5.0680e-03, -1.0325e-02,  7.6657e-05, -1.5744e-03,
        -1.1956e-02, -7.1830e-04,  1.4277e-02, -4.7024e-03, -6.9638e-03,
         5.8000e-03,  3.6218e-03, -1.0384e-02,  7.5056e-04,  1.1747e-02,
        -3.6490e-04, -6.2179e-03,  6.5819e-03,  7.0497e-03,  1.2551e-03,
         6.3772e-03, -3.7052e-03,  1.0868e-02, -1.2131e-02,  1.2624e-02,
        -1.0333e-02,  1.1913e-03, -4.3773e-04, -6.4718e-03,  1.7849e-03,
         9.5374e-05, -2.3089e-03,  1.1370e-02,  3.0023e-03, -1.3037e-02,
         8.2041e-03, -1.0469e-02, -8.4589e-03,  5.2409e-04,  4.9647e-03,
        -1.8138e-04, -8.8610e-03, -1.5430e-02,  7.6360e-03, -8.0863e-03,
         1.0988e-02, -7.8342e-04, -1.3500e-03, -9.3899e-03, -9.8814e-03,
         4.3711e-03, -9.6654e-03, -1.1557e-02, -1.0103e-02,  8.8001e-03,
         8.2369e-03, -1.3861e-03,  1.5495e-02, -1.3278e-02,  2.7955e-03,
         9.1195e-03,  6.2173e-04, -7.5796e-03,  3.7466e-03, -5.8535e-03,
        -3.7110e-03, -1.4291e-02,  1.4501e-02, -1.2502e-02,  6.4295e-03,
        -1.0149e-02,  1.4602e-02, -1.0571e-02, -5.8344e-03,  6.5204e-03,
        -6.7908e-03, -1.0864e-02,  1.1514e-02, -1.0360e-02,  2.4522e-03,
        -1.1481e-02, -2.5785e-03, -4.5344e-03])
net.mlp.net.1.batch_norm.weight tensor([0.1639, 0.1636, 0.1629, 0.1661, 0.1648, 0.1641, 0.1638, 0.1642, 0.1644,
        0.1654, 0.1663, 0.1661, 0.1645, 0.1648, 0.1636, 0.1640, 0.1670, 0.1643,
        0.1633, 0.1636, 0.1638, 0.1648, 0.1662, 0.1667, 0.1675, 0.1635, 0.1642,
        0.1655, 0.1635, 0.1640, 0.1661, 0.1644, 0.1634, 0.1646, 0.1644, 0.1634,
        0.1634, 0.1640, 0.1636, 0.1641, 0.1631, 0.1671, 0.1632, 0.1643, 0.1651,
        0.1652, 0.1643, 0.1651, 0.1633, 0.1641, 0.1642, 0.1637, 0.1639, 0.1637,
        0.1645, 0.1650, 0.1641, 0.1660, 0.1643, 0.1641, 0.1634, 0.1648, 0.1667,
        0.1669, 0.1647, 0.1644, 0.1630, 0.1640, 0.1641, 0.1648, 0.1641, 0.1641,
        0.1644, 0.1646, 0.1633, 0.1635, 0.1653, 0.1634, 0.1644, 0.1648, 0.1639,
        0.1642, 0.1642, 0.1650, 0.1668, 0.1638, 0.1662, 0.1655, 0.1641, 0.1636,
        0.1634, 0.1672, 0.1642, 0.1645, 0.1633, 0.1667, 0.1653, 0.1642, 0.1643,
        0.1644, 0.1640, 0.1640, 0.1661, 0.1649, 0.1656, 0.1637, 0.1639, 0.1638,
        0.1663, 0.1638, 0.1657, 0.1648, 0.1659, 0.1648, 0.1644, 0.1630, 0.1647,
        0.1643, 0.1635, 0.1634, 0.1658, 0.1637, 0.1634, 0.1660, 0.1636, 0.1657,
        0.1660, 0.1667])
net.mlp.net.1.batch_norm.bias tensor([ 8.2471e-05,  2.6676e-04, -6.1585e-05,  1.3905e-04, -1.5249e-05,
         6.8572e-04, -8.4501e-05, -2.6860e-04, -2.7751e-04,  1.2665e-04,
         3.7621e-05, -2.3410e-04,  8.5453e-04, -1.9958e-04, -6.8714e-06,
         4.6420e-04, -2.3344e-04, -1.2602e-05,  7.3657e-05, -4.0487e-04,
        -1.3340e-04,  4.7413e-04, -2.5419e-04,  4.3655e-04,  2.2133e-05,
        -2.8435e-04, -2.4013e-04, -3.3146e-05, -1.5512e-04,  2.2639e-04,
        -2.0219e-05,  1.1171e-04, -5.4856e-04,  4.0945e-04, -2.3167e-04,
        -6.3352e-05, -2.2407e-04,  1.0608e-04,  4.2335e-04,  4.2898e-05,
        -2.9379e-04,  5.7922e-04, -3.6790e-05, -4.7645e-04, -1.7036e-04,
        -5.1238e-05,  1.5048e-04,  2.9722e-04, -2.2565e-04,  5.1868e-05,
         2.5049e-04,  2.7837e-04,  3.7344e-04,  2.0378e-04,  1.7405e-04,
        -6.0600e-04, -6.4784e-04, -5.2892e-04, -1.7500e-04, -2.9694e-04,
         6.6616e-04,  2.6702e-04, -7.7208e-04, -9.2591e-04,  5.5960e-04,
        -5.1683e-04,  4.9337e-04, -7.6713e-05, -5.2142e-05, -2.9715e-04,
        -5.8301e-05,  2.3410e-04,  1.2237e-04, -2.2567e-04,  6.0581e-05,
         4.4368e-04,  7.4902e-04, -1.3684e-04, -2.7755e-04,  3.2278e-04,
         2.6309e-04,  3.4775e-04, -6.7435e-05,  6.0560e-04, -4.8010e-04,
         4.9635e-05,  1.8805e-04, -3.2785e-04,  3.8607e-04, -3.7903e-04,
         4.9658e-04, -3.0255e-04,  1.6280e-04, -2.3680e-04,  5.9615e-04,
         7.9480e-04, -1.2067e-04, -5.2614e-05,  6.8792e-05, -1.0867e-04,
         7.8015e-05,  2.4226e-04, -1.2623e-04,  1.5542e-05, -1.7991e-04,
        -2.8497e-04,  6.1258e-04,  6.4571e-04,  2.2664e-04, -2.9140e-04,
        -2.9672e-05, -3.1023e-04,  3.0744e-04, -1.6847e-04,  6.0494e-06,
         4.0192e-04, -4.3523e-05, -1.1907e-04,  3.5864e-04, -2.1759e-04,
        -1.4299e-04, -8.3997e-04, -1.1342e-04,  3.9218e-05, -4.0744e-04,
        -5.1979e-05,  1.0015e-04,  1.5531e-04])
net.mlp.net.1.batch_norm.running_mean tensor([0.0228, 0.0207, 0.0224, 0.0299, 0.0240, 0.0165, 0.0103, 0.0184, 0.0148,
        0.0203, 0.0185, 0.0173, 0.0255, 0.0189, 0.0152, 0.0273, 0.0261, 0.0275,
        0.0167, 0.0180, 0.0239, 0.0169, 0.0227, 0.0127, 0.0150, 0.0160, 0.0197,
        0.0257, 0.0251, 0.0300, 0.0145, 0.0184, 0.0144, 0.0175, 0.0114, 0.0217,
        0.0183, 0.0162, 0.0139, 0.0179, 0.0200, 0.0194, 0.0149, 0.0270, 0.0257,
        0.0227, 0.0193, 0.0165, 0.0197, 0.0168, 0.0152, 0.0185, 0.0279, 0.0178,
        0.0131, 0.0215, 0.0199, 0.0122, 0.0203, 0.0241, 0.0217, 0.0207, 0.0277,
        0.0174, 0.0161, 0.0227, 0.0167, 0.0239, 0.0108, 0.0249, 0.0118, 0.0179,
        0.0196, 0.0154, 0.0183, 0.0198, 0.0175, 0.0210, 0.0194, 0.0184, 0.0216,
        0.0148, 0.0132, 0.0159, 0.0230, 0.0183, 0.0154, 0.0097, 0.0214, 0.0147,
        0.0246, 0.0189, 0.0164, 0.0207, 0.0127, 0.0205, 0.0132, 0.0139, 0.0186,
        0.0338, 0.0223, 0.0171, 0.0300, 0.0147, 0.0200, 0.0217, 0.0164, 0.0139,
        0.0169, 0.0155, 0.0174, 0.0144, 0.0298, 0.0136, 0.0199, 0.0184, 0.0310,
        0.0154, 0.0128, 0.0266, 0.0142, 0.0126, 0.0229, 0.0138, 0.0243, 0.0106,
        0.0146, 0.0192])
net.mlp.net.1.batch_norm.running_var tensor([0.0013, 0.0008, 0.0015, 0.0016, 0.0010, 0.0009, 0.0004, 0.0006, 0.0009,
        0.0011, 0.0009, 0.0009, 0.0012, 0.0008, 0.0009, 0.0010, 0.0016, 0.0016,
        0.0007, 0.0006, 0.0014, 0.0007, 0.0012, 0.0006, 0.0008, 0.0012, 0.0020,
        0.0017, 0.0010, 0.0012, 0.0007, 0.0024, 0.0006, 0.0014, 0.0005, 0.0010,
        0.0011, 0.0008, 0.0012, 0.0007, 0.0008, 0.0012, 0.0010, 0.0015, 0.0009,
        0.0019, 0.0025, 0.0005, 0.0007, 0.0009, 0.0019, 0.0008, 0.0016, 0.0007,
        0.0006, 0.0012, 0.0008, 0.0005, 0.0011, 0.0013, 0.0020, 0.0009, 0.0012,
        0.0005, 0.0009, 0.0008, 0.0010, 0.0008, 0.0004, 0.0015, 0.0006, 0.0007,
        0.0009, 0.0007, 0.0010, 0.0012, 0.0010, 0.0009, 0.0010, 0.0010, 0.0012,
        0.0007, 0.0006, 0.0010, 0.0009, 0.0009, 0.0005, 0.0006, 0.0023, 0.0007,
        0.0012, 0.0007, 0.0006, 0.0013, 0.0010, 0.0011, 0.0007, 0.0008, 0.0010,
        0.0039, 0.0008, 0.0013, 0.0015, 0.0006, 0.0008, 0.0007, 0.0008, 0.0005,
        0.0006, 0.0013, 0.0006, 0.0020, 0.0026, 0.0008, 0.0007, 0.0009, 0.0013,
        0.0018, 0.0009, 0.0014, 0.0012, 0.0005, 0.0012, 0.0005, 0.0010, 0.0010,
        0.0007, 0.0009])
net.mlp.net.1.batch_norm.num_batches_tracked tensor(186)
net.mlp.net.2.weight tensor([[ 0.0011, -0.0091,  0.0097, -0.0077,  0.0003, -0.0031, -0.0108, -0.0009,
          0.0077, -0.0038, -0.0049,  0.0116, -0.0017, -0.0047, -0.0090, -0.0108,
         -0.0029,  0.0003,  0.0106,  0.0118, -0.0042, -0.0051,  0.0009, -0.0026,
         -0.0016, -0.0111, -0.0010, -0.0037,  0.0107,  0.0033, -0.0038, -0.0011,
          0.0097, -0.0043, -0.0052,  0.0123,  0.0101,  0.0055,  0.0090, -0.0098,
         -0.0109,  0.0010,  0.0110, -0.0016, -0.0052, -0.0100,  0.0058,  0.0093,
          0.0090,  0.0003,  0.0039,  0.0059, -0.0111,  0.0056,  0.0072, -0.0073,
         -0.0083, -0.0033,  0.0019, -0.0049, -0.0086,  0.0057, -0.0025, -0.0052,
          0.0110,  0.0107,  0.0084, -0.0067, -0.0003,  0.0045, -0.0099,  0.0072,
          0.0080, -0.0065, -0.0088,  0.0061,  0.0084, -0.0120, -0.0015, -0.0017,
          0.0009, -0.0109, -0.0099, -0.0005,  0.0015, -0.0071,  0.0098, -0.0052,
          0.0070, -0.0070,  0.0009, -0.0020, -0.0019,  0.0114,  0.0120,  0.0029,
         -0.0023, -0.0041, -0.0008, -0.0113,  0.0116, -0.0106, -0.0046, -0.0082,
         -0.0089, -0.0124,  0.0055,  0.0079,  0.0018,  0.0067, -0.0022,  0.0033,
         -0.0029, -0.0109, -0.0089,  0.0120,  0.0026,  0.0069, -0.0015, -0.0045,
          0.0031, -0.0046, -0.0095, -0.0029, -0.0085,  0.0109,  0.0068, -0.0008]])
