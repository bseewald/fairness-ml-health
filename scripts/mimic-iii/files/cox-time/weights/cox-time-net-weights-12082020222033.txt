Weights: 
net.embeddings.embeddings.0.weight tensor([[-0.1831,  0.2086],
        [ 0.0654, -0.2082],
        [-0.0532, -0.0033],
        [ 0.1961,  0.1726]])
net.embeddings.embeddings.1.weight tensor([[-0.0608,  0.1006],
        [ 0.0552, -0.2063],
        [-0.0440, -0.0477],
        [-0.2204,  0.2237],
        [-0.0467,  0.1565]])
net.embeddings.embeddings.2.weight tensor([[ 0.0897,  0.0874, -0.0775],
        [-0.1081, -0.0160, -0.1166],
        [-0.0266, -0.1014, -0.1377],
        [-0.1352,  0.1058, -0.1500],
        [-0.0881,  0.1157,  0.0509],
        [ 0.1278,  0.1070, -0.1529]])
net.embeddings.embeddings.3.weight tensor([[ 0.1039,  0.1163],
        [-0.0518, -0.0675],
        [ 0.0609, -0.1960],
        [ 0.0343, -0.2024]])
net.embeddings.embeddings.4.weight tensor([[-0.1110, -0.0685],
        [ 0.1055, -0.2291],
        [ 0.1794, -0.0380],
        [ 0.2111, -0.1746]])
net.mlp.net.0.linear.weight tensor([[-0.0066,  0.0247, -0.0674,  ..., -0.0857,  0.1711,  0.1252],
        [ 0.2122, -0.0221,  0.0393,  ..., -0.1645, -0.1274,  0.2425],
        [ 0.0519,  0.1310, -0.1301,  ...,  0.1641, -0.0923,  0.0086],
        ...,
        [-0.0291, -0.0632, -0.0947,  ...,  0.1625, -0.0203,  0.0833],
        [ 0.0358, -0.1270,  0.1018,  ..., -0.1151,  0.0777, -0.1162],
        [ 0.2173, -0.0181, -0.1576,  ...,  0.0423,  0.0283, -0.0471]])
net.mlp.net.0.linear.bias tensor([ 0.0154, -0.0331, -0.0534,  0.0414, -0.0369,  0.0060, -0.0584,  0.0013,
        -0.0160,  0.0668, -0.0609, -0.0462, -0.0131,  0.0172,  0.0513, -0.0067,
        -0.0565, -0.0535,  0.0153,  0.0250, -0.0596, -0.0466,  0.0674,  0.0439,
        -0.0280, -0.0381, -0.0632,  0.0331, -0.0670, -0.0746,  0.0226, -0.0635,
        -0.0623, -0.0549, -0.0242, -0.0566,  0.0573, -0.0449,  0.0495,  0.0657,
         0.0528,  0.0271, -0.0576, -0.0251,  0.0028,  0.0153,  0.0168,  0.0509,
         0.0292,  0.0191,  0.0024, -0.0690, -0.0524, -0.0195,  0.0679, -0.0111,
         0.0717, -0.0008,  0.0447, -0.0433, -0.0016,  0.0498, -0.0201, -0.0540,
         0.0555, -0.0042, -0.0046, -0.0270, -0.0337,  0.0584, -0.0742,  0.0661,
        -0.0152,  0.0151,  0.0676, -0.0521, -0.0535, -0.0161, -0.0016, -0.0226,
        -0.0096,  0.0015, -0.0012, -0.0361, -0.0338,  0.0157, -0.0485, -0.0097,
        -0.0571,  0.0551,  0.0029, -0.0345,  0.0235,  0.0291,  0.0465, -0.0142,
        -0.0310,  0.0111,  0.0526,  0.0498,  0.0134,  0.0686, -0.0559,  0.0003,
         0.0100,  0.0306, -0.0621, -0.0429, -0.0458, -0.0727,  0.0651, -0.0024,
        -0.0480, -0.0593,  0.0205, -0.0652, -0.0224,  0.0101,  0.0380,  0.0060,
         0.0212,  0.0424, -0.0404, -0.0200, -0.0481, -0.0566, -0.0365,  0.0714,
        -0.0243,  0.0712,  0.0579,  0.0774,  0.0445,  0.0395,  0.0208, -0.0461,
         0.0592, -0.0593,  0.0736, -0.0717,  0.0251,  0.0115, -0.0552,  0.0441,
         0.0554,  0.0743,  0.0171, -0.0200, -0.0485, -0.0032, -0.0681, -0.0035,
         0.0162,  0.0718, -0.0695,  0.0700, -0.0364, -0.0531,  0.0334,  0.0296,
        -0.0282, -0.0650,  0.0062, -0.0764,  0.0102, -0.0454,  0.0624, -0.0318,
        -0.0480, -0.0361,  0.0695, -0.0553, -0.0449,  0.0040,  0.0587,  0.0468,
         0.0720, -0.0367, -0.0401,  0.0412,  0.0480,  0.0602,  0.0425, -0.0024,
         0.0179,  0.0342,  0.0222, -0.0592,  0.0703,  0.0008, -0.0274,  0.0729,
        -0.0418, -0.0167,  0.0370,  0.0083, -0.0084, -0.0660,  0.0684,  0.0780,
         0.0483, -0.0212,  0.0679,  0.0055,  0.0133, -0.0392,  0.0486,  0.0531,
        -0.0718, -0.0422,  0.0438,  0.0732, -0.0405, -0.0087, -0.0017, -0.0305,
        -0.0166,  0.0197,  0.0369, -0.0089,  0.0762,  0.0281, -0.0596,  0.0570,
         0.0016,  0.0432, -0.0052, -0.0349, -0.0070,  0.0178,  0.0476, -0.0428,
        -0.0480, -0.0719, -0.0309,  0.0643,  0.0513,  0.0064,  0.0561,  0.0258,
        -0.0542, -0.0181,  0.0053, -0.0353, -0.0081,  0.0458,  0.0475, -0.0435,
        -0.0209, -0.0190, -0.0059, -0.0189,  0.0149,  0.0375,  0.0767,  0.0353])
net.mlp.net.0.batch_norm.weight tensor([0.3496, 0.3451, 0.3479, 0.3485, 0.3487, 0.3456, 0.3454, 0.3465, 0.3493,
        0.3502, 0.3477, 0.3462, 0.3452, 0.3453, 0.3477, 0.3486, 0.3463, 0.3474,
        0.3486, 0.3455, 0.3448, 0.3478, 0.3446, 0.3501, 0.3464, 0.3461, 0.3462,
        0.3449, 0.3462, 0.3453, 0.3512, 0.3474, 0.3472, 0.3482, 0.3452, 0.3450,
        0.3445, 0.3513, 0.3458, 0.3456, 0.3500, 0.3506, 0.3465, 0.3462, 0.3489,
        0.3455, 0.3474, 0.3458, 0.3492, 0.3501, 0.3473, 0.3436, 0.3475, 0.3436,
        0.3465, 0.3475, 0.3422, 0.3509, 0.3465, 0.3466, 0.3501, 0.3464, 0.3494,
        0.3486, 0.3471, 0.3439, 0.3444, 0.3433, 0.3484, 0.3477, 0.3420, 0.3469,
        0.3447, 0.3480, 0.3430, 0.3467, 0.3498, 0.3482, 0.3483, 0.3450, 0.3504,
        0.3492, 0.3450, 0.3494, 0.3471, 0.3442, 0.3514, 0.3492, 0.3505, 0.3516,
        0.3433, 0.3470, 0.3439, 0.3461, 0.3465, 0.3496, 0.3449, 0.3424, 0.3463,
        0.3503, 0.3474, 0.3446, 0.3458, 0.3484, 0.3458, 0.3473, 0.3490, 0.3457,
        0.3529, 0.3461, 0.3467, 0.3451, 0.3473, 0.3498, 0.3472, 0.3479, 0.3500,
        0.3486, 0.3448, 0.3485, 0.3443, 0.3449, 0.3463, 0.3505, 0.3499, 0.3465,
        0.3458, 0.3481, 0.3462, 0.3473, 0.3478, 0.3502, 0.3486, 0.3467, 0.3501,
        0.3473, 0.3454, 0.3501, 0.3485, 0.3497, 0.3460, 0.3484, 0.3457, 0.3462,
        0.3493, 0.3495, 0.3479, 0.3455, 0.3460, 0.3439, 0.3454, 0.3437, 0.3471,
        0.3496, 0.3447, 0.3524, 0.3463, 0.3469, 0.3481, 0.3456, 0.3480, 0.3450,
        0.3444, 0.3456, 0.3460, 0.3505, 0.3456, 0.3463, 0.3487, 0.3448, 0.3514,
        0.3485, 0.3453, 0.3474, 0.3456, 0.3519, 0.3433, 0.3478, 0.3482, 0.3471,
        0.3427, 0.3457, 0.3497, 0.3513, 0.3493, 0.3499, 0.3472, 0.3497, 0.3468,
        0.3475, 0.3452, 0.3421, 0.3454, 0.3493, 0.3465, 0.3472, 0.3503, 0.3455,
        0.3479, 0.3441, 0.3456, 0.3456, 0.3481, 0.3446, 0.3476, 0.3474, 0.3485,
        0.3471, 0.3471, 0.3450, 0.3480, 0.3506, 0.3485, 0.3454, 0.3460, 0.3489,
        0.3496, 0.3461, 0.3477, 0.3452, 0.3454, 0.3448, 0.3443, 0.3479, 0.3459,
        0.3478, 0.3510, 0.3430, 0.3513, 0.3493, 0.3522, 0.3465, 0.3476, 0.3434,
        0.3498, 0.3483, 0.3505, 0.3489, 0.3481, 0.3510, 0.3479, 0.3446, 0.3451,
        0.3503, 0.3433, 0.3493, 0.3480, 0.3495, 0.3489, 0.3471, 0.3444, 0.3484,
        0.3464, 0.3517, 0.3440, 0.3462])
net.mlp.net.0.batch_norm.bias tensor([ 6.6924e-04,  2.5035e-03, -1.9202e-03, -4.8695e-04, -1.9074e-03,
        -7.8243e-04, -1.1340e-03, -3.0932e-03, -6.2584e-04, -1.1295e-03,
         1.5175e-03, -1.5404e-03,  1.3349e-03, -1.2841e-03,  2.6508e-03,
        -1.9968e-03,  1.8624e-03, -2.1320e-04, -2.5553e-03,  1.4868e-03,
        -3.6265e-03, -2.3341e-03, -2.9162e-03, -2.9061e-03,  1.8155e-03,
        -1.8129e-03,  1.8895e-03, -2.3520e-03,  9.3220e-04,  1.4183e-03,
         2.8598e-03,  1.9088e-04, -7.9459e-04, -2.0706e-03,  3.1158e-03,
         3.5930e-03,  2.0217e-03,  3.5947e-03,  2.3542e-03,  3.1489e-03,
         2.8946e-03,  1.9835e-03, -3.3791e-03, -2.3217e-03, -1.9092e-03,
        -1.0587e-03, -1.6436e-03,  2.8377e-03, -9.2349e-04,  3.6263e-03,
         1.3303e-03,  4.8055e-03, -1.9646e-03, -8.4053e-04, -1.5204e-04,
         1.9003e-03, -1.0868e-03, -1.3655e-03,  1.6635e-03, -1.7447e-04,
        -1.1477e-03, -7.5950e-05,  1.1155e-03,  3.3336e-03,  5.0417e-04,
        -1.0792e-03,  2.0369e-03,  2.7277e-03,  1.8512e-03, -9.7518e-05,
         4.0934e-04, -1.2019e-03,  5.2056e-04,  1.1884e-03,  3.9737e-03,
         1.1608e-03,  2.0749e-03, -3.9306e-03,  9.9446e-04,  4.2261e-03,
        -6.9387e-04,  1.7302e-03, -3.9719e-04,  1.9091e-03, -1.0439e-04,
        -2.2608e-05, -2.0220e-03,  1.4732e-03,  1.9860e-03,  1.0521e-03,
        -1.3317e-03,  1.1319e-03, -2.5346e-03, -1.0388e-04,  1.2377e-03,
         1.6176e-03,  4.5339e-03, -2.8192e-03,  2.4304e-03, -1.0682e-03,
        -1.0881e-03, -2.8653e-03, -5.1477e-03, -3.4496e-03,  2.7720e-03,
         1.6400e-03,  2.5534e-03,  5.1236e-03, -2.8884e-03, -4.6867e-04,
        -2.6337e-03,  2.6164e-03, -8.6621e-04,  2.4408e-03,  3.1313e-03,
         2.2063e-03,  1.3260e-03, -2.4726e-03, -1.8065e-03,  4.1051e-03,
         2.0982e-04, -1.4381e-03,  1.7421e-03,  1.9430e-03, -2.8427e-03,
         6.3550e-04,  1.1991e-04,  2.8416e-03,  1.2137e-03, -2.6427e-03,
        -7.3112e-04, -3.8821e-04,  3.5341e-03, -1.2026e-03,  6.5130e-04,
         1.9187e-03, -1.8515e-03,  1.0635e-03, -2.2048e-03, -2.3251e-03,
        -6.0854e-05,  6.2242e-04,  1.1057e-03,  3.1208e-03,  2.3778e-04,
        -1.9583e-03, -2.8263e-03, -6.7962e-04,  4.8086e-05, -4.9544e-03,
         3.5809e-03, -2.4884e-03, -2.9407e-03,  9.9890e-05, -2.2942e-04,
        -1.7162e-04, -9.8900e-04,  1.9540e-05, -9.1318e-04,  2.9858e-03,
        -3.7633e-04,  1.0915e-03,  6.3766e-04, -1.6712e-03,  1.7423e-03,
         2.4872e-03, -1.9968e-04, -2.2691e-04,  2.7716e-03, -3.5736e-04,
        -1.2287e-04,  1.8195e-03,  1.6619e-03, -2.1666e-03, -1.6904e-03,
         2.8614e-03, -3.7227e-03, -1.1353e-04,  1.1100e-04, -2.3485e-03,
        -4.6830e-04,  1.2014e-03,  4.4348e-03, -1.2755e-03, -1.3575e-03,
         9.5825e-05, -2.5243e-03, -6.9282e-06,  1.9361e-03, -1.6386e-03,
        -2.5139e-03, -1.5218e-03, -2.4310e-03, -2.6136e-03, -4.1915e-03,
         8.3671e-04, -1.1801e-03,  2.3916e-03, -1.5030e-03, -2.4040e-03,
        -2.8668e-03, -4.2241e-03, -2.9975e-03, -3.6399e-03,  1.4911e-03,
        -2.4273e-03, -2.9225e-03, -7.5659e-04, -2.4110e-03,  3.2283e-03,
        -9.4287e-04, -1.7456e-03, -1.7237e-03,  4.3244e-03,  1.4282e-03,
         3.3272e-03, -1.0442e-03,  1.3793e-03, -1.4435e-03, -2.4840e-03,
        -5.6163e-04, -2.1030e-03,  2.9180e-03,  4.5871e-04,  1.4289e-03,
         7.3102e-04,  1.9854e-03,  4.6708e-03, -5.5981e-04, -1.8412e-03,
         2.6785e-03, -3.4032e-03,  3.0559e-03, -1.7059e-03, -2.6678e-03,
        -4.7456e-04, -4.5167e-03,  3.4140e-04,  3.2778e-03, -1.8692e-03,
         3.2022e-03,  2.1022e-03,  3.6878e-03,  1.8131e-03, -2.8372e-03,
        -2.9192e-03, -2.1245e-03, -1.7668e-03,  2.1136e-03, -2.2599e-04,
         2.3396e-03,  6.2288e-04,  3.1005e-04, -3.6209e-03, -3.6885e-03,
        -4.9969e-03])
net.mlp.net.0.batch_norm.running_mean tensor([2.1968e-03, 3.7166e-02, 9.0051e-02, 1.6028e-01, 7.8846e-02, 6.0972e-02,
        1.1682e-01, 3.5407e-02, 8.9584e-02, 2.8007e-01, 1.1906e-01, 2.4025e-01,
        1.0484e-01, 4.0937e-02, 4.1503e-02, 2.0080e-01, 5.9546e-02, 1.3219e-02,
        8.7454e-02, 4.2093e-03, 2.9392e-02, 4.0440e-02, 1.3261e-01, 1.3051e-02,
        4.9607e-01, 3.7020e-02, 3.7251e-01, 1.9454e-01, 1.8773e-03, 5.2526e-06,
        2.3151e-01, 3.3082e-01, 9.1090e-02, 1.3198e-02, 1.6351e-01, 9.2352e-02,
        4.4901e-01, 1.0166e-01, 5.6645e-02, 3.6499e-02, 2.5143e-01, 3.9804e-02,
        9.8876e-05, 1.5861e-02, 1.0007e-02, 1.2071e-04, 1.2002e-03, 1.4558e-01,
        6.3548e-02, 5.5647e-02, 9.2621e-02, 1.5644e-01, 2.8580e-02, 2.4277e-01,
        1.8351e-01, 2.8356e-01, 4.5085e-01, 3.6248e-02, 6.8455e-02, 2.0153e-01,
        2.6460e-02, 1.9519e-01, 2.2692e-01, 9.2685e-02, 1.0414e-02, 1.0195e-01,
        1.6193e-03, 1.2951e-02, 1.1657e-01, 1.0470e-02, 1.7885e-01, 1.0033e-01,
        5.1530e-02, 4.7248e-01, 5.5224e-02, 8.9443e-03, 4.5210e-03, 9.7184e-03,
        2.6220e-02, 7.4151e-02, 3.7146e-02, 2.6946e-02, 2.5249e-01, 2.1094e-01,
        9.8400e-02, 5.6315e-01, 1.3669e-02, 3.8616e-02, 1.4002e-01, 4.5386e-02,
        4.3847e-01, 1.9841e-02, 9.5111e-02, 1.4300e-03, 1.9228e-01, 1.5058e-01,
        1.6158e-01, 1.1213e-01, 2.4666e-01, 1.7652e-01, 6.2075e-02, 1.7834e-02,
        9.0191e-04, 7.9770e-02, 2.3913e-01, 1.4374e-01, 4.5062e-04, 2.5329e-01,
        1.1744e-01, 2.3020e-03, 2.3499e-02, 1.5108e-01, 6.5608e-02, 1.3718e-01,
        1.9960e-02, 1.3229e-01, 9.3747e-02, 4.4236e-02, 1.9242e-01, 1.3982e-01,
        2.1397e-02, 1.4305e-02, 2.5620e-02, 2.5091e-01, 8.8519e-02, 6.0510e-03,
        1.5263e-01, 2.4078e-02, 3.2809e-02, 1.4365e-01, 8.4575e-02, 6.9120e-02,
        6.8495e-02, 5.1293e-05, 1.5735e-01, 1.2375e-01, 8.9047e-04, 6.1771e-02,
        3.5762e-01, 1.1727e-01, 3.6880e-02, 4.6265e-02, 5.5106e-03, 1.0843e-03,
        2.3294e-01, 2.1852e-01, 4.7896e-01, 3.7149e-02, 1.4626e-02, 1.2019e-01,
        5.4183e-02, 1.9336e-02, 5.4546e-01, 4.0861e-02, 9.4558e-02, 9.1364e-02,
        7.8232e-04, 2.7881e-02, 1.8267e-02, 1.3743e-04, 3.6259e-05, 2.9036e-03,
        1.7607e-01, 5.4435e-03, 1.6080e-01, 2.7110e-02, 1.9181e-01, 1.0758e-02,
        4.5748e-02, 1.2467e-01, 1.3479e-01, 2.1561e-02, 2.5584e-01, 4.0237e-03,
        1.4659e-01, 4.7112e-01, 1.8148e-02, 9.8011e-02, 1.8273e-02, 1.9164e-01,
        4.8980e-02, 7.7847e-02, 1.5386e-01, 1.1732e-02, 1.3740e-01, 1.6338e-01,
        4.3113e-02, 1.6647e-04, 5.3209e-02, 7.6777e-02, 3.6565e-03, 1.6648e-01,
        8.4001e-02, 5.1232e-03, 2.3222e-01, 9.1108e-02, 9.0905e-02, 2.8623e-02,
        3.4726e-01, 2.5415e-01, 1.3476e-01, 3.0131e-02, 2.0402e-01, 9.6807e-02,
        3.9563e-02, 2.5239e-01, 2.7063e-01, 4.6258e-02, 1.5335e-01, 5.0292e-02,
        2.8412e-03, 1.3846e-01, 1.8133e-01, 1.7762e-02, 1.1415e-01, 1.0387e-01,
        4.3616e-03, 9.8669e-02, 2.2499e-01, 3.5388e-02, 3.3983e-02, 2.3619e-01,
        7.4963e-03, 3.8998e-02, 1.1660e-01, 1.6055e-02, 3.0813e-02, 4.4146e-03,
        4.7350e-02, 1.6768e-01, 5.1801e-01, 1.3376e-01, 9.1362e-03, 5.1612e-02,
        1.6266e-02, 2.5734e-03, 5.9706e-02, 1.5915e-01, 2.7066e-01, 3.8741e-01,
        3.3977e-02, 4.6698e-04, 2.1732e-02, 1.6646e-01, 7.6455e-02, 1.3487e-01,
        4.8626e-02, 4.4601e-02, 3.3114e-03, 2.6273e-03, 4.7848e-03, 2.3645e-02,
        3.4337e-02, 3.6998e-02, 3.9189e-01, 1.0226e-01])
net.mlp.net.0.batch_norm.running_var tensor([0.1098, 0.1185, 0.1219, 0.1424, 0.1259, 0.1145, 0.1727, 0.1218, 0.1295,
        0.2489, 0.1301, 0.1382, 0.1832, 0.1152, 0.1151, 0.1540, 0.1193, 0.1113,
        0.1252, 0.1099, 0.1136, 0.1272, 0.1261, 0.1153, 0.1725, 0.1135, 0.1396,
        0.2469, 0.1097, 0.1094, 0.1488, 0.1704, 0.1185, 0.1177, 0.1282, 0.1726,
        0.1970, 0.1253, 0.1154, 0.1133, 0.1633, 0.1150, 0.1094, 0.1117, 0.1116,
        0.1094, 0.1097, 0.1434, 0.1251, 0.1161, 0.1367, 0.1592, 0.1137, 0.1638,
        0.2542, 0.1245, 0.1567, 0.1152, 0.1299, 0.1393, 0.1133, 0.4157, 0.1583,
        0.1238, 0.1135, 0.1202, 0.1097, 0.1171, 0.1513, 0.1104, 0.1328, 0.1926,
        0.1475, 0.1734, 0.1257, 0.1104, 0.1102, 0.1102, 0.1120, 0.1680, 0.1140,
        0.1294, 0.1846, 0.1500, 0.1236, 0.1614, 0.1124, 0.1143, 0.1190, 0.1130,
        0.1586, 0.1125, 0.1253, 0.1096, 0.1229, 0.1195, 0.1342, 0.1262, 0.1416,
        0.1303, 0.1271, 0.1121, 0.1096, 0.1472, 0.1591, 0.1351, 0.1095, 0.1460,
        0.1331, 0.1096, 0.1118, 0.1434, 0.1160, 0.1296, 0.1137, 0.1482, 0.1522,
        0.1171, 0.1522, 0.1197, 0.1120, 0.1117, 0.1138, 0.1252, 0.1296, 0.1101,
        0.2286, 0.1152, 0.1390, 0.1554, 0.1218, 0.1602, 0.1399, 0.1094, 0.1232,
        0.1306, 0.1096, 0.1241, 0.1557, 0.1199, 0.1197, 0.1174, 0.1102, 0.1095,
        0.1469, 0.1313, 0.1578, 0.1256, 0.1113, 0.1193, 0.1419, 0.1117, 0.1594,
        0.1296, 0.1254, 0.1200, 0.1095, 0.1208, 0.1122, 0.1094, 0.1094, 0.1096,
        0.1347, 0.1102, 0.1465, 0.1329, 0.1314, 0.1112, 0.1414, 0.1872, 0.1845,
        0.1137, 0.1529, 0.1100, 0.1360, 0.1317, 0.1123, 0.1289, 0.1125, 0.1319,
        0.1212, 0.1223, 0.1235, 0.1126, 0.1739, 0.1240, 0.1203, 0.1094, 0.1299,
        0.1434, 0.1099, 0.1336, 0.1293, 0.1103, 0.1393, 0.1641, 0.1299, 0.1362,
        0.1494, 0.1307, 0.1334, 0.1127, 0.1218, 0.1155, 0.1272, 0.2349, 0.1532,
        0.1244, 0.1415, 0.1176, 0.1102, 0.1452, 0.1380, 0.1159, 0.1303, 0.1253,
        0.1097, 0.1318, 0.1452, 0.1127, 0.1172, 0.1485, 0.1110, 0.1437, 0.1277,
        0.1117, 0.1173, 0.1099, 0.1150, 0.1279, 0.1525, 0.1803, 0.1100, 0.1179,
        0.1105, 0.1098, 0.1178, 0.1337, 0.1522, 0.2976, 0.1285, 0.1095, 0.1124,
        0.1452, 0.1270, 0.1257, 0.1156, 0.1175, 0.1111, 0.1098, 0.1100, 0.1124,
        0.1442, 0.1133, 0.1588, 0.1350])
net.mlp.net.0.batch_norm.num_batches_tracked tensor(21)
net.mlp.net.1.linear.weight tensor([[-0.0141,  0.0335, -0.0108,  ..., -0.0343, -0.0074, -0.0306],
        [-0.0280, -0.0138, -0.0044,  ...,  0.0054,  0.0173,  0.0120],
        [ 0.0083, -0.0286, -0.0124,  ..., -0.0020, -0.0053,  0.0844],
        ...,
        [ 0.0494, -0.0403, -0.0598,  ...,  0.0054,  0.0760, -0.0310],
        [-0.0526, -0.0084,  0.0523,  ...,  0.0289, -0.0468,  0.0192],
        [ 0.0210,  0.0712, -0.0780,  ..., -0.0529,  0.0226, -0.0072]])
net.mlp.net.1.linear.bias tensor([-1.3772e-02, -2.2192e-02, -2.3143e-02,  3.1069e-03, -9.8655e-03,
         1.1349e-02, -1.2214e-04, -5.5362e-03,  1.0250e-03, -2.0453e-02,
        -6.4246e-03, -1.6068e-02,  6.9537e-03,  1.1415e-02,  9.1984e-03,
        -1.6062e-02,  8.6059e-03, -6.2541e-03,  1.2143e-02, -5.8384e-03,
        -1.6095e-02, -1.5228e-02,  1.2742e-02,  2.2853e-02,  2.3624e-03,
        -4.3736e-03,  1.6207e-02, -1.5535e-02, -1.4812e-02, -7.5866e-03,
        -3.8806e-03, -2.0144e-02,  1.8048e-02, -1.0104e-02, -1.7484e-02,
         9.2900e-03,  1.7847e-02,  1.3584e-02, -5.8865e-04, -3.3703e-03,
        -1.5823e-02, -1.7792e-02, -6.6358e-03, -9.0399e-03,  1.4444e-03,
        -1.6111e-02, -1.0251e-02,  1.9402e-03, -1.4417e-02,  6.3406e-03,
        -2.9279e-03,  8.7072e-04, -1.6119e-02, -8.8768e-03,  5.3047e-03,
         3.3024e-04, -1.7338e-02,  6.3401e-03, -1.6685e-02,  9.6609e-03,
         1.3103e-02,  9.6861e-03, -1.6683e-02,  6.7473e-03, -7.7672e-03,
         1.8123e-02,  1.2505e-02,  2.4850e-03, -1.7503e-02,  1.1682e-02,
         1.3967e-02, -1.9675e-02,  1.8275e-02, -3.1863e-03,  1.2942e-02,
        -1.7370e-02,  5.2689e-03, -3.5765e-03, -3.8378e-03,  4.0096e-03,
        -3.8742e-03,  1.5779e-02, -1.3632e-02,  4.2855e-03, -6.2964e-03,
         1.6901e-02,  1.6845e-02, -1.8244e-02,  1.9977e-02,  8.1138e-03,
         1.7746e-02,  1.1667e-02,  3.1136e-03, -1.1512e-02,  1.6202e-02,
         2.4029e-03,  1.7263e-02, -7.4909e-03,  1.0947e-02, -2.2465e-02,
         3.6470e-03,  1.0374e-02,  3.8425e-03,  2.4258e-02, -1.1462e-02,
         5.7548e-03, -2.1314e-02, -9.1305e-04,  1.3531e-02, -9.9450e-03,
         1.4771e-02, -7.8627e-03, -1.4644e-02, -1.2645e-02,  1.6226e-02,
        -6.4401e-03,  2.2554e-02,  2.0704e-02,  1.3847e-02,  7.9578e-03,
        -8.1745e-03, -6.7347e-03,  2.4053e-03,  4.2651e-03, -7.3004e-03,
         2.2506e-03,  9.8438e-03,  2.6414e-04, -6.6137e-03, -1.3933e-02,
         1.1490e-02, -1.2783e-02,  2.5373e-03, -2.1130e-02, -1.6093e-02,
        -9.5105e-04,  1.7679e-02,  1.8811e-02, -1.1319e-02, -3.9703e-03,
        -1.9485e-02,  1.1609e-02, -1.6571e-02, -1.5115e-04,  1.7058e-02,
         2.0053e-02,  5.9907e-05,  1.2438e-02,  1.0422e-02, -7.8075e-04,
         7.7912e-05,  1.8208e-04,  1.4079e-02,  1.7873e-02,  7.5481e-03,
         2.3791e-03,  2.2312e-03, -2.2126e-02, -6.6269e-03, -1.3930e-02,
        -5.2726e-03,  1.0666e-02, -4.2392e-04,  2.6644e-03,  1.8305e-02,
        -1.1105e-02,  1.2909e-02,  1.4120e-02,  1.6704e-02,  9.0975e-03,
        -1.8668e-02, -1.2474e-02, -5.8956e-03, -1.1231e-02,  1.6627e-02,
        -2.4332e-03,  1.6107e-02,  1.8128e-03,  2.1153e-02,  1.1528e-02,
         7.9993e-03, -1.2977e-02,  3.9667e-03, -1.1077e-02,  2.0184e-02,
         1.0384e-03, -1.9490e-02,  5.4212e-03,  9.7187e-04, -1.3156e-02,
        -1.7189e-03, -1.7759e-02, -9.6322e-03,  1.7746e-02,  1.8496e-03,
         4.0107e-03,  1.0932e-02, -1.7893e-03,  1.2692e-02,  9.4998e-03,
        -2.2080e-02,  1.3549e-02, -9.3402e-03, -1.8523e-02, -2.4505e-03,
         4.9885e-03, -1.5284e-02, -6.5906e-03,  4.0992e-03, -1.7761e-02,
         1.4866e-02, -1.1873e-03, -4.5976e-03,  3.9046e-03,  5.8464e-03,
        -2.2807e-03,  9.8178e-03,  1.5468e-02,  2.4884e-04,  7.9712e-03,
         5.0161e-03, -1.0701e-02, -4.7217e-03,  1.3968e-02,  1.2277e-02,
         7.5827e-03, -1.4278e-02, -2.6881e-03, -2.0831e-03,  1.3784e-02,
         2.0385e-02, -7.3135e-03,  1.1024e-02, -1.5665e-02, -1.8889e-02,
        -2.0596e-02,  1.3575e-02, -1.6814e-02, -1.5020e-02, -8.8708e-04,
         2.9367e-03,  1.5767e-02, -1.9777e-03, -3.4079e-03, -1.2682e-02,
         2.8277e-03,  1.5260e-02,  1.4504e-02, -2.4553e-02,  2.0783e-02,
        -4.1333e-03,  2.4958e-03,  1.6654e-02, -2.0631e-03,  1.1869e-02,
        -1.5455e-02])
net.mlp.net.1.batch_norm.weight tensor([0.3476, 0.3484, 0.3449, 0.3452, 0.3492, 0.3453, 0.3507, 0.3454, 0.3499,
        0.3475, 0.3494, 0.3439, 0.3455, 0.3442, 0.3483, 0.3443, 0.3483, 0.3475,
        0.3529, 0.3441, 0.3486, 0.3477, 0.3483, 0.3472, 0.3494, 0.3505, 0.3452,
        0.3498, 0.3454, 0.3467, 0.3493, 0.3441, 0.3469, 0.3502, 0.3458, 0.3446,
        0.3423, 0.3494, 0.3462, 0.3498, 0.3491, 0.3457, 0.3457, 0.3440, 0.3475,
        0.3504, 0.3447, 0.3485, 0.3441, 0.3478, 0.3504, 0.3498, 0.3496, 0.3416,
        0.3432, 0.3481, 0.3457, 0.3443, 0.3464, 0.3488, 0.3470, 0.3480, 0.3448,
        0.3434, 0.3476, 0.3440, 0.3484, 0.3427, 0.3508, 0.3438, 0.3447, 0.3454,
        0.3514, 0.3437, 0.3517, 0.3453, 0.3426, 0.3449, 0.3517, 0.3486, 0.3472,
        0.3510, 0.3500, 0.3467, 0.3515, 0.3452, 0.3495, 0.3507, 0.3452, 0.3464,
        0.3437, 0.3442, 0.3496, 0.3490, 0.3460, 0.3498, 0.3462, 0.3482, 0.3508,
        0.3503, 0.3459, 0.3485, 0.3476, 0.3449, 0.3485, 0.3512, 0.3472, 0.3514,
        0.3454, 0.3446, 0.3457, 0.3457, 0.3476, 0.3439, 0.3467, 0.3462, 0.3479,
        0.3493, 0.3458, 0.3466, 0.3458, 0.3493, 0.3475, 0.3500, 0.3432, 0.3489,
        0.3447, 0.3477, 0.3463, 0.3433, 0.3517, 0.3501, 0.3486, 0.3494, 0.3440,
        0.3455, 0.3464, 0.3488, 0.3456, 0.3406, 0.3492, 0.3473, 0.3443, 0.3460,
        0.3459, 0.3504, 0.3452, 0.3432, 0.3475, 0.3438, 0.3435, 0.3474, 0.3485,
        0.3483, 0.3513, 0.3494, 0.3436, 0.3504, 0.3456, 0.3466, 0.3466, 0.3472,
        0.3483, 0.3488, 0.3441, 0.3477, 0.3444, 0.3514, 0.3453, 0.3446, 0.3489,
        0.3502, 0.3490, 0.3469, 0.3471, 0.3478, 0.3453, 0.3472, 0.3462, 0.3509,
        0.3461, 0.3468, 0.3522, 0.3482, 0.3510, 0.3477, 0.3463, 0.3446, 0.3450,
        0.3525, 0.3450, 0.3446, 0.3453, 0.3468, 0.3437, 0.3455, 0.3465, 0.3455,
        0.3468, 0.3501, 0.3469, 0.3449, 0.3489, 0.3482, 0.3470, 0.3417, 0.3463,
        0.3440, 0.3466, 0.3418, 0.3495, 0.3492, 0.3500, 0.3449, 0.3488, 0.3498,
        0.3446, 0.3485, 0.3461, 0.3502, 0.3443, 0.3433, 0.3481, 0.3479, 0.3489,
        0.3464, 0.3470, 0.3442, 0.3471, 0.3437, 0.3477, 0.3477, 0.3504, 0.3465,
        0.3462, 0.3453, 0.3486, 0.3487, 0.3488, 0.3509, 0.3486, 0.3485, 0.3466,
        0.3471, 0.3458, 0.3428, 0.3446, 0.3487, 0.3502, 0.3507, 0.3452, 0.3477,
        0.3495, 0.3465, 0.3484, 0.3480])
net.mlp.net.1.batch_norm.bias tensor([-3.8150e-03, -4.0273e-03,  3.7053e-04,  2.2769e-03,  3.4788e-03,
        -1.0917e-03, -4.2852e-04, -1.5828e-03, -7.8691e-04,  8.8128e-04,
         6.1267e-03,  2.1936e-03,  2.4445e-03,  3.4102e-04, -1.7910e-03,
         3.7665e-03, -8.1334e-04,  1.5946e-03, -9.3884e-04, -2.5939e-03,
        -4.2268e-03,  3.6067e-03, -4.2123e-04, -3.9620e-03,  5.7315e-04,
        -1.2395e-03,  1.5036e-03,  4.0018e-03,  3.0192e-03,  1.6374e-03,
        -2.9445e-03,  5.0082e-04,  9.5039e-04,  3.1377e-04,  4.7664e-03,
        -4.6694e-04, -2.4348e-03,  2.4458e-03,  1.7900e-03,  1.5242e-03,
        -3.0331e-03,  2.3545e-03,  2.4811e-04,  5.6015e-04, -1.5564e-03,
         4.4520e-03,  6.1926e-04,  1.7837e-03,  8.6493e-04, -5.5261e-03,
        -1.1482e-03, -7.1043e-04, -2.5762e-03,  1.3898e-04, -3.1482e-03,
         1.6773e-03,  9.8936e-04, -3.4059e-03, -3.4894e-03,  3.8499e-03,
         3.2266e-03,  7.1155e-04, -2.7030e-03,  3.6819e-03, -2.4639e-03,
        -2.1600e-03,  6.8782e-04,  7.6808e-05, -1.3857e-03, -8.5719e-04,
         1.9150e-03,  8.1999e-04,  7.6564e-04, -6.9560e-04, -4.8302e-04,
        -2.0350e-03, -1.8923e-03,  4.9756e-04, -8.6433e-04, -2.7818e-03,
        -2.2084e-03, -2.2963e-03,  1.7900e-03,  2.6779e-03,  1.0776e-03,
        -4.8448e-04, -5.5863e-04, -4.9335e-04, -1.2616e-03, -1.8631e-03,
        -4.2712e-03,  7.8317e-04,  1.3217e-04,  1.9299e-03, -2.1959e-03,
        -6.9942e-04, -2.3082e-03,  1.2624e-03,  1.2185e-03,  9.0219e-04,
         2.1451e-03, -3.9759e-03,  2.5586e-03,  9.9459e-04, -1.6281e-03,
        -2.1155e-03,  1.8689e-04, -2.3084e-03, -3.0162e-03,  1.5747e-03,
        -1.3013e-03, -3.6856e-03, -1.0605e-03,  6.5590e-04, -4.9409e-04,
        -3.4225e-04,  2.3700e-03,  2.5416e-03,  1.7944e-05,  1.0631e-03,
         1.1157e-03, -3.2967e-03, -2.7094e-03, -1.4332e-03,  7.0218e-04,
         1.4468e-04, -3.6606e-03,  1.2356e-03,  4.8365e-04, -1.8800e-03,
         1.3968e-03,  3.1064e-03,  4.2671e-03, -4.4615e-04,  4.5405e-03,
         1.3281e-03, -7.5066e-04, -1.3296e-03, -2.0895e-03,  2.0537e-03,
        -2.3478e-03, -2.3571e-03,  5.1129e-04, -1.2876e-03,  1.0880e-05,
        -4.6545e-03, -1.6782e-03,  1.2576e-03,  1.0448e-03,  1.5997e-04,
         1.4230e-03, -4.7309e-03,  2.9236e-03,  1.4826e-03,  1.3080e-03,
         2.1200e-03, -1.0509e-03,  2.3722e-03, -2.6770e-03,  1.5229e-03,
        -2.2514e-03,  9.4644e-04,  1.5050e-04, -2.7581e-03,  4.6330e-04,
         1.5843e-03, -4.6613e-03, -2.2659e-03,  3.0103e-03, -2.1916e-04,
        -9.7667e-05,  4.3434e-04,  2.7666e-03, -1.1242e-03,  1.1337e-03,
         2.4662e-03,  3.0093e-03, -3.4370e-05, -2.1575e-04,  5.9874e-04,
         2.7174e-03, -1.5391e-03,  3.3660e-04,  1.6425e-03,  9.3350e-04,
         2.2787e-03,  2.4013e-03,  8.1376e-04, -2.0723e-04,  3.9568e-04,
         1.5121e-03,  2.2461e-03,  1.9170e-03,  1.5638e-03, -2.4672e-03,
        -1.1309e-03,  1.6734e-03,  2.5395e-03, -2.5829e-03, -1.6850e-03,
         8.2509e-04, -2.4562e-03, -5.2067e-04, -1.4253e-03, -1.4425e-03,
         1.7549e-03, -5.8356e-04, -1.6625e-03,  9.5969e-04,  4.0483e-03,
         3.0777e-03,  3.4004e-03,  2.4238e-03,  4.1550e-03,  2.0281e-03,
         4.0916e-04, -2.2777e-03, -1.4785e-03,  8.0364e-04,  3.2410e-03,
         3.6433e-03,  2.0375e-03, -3.7597e-03,  6.5028e-04, -3.5441e-03,
        -1.8962e-03, -2.4894e-03, -2.4482e-03,  1.9198e-03,  4.7330e-03,
         4.1796e-03,  3.0239e-03,  2.2966e-03, -2.6814e-03,  2.8220e-03,
         3.5240e-03,  5.1575e-03, -1.0142e-03,  2.6988e-03,  4.0980e-03,
         1.9390e-03,  5.2313e-05,  1.3776e-03,  1.5968e-03, -5.4163e-05,
         3.2728e-04,  6.6795e-04,  1.1258e-03,  1.4657e-03,  9.6042e-04,
        -1.4633e-03,  3.8953e-03, -1.0578e-03,  2.0034e-03, -6.7796e-04,
         2.0456e-03])
net.mlp.net.1.batch_norm.running_mean tensor([0.1037, 0.1154, 0.1046, 0.2116, 0.1658, 0.0902, 0.0840, 0.1317, 0.1046,
        0.0736, 0.0664, 0.0914, 0.1536, 0.1067, 0.1146, 0.1123, 0.0808, 0.1268,
        0.1082, 0.0708, 0.1205, 0.0809, 0.0951, 0.1208, 0.0983, 0.0953, 0.1189,
        0.0926, 0.0867, 0.1253, 0.0910, 0.1010, 0.1017, 0.0988, 0.1108, 0.1159,
        0.0972, 0.0984, 0.1048, 0.0987, 0.0832, 0.0902, 0.1060, 0.1270, 0.0839,
        0.0724, 0.1040, 0.1175, 0.1062, 0.1001, 0.0995, 0.0843, 0.0728, 0.1125,
        0.0858, 0.1082, 0.0926, 0.0836, 0.0754, 0.0852, 0.1193, 0.1378, 0.0742,
        0.1041, 0.0943, 0.1133, 0.1642, 0.1059, 0.1020, 0.1475, 0.1138, 0.1012,
        0.1035, 0.1159, 0.1132, 0.0757, 0.1042, 0.0862, 0.0649, 0.1072, 0.1293,
        0.1194, 0.0889, 0.0934, 0.1644, 0.1392, 0.1510, 0.1021, 0.1275, 0.1083,
        0.0901, 0.1366, 0.0947, 0.1159, 0.1188, 0.0884, 0.1718, 0.1134, 0.0893,
        0.1139, 0.1366, 0.1134, 0.1048, 0.1138, 0.0971, 0.0991, 0.1490, 0.1597,
        0.0901, 0.1091, 0.1310, 0.0918, 0.1009, 0.0686, 0.0859, 0.1375, 0.0870,
        0.1089, 0.1100, 0.0904, 0.1014, 0.1039, 0.1032, 0.1376, 0.1106, 0.1048,
        0.0942, 0.0824, 0.1442, 0.1384, 0.1124, 0.0883, 0.1517, 0.0890, 0.0945,
        0.0838, 0.1320, 0.1099, 0.0994, 0.0961, 0.0821, 0.0807, 0.0887, 0.1034,
        0.1319, 0.1073, 0.1075, 0.1069, 0.1129, 0.1654, 0.0928, 0.1097, 0.1223,
        0.0913, 0.0806, 0.0713, 0.1134, 0.1026, 0.1123, 0.0913, 0.1027, 0.1174,
        0.0794, 0.1137, 0.1051, 0.0676, 0.1129, 0.0999, 0.1064, 0.1136, 0.1021,
        0.1366, 0.0859, 0.0910, 0.1292, 0.0991, 0.0975, 0.1039, 0.1332, 0.1226,
        0.1158, 0.0807, 0.0860, 0.1229, 0.1380, 0.1030, 0.0872, 0.1209, 0.1432,
        0.0876, 0.0856, 0.0904, 0.1414, 0.1601, 0.0773, 0.1275, 0.1437, 0.0810,
        0.0803, 0.0752, 0.0895, 0.0908, 0.1053, 0.1210, 0.1037, 0.0912, 0.0814,
        0.0986, 0.0934, 0.0810, 0.1214, 0.1118, 0.0938, 0.0948, 0.1292, 0.0975,
        0.0967, 0.0907, 0.0959, 0.0876, 0.1137, 0.0964, 0.1000, 0.1154, 0.0805,
        0.1011, 0.1048, 0.0977, 0.1103, 0.1289, 0.1027, 0.1087, 0.1182, 0.0958,
        0.1106, 0.1005, 0.1148, 0.1024, 0.0819, 0.0911, 0.1113, 0.0995, 0.0997,
        0.1025, 0.0962, 0.0837, 0.0904, 0.1274, 0.0863, 0.1006, 0.0861, 0.0930,
        0.1010, 0.0833, 0.1200, 0.1363])
net.mlp.net.1.batch_norm.running_var tensor([0.2044, 0.1602, 0.1844, 0.2480, 0.1875, 0.1540, 0.1470, 0.1614, 0.1502,
        0.1330, 0.1284, 0.1596, 0.1774, 0.1477, 0.1534, 0.1533, 0.1314, 0.1623,
        0.1404, 0.1401, 0.1882, 0.1408, 0.1397, 0.1443, 0.1483, 0.1363, 0.1948,
        0.1732, 0.1678, 0.1603, 0.2213, 0.1553, 0.1457, 0.1987, 0.1482, 0.1579,
        0.1345, 0.1503, 0.1567, 0.1412, 0.1439, 0.1566, 0.1712, 0.1750, 0.1476,
        0.1300, 0.2512, 0.1544, 0.1610, 0.1454, 0.1548, 0.1348, 0.1448, 0.1742,
        0.1440, 0.2047, 0.1417, 0.1446, 0.1473, 0.1292, 0.1524, 0.1681, 0.1291,
        0.1325, 0.1836, 0.1701, 0.1728, 0.1424, 0.1736, 0.1858, 0.1536, 0.1638,
        0.1362, 0.1618, 0.1793, 0.1482, 0.1488, 0.1437, 0.1326, 0.1518, 0.1544,
        0.1730, 0.1447, 0.1420, 0.1856, 0.1658, 0.1789, 0.1758, 0.1472, 0.1407,
        0.1420, 0.2089, 0.1474, 0.1471, 0.1484, 0.1583, 0.1831, 0.1492, 0.1818,
        0.1446, 0.1576, 0.1496, 0.1572, 0.3130, 0.1440, 0.1539, 0.2688, 0.1653,
        0.1333, 0.1695, 0.1667, 0.1709, 0.1522, 0.1395, 0.1354, 0.1933, 0.1413,
        0.2349, 0.1527, 0.1506, 0.1511, 0.1653, 0.1540, 0.1920, 0.1711, 0.1453,
        0.1400, 0.1414, 0.1831, 0.1817, 0.1577, 0.1394, 0.2359, 0.1688, 0.1551,
        0.1375, 0.2083, 0.1549, 0.1446, 0.1408, 0.1350, 0.1553, 0.1504, 0.1596,
        0.1674, 0.1566, 0.2090, 0.1511, 0.1583, 0.4506, 0.1353, 0.1688, 0.1622,
        0.1342, 0.1454, 0.1375, 0.1779, 0.1875, 0.1490, 0.1506, 0.1938, 0.1760,
        0.1365, 0.1458, 0.1467, 0.1430, 0.1638, 0.1490, 0.1722, 0.1627, 0.1575,
        0.1980, 0.1365, 0.1463, 0.2171, 0.1626, 0.1383, 0.1621, 0.1642, 0.2265,
        0.1651, 0.1455, 0.1601, 0.2059, 0.1770, 0.1414, 0.1467, 0.1532, 0.1621,
        0.1400, 0.1594, 0.1454, 0.1730, 0.2118, 0.1309, 0.1860, 0.1751, 0.1376,
        0.1403, 0.1288, 0.1637, 0.1379, 0.1544, 0.2416, 0.1676, 0.1558, 0.1371,
        0.1373, 0.1428, 0.1438, 0.1763, 0.1713, 0.1369, 0.1361, 0.1865, 0.1408,
        0.1422, 0.1385, 0.1360, 0.1387, 0.1596, 0.1645, 0.1627, 0.1454, 0.1340,
        0.1741, 0.1514, 0.1400, 0.1618, 0.1597, 0.1529, 0.1555, 0.1582, 0.1462,
        0.1845, 0.1479, 0.1457, 0.1497, 0.1504, 0.1398, 0.1518, 0.1440, 0.1442,
        0.1475, 0.1551, 0.1319, 0.1362, 0.1616, 0.1788, 0.1358, 0.1380, 0.1441,
        0.1475, 0.1377, 0.1664, 0.2380])
net.mlp.net.1.batch_norm.num_batches_tracked tensor(21)
net.mlp.net.2.linear.weight tensor([[ 0.0074,  0.0201, -0.0060,  ..., -0.0127,  0.0572,  0.0455],
        [-0.0011, -0.0116,  0.0205,  ..., -0.0239, -0.0088,  0.0215],
        [-0.0191,  0.0411, -0.0168,  ..., -0.0147,  0.0157,  0.0070],
        ...,
        [ 0.0125, -0.0045, -0.0233,  ..., -0.0055, -0.0180,  0.0246],
        [ 0.0320,  0.0396,  0.0135,  ...,  0.0012, -0.0257, -0.0140],
        [ 0.0004,  0.0482,  0.0081,  ...,  0.0748,  0.0010,  0.0437]])
net.mlp.net.2.linear.bias tensor([ 7.0162e-03,  1.3164e-02,  1.2709e-02,  4.7122e-04, -1.3504e-03,
         1.2944e-02,  1.5584e-02, -1.5371e-02,  1.0012e-02,  1.4446e-02,
         1.1529e-02, -2.1758e-02,  9.1078e-03, -3.0711e-03,  8.3055e-04,
        -2.8386e-03,  4.6773e-03,  4.5145e-03,  6.1573e-03,  1.5859e-02,
         8.7458e-04,  2.1275e-02, -3.6931e-03,  1.3786e-02,  3.4247e-03,
         1.9549e-02, -5.4898e-03, -1.4160e-02,  1.0140e-02,  5.8038e-03,
        -2.0019e-02,  6.9125e-03,  9.1788e-03,  2.5959e-03, -1.2703e-02,
         3.7898e-03,  2.0204e-02,  2.1879e-02, -1.3436e-02,  1.9394e-02,
         8.9072e-04,  2.3096e-03,  9.6941e-03, -9.6942e-03,  5.7953e-03,
        -9.4075e-03,  1.5615e-02,  1.5910e-02, -3.3333e-03, -1.8269e-02,
         7.2354e-03,  7.4034e-03, -1.1272e-02,  1.4653e-03, -1.3818e-02,
         1.3413e-02,  3.8172e-03,  6.6385e-03,  7.3177e-04, -4.0040e-03,
        -9.3307e-03,  1.4989e-02, -2.0597e-02,  3.7932e-03,  1.1454e-02,
        -6.9286e-03, -6.2408e-03,  1.2471e-02, -1.6168e-02,  2.2941e-02,
        -2.5831e-02, -4.6632e-03,  4.5186e-03, -1.9801e-03,  1.0705e-02,
        -2.0329e-02, -1.5205e-02,  3.8211e-03, -1.4073e-02,  7.4943e-03,
        -6.9174e-03, -6.6401e-03,  2.1394e-02,  1.7389e-02, -1.1333e-02,
         1.1198e-02, -3.0505e-03,  2.2720e-02,  6.1364e-03, -1.5774e-02,
         4.2776e-03, -1.6095e-02,  1.1279e-02,  1.6369e-02, -1.2891e-02,
         1.2375e-02,  1.5911e-02,  1.7773e-02, -1.7677e-02,  1.2368e-02,
        -1.2111e-02,  1.8080e-02, -1.5604e-03, -5.4868e-04, -1.7370e-02,
         1.1759e-02,  6.1052e-03,  1.4575e-02,  9.9422e-03,  1.2955e-02,
        -5.4802e-03, -1.1798e-02, -1.0217e-02, -1.3781e-02,  1.9516e-02,
         1.5147e-02,  5.5387e-04,  7.0567e-03, -1.1293e-02,  1.1551e-02,
         1.8060e-02,  1.1490e-02, -2.4831e-02,  1.4274e-02, -1.2878e-02,
         1.0694e-02, -2.6693e-03, -8.6277e-03, -3.6889e-03, -1.0130e-02,
         1.9802e-02,  3.9788e-03,  2.1017e-03, -5.3865e-03, -5.9425e-03,
        -6.4761e-03, -1.6692e-02,  1.4180e-02,  6.3123e-03,  1.0670e-02,
        -1.7552e-02, -6.4722e-03,  1.4372e-02, -1.0710e-04,  1.2742e-02,
        -1.2619e-03,  7.3712e-03, -8.2640e-03, -4.7050e-03,  8.3432e-03,
        -2.3374e-02,  5.7100e-03, -6.8398e-03, -1.8825e-02,  1.7899e-03,
        -1.9751e-02,  1.0807e-02, -7.6501e-03,  1.0595e-02,  3.0167e-03,
         6.7892e-03, -2.2620e-02, -5.4981e-03,  5.6100e-03,  2.0637e-02,
        -2.6142e-03,  5.0983e-03,  1.4491e-02,  1.3623e-02, -3.1413e-03,
         1.7712e-02, -2.1272e-03,  2.2803e-03,  1.3046e-02, -9.1634e-03,
        -1.5093e-02, -1.0365e-02, -2.0315e-02, -2.0718e-02,  7.5281e-03,
        -4.6379e-03,  2.1897e-02,  9.8662e-04,  1.8835e-02, -7.7536e-03,
        -4.8526e-03,  1.9909e-02,  9.2823e-03, -1.5124e-02, -3.9573e-04,
         1.6760e-02,  1.8704e-02,  1.2748e-02, -1.1724e-02, -1.6392e-02,
        -5.0678e-03,  2.2911e-02,  2.1612e-02,  9.4749e-06, -1.7107e-02,
         1.0854e-02,  1.7162e-02, -1.2491e-02,  1.9069e-02, -1.5102e-02,
        -1.6842e-02, -3.3571e-03,  1.2176e-02,  6.0469e-03, -4.4196e-03,
         1.6423e-02, -1.6521e-03,  8.3887e-03, -8.1758e-03, -4.0439e-03,
        -2.0585e-02, -1.2569e-02, -4.3606e-03, -1.6448e-02, -1.3866e-02,
        -2.3926e-02,  2.9007e-03, -1.0942e-02, -1.3502e-02, -1.3462e-02,
        -1.3245e-02,  1.4881e-02, -3.8551e-03,  2.9777e-03,  9.6981e-03,
         8.0141e-03,  1.0234e-02,  1.8247e-02, -8.8870e-03, -1.4028e-02,
         2.3184e-02,  4.9330e-03,  1.9541e-02,  2.1769e-02,  1.8741e-02,
        -2.2029e-02,  6.2199e-03, -1.2384e-02, -8.7161e-03,  4.8401e-03,
        -8.3620e-04,  3.3271e-03,  1.2075e-03, -1.6366e-02, -1.8239e-02,
        -2.0178e-03, -1.3697e-02, -3.4884e-04, -2.1210e-02,  1.1483e-02,
         1.3059e-02])
net.mlp.net.2.batch_norm.weight tensor([0.3476, 0.3514, 0.3482, 0.3440, 0.3439, 0.3495, 0.3484, 0.3479, 0.3457,
        0.3446, 0.3506, 0.3497, 0.3490, 0.3456, 0.3506, 0.3468, 0.3502, 0.3445,
        0.3461, 0.3467, 0.3482, 0.3484, 0.3479, 0.3502, 0.3498, 0.3456, 0.3448,
        0.3472, 0.3453, 0.3465, 0.3490, 0.3458, 0.3460, 0.3482, 0.3450, 0.3463,
        0.3460, 0.3469, 0.3463, 0.3456, 0.3491, 0.3489, 0.3476, 0.3449, 0.3458,
        0.3460, 0.3482, 0.3463, 0.3431, 0.3446, 0.3473, 0.3440, 0.3489, 0.3516,
        0.3451, 0.3510, 0.3475, 0.3513, 0.3489, 0.3468, 0.3428, 0.3490, 0.3489,
        0.3466, 0.3476, 0.3449, 0.3478, 0.3479, 0.3452, 0.3466, 0.3440, 0.3425,
        0.3467, 0.3459, 0.3505, 0.3508, 0.3478, 0.3462, 0.3464, 0.3534, 0.3484,
        0.3521, 0.3492, 0.3499, 0.3454, 0.3475, 0.3467, 0.3500, 0.3484, 0.3471,
        0.3457, 0.3462, 0.3495, 0.3445, 0.3465, 0.3496, 0.3479, 0.3450, 0.3489,
        0.3505, 0.3458, 0.3475, 0.3478, 0.3476, 0.3430, 0.3505, 0.3458, 0.3470,
        0.3470, 0.3476, 0.3446, 0.3464, 0.3508, 0.3442, 0.3474, 0.3458, 0.3425,
        0.3501, 0.3492, 0.3473, 0.3476, 0.3485, 0.3489, 0.3462, 0.3488, 0.3476,
        0.3471, 0.3472, 0.3434, 0.3484, 0.3492, 0.3438, 0.3442, 0.3468, 0.3462,
        0.3453, 0.3496, 0.3443, 0.3468, 0.3462, 0.3527, 0.3468, 0.3509, 0.3478,
        0.3445, 0.3471, 0.3497, 0.3449, 0.3472, 0.3479, 0.3508, 0.3444, 0.3425,
        0.3487, 0.3433, 0.3450, 0.3480, 0.3442, 0.3477, 0.3448, 0.3473, 0.3429,
        0.3474, 0.3497, 0.3504, 0.3490, 0.3479, 0.3453, 0.3491, 0.3486, 0.3462,
        0.3531, 0.3499, 0.3443, 0.3506, 0.3467, 0.3486, 0.3492, 0.3483, 0.3466,
        0.3485, 0.3445, 0.3446, 0.3490, 0.3471, 0.3438, 0.3454, 0.3492, 0.3430,
        0.3508, 0.3480, 0.3503, 0.3447, 0.3504, 0.3467, 0.3453, 0.3458, 0.3454,
        0.3468, 0.3490, 0.3486, 0.3433, 0.3457, 0.3449, 0.3496, 0.3496, 0.3493,
        0.3508, 0.3474, 0.3505, 0.3444, 0.3508, 0.3474, 0.3491, 0.3487, 0.3476,
        0.3494, 0.3477, 0.3438, 0.3498, 0.3493, 0.3491, 0.3458, 0.3470, 0.3484,
        0.3464, 0.3455, 0.3448, 0.3457, 0.3461, 0.3493, 0.3443, 0.3481, 0.3483,
        0.3475, 0.3437, 0.3493, 0.3476, 0.3491, 0.3439, 0.3457, 0.3510, 0.3458,
        0.3483, 0.3497, 0.3444, 0.3456, 0.3445, 0.3475, 0.3496, 0.3489, 0.3464,
        0.3454, 0.3480, 0.3492, 0.3527])
net.mlp.net.2.batch_norm.bias tensor([-2.3574e-04, -3.3876e-05, -3.3272e-03, -2.2032e-07, -1.0570e-03,
         6.1572e-04,  4.8710e-04, -2.7940e-03, -2.7790e-03,  1.1021e-03,
        -2.3895e-03,  2.8601e-03,  1.8373e-03, -1.7844e-03, -2.4429e-03,
         1.2722e-03, -4.2011e-03,  1.2620e-03,  7.2693e-04, -1.6942e-03,
         2.6218e-03, -2.5571e-04, -2.9613e-03, -2.6043e-03,  3.3372e-03,
         8.2140e-04, -4.4519e-03, -4.6082e-04,  5.2725e-04, -2.5857e-03,
         8.6401e-04, -8.6030e-04, -1.3231e-03,  2.1736e-03,  6.8358e-04,
        -2.2629e-03,  1.7287e-03,  2.8102e-03, -1.3643e-03,  1.5936e-03,
        -2.9226e-03,  4.3722e-03, -2.5686e-03, -7.6948e-05, -7.5256e-04,
         3.3758e-03,  2.4102e-04,  7.5627e-04,  3.7805e-03,  1.7744e-03,
         4.5937e-03, -1.6762e-03, -3.5475e-03, -3.0489e-04, -1.5560e-03,
        -1.2420e-03,  1.1805e-03,  9.0879e-04,  3.7150e-03, -2.0751e-03,
         1.2000e-03,  2.6866e-04,  8.4834e-04,  1.3846e-03,  1.8926e-03,
         2.9730e-04, -2.0800e-03,  3.5508e-04,  2.0317e-03,  2.8663e-04,
        -1.3337e-03, -2.9867e-04, -2.3501e-03, -1.9253e-03, -3.9458e-04,
        -6.0666e-04, -2.8772e-03, -8.6968e-04, -3.3742e-03, -1.3213e-03,
         8.2296e-04,  3.8355e-04, -2.9032e-04, -1.6857e-04, -1.9940e-03,
         9.7408e-04, -3.9943e-03,  2.5400e-03, -1.2248e-03, -9.3689e-04,
         1.7039e-04, -7.0797e-04, -9.3012e-04,  9.3823e-04, -1.2419e-03,
        -2.3945e-03,  1.9707e-03, -3.7079e-03, -8.8502e-04,  2.1823e-03,
        -1.9444e-04,  1.5871e-03,  2.1805e-03, -8.2978e-04, -1.6282e-04,
         1.2740e-03, -3.8288e-04, -2.3980e-04,  1.1167e-03,  2.7377e-03,
         4.5537e-03,  5.4593e-04, -1.8291e-04,  2.1098e-03,  2.3921e-03,
         3.5176e-03,  1.0909e-03,  7.3202e-04, -4.2232e-03, -3.9831e-03,
        -3.6690e-03,  7.3744e-05, -1.3742e-03,  1.5045e-03,  1.2091e-03,
        -1.0047e-03,  4.4162e-03,  2.0484e-03,  5.5204e-04,  6.3112e-05,
         1.5912e-04, -3.4402e-03,  3.5660e-05, -2.3446e-03,  5.9265e-04,
        -1.3068e-03,  2.3778e-03,  6.4088e-04, -3.8310e-03, -6.1228e-04,
        -3.1851e-03,  6.8163e-04,  1.4007e-03, -3.3344e-03,  3.2645e-03,
         6.6603e-04,  1.2963e-03, -2.8712e-03, -2.4305e-03, -1.5336e-03,
         3.8122e-03, -5.5004e-04, -2.4866e-03,  9.6776e-04,  5.5276e-04,
        -1.3021e-05,  1.5512e-03, -2.7203e-05,  1.4023e-03,  2.1150e-03,
        -6.4923e-04, -2.2929e-03,  3.3448e-04, -2.8792e-03,  6.0270e-04,
         1.3793e-04,  1.5659e-03, -9.6989e-05,  8.5612e-04,  1.3861e-03,
         3.6325e-04, -7.3112e-04, -2.7999e-03,  4.0167e-03, -9.8303e-05,
         1.6418e-03,  6.7912e-04, -1.1602e-03,  1.6791e-03,  3.2178e-03,
         2.6159e-03,  3.8618e-03, -3.0587e-03,  9.6848e-05, -2.2729e-03,
        -2.2634e-03,  1.2599e-03,  2.3878e-03, -1.0868e-03,  4.0315e-03,
         2.6246e-03,  7.5567e-04,  2.0998e-03, -5.5391e-03, -2.5731e-04,
        -4.2617e-04,  1.0143e-04, -1.9652e-03,  4.9475e-04, -1.8587e-04,
        -8.2745e-04,  1.2352e-04,  1.6705e-03,  1.9047e-03,  4.9227e-03,
        -8.1145e-04,  1.2470e-03, -1.1909e-03, -3.1732e-04,  4.7718e-04,
        -3.3142e-04, -1.8547e-03,  2.9486e-03, -3.6249e-03,  1.5600e-03,
        -3.2911e-03, -2.1998e-04, -1.6062e-03, -3.2767e-04,  1.1272e-03,
         1.5570e-03,  6.7642e-04,  2.5803e-04, -4.5680e-03, -4.1539e-04,
        -3.5455e-03, -2.1900e-03, -3.5966e-03, -1.6264e-03, -1.5592e-03,
         3.6178e-03,  3.2067e-03,  8.5191e-04, -4.0935e-04, -3.0357e-03,
        -2.5270e-03, -1.3307e-03,  2.4092e-03, -1.8588e-03,  4.3238e-04,
        -1.4015e-03,  5.4682e-04,  3.2943e-03, -1.4966e-03,  1.3709e-03,
        -1.0797e-03, -3.2868e-04, -2.2427e-03,  9.7467e-04, -1.6484e-04,
        -1.8361e-05, -1.7934e-04,  7.4704e-04, -2.4989e-05,  3.1098e-03,
         9.2046e-04])
net.mlp.net.2.batch_norm.running_mean tensor([0.0946, 0.1357, 0.1140, 0.1061, 0.1112, 0.1146, 0.0934, 0.1036, 0.1391,
        0.1189, 0.1079, 0.1108, 0.1090, 0.1118, 0.1060, 0.1430, 0.1273, 0.1067,
        0.1230, 0.1457, 0.1048, 0.0993, 0.1069, 0.1096, 0.1179, 0.0989, 0.0985,
        0.1020, 0.1167, 0.0931, 0.0933, 0.1124, 0.1341, 0.1010, 0.1004, 0.1211,
        0.1152, 0.1336, 0.0837, 0.0949, 0.0992, 0.1146, 0.0945, 0.1207, 0.0978,
        0.0918, 0.1523, 0.1276, 0.1090, 0.1159, 0.1383, 0.1011, 0.1185, 0.0986,
        0.1049, 0.1411, 0.1058, 0.1280, 0.1340, 0.1062, 0.1191, 0.1121, 0.0992,
        0.1133, 0.1199, 0.1091, 0.1064, 0.1092, 0.1088, 0.1203, 0.0966, 0.1031,
        0.0954, 0.1096, 0.1129, 0.0928, 0.0905, 0.1054, 0.1008, 0.1219, 0.1016,
        0.1130, 0.1310, 0.1274, 0.1127, 0.1157, 0.0943, 0.1410, 0.0929, 0.1016,
        0.1144, 0.0978, 0.1435, 0.1233, 0.0823, 0.1308, 0.1224, 0.1046, 0.1172,
        0.1072, 0.0889, 0.1064, 0.1044, 0.1142, 0.0905, 0.1132, 0.1276, 0.1044,
        0.1237, 0.1204, 0.1113, 0.1350, 0.1108, 0.1104, 0.1414, 0.1082, 0.1287,
        0.1012, 0.0946, 0.1128, 0.1286, 0.1016, 0.0900, 0.1289, 0.0992, 0.1259,
        0.1026, 0.0884, 0.1178, 0.1233, 0.1206, 0.1129, 0.1329, 0.1189, 0.1155,
        0.1023, 0.0890, 0.1196, 0.1035, 0.0910, 0.0790, 0.1131, 0.1011, 0.1131,
        0.1549, 0.1045, 0.1049, 0.1127, 0.0915, 0.1092, 0.0886, 0.1510, 0.1172,
        0.1029, 0.1129, 0.0709, 0.1067, 0.0966, 0.1042, 0.0903, 0.1100, 0.1037,
        0.0914, 0.1067, 0.1395, 0.0942, 0.1062, 0.0981, 0.1140, 0.1075, 0.1138,
        0.0944, 0.1028, 0.1284, 0.1106, 0.0800, 0.1209, 0.0987, 0.0745, 0.1278,
        0.1050, 0.1103, 0.1081, 0.1133, 0.1197, 0.0913, 0.0978, 0.1028, 0.1260,
        0.1004, 0.1520, 0.1579, 0.1339, 0.0928, 0.0911, 0.1135, 0.1438, 0.1199,
        0.1010, 0.1252, 0.1297, 0.1242, 0.0888, 0.1109, 0.0998, 0.0814, 0.1153,
        0.0993, 0.1204, 0.0872, 0.1015, 0.0979, 0.1081, 0.0867, 0.0935, 0.1085,
        0.1124, 0.1495, 0.0755, 0.1319, 0.1196, 0.0927, 0.1178, 0.1007, 0.1009,
        0.1028, 0.1242, 0.1062, 0.1123, 0.1185, 0.0989, 0.1034, 0.1243, 0.1070,
        0.1118, 0.1242, 0.1304, 0.1259, 0.1278, 0.1515, 0.0965, 0.1058, 0.0987,
        0.0978, 0.1003, 0.1134, 0.1146, 0.1236, 0.1026, 0.0849, 0.1022, 0.1069,
        0.0956, 0.0790, 0.1297, 0.1055])
net.mlp.net.2.batch_norm.running_var tensor([0.1448, 0.1714, 0.1575, 0.1630, 0.1431, 0.1551, 0.1377, 0.1661, 0.1714,
        0.1660, 0.1536, 0.1961, 0.1544, 0.1494, 0.1535, 0.2026, 0.1742, 0.1575,
        0.1482, 0.1669, 0.1418, 0.1561, 0.1850, 0.1535, 0.1472, 0.1417, 0.1427,
        0.1693, 0.1731, 0.1372, 0.1384, 0.1591, 0.1726, 0.1498, 0.1588, 0.1547,
        0.1589, 0.1850, 0.1373, 0.1481, 0.1482, 0.1834, 0.1377, 0.1768, 0.1499,
        0.1396, 0.1741, 0.1587, 0.1443, 0.1699, 0.2648, 0.1537, 0.1583, 0.1396,
        0.1599, 0.1845, 0.1600, 0.1519, 0.1561, 0.1464, 0.1518, 0.1537, 0.1868,
        0.2148, 0.1604, 0.1560, 0.1461, 0.1746, 0.1747, 0.1536, 0.1564, 0.1468,
        0.1424, 0.1549, 0.1682, 0.1693, 0.1429, 0.1738, 0.1544, 0.1822, 0.1628,
        0.1571, 0.1546, 0.1586, 0.1553, 0.1533, 0.1445, 0.1741, 0.1500, 0.1510,
        0.2004, 0.1857, 0.1808, 0.1753, 0.1535, 0.1536, 0.1559, 0.1375, 0.1658,
        0.1555, 0.1515, 0.1458, 0.1444, 0.1866, 0.1623, 0.1767, 0.1776, 0.1554,
        0.1715, 0.1816, 0.1489, 0.2206, 0.1555, 0.1715, 0.1647, 0.1477, 0.1731,
        0.1435, 0.1599, 0.1776, 0.1963, 0.1412, 0.1543, 0.1612, 0.1635, 0.1573,
        0.1830, 0.1417, 0.1800, 0.1936, 0.1690, 0.1514, 0.2075, 0.1816, 0.1590,
        0.1481, 0.1511, 0.1592, 0.1874, 0.1463, 0.1522, 0.1527, 0.1599, 0.2304,
        0.2435, 0.1537, 0.1500, 0.1503, 0.1412, 0.1508, 0.1373, 0.2184, 0.1589,
        0.1584, 0.1532, 0.1391, 0.1647, 0.1494, 0.1521, 0.1450, 0.1637, 0.1613,
        0.1452, 0.1456, 0.2153, 0.1373, 0.1500, 0.1501, 0.1492, 0.1564, 0.1602,
        0.1463, 0.2065, 0.1639, 0.1719, 0.1355, 0.1640, 0.1508, 0.1326, 0.1703,
        0.1550, 0.1443, 0.1561, 0.1702, 0.1569, 0.1526, 0.1441, 0.1631, 0.2195,
        0.1505, 0.1791, 0.1839, 0.1653, 0.1493, 0.1521, 0.1560, 0.1908, 0.1608,
        0.1543, 0.1693, 0.2334, 0.1629, 0.1449, 0.1407, 0.1494, 0.1424, 0.1632,
        0.1394, 0.1600, 0.1565, 0.1453, 0.1429, 0.1501, 0.1512, 0.1691, 0.1564,
        0.1721, 0.1786, 0.1377, 0.1724, 0.2453, 0.1451, 0.1646, 0.1499, 0.1574,
        0.2079, 0.2106, 0.1972, 0.1770, 0.1719, 0.1455, 0.1538, 0.1483, 0.1603,
        0.1761, 0.1535, 0.1758, 0.1637, 0.1626, 0.1601, 0.1531, 0.1561, 0.1459,
        0.1599, 0.1488, 0.1567, 0.1559, 0.2369, 0.1518, 0.1529, 0.1459, 0.1428,
        0.1466, 0.1419, 0.1594, 0.1575])
net.mlp.net.2.batch_norm.num_batches_tracked tensor(21)
net.mlp.net.3.linear.weight tensor([[ 0.0050,  0.0178,  0.0122,  ..., -0.0407,  0.0073, -0.0207],
        [-0.0439, -0.0401,  0.0332,  ..., -0.0253,  0.0193,  0.0556],
        [ 0.0310, -0.0126,  0.0139,  ...,  0.0653,  0.0021, -0.0384],
        ...,
        [ 0.0340,  0.0023,  0.0258,  ...,  0.0201, -0.0026,  0.0169],
        [-0.0030,  0.0309,  0.0371,  ...,  0.0120, -0.0148, -0.0572],
        [-0.0050,  0.0252,  0.0491,  ...,  0.0220, -0.0014,  0.0098]])
net.mlp.net.3.linear.bias tensor([-1.8205e-02,  5.6048e-03,  5.5623e-03, -2.7345e-03, -1.4557e-02,
        -1.5864e-02, -4.1864e-03,  9.1260e-03,  7.3619e-05,  3.0911e-03,
        -2.0635e-02, -3.6297e-04, -8.3498e-03,  1.0054e-03,  1.1551e-02,
         9.2439e-03, -2.0251e-02, -5.2618e-03,  4.7741e-04, -1.5729e-02,
         1.6335e-02, -1.5289e-02, -1.4559e-02,  1.9237e-02,  1.5997e-02,
         8.4351e-03,  6.3785e-03, -8.8443e-03, -1.9959e-02, -2.0776e-02,
        -2.7829e-03,  1.5469e-02, -2.2564e-02,  3.8922e-03,  5.1678e-04,
         1.2385e-02,  1.7640e-02, -1.6589e-02,  6.7170e-03,  1.6054e-02,
         6.6802e-03, -1.6422e-02,  1.1971e-02, -1.9885e-02,  7.7346e-03,
        -1.6434e-02, -1.5281e-02, -1.2135e-02,  3.7768e-03,  1.1755e-02,
        -1.1395e-02,  5.0423e-03, -2.5550e-04,  1.4551e-02,  1.2973e-03,
         8.1744e-03,  6.0631e-03,  2.1424e-02,  3.8886e-03,  2.0792e-02,
        -2.6050e-03,  5.1243e-03,  5.1955e-03, -3.6757e-03, -2.0977e-02,
         1.2400e-02,  2.5457e-03, -8.2847e-03, -1.8186e-02,  3.9505e-03,
         5.9053e-04,  1.9369e-02,  2.4951e-03,  4.0041e-03,  2.0347e-02,
        -2.5103e-02,  1.1634e-02,  2.4771e-03,  1.7728e-02,  1.8261e-02,
         2.1368e-02, -8.9844e-03, -6.8498e-03, -2.0296e-02,  1.8684e-03,
         1.5199e-02,  4.3838e-03,  6.8594e-03, -2.2677e-02,  3.8088e-03,
         1.2618e-03, -1.1891e-02,  4.1278e-03,  1.9152e-02,  2.1193e-03,
        -1.3135e-02, -1.4541e-02,  1.6263e-02,  1.1520e-02,  1.3907e-02,
        -9.1991e-03, -8.0946e-04,  2.0965e-02, -1.6189e-02, -5.7313e-03,
         1.7156e-02, -9.2663e-03, -2.1485e-02,  1.9039e-02, -2.6669e-03,
         1.0984e-02,  1.8537e-02,  1.2890e-02, -2.5919e-03, -1.9721e-02,
        -1.8967e-02,  6.1172e-03,  1.0786e-02,  1.5312e-02, -2.0438e-02,
        -8.7663e-04,  1.8456e-02, -1.2470e-02, -1.5606e-02,  6.3456e-03,
         1.0426e-02, -1.9382e-03, -1.1608e-02,  1.1636e-02, -2.0660e-02,
        -4.6935e-03,  5.1787e-03,  1.1110e-02,  2.3779e-02,  1.8844e-02,
         6.2936e-05,  6.4574e-03,  1.1855e-02, -1.0765e-02, -1.7516e-02,
         1.9995e-02, -6.1795e-03, -5.3043e-03, -1.4872e-02, -1.2633e-02,
        -1.2363e-02,  6.1656e-04,  7.1921e-03, -2.2170e-02,  2.5901e-03,
         1.9969e-02, -2.3395e-02,  5.1171e-03,  4.9686e-03,  2.6502e-03,
         9.9102e-03,  1.2789e-02, -6.6389e-03, -1.7606e-02, -2.0378e-02,
         4.1496e-04,  1.2891e-02, -7.3776e-03,  1.4072e-02,  1.4357e-02,
        -8.3429e-03, -3.1338e-03, -6.6899e-03,  5.3651e-03, -1.8083e-02,
        -8.8804e-03,  6.3041e-03,  5.4603e-03, -1.0937e-02,  1.4617e-02,
         4.4487e-03,  1.8671e-02, -1.1427e-03,  1.9701e-02,  1.1532e-02,
         7.8457e-03,  1.2457e-02,  1.5426e-02, -1.6114e-03,  2.1391e-02,
        -1.6489e-02,  9.2866e-03, -1.2553e-02,  1.0801e-02, -6.3856e-03,
         8.1657e-03, -2.1929e-02,  6.0108e-03, -8.2586e-03,  1.1119e-02,
         7.9723e-03,  1.5516e-02,  8.9205e-03, -2.2131e-02, -1.2123e-02,
        -1.6879e-03,  1.5589e-02,  7.7996e-03,  4.5366e-03, -4.7197e-04,
        -1.7438e-02,  1.7912e-02, -6.7289e-03,  1.8675e-02,  8.2656e-03,
         1.6965e-03,  2.5523e-03, -2.1670e-03, -2.3328e-02, -4.3791e-03,
        -2.6077e-03, -2.1326e-02, -1.1646e-02, -7.7517e-03, -6.8720e-03,
        -1.3610e-03, -3.4875e-03, -6.6022e-03, -2.2133e-02,  1.9383e-02,
        -1.7063e-02,  1.2186e-02, -4.4605e-03, -3.2376e-03, -5.2563e-03,
        -3.6961e-03,  2.8778e-03,  1.0041e-02,  8.1789e-03, -2.8087e-05,
         7.2797e-03, -4.0167e-03,  1.5627e-02, -1.4791e-03,  5.7930e-03,
        -3.7905e-03,  1.5907e-02, -1.8753e-02, -1.5774e-02,  2.4240e-03,
         2.3998e-02, -1.8711e-02, -3.6119e-03,  2.3062e-02, -2.9414e-03,
        -1.1408e-02, -5.3923e-03,  3.3463e-03,  5.1021e-03, -6.1965e-03,
         1.6803e-02])
net.mlp.net.3.batch_norm.weight tensor([0.3432, 0.3462, 0.3447, 0.3512, 0.3446, 0.3441, 0.3500, 0.3471, 0.3473,
        0.3462, 0.3460, 0.3494, 0.3430, 0.3478, 0.3468, 0.3467, 0.3467, 0.3456,
        0.3448, 0.3453, 0.3483, 0.3452, 0.3466, 0.3461, 0.3448, 0.3456, 0.3438,
        0.3454, 0.3456, 0.3454, 0.3440, 0.3495, 0.3438, 0.3456, 0.3420, 0.3480,
        0.3498, 0.3436, 0.3441, 0.3464, 0.3497, 0.3467, 0.3435, 0.3432, 0.3478,
        0.3442, 0.3444, 0.3478, 0.3510, 0.3491, 0.3472, 0.3456, 0.3509, 0.3443,
        0.3480, 0.3440, 0.3459, 0.3465, 0.3514, 0.3487, 0.3434, 0.3445, 0.3458,
        0.3449, 0.3462, 0.3450, 0.3444, 0.3488, 0.3435, 0.3456, 0.3475, 0.3428,
        0.3465, 0.3509, 0.3440, 0.3456, 0.3445, 0.3446, 0.3446, 0.3470, 0.3479,
        0.3461, 0.3450, 0.3517, 0.3443, 0.3471, 0.3463, 0.3434, 0.3500, 0.3436,
        0.3435, 0.3451, 0.3432, 0.3463, 0.3495, 0.3435, 0.3439, 0.3460, 0.3453,
        0.3457, 0.3474, 0.3441, 0.3486, 0.3424, 0.3491, 0.3457, 0.3434, 0.3450,
        0.3450, 0.3457, 0.3439, 0.3476, 0.3472, 0.3461, 0.3442, 0.3458, 0.3459,
        0.3450, 0.3446, 0.3490, 0.3478, 0.3454, 0.3468, 0.3458, 0.3472, 0.3470,
        0.3450, 0.3454, 0.3483, 0.3447, 0.3483, 0.3459, 0.3470, 0.3447, 0.3450,
        0.3453, 0.3459, 0.3498, 0.3464, 0.3475, 0.3488, 0.3472, 0.3468, 0.3484,
        0.3475, 0.3489, 0.3459, 0.3444, 0.3501, 0.3494, 0.3456, 0.3487, 0.3500,
        0.3455, 0.3443, 0.3488, 0.3439, 0.3454, 0.3452, 0.3454, 0.3479, 0.3481,
        0.3471, 0.3476, 0.3457, 0.3470, 0.3487, 0.3479, 0.3437, 0.3434, 0.3449,
        0.3481, 0.3430, 0.3469, 0.3504, 0.3463, 0.3471, 0.3437, 0.3439, 0.3459,
        0.3476, 0.3514, 0.3466, 0.3441, 0.3452, 0.3438, 0.3442, 0.3447, 0.3465,
        0.3476, 0.3490, 0.3477, 0.3464, 0.3436, 0.3461, 0.3446, 0.3460, 0.3438,
        0.3480, 0.3483, 0.3476, 0.3495, 0.3482, 0.3436, 0.3445, 0.3468, 0.3454,
        0.3484, 0.3451, 0.3439, 0.3519, 0.3467, 0.3492, 0.3471, 0.3423, 0.3493,
        0.3482, 0.3477, 0.3477, 0.3442, 0.3459, 0.3448, 0.3429, 0.3459, 0.3459,
        0.3456, 0.3435, 0.3446, 0.3504, 0.3478, 0.3461, 0.3454, 0.3461, 0.3461,
        0.3446, 0.3447, 0.3444, 0.3461, 0.3439, 0.3439, 0.3427, 0.3437, 0.3445,
        0.3433, 0.3442, 0.3466, 0.3448, 0.3432, 0.3464, 0.3423, 0.3467, 0.3428,
        0.3454, 0.3473, 0.3454, 0.3436])
net.mlp.net.3.batch_norm.bias tensor([-0.0028,  0.0022, -0.0041,  0.0051, -0.0035, -0.0031,  0.0016, -0.0043,
         0.0017,  0.0029,  0.0023, -0.0043,  0.0028, -0.0030, -0.0041,  0.0050,
         0.0031, -0.0053,  0.0024,  0.0023,  0.0033, -0.0048, -0.0037, -0.0026,
        -0.0034,  0.0032, -0.0020,  0.0024,  0.0011,  0.0048, -0.0032,  0.0038,
         0.0046, -0.0028, -0.0048,  0.0015,  0.0052, -0.0041, -0.0039,  0.0049,
         0.0029, -0.0009, -0.0039, -0.0021,  0.0040,  0.0035,  0.0029, -0.0027,
         0.0048, -0.0025, -0.0062, -0.0018,  0.0052, -0.0024,  0.0055, -0.0030,
        -0.0053,  0.0035,  0.0049, -0.0046, -0.0012, -0.0037, -0.0033,  0.0020,
         0.0022, -0.0028,  0.0041,  0.0051,  0.0051,  0.0048,  0.0030,  0.0042,
         0.0022, -0.0022, -0.0001, -0.0005, -0.0055,  0.0006, -0.0024,  0.0009,
         0.0035, -0.0021, -0.0025,  0.0013, -0.0038, -0.0031, -0.0007, -0.0028,
         0.0023, -0.0014,  0.0026, -0.0019, -0.0013,  0.0048, -0.0004,  0.0034,
        -0.0021, -0.0023,  0.0042,  0.0036,  0.0054, -0.0042, -0.0018, -0.0018,
        -0.0025, -0.0009,  0.0032,  0.0053,  0.0007, -0.0033,  0.0036, -0.0050,
        -0.0022, -0.0024,  0.0044,  0.0008, -0.0063, -0.0023, -0.0033,  0.0020,
        -0.0027,  0.0041,  0.0019,  0.0013, -0.0016, -0.0045,  0.0035, -0.0030,
         0.0056, -0.0054,  0.0030, -0.0069,  0.0053,  0.0049, -0.0010, -0.0020,
        -0.0015, -0.0038,  0.0013,  0.0001,  0.0002,  0.0049,  0.0051, -0.0051,
        -0.0034,  0.0047, -0.0049,  0.0009,  0.0027,  0.0031, -0.0049,  0.0047,
        -0.0046, -0.0033, -0.0039,  0.0006, -0.0041, -0.0048, -0.0020,  0.0067,
         0.0006,  0.0037,  0.0015,  0.0022,  0.0048, -0.0020,  0.0036,  0.0045,
         0.0025, -0.0025, -0.0024, -0.0036, -0.0017,  0.0054, -0.0007,  0.0041,
         0.0064,  0.0008, -0.0024, -0.0039,  0.0058,  0.0031, -0.0034, -0.0038,
        -0.0025,  0.0021, -0.0032, -0.0046, -0.0016,  0.0033, -0.0024,  0.0021,
         0.0045,  0.0012,  0.0049, -0.0040, -0.0030,  0.0037,  0.0057, -0.0044,
        -0.0042,  0.0046,  0.0030, -0.0036, -0.0046, -0.0031, -0.0024,  0.0013,
         0.0020, -0.0012,  0.0017, -0.0027,  0.0030, -0.0019,  0.0049, -0.0040,
         0.0018,  0.0023, -0.0042,  0.0031, -0.0022, -0.0001,  0.0030, -0.0018,
        -0.0024, -0.0035,  0.0049, -0.0015,  0.0048,  0.0026,  0.0038, -0.0006,
        -0.0047, -0.0004, -0.0049,  0.0051, -0.0044,  0.0051,  0.0016,  0.0010,
         0.0020, -0.0030,  0.0050, -0.0050, -0.0034,  0.0018, -0.0001, -0.0043,
        -0.0023, -0.0037, -0.0030,  0.0048,  0.0002,  0.0041,  0.0028, -0.0021])
net.mlp.net.3.batch_norm.running_mean tensor([0.0926, 0.1183, 0.1116, 0.0978, 0.0907, 0.1016, 0.0987, 0.1126, 0.1135,
        0.1386, 0.1025, 0.1008, 0.1076, 0.1033, 0.1193, 0.1222, 0.0895, 0.1088,
        0.1065, 0.1018, 0.1427, 0.1115, 0.0827, 0.1161, 0.1110, 0.1131, 0.1068,
        0.1018, 0.1036, 0.1077, 0.1093, 0.1156, 0.0925, 0.1237, 0.0947, 0.1104,
        0.1227, 0.0936, 0.1224, 0.1156, 0.1098, 0.0963, 0.1237, 0.0987, 0.1229,
        0.1131, 0.1056, 0.1110, 0.0979, 0.1095, 0.0896, 0.1268, 0.1086, 0.1387,
        0.1125, 0.0949, 0.1062, 0.1664, 0.1062, 0.1166, 0.1025, 0.1130, 0.1526,
        0.1143, 0.1066, 0.1051, 0.1208, 0.1125, 0.0864, 0.1014, 0.1051, 0.1341,
        0.1170, 0.1146, 0.1191, 0.0888, 0.1181, 0.1048, 0.1113, 0.1268, 0.1204,
        0.1525, 0.1010, 0.0875, 0.1239, 0.1488, 0.1038, 0.1153, 0.0983, 0.1188,
        0.1140, 0.1215, 0.1150, 0.1247, 0.1141, 0.0887, 0.1200, 0.0981, 0.1155,
        0.1163, 0.1052, 0.1465, 0.1214, 0.1223, 0.1201, 0.1501, 0.0982, 0.1146,
        0.1292, 0.1209, 0.1153, 0.1174, 0.1129, 0.1091, 0.0784, 0.0954, 0.1417,
        0.0988, 0.1059, 0.0878, 0.1331, 0.1219, 0.1012, 0.0917, 0.1185, 0.1288,
        0.0988, 0.1020, 0.1267, 0.0951, 0.1128, 0.1071, 0.1309, 0.1404, 0.1284,
        0.1046, 0.1110, 0.1296, 0.1031, 0.1017, 0.1021, 0.0994, 0.1189, 0.1055,
        0.1163, 0.1060, 0.1049, 0.1212, 0.0936, 0.1188, 0.1542, 0.0940, 0.1195,
        0.1053, 0.1075, 0.1010, 0.1336, 0.1099, 0.1117, 0.1161, 0.1083, 0.1087,
        0.1159, 0.1161, 0.1156, 0.1102, 0.1076, 0.1169, 0.1049, 0.0768, 0.1010,
        0.1124, 0.1088, 0.1087, 0.1337, 0.1181, 0.1159, 0.1157, 0.1223, 0.1254,
        0.1215, 0.1081, 0.1258, 0.1342, 0.1251, 0.1003, 0.1187, 0.1075, 0.1082,
        0.1045, 0.1133, 0.0977, 0.1115, 0.1000, 0.1389, 0.0994, 0.1248, 0.1348,
        0.0885, 0.1075, 0.1322, 0.1099, 0.1268, 0.1160, 0.1190, 0.0999, 0.1109,
        0.0991, 0.1106, 0.0919, 0.1080, 0.1121, 0.1308, 0.1098, 0.1077, 0.1057,
        0.1028, 0.0990, 0.1133, 0.1329, 0.1240, 0.1085, 0.0989, 0.0891, 0.1114,
        0.1230, 0.1096, 0.1094, 0.1151, 0.1042, 0.1391, 0.1153, 0.1313, 0.1146,
        0.1096, 0.1086, 0.1023, 0.1162, 0.0999, 0.1033, 0.1111, 0.1228, 0.1088,
        0.0948, 0.1095, 0.1122, 0.0893, 0.1152, 0.1476, 0.1260, 0.0946, 0.1117,
        0.1154, 0.1066, 0.1039, 0.1077])
net.mlp.net.3.batch_norm.running_var tensor([0.1677, 0.1536, 0.1752, 0.1857, 0.1431, 0.1478, 0.1416, 0.1599, 0.1510,
        0.1983, 0.1616, 0.1416, 0.1571, 0.1557, 0.1458, 0.1733, 0.1542, 0.1733,
        0.1484, 0.1478, 0.1728, 0.1511, 0.1406, 0.1688, 0.1536, 0.1578, 0.1789,
        0.1830, 0.1848, 0.1496, 0.1582, 0.1816, 0.1561, 0.1696, 0.1506, 0.1620,
        0.1570, 0.1451, 0.1690, 0.1841, 0.1779, 0.1477, 0.1759, 0.1425, 0.1736,
        0.1646, 0.1725, 0.1534, 0.1504, 0.1500, 0.1473, 0.2216, 0.1642, 0.1643,
        0.2138, 0.1525, 0.1458, 0.1977, 0.1651, 0.1589, 0.1475, 0.1789, 0.1838,
        0.1954, 0.2140, 0.1496, 0.1494, 0.1697, 0.1518, 0.1612, 0.1590, 0.1953,
        0.1539, 0.1761, 0.1684, 0.1508, 0.1688, 0.1468, 0.1472, 0.1689, 0.1981,
        0.1962, 0.1459, 0.1460, 0.1849, 0.1707, 0.1443, 0.1488, 0.1505, 0.1484,
        0.1582, 0.1728, 0.1585, 0.1586, 0.1613, 0.1465, 0.2120, 0.1421, 0.1519,
        0.1568, 0.1513, 0.1779, 0.1526, 0.1734, 0.1578, 0.1677, 0.1451, 0.1589,
        0.2312, 0.1518, 0.1644, 0.1561, 0.1516, 0.1502, 0.1433, 0.1545, 0.1978,
        0.1453, 0.1575, 0.1515, 0.1544, 0.1553, 0.1722, 0.1580, 0.1513, 0.1785,
        0.1443, 0.1648, 0.2030, 0.1638, 0.2104, 0.1582, 0.1671, 0.1861, 0.1647,
        0.1493, 0.2014, 0.1698, 0.1496, 0.1462, 0.1512, 0.1496, 0.1881, 0.1592,
        0.1929, 0.1686, 0.1581, 0.1694, 0.1509, 0.1586, 0.1954, 0.1466, 0.1554,
        0.1481, 0.1517, 0.1448, 0.1631, 0.1745, 0.1531, 0.1643, 0.1555, 0.1573,
        0.1783, 0.1646, 0.1508, 0.1563, 0.1585, 0.1533, 0.1556, 0.1342, 0.1507,
        0.1632, 0.1588, 0.1559, 0.1577, 0.1569, 0.1516, 0.1890, 0.1737, 0.1609,
        0.1599, 0.1571, 0.1594, 0.1663, 0.1802, 0.1492, 0.1586, 0.1584, 0.1636,
        0.1566, 0.1699, 0.1498, 0.1515, 0.1610, 0.1750, 0.1474, 0.1637, 0.1723,
        0.1549, 0.1633, 0.1763, 0.1674, 0.1754, 0.1556, 0.1634, 0.1524, 0.1658,
        0.1551, 0.1532, 0.1438, 0.1557, 0.1620, 0.2406, 0.1724, 0.1569, 0.1505,
        0.1751, 0.1550, 0.1537, 0.1690, 0.1911, 0.1648, 0.1446, 0.1476, 0.1645,
        0.1815, 0.1589, 0.1486, 0.1697, 0.1484, 0.1952, 0.1704, 0.1567, 0.1649,
        0.1654, 0.1604, 0.1448, 0.1542, 0.1879, 0.1530, 0.1655, 0.1559, 0.1595,
        0.1462, 0.1711, 0.1649, 0.1430, 0.1756, 0.2016, 0.1549, 0.1538, 0.1604,
        0.1549, 0.1700, 0.1753, 0.1569])
net.mlp.net.3.batch_norm.num_batches_tracked tensor(21)
net.mlp.net.4.weight tensor([[ 2.0548e-03, -1.1536e-02,  1.4760e-02, -1.5687e-02,  7.1612e-03,
         -2.8674e-05, -1.7237e-02,  1.6754e-03, -8.7792e-03, -1.2390e-02,
         -3.2856e-03,  1.2046e-02, -1.3703e-02,  3.2228e-03,  2.9566e-03,
         -2.0322e-03, -1.9229e-02,  8.6449e-03, -1.3081e-02, -1.7905e-03,
         -9.5650e-03,  1.0256e-02,  4.0280e-03,  8.9077e-03,  1.8716e-02,
         -1.8032e-02,  6.1954e-03, -4.5970e-03,  5.0053e-03, -7.1778e-03,
          1.8301e-02, -4.1275e-03, -1.6394e-02,  1.8264e-02,  1.9269e-03,
         -8.6156e-03, -1.2958e-02,  1.2576e-02,  8.6072e-03, -6.7864e-03,
         -1.5023e-02, -1.7249e-02,  1.6483e-02,  6.3909e-03, -2.2405e-02,
         -1.7093e-02, -1.7759e-03,  1.3650e-02, -8.0550e-03,  9.1183e-03,
          1.6741e-02,  1.3659e-02, -1.1938e-02,  5.0986e-03, -2.1384e-02,
          4.9204e-03,  3.8189e-03, -1.9037e-02, -1.9786e-02,  1.5850e-02,
          1.3457e-02,  3.3471e-03,  1.6926e-02, -1.3562e-02, -1.8427e-02,
          1.6458e-02, -1.1811e-02, -2.1426e-02, -5.1667e-03, -9.2104e-03,
         -4.6432e-03, -3.1161e-03, -7.5179e-03,  8.4414e-03,  1.8057e-02,
          1.6002e-02,  1.8908e-02, -7.2989e-04,  1.2564e-02,  1.4438e-02,
         -1.7712e-03,  7.0187e-03,  8.2651e-04, -6.0259e-03,  1.1627e-02,
          8.9078e-03,  1.5156e-02,  1.6624e-02, -9.7490e-03,  8.5432e-04,
         -3.7630e-03,  8.2247e-03,  8.7704e-03, -1.0065e-02,  2.2287e-02,
         -1.1647e-02,  1.5967e-02,  6.1900e-03, -1.9515e-02, -1.6803e-02,
         -7.8098e-03,  1.4763e-02,  1.1139e-02,  1.2168e-02,  1.1125e-02,
          8.8689e-03, -3.9675e-03, -1.8009e-02, -5.5547e-03,  3.4941e-03,
         -1.1848e-02,  2.1613e-02,  7.1914e-03,  1.9578e-02, -1.6478e-02,
         -8.2600e-04,  6.0669e-03,  1.6127e-02,  1.0690e-02, -9.9479e-03,
          2.1043e-02, -1.9359e-02, -8.3052e-03, -1.0415e-02,  8.2427e-03,
          1.6278e-02, -1.3559e-02,  1.8856e-02, -1.2211e-02,  3.3759e-03,
         -1.0344e-02,  4.6853e-03, -1.7261e-02, -1.2627e-03,  1.2090e-02,
          9.1299e-03,  1.1676e-02,  1.1359e-02, -7.1134e-03,  1.0449e-02,
         -7.7536e-03, -1.8537e-02, -7.5543e-03,  1.3664e-02,  6.6767e-03,
         -2.1242e-02,  1.3331e-02, -1.7103e-02, -1.2717e-02, -1.0310e-02,
          1.9442e-02, -2.2371e-02,  1.0317e-02,  8.2536e-03, -3.7418e-04,
         -1.4491e-02,  5.7011e-03,  9.5058e-03,  1.0036e-02, -1.0517e-02,
         -6.8129e-03, -1.2541e-02, -5.6202e-03, -1.0017e-02, -8.5839e-04,
          1.5758e-02, -3.8931e-03, -1.1802e-02, -3.1989e-03,  7.5318e-03,
          1.1082e-02,  1.3144e-02, -1.1889e-03, -1.6325e-02,  1.2091e-02,
         -2.7967e-03, -1.3721e-02,  1.3248e-03,  7.0187e-03, -1.5169e-03,
         -1.8593e-03, -2.2026e-02,  1.2958e-02,  1.2040e-02,  1.6122e-02,
         -1.3953e-02,  1.1091e-03,  1.2062e-02,  1.8620e-02, -1.0768e-02,
          1.9402e-02, -9.7155e-03, -1.3048e-02, -8.1563e-03, -1.3806e-03,
          6.6076e-03,  9.6561e-03,  1.5693e-03, -1.4889e-02,  8.2606e-03,
          8.0812e-03, -2.0756e-02, -5.9843e-03,  1.3638e-02,  3.6234e-03,
          1.3485e-02,  3.3486e-03, -2.3059e-03, -7.1848e-03,  1.5240e-02,
         -5.3253e-03,  8.7076e-03, -1.6793e-02,  7.5975e-03, -8.9314e-03,
          4.2285e-03, -1.2395e-02, -6.4014e-03,  1.6304e-02, -1.2172e-02,
          8.1446e-03, -1.3208e-02, -5.7124e-03, -1.8884e-03,  3.6706e-03,
          1.4358e-02, -1.4319e-02,  4.4889e-03, -1.0052e-02, -6.8878e-03,
         -1.4879e-02,  1.3094e-02,  1.2992e-02, -2.5854e-03,  1.8699e-02,
         -1.9002e-03,  3.3018e-03, -1.5137e-02, -6.3125e-03, -1.3064e-03,
         -4.8774e-04,  1.4894e-02, -1.7131e-02,  7.4233e-03,  3.8179e-03,
         -1.8890e-02, -1.2487e-02,  1.7087e-03,  1.9655e-02,  9.3153e-03,
          1.2078e-02, -8.9416e-03,  1.9872e-03, -1.5439e-02, -1.8843e-02,
          8.7895e-03]])
