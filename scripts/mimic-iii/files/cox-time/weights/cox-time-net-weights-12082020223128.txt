Weights: 
net.embeddings.embeddings.0.weight tensor([[ 0.0916,  0.0363],
        [ 0.0604, -0.1288],
        [ 0.2099,  0.3033],
        [ 0.1591,  0.3370]])
net.embeddings.embeddings.1.weight tensor([[-0.2151,  0.0109],
        [-0.3327,  0.0054],
        [-0.1641,  0.1053],
        [ 0.3109,  0.0586],
        [-0.2074, -0.0720]])
net.embeddings.embeddings.2.weight tensor([[ 0.0439,  0.0746, -0.0765],
        [-0.1003, -0.2693, -0.1132],
        [-0.2111,  0.0922, -0.2402],
        [-0.1069,  0.1091,  0.2269],
        [ 0.0977, -0.0794,  0.0145],
        [-0.1892, -0.2404, -0.1479]])
net.embeddings.embeddings.3.weight tensor([[ 0.1842,  0.1757],
        [-0.0921, -0.2665],
        [ 0.1207,  0.0786],
        [-0.1572, -0.0079]])
net.embeddings.embeddings.4.weight tensor([[-0.0060,  0.2555],
        [-0.3501, -0.0195],
        [-0.1440,  0.2645],
        [ 0.2064,  0.2091]])
net.mlp.net.0.linear.weight tensor([[ 0.0449,  0.0571, -0.2291,  ..., -0.4802,  0.0534,  0.2628],
        [ 0.0086,  0.3953, -0.1801,  ...,  0.0998, -0.4391, -0.2063],
        [ 0.0801, -0.0952,  0.0591,  ..., -0.1922, -0.0971,  0.2739],
        ...,
        [ 0.1277, -0.1794, -0.0486,  ..., -0.6080, -0.1126, -0.0500],
        [-0.1456,  0.1914,  0.2184,  ..., -0.2090, -0.2772,  0.2578],
        [-0.0248, -0.1660,  0.1759,  ...,  0.1641,  0.2136, -0.1658]])
net.mlp.net.0.linear.bias tensor([-8.4112e-02,  9.8121e-02,  7.3380e-02, -9.6466e-02,  9.1705e-02,
        -1.0462e-01, -1.1548e-01,  9.4596e-02,  1.0408e-01,  7.5860e-02,
         3.2927e-02,  4.7516e-02, -8.7059e-02, -1.1221e-03,  1.1593e-01,
        -7.1062e-02, -9.2936e-02,  1.7094e-02, -2.2396e-02, -7.6493e-02,
        -5.6950e-02,  1.8897e-02, -4.0819e-02, -8.4019e-02,  6.2899e-02,
        -1.6965e-02, -1.1087e-02, -9.8879e-02, -1.0611e-01, -4.2389e-03,
         4.9327e-02,  2.2344e-02,  2.1091e-05,  1.1051e-01, -4.2422e-02,
         1.5444e-02, -1.7914e-02,  8.3649e-02,  2.7484e-02, -6.4991e-02,
        -1.3296e-02,  9.1566e-03, -9.5177e-02,  9.8928e-02,  4.1608e-02,
        -8.9931e-02, -8.1506e-02,  3.0128e-02,  7.6841e-02, -8.8289e-02,
         9.3432e-02, -4.8556e-02,  2.7842e-02, -6.2961e-02,  1.3820e-02,
        -1.0419e-01,  1.9899e-02,  3.4609e-02,  8.8598e-02,  2.5916e-02,
        -9.5063e-02, -9.7576e-02, -1.3412e-02,  1.1783e-01, -7.2530e-02,
         4.8924e-02,  5.4831e-02,  7.5333e-02, -1.4714e-02,  4.6622e-02,
         1.1743e-01,  7.6338e-02, -2.8968e-02, -3.9101e-02,  2.9172e-02,
         5.0407e-02,  1.1241e-01,  9.3703e-02, -8.8204e-02,  4.7834e-02,
         1.1523e-01, -6.6771e-02, -1.1717e-01, -9.5209e-02, -1.1096e-01,
        -7.7638e-02, -1.9529e-02, -5.0472e-02, -2.2255e-02, -1.0891e-01,
        -2.7074e-02, -1.5452e-02,  2.1156e-02,  1.0369e-01, -1.2214e-01,
        -8.3798e-02, -1.2014e-01,  7.0395e-02,  7.6173e-03, -6.8821e-02,
        -5.7725e-02,  2.4545e-02,  9.5428e-02,  1.1297e-01, -2.3151e-02,
        -4.6175e-02, -2.0311e-02,  1.0532e-01,  2.6777e-02,  3.3194e-02,
        -4.2323e-02,  8.0058e-02,  1.1694e-01,  7.3647e-02,  4.2091e-02,
         9.2337e-02,  8.4919e-02, -3.2094e-02,  9.0291e-02,  4.1079e-03,
         8.0922e-02, -6.6856e-02, -1.2597e-01,  5.9731e-02, -1.7295e-02,
        -6.9474e-02, -1.2283e-02, -8.0306e-02,  5.6453e-02,  6.2349e-02,
        -6.8264e-02, -6.6739e-02, -5.6707e-02,  3.1523e-02,  8.4823e-02,
        -5.7274e-02,  8.9684e-02, -4.6491e-02, -4.2018e-02,  4.7192e-02,
        -8.4518e-02, -5.1727e-02,  4.2524e-02,  6.2177e-02,  5.9321e-02,
        -1.6730e-02, -1.2159e-02, -3.3356e-03,  1.2567e-01,  2.7183e-02,
        -2.9031e-02,  3.5559e-02,  9.4385e-02, -6.3815e-02,  7.9024e-02,
         1.2262e-01,  5.1754e-02, -4.2706e-02, -5.4697e-02, -1.2004e-01,
        -7.2171e-02,  9.9637e-02, -6.7291e-02, -1.3504e-02, -1.0422e-01,
        -2.7169e-02, -4.5639e-02, -1.1831e-01, -1.3281e-02,  4.9361e-02,
        -2.1698e-03,  5.9475e-02, -6.6626e-02,  6.6715e-02,  2.3157e-02,
         7.6987e-02, -9.8884e-03, -1.7126e-02,  9.0185e-03,  2.8333e-02,
        -1.0025e-01,  1.1828e-01, -4.2773e-02, -9.2000e-03,  2.2145e-03,
        -8.8701e-03,  5.3607e-02, -5.5650e-02, -8.2261e-02,  2.4081e-02,
         3.3845e-02,  6.1330e-02,  1.0123e-01, -9.6667e-02,  9.4886e-02,
         2.8942e-02,  1.3152e-02, -5.4998e-02,  3.6905e-02, -8.4666e-02,
         5.8346e-02, -7.2687e-02,  8.1827e-02,  6.7430e-02, -1.2443e-01,
         7.6153e-02, -3.8117e-02,  9.0529e-02, -1.2686e-01,  1.2147e-01,
        -7.8092e-02,  9.9675e-02, -2.1435e-02,  7.1785e-02,  7.9477e-02,
        -9.0079e-02,  7.6665e-02,  6.5916e-02,  1.2475e-01,  9.9600e-02,
         4.7554e-02, -2.2109e-02,  5.7838e-02,  1.8004e-02, -1.7376e-04,
        -9.1897e-02,  8.6762e-02, -4.8440e-02, -8.9716e-02, -3.2991e-03,
         7.0352e-02,  6.9715e-03, -3.9897e-02,  9.4343e-02, -5.3826e-02,
        -6.6114e-02,  2.1132e-02, -9.8034e-02,  1.0938e-03, -4.2666e-02,
        -9.2879e-02,  4.5468e-02, -7.3338e-03,  6.9661e-02, -3.6031e-02,
        -2.3954e-02,  4.1443e-02,  5.5124e-02,  7.4610e-02,  1.2448e-01,
         1.6976e-02,  1.0673e-01, -6.6495e-02,  7.3956e-02, -1.2995e-02,
         7.4200e-02])
net.mlp.net.0.batch_norm.weight tensor([0.5614, 0.5593, 0.5613, 0.5606, 0.5608, 0.5639, 0.5612, 0.5624, 0.5601,
        0.5615, 0.5588, 0.5637, 0.5601, 0.5593, 0.5613, 0.5589, 0.5631, 0.5589,
        0.5636, 0.5597, 0.5630, 0.5592, 0.5621, 0.5637, 0.5589, 0.5638, 0.5607,
        0.5632, 0.5613, 0.5632, 0.5631, 0.5620, 0.5625, 0.5617, 0.5631, 0.5595,
        0.5635, 0.5635, 0.5635, 0.5598, 0.5588, 0.5637, 0.5628, 0.5620, 0.5613,
        0.5592, 0.5586, 0.5609, 0.5612, 0.5634, 0.5603, 0.5612, 0.5635, 0.5587,
        0.5594, 0.5638, 0.5614, 0.5603, 0.5640, 0.5604, 0.5604, 0.5588, 0.5627,
        0.5591, 0.5617, 0.5626, 0.5625, 0.5614, 0.5632, 0.5619, 0.5636, 0.5595,
        0.5612, 0.5611, 0.5592, 0.5604, 0.5618, 0.5614, 0.5635, 0.5633, 0.5634,
        0.5631, 0.5635, 0.5628, 0.5636, 0.5602, 0.5590, 0.5622, 0.5595, 0.5589,
        0.5631, 0.5588, 0.5636, 0.5624, 0.5589, 0.5621, 0.5630, 0.5586, 0.5621,
        0.5592, 0.5636, 0.5636, 0.5589, 0.5591, 0.5621, 0.5623, 0.5596, 0.5612,
        0.5632, 0.5621, 0.5590, 0.5592, 0.5590, 0.5619, 0.5614, 0.5590, 0.5598,
        0.5598, 0.5602, 0.5608, 0.5636, 0.5608, 0.5634, 0.5609, 0.5610, 0.5607,
        0.5588, 0.5588, 0.5591, 0.5622, 0.5594, 0.5593, 0.5595, 0.5620, 0.5611,
        0.5628, 0.5595, 0.5588, 0.5590, 0.5594, 0.5612, 0.5617, 0.5593, 0.5625,
        0.5610, 0.5621, 0.5616, 0.5594, 0.5630, 0.5634, 0.5589, 0.5621, 0.5622,
        0.5638, 0.5611, 0.5612, 0.5622, 0.5609, 0.5602, 0.5638, 0.5589, 0.5586,
        0.5635, 0.5618, 0.5629, 0.5607, 0.5601, 0.5632, 0.5607, 0.5598, 0.5630,
        0.5623, 0.5607, 0.5622, 0.5629, 0.5591, 0.5601, 0.5637, 0.5619, 0.5592,
        0.5602, 0.5593, 0.5612, 0.5625, 0.5592, 0.5612, 0.5636, 0.5629, 0.5603,
        0.5608, 0.5631, 0.5629, 0.5592, 0.5634, 0.5620, 0.5592, 0.5608, 0.5621,
        0.5591, 0.5616, 0.5631, 0.5593, 0.5607, 0.5587, 0.5634, 0.5618, 0.5627,
        0.5593, 0.5611, 0.5605, 0.5603, 0.5594, 0.5605, 0.5616, 0.5615, 0.5636,
        0.5618, 0.5604, 0.5613, 0.5599, 0.5590, 0.5588, 0.5623, 0.5614, 0.5635,
        0.5614, 0.5594, 0.5628, 0.5614, 0.5588, 0.5627, 0.5590, 0.5600, 0.5639,
        0.5624, 0.5640, 0.5593, 0.5616, 0.5610, 0.5615, 0.5628, 0.5629, 0.5593,
        0.5621, 0.5637, 0.5622, 0.5629, 0.5632, 0.5599, 0.5610, 0.5614, 0.5591,
        0.5637, 0.5619, 0.5593, 0.5595])
net.mlp.net.0.batch_norm.bias tensor([ 1.3414e-03,  2.3042e-03,  2.3308e-03,  2.2342e-03,  7.8938e-04,
        -2.4406e-04,  2.3497e-03,  2.0893e-03,  1.7893e-03, -1.5658e-03,
        -2.8287e-04,  1.2882e-03,  7.6028e-04, -6.1590e-04, -2.5023e-03,
        -9.0123e-04, -2.6935e-03, -9.0435e-04, -1.3806e-03,  1.2788e-03,
        -9.7767e-04, -4.1813e-04, -1.3321e-03,  2.7210e-03,  5.6760e-04,
         1.1839e-03,  2.6250e-03, -2.5775e-03, -6.2087e-04, -3.1883e-04,
         5.4303e-04,  2.3911e-03,  1.6668e-03,  1.1556e-03,  1.2541e-03,
        -1.6031e-03,  1.9233e-03,  1.7580e-03, -2.6660e-03, -8.3278e-04,
        -3.6037e-04,  2.0022e-03, -2.1159e-04, -6.5172e-04,  2.3078e-03,
         2.2073e-03,  3.3082e-04, -3.3133e-04, -3.9242e-05,  2.3166e-03,
         1.7453e-03,  3.3591e-04,  1.6231e-03,  2.4048e-03,  1.8037e-03,
        -1.3078e-03, -1.9631e-03,  1.7286e-03,  4.6325e-04,  2.2298e-03,
        -1.9073e-03, -1.8124e-03, -1.3911e-03, -4.1523e-04,  1.0356e-03,
        -1.0335e-03,  1.2278e-03,  2.6344e-03, -2.0395e-03, -1.5385e-03,
         1.5204e-03, -2.1384e-03, -2.4274e-03,  2.4851e-03,  5.0887e-04,
         2.2323e-04,  2.4142e-03,  1.1216e-03, -7.3509e-04, -1.4684e-03,
        -2.3471e-03, -9.1018e-04, -2.0678e-03,  2.2754e-03,  8.1282e-04,
        -1.8342e-03,  1.5099e-03, -2.7548e-03,  2.3316e-03,  6.1636e-04,
         2.5581e-03,  5.4129e-04, -2.4170e-03,  1.1078e-04, -2.0349e-03,
        -2.2919e-04,  8.5584e-04, -1.7377e-03, -1.2622e-03,  1.0831e-04,
        -2.3778e-03,  1.5874e-03,  1.2329e-03, -3.0700e-05,  5.7354e-04,
        -1.7452e-04, -7.2516e-04, -1.3926e-03,  3.6676e-04,  2.0177e-03,
        -2.2142e-03,  2.3449e-03, -1.4074e-03, -3.9475e-04, -1.1596e-03,
         4.1042e-04, -2.1874e-03, -8.1928e-04, -2.4187e-03,  1.8048e-03,
        -1.2061e-03, -1.7847e-03,  2.2484e-03,  2.3083e-03,  1.3480e-03,
        -2.2140e-03,  2.5020e-03, -1.4553e-03, -1.9738e-03,  1.7808e-04,
        -4.0474e-04,  2.3347e-04, -1.9108e-03, -5.1914e-04, -4.5117e-04,
        -2.8565e-05,  2.2770e-03,  2.1154e-03,  2.8045e-04,  2.4081e-03,
        -1.2543e-03,  2.0854e-03,  2.1590e-03,  8.4940e-05, -3.6960e-04,
         1.9666e-03,  1.1714e-03,  1.9250e-03, -1.8367e-04, -2.3371e-03,
         1.6248e-03, -8.2293e-04,  8.5587e-04, -2.3053e-03, -5.5905e-04,
        -2.0751e-03, -1.0301e-03, -2.2357e-03, -2.4751e-04, -2.8048e-03,
         7.0898e-04, -4.5107e-04,  2.1147e-03, -1.8278e-03, -2.5314e-03,
        -2.8327e-04,  2.9884e-04, -2.2186e-03,  3.7169e-04,  2.0629e-03,
         3.0288e-04, -2.1837e-03, -2.0866e-03,  1.6149e-03, -2.6080e-03,
        -9.0079e-04,  2.5494e-03, -4.6019e-05,  2.0383e-03, -6.8998e-04,
         1.9800e-03,  2.5735e-03,  2.1011e-03, -8.5432e-04, -2.5040e-03,
        -2.6407e-03,  1.2769e-03,  5.6688e-04,  3.9231e-04,  4.8909e-04,
        -2.4581e-04, -3.3293e-04, -2.5827e-03, -1.9348e-03,  7.9472e-05,
         1.8261e-04,  2.1150e-03, -2.2309e-03,  1.2053e-03, -2.7487e-04,
         2.1980e-03,  2.3040e-04,  2.6188e-03, -1.9420e-03, -3.6239e-04,
        -1.8934e-03,  2.7534e-03, -1.5897e-04, -1.3015e-03, -1.4470e-03,
        -1.3636e-03, -1.4998e-03,  1.6499e-04,  1.2246e-04,  1.1420e-03,
        -1.2001e-06, -2.3610e-03,  9.9851e-04,  1.6923e-03,  1.7289e-03,
        -1.8955e-03, -9.6638e-06, -7.6400e-04,  1.6307e-03,  4.1920e-05,
         6.1208e-04, -1.6258e-03, -2.5350e-03,  2.9165e-04, -1.8545e-03,
        -6.3505e-05,  1.4757e-03,  2.4369e-03,  4.3443e-04,  7.9227e-04,
        -2.3768e-03,  3.6832e-04, -3.9195e-04, -1.2339e-03, -2.2121e-03,
         5.1894e-04, -1.3725e-04,  1.2520e-03,  1.7535e-03, -1.6420e-03,
        -1.2209e-03, -1.0058e-03, -1.7953e-04, -1.1711e-03, -1.3802e-03,
         5.7278e-05,  1.1502e-03,  1.6762e-03,  2.2472e-03, -1.3745e-05,
        -5.8182e-05])
net.mlp.net.0.batch_norm.running_mean tensor([2.2492e-02, 7.6852e-02, 1.1424e-01, 8.0123e-02, 1.4475e-02, 2.5035e-02,
        2.3124e-02, 5.9596e-02, 6.2529e-03, 3.7226e-02, 2.5695e-02, 6.4015e-02,
        9.8842e-04, 1.3431e-01, 1.4005e-01, 1.4001e-03, 9.1041e-02, 4.6181e-02,
        4.5104e-02, 2.2882e-02, 1.7960e-01, 2.1720e-02, 3.0084e-02, 4.8235e-02,
        2.1601e-02, 9.7402e-02, 2.4779e-04, 3.9531e-02, 6.2447e-04, 7.1771e-02,
        8.5004e-05, 1.5757e-01, 3.3474e-01, 1.6285e-01, 8.9281e-02, 1.0663e-04,
        7.4364e-02, 2.1247e-01, 7.6151e-02, 1.4993e-02, 2.0886e-02, 7.3668e-02,
        5.1793e-02, 1.3027e-01, 5.8898e-02, 1.2972e-02, 6.9841e-04, 2.1037e-01,
        1.0822e-04, 1.6447e-01, 5.0532e-02, 2.4429e-01, 6.1932e-02, 3.7828e-02,
        1.7593e-01, 1.1513e-01, 2.2992e-01, 2.0489e-03, 1.3074e-01, 1.0261e-03,
        1.5855e-01, 6.9099e-02, 2.7259e-02, 3.5457e-03, 5.2557e-01, 5.6482e-02,
        2.0815e-02, 6.2580e-02, 1.6423e-03, 1.0561e-01, 2.2943e-02, 1.1920e-02,
        2.5050e-02, 1.1345e-02, 2.2525e-02, 4.9953e-02, 5.6719e-02, 1.3663e-01,
        1.2687e-02, 8.6335e-02, 1.0520e-01, 1.5451e-02, 1.2925e-04, 1.9307e-01,
        8.3531e-02, 4.0295e-02, 8.6044e-02, 1.9233e-03, 5.0438e-02, 7.2858e-02,
        2.9081e-01, 4.1137e-02, 8.1953e-02, 2.6240e-02, 1.3748e-02, 9.2103e-03,
        1.5922e-01, 2.0356e-02, 1.0265e-02, 9.1713e-03, 2.8604e-02, 1.0465e-01,
        2.1228e-01, 9.4868e-02, 2.6861e-01, 2.1520e-01, 2.6087e-01, 1.9837e-02,
        2.5938e-01, 3.6267e-02, 9.4202e-02, 1.2113e-02, 1.1821e-01, 2.9738e-01,
        2.7033e-01, 5.8494e-02, 5.2696e-02, 7.5274e-02, 1.8998e-01, 6.7037e-02,
        2.5757e-01, 1.2583e-01, 1.0542e-01, 3.3074e-03, 1.7866e-01, 5.0731e-03,
        1.6017e-01, 4.4592e-02, 9.3520e-02, 3.4442e-02, 1.5971e-01, 1.1416e-01,
        6.0802e-02, 5.1274e-02, 1.5912e-01, 9.0304e-03, 1.8733e-02, 6.6628e-02,
        2.3394e-01, 8.6778e-02, 1.5959e-03, 1.2474e-04, 4.3709e-03, 3.2018e-01,
        7.0886e-02, 1.3386e-01, 3.7114e-02, 3.3176e-02, 1.1554e-02, 2.4816e-01,
        7.6743e-04, 8.8823e-02, 5.0309e-02, 1.0322e-01, 7.3093e-04, 1.1005e-01,
        2.4152e-01, 6.6228e-02, 1.7774e-01, 1.3416e-01, 3.3421e-02, 1.1174e-01,
        1.3868e-04, 3.9759e-02, 1.7593e-03, 4.2405e-02, 2.4121e-03, 7.4338e-02,
        3.6380e-02, 4.5222e-02, 4.4548e-02, 3.0275e-01, 2.8310e-03, 9.3442e-02,
        1.6900e-01, 5.0247e-02, 7.4184e-02, 3.7366e-02, 3.5189e-03, 8.1429e-02,
        3.4794e-02, 1.5642e-01, 1.3895e-01, 3.5395e-02, 1.8516e-02, 5.8849e-02,
        7.2751e-02, 9.0983e-03, 1.1963e-02, 8.5344e-02, 1.1008e-02, 5.2748e-03,
        3.5494e-01, 1.4271e-02, 1.4181e-02, 1.3493e-02, 1.3739e-01, 1.2530e-01,
        6.3124e-03, 9.5517e-02, 1.8540e-01, 3.0154e-01, 2.4171e-02, 2.8534e-02,
        2.0421e-02, 5.0726e-02, 9.5971e-02, 9.0675e-02, 7.4921e-02, 1.1120e-01,
        7.9875e-03, 5.9811e-02, 1.4418e-02, 2.9199e-01, 1.3288e-02, 3.1111e-02,
        1.5000e-03, 1.4681e-02, 8.9895e-03, 1.1493e-01, 2.7394e-03, 6.9751e-02,
        1.6848e-02, 3.6971e-02, 1.8521e-02, 1.4286e-01, 9.1847e-02, 4.0920e-02,
        9.9552e-02, 1.6491e-01, 4.2057e-02, 1.6483e-01, 3.2640e-01, 4.1992e-02,
        1.0103e-01, 3.3269e-03, 1.2311e-01, 1.2103e-02, 4.4567e-02, 3.7585e-01,
        1.1505e-03, 1.0208e-02, 1.6483e-01, 2.6683e-02, 1.1661e-01, 5.1086e-02,
        1.5781e-01, 1.2231e-01, 7.7338e-02, 4.5695e-03, 2.5649e-03, 3.7244e-01,
        1.0161e-02, 1.1174e-02, 5.4433e-02, 1.6329e-02])
net.mlp.net.0.batch_norm.running_var tensor([0.6626, 0.6803, 0.6768, 0.6925, 0.6589, 0.6727, 0.6644, 0.6727, 0.6577,
        0.6854, 0.6654, 0.6904, 0.6563, 0.9315, 0.7817, 0.6564, 0.6668, 0.6650,
        0.6775, 0.6603, 0.6850, 0.6635, 0.6728, 0.6688, 0.6606, 0.6883, 0.6561,
        0.6659, 0.6562, 0.6877, 0.6561, 0.7765, 0.7503, 0.6984, 0.6882, 0.6561,
        0.6911, 0.6713, 0.6974, 0.6615, 0.6837, 0.6749, 0.6678, 0.7003, 0.6763,
        0.6598, 0.6562, 0.7143, 0.6561, 0.6838, 0.6688, 0.7448, 0.6674, 0.7071,
        0.6740, 0.7280, 0.7026, 0.6564, 0.6944, 0.6562, 0.8564, 0.6868, 0.6907,
        0.6568, 0.7140, 0.6781, 0.6594, 0.6900, 0.6573, 0.6841, 0.6608, 0.6610,
        0.6655, 0.6596, 0.6620, 0.7165, 0.6656, 0.7034, 0.6752, 0.6750, 0.6980,
        0.6601, 0.6561, 0.7102, 0.6738, 0.6731, 0.6784, 0.6570, 0.7321, 0.6787,
        0.6965, 0.6879, 0.6764, 0.6621, 0.6793, 0.6653, 0.6888, 0.6613, 0.6587,
        0.6678, 0.6605, 0.6816, 0.6836, 0.7018, 0.7297, 0.7079, 0.7102, 0.6737,
        0.7565, 0.7114, 0.6819, 0.6611, 0.6992, 0.6917, 0.7135, 0.6732, 0.6845,
        0.6736, 0.6958, 0.6807, 0.7347, 0.6891, 0.6725, 0.6568, 0.6771, 0.6573,
        0.7652, 0.6717, 0.6817, 0.6824, 0.7926, 0.6880, 0.6689, 0.7219, 0.9063,
        0.6583, 0.6605, 0.6746, 0.6887, 0.7686, 0.6569, 0.6561, 0.6571, 0.6877,
        0.6750, 0.6846, 0.6624, 0.6645, 0.6587, 0.7050, 0.6562, 0.6875, 0.6723,
        0.6844, 0.6562, 0.6774, 0.7599, 0.6770, 0.7048, 0.6849, 0.6664, 0.6868,
        0.6561, 0.6731, 0.6570, 0.6657, 0.6566, 0.6938, 0.6670, 0.6670, 0.6690,
        0.6986, 0.6568, 0.7187, 0.6941, 0.7511, 0.7193, 0.6649, 0.6573, 0.6831,
        0.6687, 0.6867, 0.6803, 0.6665, 0.6603, 0.6655, 0.6728, 0.6584, 0.6657,
        0.6738, 0.6646, 0.6575, 0.6853, 0.6593, 0.6594, 0.6740, 0.6951, 0.6965,
        0.6583, 0.6975, 0.6965, 0.7182, 0.7052, 0.6615, 0.6618, 0.6807, 0.6769,
        0.6893, 0.6741, 0.6811, 0.6577, 0.6739, 0.6617, 0.7384, 0.6596, 0.6685,
        0.6564, 0.6655, 0.6617, 0.6957, 0.6570, 0.7146, 0.6764, 0.6642, 0.6619,
        0.7032, 0.6932, 0.6861, 0.6808, 0.7069, 0.6667, 0.6799, 0.6856, 0.6672,
        0.6751, 0.6568, 0.7479, 0.6583, 0.6708, 0.7295, 0.6563, 0.6628, 0.7004,
        0.6868, 0.7115, 0.6844, 0.6732, 0.6861, 0.6697, 0.6567, 0.6569, 0.7160,
        0.6589, 0.6587, 0.6778, 0.6832])
net.mlp.net.0.batch_norm.num_batches_tracked tensor(4)
net.mlp.net.1.linear.weight tensor([[ 0.0672,  0.0691, -0.0412,  ...,  0.0499,  0.1240, -0.0574],
        [ 0.0210, -0.0059, -0.0060,  ..., -0.0606, -0.0021,  0.0284],
        [ 0.1396, -0.0385, -0.0624,  ...,  0.0343, -0.0480, -0.0117],
        ...,
        [-0.0204,  0.0282, -0.0880,  ...,  0.0130,  0.0676, -0.0637],
        [ 0.0036, -0.0151, -0.0589,  ...,  0.0912, -0.0406,  0.0541],
        [ 0.0100, -0.0475, -0.0623,  ..., -0.0612,  0.1040, -0.0475]])
net.mlp.net.1.linear.bias tensor([-2.0436e-02,  2.0340e-02,  2.9355e-02, -2.5203e-02,  1.6191e-02,
        -3.4621e-02, -3.0258e-02, -1.0038e-02, -3.4504e-02, -2.6356e-02,
         7.0364e-03, -5.6902e-03,  1.9902e-02,  1.4752e-02, -8.6100e-03,
        -3.1247e-02, -1.9780e-02,  3.6266e-03, -2.4042e-02,  2.2397e-02,
         4.6644e-03,  2.0580e-02,  9.6322e-03, -3.3629e-02, -8.3467e-03,
        -1.4918e-03, -6.7683e-03, -2.0124e-02, -7.3305e-03, -1.1397e-02,
        -2.3633e-03, -2.5116e-02,  1.6220e-02,  5.7978e-03, -1.8502e-03,
         1.9508e-02, -8.7467e-03, -2.5058e-02, -2.5549e-02, -1.8372e-02,
        -6.6646e-03, -3.1849e-02, -2.0076e-02,  1.0078e-02,  1.0923e-02,
         8.7699e-03, -1.7644e-02, -1.3856e-02,  1.3158e-02, -8.6865e-03,
         4.8880e-03,  2.3334e-02,  5.7857e-03,  1.0254e-02,  1.8723e-02,
         2.6751e-02, -1.6050e-02,  2.6178e-03,  1.0999e-02, -3.0787e-02,
         2.1032e-02,  1.4957e-02, -3.1172e-03,  2.2104e-02,  1.7464e-02,
         4.0220e-03, -2.2197e-02, -2.9382e-02, -2.4393e-02,  2.1530e-02,
        -2.8273e-02,  1.6885e-02,  4.2965e-03,  8.2131e-05,  3.3266e-02,
        -7.5779e-03, -1.6099e-02, -2.1572e-02,  2.3139e-02,  3.4948e-02,
        -1.1335e-03,  3.2072e-02, -3.5423e-03, -1.1402e-02,  2.5371e-02,
         2.3186e-02, -2.9157e-02,  2.6810e-02,  1.1924e-02,  3.3976e-02,
         4.1842e-03, -9.9243e-04,  1.5056e-02, -4.0495e-03, -2.4452e-02,
         8.6530e-03, -7.7292e-04,  1.4178e-02,  1.7440e-02,  8.5389e-03,
         2.6054e-04,  7.6088e-03,  3.3352e-02, -2.9686e-02,  3.2444e-02,
        -2.8245e-02,  3.1585e-02, -4.0233e-03, -2.0456e-02,  1.9116e-02,
        -2.2426e-02, -1.6852e-02, -2.3497e-02,  8.6373e-03, -1.4002e-02,
        -3.4362e-02, -2.5777e-02, -2.5130e-02, -2.8584e-02, -5.6210e-04,
         9.4400e-03,  3.8355e-03,  1.2257e-02, -3.5811e-02,  1.5009e-02,
         3.6252e-02,  2.4635e-02,  3.5030e-02,  2.3658e-02,  2.6074e-02,
         3.0580e-02, -6.5322e-03,  3.0069e-02,  3.0618e-02, -2.9600e-02,
         2.1109e-02, -8.6538e-03, -1.2693e-02, -1.6598e-02, -2.1375e-02,
        -1.6466e-03, -5.7121e-03,  2.8491e-02,  2.5855e-02, -3.1249e-03,
         1.1527e-03, -3.2455e-02, -2.4967e-02, -1.9950e-02, -2.9063e-02,
        -1.3656e-02, -3.3270e-02, -3.2158e-02, -3.4903e-02,  2.9732e-02,
        -3.3728e-02, -1.5215e-02, -2.3723e-02, -7.2918e-03,  2.1793e-02,
         1.9771e-03,  2.1047e-02, -3.0761e-02,  1.6391e-03,  1.0179e-02,
         1.3735e-02, -1.9149e-02,  1.8498e-02,  2.4236e-02,  3.2456e-02,
         1.7743e-02,  7.0930e-03,  3.0340e-02, -2.7948e-02,  3.0087e-02,
        -2.0845e-03, -1.3943e-02, -1.8209e-02, -2.0866e-02,  5.3135e-03,
        -3.3314e-02, -2.1853e-03, -2.7757e-02, -1.7834e-02,  1.7956e-02,
         1.1220e-02,  1.1473e-02, -1.2440e-02,  7.3208e-03,  2.1334e-02,
        -2.0430e-03, -5.4062e-03, -1.0021e-02,  3.6823e-02,  3.8797e-03,
         6.5075e-03, -1.9647e-02, -2.3398e-02,  4.7191e-03,  2.4570e-03,
         1.3787e-02,  7.6005e-03, -2.1653e-02, -3.3879e-02, -3.6746e-03,
         3.0792e-02,  2.0605e-02, -3.1713e-02,  2.3985e-02,  1.5123e-02,
        -7.6861e-03, -4.0843e-03, -8.9170e-03, -1.6411e-02,  1.0563e-02,
         2.7015e-02, -4.5257e-03, -2.7153e-02,  1.9211e-02, -1.7772e-02,
        -1.3547e-02,  1.4667e-02,  3.0069e-02, -2.4622e-02, -2.4882e-02,
         8.6247e-03, -1.2704e-02,  2.2775e-02, -4.5789e-03, -2.9956e-02,
         2.0988e-02, -1.8566e-02, -1.7917e-02,  3.1349e-02,  3.2388e-02,
        -4.6820e-03,  1.3161e-02, -2.0443e-02, -1.8094e-02, -5.4586e-03,
         3.8095e-03, -3.2185e-02,  2.1612e-02,  2.8271e-02, -3.1457e-02,
        -2.5125e-02, -2.0947e-03,  2.1913e-02, -3.1224e-02, -2.0574e-02,
        -2.9647e-02, -1.8720e-02,  1.8355e-03, -3.1047e-02, -3.5972e-02,
         3.2642e-02])
net.mlp.net.1.batch_norm.weight tensor([0.5593, 0.5589, 0.5609, 0.5616, 0.5615, 0.5602, 0.5631, 0.5639, 0.5620,
        0.5614, 0.5616, 0.5639, 0.5619, 0.5620, 0.5617, 0.5594, 0.5587, 0.5607,
        0.5634, 0.5604, 0.5632, 0.5609, 0.5597, 0.5627, 0.5591, 0.5598, 0.5600,
        0.5636, 0.5610, 0.5588, 0.5598, 0.5636, 0.5637, 0.5592, 0.5605, 0.5592,
        0.5607, 0.5621, 0.5591, 0.5616, 0.5630, 0.5609, 0.5634, 0.5634, 0.5628,
        0.5588, 0.5626, 0.5605, 0.5592, 0.5589, 0.5621, 0.5595, 0.5601, 0.5610,
        0.5602, 0.5609, 0.5594, 0.5629, 0.5627, 0.5615, 0.5608, 0.5598, 0.5603,
        0.5630, 0.5595, 0.5591, 0.5632, 0.5635, 0.5634, 0.5589, 0.5632, 0.5612,
        0.5629, 0.5608, 0.5613, 0.5632, 0.5609, 0.5590, 0.5629, 0.5635, 0.5597,
        0.5607, 0.5591, 0.5595, 0.5590, 0.5618, 0.5599, 0.5588, 0.5633, 0.5619,
        0.5630, 0.5634, 0.5594, 0.5625, 0.5598, 0.5588, 0.5617, 0.5613, 0.5610,
        0.5634, 0.5605, 0.5594, 0.5588, 0.5615, 0.5611, 0.5595, 0.5627, 0.5591,
        0.5620, 0.5631, 0.5594, 0.5612, 0.5629, 0.5612, 0.5625, 0.5613, 0.5634,
        0.5611, 0.5620, 0.5596, 0.5598, 0.5590, 0.5618, 0.5610, 0.5613, 0.5638,
        0.5618, 0.5638, 0.5614, 0.5636, 0.5630, 0.5620, 0.5600, 0.5626, 0.5610,
        0.5596, 0.5605, 0.5637, 0.5617, 0.5585, 0.5604, 0.5633, 0.5595, 0.5629,
        0.5589, 0.5592, 0.5600, 0.5636, 0.5611, 0.5603, 0.5639, 0.5636, 0.5586,
        0.5606, 0.5625, 0.5631, 0.5639, 0.5615, 0.5599, 0.5633, 0.5637, 0.5614,
        0.5630, 0.5633, 0.5622, 0.5598, 0.5636, 0.5590, 0.5597, 0.5612, 0.5614,
        0.5608, 0.5595, 0.5602, 0.5632, 0.5637, 0.5589, 0.5622, 0.5621, 0.5638,
        0.5611, 0.5594, 0.5619, 0.5630, 0.5589, 0.5627, 0.5622, 0.5606, 0.5623,
        0.5636, 0.5619, 0.5596, 0.5588, 0.5599, 0.5617, 0.5627, 0.5611, 0.5629,
        0.5614, 0.5632, 0.5635, 0.5596, 0.5640, 0.5626, 0.5631, 0.5604, 0.5627,
        0.5620, 0.5610, 0.5621, 0.5598, 0.5605, 0.5624, 0.5596, 0.5587, 0.5628,
        0.5600, 0.5638, 0.5626, 0.5610, 0.5635, 0.5591, 0.5596, 0.5593, 0.5595,
        0.5633, 0.5604, 0.5609, 0.5636, 0.5632, 0.5612, 0.5603, 0.5593, 0.5613,
        0.5638, 0.5632, 0.5629, 0.5620, 0.5633, 0.5611, 0.5633, 0.5587, 0.5592,
        0.5613, 0.5591, 0.5606, 0.5597, 0.5620, 0.5596, 0.5633, 0.5609, 0.5615,
        0.5620, 0.5631, 0.5630, 0.5614])
net.mlp.net.1.batch_norm.bias tensor([-1.6024e-03, -1.6227e-04,  5.5582e-04,  4.4030e-05,  2.5327e-05,
        -1.8402e-03, -2.7428e-03, -8.3947e-04,  4.0351e-04,  1.6604e-03,
        -7.3381e-04,  3.3207e-04,  1.8157e-03,  1.7965e-03, -6.8590e-04,
         1.1936e-03, -3.5725e-04,  3.1017e-04, -5.8727e-05, -2.4777e-03,
        -1.3340e-03, -9.9084e-04, -1.3628e-03,  2.0347e-03, -2.3178e-03,
         6.9847e-05, -2.3937e-03,  1.5002e-03, -8.1650e-04,  2.5635e-03,
        -1.7463e-03,  4.1054e-04, -2.0456e-03,  2.2548e-03, -1.7014e-03,
        -8.2753e-04, -5.1333e-04,  2.7601e-03,  5.9089e-04,  1.3757e-03,
         5.6008e-04,  2.1335e-03, -1.7297e-04,  5.4552e-05,  2.0566e-03,
         6.4879e-04, -1.9140e-03,  4.8530e-05,  1.9092e-03, -8.9758e-04,
         1.4935e-03, -5.9443e-04,  9.8525e-04,  1.4357e-03,  6.0811e-04,
        -1.2947e-03,  7.0789e-04,  6.7875e-04,  1.9467e-04, -1.0227e-03,
        -2.1004e-03, -1.1426e-03, -2.6873e-03, -4.6862e-04, -2.3638e-03,
         7.2369e-05,  1.1448e-03,  1.1918e-03, -2.5937e-03,  1.3412e-04,
        -2.6000e-03, -6.5773e-04,  1.9973e-03, -2.5926e-04, -4.2641e-04,
         7.0398e-04,  2.1110e-04,  1.1415e-03,  7.4020e-04,  1.9280e-03,
        -1.1941e-03, -6.2423e-05, -1.4558e-03, -1.9349e-03,  2.1303e-03,
        -5.9816e-04, -2.3933e-03, -3.3590e-04,  6.1327e-04, -1.3455e-03,
        -1.7009e-03,  1.0419e-03,  1.4116e-03,  1.5975e-03, -1.6540e-03,
        -2.0052e-04,  4.1594e-04,  4.9806e-04, -7.2801e-05, -2.1670e-03,
         5.1031e-04,  3.2526e-04,  8.8498e-04, -1.6528e-03, -2.1569e-03,
         1.7090e-03, -1.6612e-04, -6.7643e-04, -2.1232e-03,  1.1280e-03,
         2.1921e-03, -1.9268e-03,  2.4103e-03, -1.6753e-03, -1.6605e-03,
        -1.6889e-03, -1.4888e-03,  1.0367e-03,  5.4298e-04,  1.3982e-03,
        -1.9207e-03, -2.9896e-04,  3.2685e-04, -1.0911e-03, -8.8555e-04,
         3.5353e-05, -4.0926e-04,  3.5094e-04, -1.8272e-03, -4.2885e-04,
         5.9983e-04,  7.7307e-04,  1.9103e-03,  7.1686e-05,  1.3676e-03,
        -6.9594e-04,  5.3550e-04,  3.4529e-04,  2.6536e-03,  1.8250e-03,
         3.5536e-04, -3.9857e-04, -7.8353e-04,  9.1168e-04,  2.2896e-03,
        -2.3898e-04,  1.7295e-03, -1.6390e-03,  1.2990e-03, -1.0686e-03,
        -2.5117e-03,  1.3873e-03, -2.0714e-03,  1.5708e-06, -2.6004e-03,
         1.4292e-03,  1.9034e-03, -5.8349e-04, -6.5487e-04, -3.0608e-04,
        -2.1980e-03,  6.6126e-04,  1.6726e-04, -3.2752e-04,  5.3230e-04,
         6.9803e-04, -9.1353e-05, -1.3590e-03,  1.9289e-03,  4.4015e-04,
         5.3743e-04, -5.6841e-04, -2.5068e-03, -2.0549e-03, -1.4733e-03,
        -1.4565e-03,  1.8382e-03,  4.0966e-04, -2.5937e-03, -9.8421e-04,
         2.0322e-03,  2.0641e-03,  1.7704e-04, -5.6025e-06, -1.1987e-03,
        -1.6640e-03, -1.0932e-03, -1.1311e-03, -2.6837e-04,  2.5394e-03,
         7.2477e-06,  1.3808e-03,  4.7374e-04,  5.6742e-04,  1.7924e-03,
        -1.7725e-03, -3.7370e-04,  2.3108e-04, -6.1018e-04, -1.7173e-03,
        -2.6432e-03, -2.2107e-03, -1.5427e-03, -2.4972e-03,  2.0308e-03,
        -6.9518e-04,  1.7123e-03, -8.8953e-04,  2.3707e-03, -3.0364e-04,
         1.8974e-03,  5.0546e-04, -2.2704e-03, -1.0311e-03, -1.9296e-04,
        -2.3511e-03,  9.4353e-04, -8.2391e-04,  6.1928e-05, -2.6060e-04,
        -2.5344e-03,  2.1882e-03, -1.6013e-03,  1.0154e-03,  8.6499e-04,
         1.6900e-03,  7.7022e-04,  1.1393e-03, -1.5535e-03,  5.7894e-04,
         1.0901e-04,  1.7171e-03,  9.6211e-04,  2.1302e-03,  4.9589e-04,
        -8.3251e-04,  2.4521e-03,  2.2530e-03,  1.9744e-03,  1.0258e-03,
         5.6915e-05, -1.1901e-03, -2.5789e-03,  6.0860e-04,  1.5894e-03,
        -1.3170e-03, -4.7182e-04, -1.4510e-03, -2.0363e-03, -3.4393e-04,
        -1.5438e-03, -3.3064e-04,  1.0976e-03, -1.1733e-03,  2.1846e-03,
         1.8351e-03])
net.mlp.net.1.batch_norm.running_mean tensor([0.0941, 0.1098, 0.0886, 0.1309, 0.0961, 0.0932, 0.1211, 0.1164, 0.0730,
        0.1149, 0.1178, 0.0788, 0.1538, 0.1187, 0.1119, 0.1147, 0.1597, 0.1238,
        0.0753, 0.0727, 0.1363, 0.1699, 0.1047, 0.1634, 0.1109, 0.1274, 0.1161,
        0.0769, 0.0898, 0.0806, 0.1352, 0.0764, 0.1059, 0.0927, 0.1002, 0.1082,
        0.1294, 0.1018, 0.0870, 0.0782, 0.0824, 0.1278, 0.0917, 0.1102, 0.0876,
        0.1835, 0.0972, 0.1109, 0.1205, 0.1340, 0.1070, 0.1064, 0.1083, 0.1086,
        0.1246, 0.1021, 0.0959, 0.1116, 0.1066, 0.1441, 0.1126, 0.1201, 0.1195,
        0.0978, 0.1171, 0.0940, 0.1075, 0.1050, 0.1021, 0.0764, 0.1112, 0.0938,
        0.1167, 0.1152, 0.1551, 0.0884, 0.1370, 0.0990, 0.1249, 0.1468, 0.1236,
        0.1160, 0.0983, 0.1010, 0.1753, 0.1137, 0.1514, 0.0987, 0.0755, 0.1034,
        0.0894, 0.1063, 0.0891, 0.1577, 0.0986, 0.1226, 0.0793, 0.1214, 0.1734,
        0.1044, 0.0995, 0.1235, 0.1383, 0.1067, 0.0999, 0.0854, 0.1197, 0.0796,
        0.0862, 0.0963, 0.1076, 0.1012, 0.1184, 0.0950, 0.1020, 0.1086, 0.1490,
        0.0879, 0.0919, 0.1204, 0.0865, 0.1058, 0.0891, 0.0772, 0.1552, 0.1191,
        0.1071, 0.0935, 0.1508, 0.0814, 0.0946, 0.1502, 0.1355, 0.1608, 0.1099,
        0.1112, 0.1034, 0.0886, 0.1406, 0.0984, 0.1507, 0.1509, 0.1076, 0.0814,
        0.0963, 0.1192, 0.0897, 0.0756, 0.1243, 0.0909, 0.0959, 0.0727, 0.1090,
        0.0990, 0.1322, 0.0648, 0.1034, 0.0830, 0.0988, 0.1110, 0.1073, 0.1034,
        0.1080, 0.1009, 0.0901, 0.1106, 0.1193, 0.0740, 0.1033, 0.1242, 0.1720,
        0.1475, 0.1204, 0.1185, 0.1044, 0.0844, 0.0866, 0.0730, 0.1136, 0.1164,
        0.1251, 0.0985, 0.1767, 0.1154, 0.1152, 0.0864, 0.1334, 0.1133, 0.0960,
        0.0998, 0.0946, 0.0629, 0.1013, 0.0939, 0.1711, 0.0819, 0.0957, 0.0969,
        0.1508, 0.0921, 0.0962, 0.1044, 0.0804, 0.0888, 0.1172, 0.0895, 0.1422,
        0.0704, 0.1082, 0.1169, 0.0856, 0.0978, 0.0948, 0.0968, 0.0784, 0.1375,
        0.1021, 0.0927, 0.0815, 0.1101, 0.1310, 0.1096, 0.1749, 0.1056, 0.0753,
        0.1159, 0.1195, 0.1258, 0.1117, 0.0981, 0.1134, 0.1003, 0.0822, 0.1291,
        0.1534, 0.1158, 0.1365, 0.1122, 0.1432, 0.1162, 0.0947, 0.0706, 0.1028,
        0.1066, 0.0985, 0.0647, 0.1006, 0.0979, 0.0863, 0.0750, 0.0939, 0.1090,
        0.1298, 0.1025, 0.0998, 0.1267])
net.mlp.net.1.batch_norm.running_var tensor([0.7092, 0.9065, 0.7186, 0.7528, 0.7120, 0.7561, 0.7958, 0.7669, 0.7106,
        0.7625, 0.7993, 0.7097, 0.9484, 0.7717, 0.8102, 0.7540, 0.7905, 0.8465,
        0.7130, 0.7043, 0.8159, 1.0600, 0.7247, 0.8385, 0.7873, 0.7634, 0.7509,
        0.7451, 0.7182, 0.6991, 0.7965, 0.7164, 0.7303, 0.7187, 0.7361, 0.7314,
        0.7475, 0.7201, 0.7275, 0.7017, 0.7050, 0.7660, 0.7691, 0.7492, 0.8275,
        0.8767, 0.7376, 0.7368, 0.7635, 0.7753, 0.7883, 0.7418, 0.7333, 0.7724,
        0.7424, 0.7129, 0.7146, 0.7412, 0.7287, 0.9484, 0.7369, 0.7338, 0.7479,
        0.7093, 0.7182, 0.7207, 0.7307, 0.7516, 0.7110, 0.7112, 0.7608, 0.7488,
        0.7423, 0.7777, 0.7982, 0.7062, 0.7978, 0.7265, 0.7770, 0.7635, 0.7703,
        0.7469, 0.7447, 0.7319, 0.8230, 0.7259, 0.7742, 0.7492, 0.7026, 0.7346,
        0.7329, 0.7296, 0.7134, 1.1088, 0.7683, 0.7810, 0.7074, 0.7999, 0.8318,
        0.7197, 0.7211, 0.7429, 0.7388, 0.8665, 0.7448, 0.7087, 0.7653, 0.7100,
        0.7438, 0.7102, 0.7660, 0.7335, 0.7732, 0.7352, 0.7315, 0.7405, 0.9064,
        0.7306, 0.7621, 0.8318, 0.6979, 0.7276, 0.7131, 0.7205, 0.8056, 0.7378,
        0.7687, 0.7241, 0.9316, 0.7160, 0.7682, 0.7927, 0.9792, 0.8117, 0.7457,
        0.7216, 0.7586, 0.8347, 0.7720, 0.7222, 0.8174, 0.8346, 0.7298, 0.7032,
        0.7274, 0.7296, 0.7198, 0.7313, 1.0868, 0.7159, 0.7693, 0.7235, 0.7319,
        0.7732, 0.7864, 0.6935, 0.7210, 0.7154, 0.7470, 0.7670, 0.7232, 0.7129,
        0.7652, 0.7485, 0.8011, 0.7191, 0.8470, 0.7028, 0.7495, 0.7452, 0.8552,
        0.8131, 0.7945, 0.7658, 0.7303, 0.7219, 0.7265, 0.7053, 0.7361, 0.7268,
        0.7645, 0.7537, 0.7927, 0.7278, 0.7162, 0.7651, 0.7773, 0.7493, 0.7675,
        0.8397, 0.7250, 0.6961, 0.7141, 0.7181, 0.8365, 0.7328, 0.7084, 0.7284,
        1.0207, 0.7116, 0.7208, 0.7296, 0.7105, 0.7164, 0.8478, 0.6991, 0.7420,
        0.7660, 0.7687, 0.7513, 0.7087, 0.7419, 0.7127, 0.7209, 0.6964, 0.7775,
        0.7668, 0.7111, 0.7042, 0.7441, 0.7903, 0.7315, 0.8248, 0.7621, 0.7074,
        0.7311, 0.8318, 0.7687, 0.7564, 0.7158, 0.8689, 0.8174, 0.7130, 0.7510,
        0.8060, 0.7851, 0.7710, 0.7365, 0.7972, 0.8717, 0.8647, 0.6939, 0.7267,
        0.7450, 0.7557, 0.7080, 0.7264, 0.7078, 0.7121, 0.7125, 0.7204, 0.7194,
        0.7400, 0.7243, 0.7725, 0.7398])
net.mlp.net.1.batch_norm.num_batches_tracked tensor(4)
net.mlp.net.2.linear.weight tensor([[ 0.0718,  0.0436, -0.0420,  ..., -0.0680, -0.0155,  0.0296],
        [ 0.0931,  0.0079, -0.0312,  ...,  0.0002, -0.0687,  0.0596],
        [ 0.0586, -0.0004, -0.0103,  ...,  0.0503, -0.0877, -0.0084],
        ...,
        [-0.0559, -0.0592, -0.0202,  ...,  0.0045, -0.0049,  0.0336],
        [-0.0566,  0.0770,  0.0846,  ...,  0.0176, -0.0005,  0.0586],
        [-0.0395, -0.0485,  0.0026,  ..., -0.0092,  0.0095, -0.0001]])
net.mlp.net.2.linear.bias tensor([-1.3542e-02,  2.2477e-02,  7.1690e-03,  2.0459e-02,  1.6944e-02,
         1.1273e-02,  1.5014e-03,  2.5678e-02, -2.9902e-02, -9.3205e-03,
         6.9089e-03,  2.8750e-02,  1.7068e-02,  6.1711e-03, -1.2076e-02,
        -5.6007e-04,  6.0386e-03, -3.5233e-02,  1.2223e-03, -7.5870e-03,
        -8.4708e-03, -2.5406e-03,  3.2945e-02, -8.1744e-03,  1.2330e-02,
        -4.0715e-03, -2.0371e-02,  6.0156e-03, -6.7153e-03,  7.1726e-03,
         8.8925e-03, -6.0620e-03, -1.3138e-02, -2.5499e-02,  1.9542e-02,
        -7.7193e-03, -2.5220e-02, -3.2583e-03, -1.1690e-03, -1.8173e-02,
         3.3091e-02, -3.1006e-02, -3.2055e-02,  2.4561e-02, -1.6858e-03,
        -2.2334e-02, -1.7988e-02,  2.4213e-02, -3.6922e-03, -1.1185e-02,
        -2.3945e-02, -1.7591e-02, -2.4585e-02, -2.5137e-02,  1.4152e-03,
         2.8925e-02,  2.1432e-02,  1.4074e-02, -1.0751e-02,  8.5075e-03,
         1.0374e-02, -2.1611e-02,  1.0103e-03, -3.2961e-03, -2.7129e-02,
        -3.0367e-04, -2.5073e-02, -2.3853e-02,  2.5440e-02, -1.1418e-03,
         2.0154e-02, -2.4020e-02,  1.8818e-02, -2.4077e-02,  4.1363e-03,
         2.3184e-02, -2.6969e-02,  1.8481e-02,  1.6669e-02, -1.2984e-02,
        -1.6534e-02,  6.9589e-03,  1.9983e-02, -3.2002e-02,  3.6322e-02,
         3.7073e-02, -2.7641e-03, -8.8541e-03,  5.3455e-03,  1.4483e-02,
        -4.1168e-04,  2.5209e-02,  6.3905e-03, -1.1310e-02,  2.5980e-02,
         5.9614e-03,  3.8360e-03,  1.5721e-02,  1.0201e-02, -8.8222e-03,
         3.2573e-02,  1.6123e-02, -2.0279e-02, -2.5068e-02,  2.1554e-02,
        -3.3110e-02, -9.0372e-03,  1.4307e-02,  7.2323e-03,  5.6283e-03,
        -3.2346e-02, -2.0127e-02,  2.6905e-02,  7.4765e-03, -2.7846e-02,
         5.6228e-03,  1.0550e-02, -3.3040e-02,  2.7831e-02,  8.7404e-03,
         2.0271e-02, -1.8215e-02,  1.2236e-02,  2.9403e-02, -4.6850e-03,
         3.7541e-03,  1.9833e-02,  2.4010e-02,  2.1957e-02, -1.3954e-02,
         4.2497e-03,  1.8506e-02, -3.0811e-02, -3.0429e-02, -2.3608e-02,
        -1.7290e-02, -2.7272e-02,  1.1627e-02,  3.3339e-02, -3.0532e-04,
        -2.1343e-03, -2.5145e-02,  5.4017e-05, -1.1697e-02, -1.2189e-02,
         2.7066e-02,  2.3394e-02,  9.7130e-05, -6.8724e-03, -2.0220e-02,
         2.6472e-02, -1.4817e-02, -3.4380e-02,  2.6081e-03, -1.0823e-02,
         2.4171e-02, -6.6796e-04, -2.7740e-02,  2.3592e-02,  3.2576e-02,
         1.7997e-02, -1.8398e-02,  1.3453e-02, -3.4837e-02, -1.2193e-02,
        -4.4059e-03,  2.0064e-03, -2.1163e-02,  1.8488e-02, -1.2110e-02,
        -2.1621e-02,  1.5150e-02,  3.1415e-03,  2.0795e-02,  2.5745e-02,
        -8.8733e-03,  9.4505e-03, -3.4582e-02,  8.3569e-03, -3.0774e-03,
        -5.2997e-03,  1.5784e-02, -1.9188e-02, -6.8868e-03,  3.7380e-02,
        -2.1506e-02, -2.8360e-02, -2.0468e-02, -1.6056e-02,  3.1203e-02,
         1.3883e-02,  1.8934e-03, -1.3825e-02,  2.2388e-02,  2.2550e-02,
         2.4286e-02,  1.2770e-03, -2.7838e-02,  2.9948e-02,  3.1304e-02,
         1.8161e-02, -1.7944e-02, -2.5603e-02,  3.0185e-02,  5.8351e-03,
         3.6189e-02,  2.8147e-02,  1.2139e-04,  2.0739e-02, -5.8981e-03,
         3.4962e-03,  1.0115e-02,  3.5610e-02,  2.6759e-02,  3.3560e-02,
         7.0760e-03, -7.6886e-03,  8.8139e-03,  4.5063e-04,  7.9103e-03,
         1.9268e-02, -2.7354e-03,  1.9601e-02,  4.8982e-03, -9.6629e-03,
         1.9546e-02, -1.4535e-02,  2.0295e-02,  1.0123e-02,  1.2650e-02,
         2.1707e-02,  1.4687e-02,  1.6286e-02, -1.2558e-02, -1.6838e-02,
         3.3177e-03,  2.8475e-03,  3.5816e-03,  3.2930e-04, -1.8898e-02,
         2.8688e-02,  4.1981e-03,  1.2601e-03,  1.2393e-02, -1.5123e-02,
        -7.0535e-03,  2.1629e-02,  3.2118e-02, -2.0578e-02, -2.9316e-02,
         2.9358e-02,  2.9469e-02,  1.2715e-02, -3.1722e-02, -2.4610e-03,
         5.4495e-03])
net.mlp.net.2.batch_norm.weight tensor([0.5610, 0.5616, 0.5610, 0.5592, 0.5603, 0.5623, 0.5625, 0.5627, 0.5631,
        0.5603, 0.5620, 0.5607, 0.5598, 0.5619, 0.5623, 0.5636, 0.5612, 0.5601,
        0.5637, 0.5587, 0.5616, 0.5617, 0.5589, 0.5594, 0.5634, 0.5635, 0.5626,
        0.5600, 0.5608, 0.5639, 0.5617, 0.5620, 0.5615, 0.5626, 0.5617, 0.5631,
        0.5620, 0.5628, 0.5617, 0.5585, 0.5602, 0.5601, 0.5635, 0.5608, 0.5591,
        0.5636, 0.5639, 0.5623, 0.5609, 0.5597, 0.5608, 0.5602, 0.5607, 0.5587,
        0.5628, 0.5603, 0.5615, 0.5585, 0.5603, 0.5634, 0.5614, 0.5637, 0.5617,
        0.5612, 0.5629, 0.5628, 0.5633, 0.5603, 0.5611, 0.5634, 0.5614, 0.5599,
        0.5591, 0.5595, 0.5638, 0.5601, 0.5632, 0.5637, 0.5620, 0.5588, 0.5637,
        0.5626, 0.5633, 0.5637, 0.5607, 0.5596, 0.5589, 0.5594, 0.5634, 0.5614,
        0.5602, 0.5615, 0.5599, 0.5631, 0.5602, 0.5625, 0.5609, 0.5616, 0.5621,
        0.5633, 0.5627, 0.5628, 0.5595, 0.5604, 0.5599, 0.5620, 0.5632, 0.5637,
        0.5592, 0.5623, 0.5597, 0.5604, 0.5634, 0.5638, 0.5590, 0.5622, 0.5600,
        0.5609, 0.5590, 0.5629, 0.5638, 0.5612, 0.5598, 0.5596, 0.5603, 0.5611,
        0.5618, 0.5597, 0.5614, 0.5610, 0.5588, 0.5617, 0.5621, 0.5595, 0.5629,
        0.5591, 0.5599, 0.5618, 0.5599, 0.5614, 0.5640, 0.5626, 0.5616, 0.5634,
        0.5617, 0.5615, 0.5632, 0.5612, 0.5632, 0.5586, 0.5608, 0.5619, 0.5624,
        0.5623, 0.5614, 0.5625, 0.5610, 0.5592, 0.5599, 0.5601, 0.5598, 0.5629,
        0.5630, 0.5605, 0.5597, 0.5610, 0.5610, 0.5610, 0.5613, 0.5625, 0.5618,
        0.5586, 0.5630, 0.5612, 0.5603, 0.5600, 0.5630, 0.5617, 0.5638, 0.5636,
        0.5629, 0.5595, 0.5614, 0.5637, 0.5635, 0.5614, 0.5603, 0.5594, 0.5617,
        0.5632, 0.5622, 0.5620, 0.5612, 0.5636, 0.5620, 0.5620, 0.5612, 0.5635,
        0.5594, 0.5638, 0.5599, 0.5634, 0.5633, 0.5623, 0.5623, 0.5640, 0.5636,
        0.5620, 0.5621, 0.5588, 0.5621, 0.5636, 0.5638, 0.5621, 0.5630, 0.5637,
        0.5587, 0.5635, 0.5612, 0.5635, 0.5622, 0.5604, 0.5639, 0.5611, 0.5629,
        0.5621, 0.5609, 0.5597, 0.5631, 0.5591, 0.5626, 0.5590, 0.5628, 0.5593,
        0.5617, 0.5591, 0.5633, 0.5618, 0.5610, 0.5632, 0.5630, 0.5614, 0.5625,
        0.5630, 0.5590, 0.5596, 0.5624, 0.5604, 0.5586, 0.5590, 0.5635, 0.5625,
        0.5609, 0.5623, 0.5612, 0.5621])
net.mlp.net.2.batch_norm.bias tensor([ 1.0178e-03, -8.9432e-04, -2.0394e-03, -1.6940e-03,  1.9743e-03,
         3.6504e-04, -2.2434e-03, -1.6461e-03,  2.5444e-03,  7.6054e-04,
        -2.5027e-03,  2.2218e-03,  2.6569e-03,  1.8867e-04, -2.5491e-03,
        -1.3789e-04, -4.3491e-04, -8.9567e-04,  1.8140e-03,  1.6316e-03,
        -2.8162e-04, -5.4252e-04, -9.5256e-04, -6.4172e-04, -1.7804e-03,
        -1.2654e-03, -2.4631e-03,  7.1586e-04,  1.8324e-03,  2.3059e-03,
         3.5084e-04,  3.1275e-04,  2.7583e-03, -2.5700e-03, -6.0792e-04,
         2.3436e-04, -3.3423e-04,  1.0982e-03,  1.6241e-03, -2.0164e-03,
        -2.5313e-03, -5.9969e-04, -2.3941e-04, -2.5282e-03,  2.3885e-04,
        -2.2822e-03, -2.7161e-03, -2.2515e-03, -1.5043e-03,  2.6684e-03,
        -8.2774e-04, -2.4031e-03, -1.6322e-03,  2.5623e-03,  6.7941e-04,
         2.2001e-03, -2.6164e-03,  1.5360e-03,  1.0297e-03, -1.2097e-03,
         1.2292e-04, -2.0124e-03, -6.4347e-04,  8.3580e-04, -1.7534e-04,
        -1.6518e-03,  8.9049e-04,  3.1753e-04, -1.1195e-03,  2.9427e-04,
        -1.6198e-03,  2.5371e-03,  5.6114e-04,  1.8084e-03,  1.3158e-03,
         8.3669e-04, -1.9242e-03,  1.5907e-03, -5.1714e-04,  2.5843e-03,
         1.4279e-03, -2.4488e-03, -9.0681e-04,  1.5816e-03, -1.0333e-03,
         1.0145e-03, -1.9958e-03,  1.9419e-03,  1.5487e-04,  2.0972e-03,
        -2.2805e-03,  1.8553e-03, -1.2080e-03, -1.5514e-03,  1.7337e-03,
        -8.3519e-04,  5.0936e-04,  1.0615e-03,  5.2872e-04, -5.4302e-04,
        -1.7993e-03,  1.5635e-03, -3.9002e-04, -1.9079e-03,  1.1545e-03,
        -2.3030e-03, -8.1146e-04,  7.8413e-04,  1.8209e-03, -7.4445e-04,
         1.0755e-03,  1.3796e-03, -1.1610e-03, -5.4688e-04,  2.7919e-04,
         1.3350e-03,  2.2923e-03,  3.4189e-04,  8.4525e-04,  2.2030e-04,
        -1.7879e-03, -1.2856e-03,  1.3114e-03, -9.5504e-04,  1.3916e-03,
        -1.6729e-03, -2.4925e-03, -4.6354e-04, -1.4482e-03, -2.0850e-03,
         5.6790e-04, -2.1948e-03,  8.7118e-04,  2.4955e-03, -9.2174e-05,
         2.5177e-04, -1.6679e-03,  8.3578e-04,  1.6670e-03,  9.0448e-04,
         1.5285e-03,  8.8104e-05, -3.3290e-04,  1.2108e-03,  2.9689e-04,
        -1.6824e-03, -2.2931e-03,  9.7226e-05,  3.7454e-04, -1.3363e-05,
        -5.6066e-04,  2.4882e-03,  8.8357e-04, -1.4731e-03, -1.9875e-03,
         2.4067e-03,  2.2774e-03,  1.4170e-03,  1.4856e-03, -2.1529e-03,
        -4.2973e-04,  1.5559e-03, -2.6193e-03,  2.9375e-04,  1.9730e-03,
        -5.5872e-04,  1.3070e-03,  2.5609e-04, -2.8753e-04,  1.9693e-03,
         2.9852e-04,  2.0243e-03,  2.0979e-03,  1.9409e-04, -1.6392e-03,
        -1.8173e-03, -8.6311e-05,  2.0168e-04,  7.2918e-05, -1.1973e-03,
        -1.8232e-03, -1.9324e-03,  7.8230e-04, -2.5308e-03,  2.0033e-03,
        -7.7835e-05,  1.2148e-03, -2.7280e-03,  6.4992e-04, -8.3012e-04,
         1.9426e-03,  1.2971e-03,  3.5467e-05, -2.7288e-03,  3.4571e-05,
         8.8284e-05,  2.2780e-03, -2.5276e-03, -1.4911e-03,  4.6722e-04,
         1.6418e-03, -1.2435e-03, -1.5532e-03,  2.2502e-03,  5.7519e-04,
        -8.4060e-05, -6.1240e-05, -1.6411e-03,  2.1511e-03,  1.6256e-03,
        -1.8751e-03,  1.3416e-03, -4.2708e-04, -1.8925e-03,  3.2187e-04,
        -4.3888e-04,  2.0801e-03, -2.1971e-03, -1.6722e-03, -2.1869e-03,
         1.2242e-03,  7.5049e-04,  7.7591e-04, -9.4507e-04,  1.9296e-03,
         1.8546e-03, -2.0832e-03, -2.0898e-03, -1.6695e-03, -2.1035e-03,
        -7.1238e-04,  1.7804e-03, -1.8760e-03, -6.7151e-04, -7.1059e-06,
         7.2788e-04, -1.7510e-03,  2.3586e-03, -2.7598e-03, -1.8588e-03,
         1.2387e-03, -2.7769e-03, -1.9007e-03, -3.0726e-04, -2.0951e-03,
         6.6510e-04,  1.1511e-03, -4.6175e-04, -1.7548e-03, -1.8829e-03,
         5.7504e-05, -7.6252e-04, -1.3650e-03, -2.6702e-03,  2.3865e-03,
        -1.0656e-04])
net.mlp.net.2.batch_norm.running_mean tensor([0.0903, 0.1192, 0.0834, 0.1237, 0.0972, 0.1497, 0.1183, 0.1291, 0.0838,
        0.1061, 0.1104, 0.1123, 0.1001, 0.1211, 0.1220, 0.1265, 0.1084, 0.0984,
        0.1118, 0.0946, 0.1153, 0.1207, 0.1088, 0.1074, 0.1208, 0.1190, 0.0960,
        0.1217, 0.1258, 0.0961, 0.1145, 0.1206, 0.0943, 0.1008, 0.1449, 0.1224,
        0.0908, 0.1440, 0.1146, 0.1005, 0.1129, 0.0916, 0.1089, 0.1141, 0.1191,
        0.1019, 0.0995, 0.1177, 0.1456, 0.1017, 0.0960, 0.0887, 0.1149, 0.0913,
        0.1318, 0.1436, 0.1195, 0.0919, 0.1222, 0.1537, 0.1010, 0.1277, 0.1246,
        0.0870, 0.1210, 0.1117, 0.1182, 0.1198, 0.1229, 0.1157, 0.1272, 0.1053,
        0.1127, 0.0899, 0.1485, 0.1177, 0.0986, 0.1083, 0.1371, 0.0894, 0.0834,
        0.1014, 0.1422, 0.0976, 0.1100, 0.1212, 0.0961, 0.1070, 0.1090, 0.1410,
        0.1063, 0.1053, 0.1228, 0.0950, 0.1076, 0.1068, 0.1299, 0.1232, 0.1131,
        0.1155, 0.1298, 0.1317, 0.0958, 0.1000, 0.1525, 0.0865, 0.1056, 0.0990,
        0.1191, 0.0946, 0.1355, 0.1107, 0.0857, 0.0832, 0.0973, 0.1028, 0.1051,
        0.0972, 0.1431, 0.1320, 0.1684, 0.1018, 0.1027, 0.1008, 0.1393, 0.1096,
        0.1196, 0.1258, 0.1221, 0.1131, 0.1010, 0.1277, 0.1107, 0.1219, 0.0999,
        0.0996, 0.1576, 0.0938, 0.1215, 0.1168, 0.1133, 0.0905, 0.1103, 0.1258,
        0.1044, 0.1136, 0.1117, 0.0978, 0.1160, 0.1354, 0.1040, 0.1157, 0.1234,
        0.1232, 0.1138, 0.1102, 0.0940, 0.1261, 0.0939, 0.1380, 0.1451, 0.1047,
        0.1152, 0.0857, 0.0944, 0.0959, 0.1239, 0.1067, 0.1193, 0.0986, 0.0943,
        0.1063, 0.1339, 0.1116, 0.1040, 0.0968, 0.0949, 0.0877, 0.1368, 0.1243,
        0.0957, 0.0991, 0.0939, 0.0892, 0.1239, 0.1284, 0.0954, 0.1031, 0.1045,
        0.1001, 0.1372, 0.1283, 0.0986, 0.1145, 0.1251, 0.1150, 0.1057, 0.0994,
        0.1132, 0.1262, 0.1198, 0.1189, 0.1185, 0.1110, 0.1217, 0.1372, 0.1076,
        0.1390, 0.1188, 0.0978, 0.1474, 0.0857, 0.1151, 0.1036, 0.1109, 0.1028,
        0.1076, 0.1318, 0.0997, 0.1096, 0.0960, 0.1135, 0.1467, 0.1140, 0.1177,
        0.1066, 0.0916, 0.1025, 0.0971, 0.1056, 0.1045, 0.1312, 0.1077, 0.0966,
        0.1121, 0.1054, 0.1274, 0.1096, 0.0952, 0.1078, 0.0978, 0.1173, 0.1127,
        0.1122, 0.1011, 0.0845, 0.1253, 0.1185, 0.0956, 0.0877, 0.1491, 0.1298,
        0.1164, 0.1136, 0.1115, 0.1040])
net.mlp.net.2.batch_norm.running_var tensor([0.7286, 0.7488, 0.7286, 0.7950, 0.7376, 0.8124, 0.7438, 0.8229, 0.7748,
        0.8598, 0.7267, 0.7452, 0.7309, 0.7618, 0.7870, 0.7833, 0.7657, 0.7274,
        0.7430, 0.7273, 0.7793, 0.8188, 0.7443, 0.7462, 0.7735, 0.7441, 0.7457,
        0.7629, 0.7513, 0.7418, 0.7396, 0.7699, 0.7297, 0.7556, 0.7603, 0.8041,
        0.7221, 0.8133, 0.7638, 0.7133, 0.7405, 0.7253, 0.7590, 0.7901, 0.7579,
        0.7960, 0.7689, 0.7419, 0.7518, 0.7376, 0.7227, 0.7750, 0.7527, 0.7906,
        0.7742, 0.7986, 0.7630, 0.7317, 0.8623, 0.8224, 0.7420, 0.7729, 0.7857,
        0.7043, 0.7714, 0.7360, 0.7925, 0.7451, 0.7991, 0.7374, 0.8200, 0.7364,
        0.7669, 0.7437, 0.7730, 0.7909, 0.7690, 0.7441, 0.8657, 0.7364, 0.7127,
        0.7568, 0.8156, 0.7517, 0.7511, 0.7926, 0.7108, 0.7848, 0.7216, 0.8217,
        0.7435, 0.7293, 0.7307, 0.7308, 0.7383, 0.7258, 0.7623, 0.7310, 0.7469,
        0.7354, 0.7820, 0.7576, 0.7576, 0.7340, 0.8127, 0.7130, 0.7308, 0.7539,
        0.7467, 0.7283, 0.8500, 0.7739, 0.7144, 0.6981, 0.7275, 0.7370, 0.7207,
        0.7844, 0.7677, 0.8363, 0.9654, 0.7338, 0.7130, 0.7241, 0.9053, 0.7413,
        0.7362, 0.7384, 0.7702, 0.7802, 0.7041, 0.7538, 0.7918, 0.7933, 0.7665,
        0.7328, 0.7911, 0.7454, 0.7648, 0.7596, 0.7727, 0.7483, 0.7331, 0.9176,
        0.7528, 0.7488, 0.7295, 0.7803, 0.7585, 0.8129, 0.7139, 0.7543, 0.7972,
        0.7432, 0.8691, 0.7802, 0.7251, 0.7589, 0.7491, 0.7684, 0.8197, 0.7934,
        0.7405, 0.7338, 0.7513, 0.7738, 0.7672, 0.7468, 0.7269, 0.7235, 0.7341,
        0.7601, 0.8260, 0.7386, 0.7410, 0.7189, 0.7133, 0.7110, 0.8847, 0.7870,
        0.7437, 0.7609, 0.7433, 0.6999, 0.7445, 0.7904, 0.7532, 0.7792, 0.8839,
        0.7238, 0.8040, 0.7548, 0.7201, 0.7530, 0.7657, 0.7873, 0.8170, 0.7354,
        0.8446, 0.7789, 0.7535, 0.7548, 0.7556, 0.7240, 0.7751, 0.7873, 0.7375,
        0.8205, 0.7473, 0.7151, 0.7770, 0.7075, 0.7392, 0.7381, 0.7305, 0.7688,
        0.7333, 0.7709, 0.7106, 0.7312, 0.7403, 0.7843, 0.7926, 0.8036, 0.7557,
        0.7404, 0.7542, 0.7530, 0.7224, 0.7394, 0.7333, 0.7626, 0.7665, 0.7225,
        0.8065, 0.7612, 0.7439, 0.7491, 0.7504, 0.7684, 0.7256, 0.7663, 0.7304,
        0.7670, 0.7504, 0.7261, 0.7904, 0.7192, 0.7711, 0.7169, 0.7798, 0.7632,
        0.7383, 0.7770, 0.7367, 0.7373])
net.mlp.net.2.batch_norm.num_batches_tracked tensor(4)
net.mlp.net.3.linear.weight tensor([[-0.0139, -0.0030,  0.0047,  ...,  0.1468,  0.0450,  0.0253],
        [-0.0347, -0.0287,  0.0468,  ...,  0.0579, -0.0437,  0.0997],
        [ 0.0171, -0.0780, -0.0121,  ..., -0.0557,  0.0118, -0.0432],
        ...,
        [-0.0255,  0.0640, -0.0120,  ..., -0.0454,  0.0868, -0.0402],
        [-0.0409, -0.0464, -0.0191,  ...,  0.0633, -0.0555,  0.0112],
        [ 0.0688, -0.0601,  0.0218,  ..., -0.0502,  0.1286, -0.0241]])
net.mlp.net.3.linear.bias tensor([ 6.6299e-03, -2.3627e-02,  3.1178e-02, -1.3474e-02, -9.1944e-03,
         7.8699e-03, -3.4306e-02, -7.9605e-03, -1.1114e-02, -9.2747e-03,
        -2.6030e-02,  2.3035e-02,  1.3873e-02,  2.6557e-02,  2.4302e-02,
        -1.5691e-02, -1.0479e-02, -2.4219e-02,  2.4438e-02,  1.3462e-02,
        -2.3685e-02, -1.8311e-02,  2.4452e-02, -1.0191e-02,  1.2743e-02,
        -9.8772e-03,  1.0405e-02,  2.9227e-02, -3.3649e-02,  5.0668e-03,
         5.3180e-03, -6.2127e-03,  8.3208e-03, -1.6946e-02,  9.2269e-03,
         9.3368e-03, -2.5839e-02, -3.4769e-02,  1.0993e-02, -2.0906e-02,
         3.1812e-02, -2.0499e-02, -1.2085e-02,  2.3387e-03,  3.2411e-02,
        -2.4078e-02,  5.2840e-03, -1.1589e-02, -1.3266e-02,  7.3030e-03,
        -1.2302e-02,  1.8495e-02, -3.4742e-02,  3.4912e-02,  7.3074e-05,
        -3.6065e-03, -1.7101e-02,  3.1449e-02,  3.5551e-02, -1.4706e-02,
        -8.8041e-03,  2.1101e-02, -2.2908e-02,  3.2971e-02,  1.4125e-02,
         2.5118e-03,  5.9361e-03, -1.3478e-02, -2.5299e-03, -1.4881e-02,
         1.2701e-02, -1.3728e-02,  1.4997e-02, -3.2017e-02, -3.2630e-02,
        -1.7547e-02, -2.8604e-02,  2.6790e-02,  3.7750e-03, -3.3909e-04,
        -3.4881e-02, -1.3489e-02,  1.5400e-03,  4.0176e-03,  1.9774e-02,
         2.2239e-02, -3.3624e-02,  2.6597e-03,  5.3278e-03,  2.9493e-02,
        -5.8128e-03, -2.6523e-02,  1.0402e-02,  1.8093e-02,  1.4410e-02,
        -1.1824e-02, -2.4120e-02, -3.0014e-02,  1.9153e-02,  8.1039e-03,
         1.0166e-02, -1.2040e-02,  3.4795e-02, -3.0601e-03,  1.8932e-02,
         5.8346e-03,  3.0703e-02,  3.1000e-02, -2.8064e-03, -3.1534e-02,
         9.6546e-03, -3.0191e-02,  1.5917e-02,  2.0569e-02, -4.0508e-03,
         3.1875e-02,  2.5437e-03,  1.1262e-04, -4.5740e-03, -1.0415e-02,
        -2.0900e-02, -2.0051e-02, -5.8811e-03,  2.8132e-02, -2.3912e-02,
         5.4176e-04,  2.9231e-02,  8.2479e-03,  1.5398e-02, -2.4372e-02,
         3.5205e-03, -3.2469e-03,  2.8175e-02,  7.0559e-03,  2.3061e-02,
        -2.6723e-02,  1.2417e-02, -2.5939e-03, -1.6118e-02, -2.3767e-02,
         2.9958e-02, -1.9749e-02,  1.5875e-02,  3.3857e-02, -2.3586e-02,
        -5.8278e-03,  3.4241e-02,  2.2546e-04,  2.7335e-03, -7.9627e-03,
         1.2248e-02,  2.2775e-03,  2.4202e-02,  1.5500e-02, -1.7362e-02,
        -2.4314e-03,  1.6730e-03, -1.7003e-02, -1.2426e-02,  1.7046e-02,
         1.0807e-02, -2.2096e-03, -2.2099e-02,  2.2804e-04,  2.9774e-02,
        -3.4408e-02,  1.5662e-02,  1.5955e-02,  2.0489e-02,  1.8552e-03,
        -9.3991e-03, -7.0150e-03,  1.1562e-02,  3.4267e-02, -1.5586e-02,
        -2.4793e-02,  1.9224e-03,  1.4356e-02, -2.7051e-02, -2.4612e-03,
        -9.5244e-04, -3.0559e-02, -6.3952e-03, -1.4446e-02,  2.0429e-02,
         2.0376e-02, -1.2208e-02,  2.9137e-02,  2.7322e-02,  1.8514e-02,
        -2.3713e-02,  1.5966e-02,  2.2235e-02, -2.2243e-03,  9.7186e-03,
        -2.6592e-02,  3.2602e-02, -1.1964e-02, -1.3550e-02,  9.2681e-03,
         2.9574e-02,  1.1309e-02,  2.0948e-03, -2.6109e-02, -2.2096e-02,
         4.7696e-03,  1.9059e-02,  1.9092e-02,  1.2884e-03, -2.0381e-02,
         1.0150e-02,  1.6704e-02,  8.1255e-03, -2.0934e-02, -1.1829e-02,
         1.5397e-02,  2.3995e-02, -1.4561e-03,  1.5275e-02,  2.4384e-02,
         2.1200e-02, -2.4147e-03,  5.5968e-03, -1.9298e-02,  1.7379e-02,
        -1.4406e-02, -4.6072e-03,  2.6031e-02,  2.7557e-02,  1.2780e-02,
        -3.4203e-02, -2.3487e-02,  2.1694e-02, -1.1310e-02,  2.1286e-02,
        -3.6042e-02,  2.4215e-02,  1.6503e-02,  1.1456e-02,  1.6427e-02,
        -2.8022e-02, -2.4155e-02,  2.9195e-02, -1.5690e-02,  2.3240e-02,
        -9.1246e-03, -2.2711e-02, -1.0501e-02,  1.3727e-02, -1.0049e-03,
        -9.4706e-03, -2.4188e-02, -7.7499e-03,  3.5398e-02,  4.3319e-03,
        -2.7001e-02])
net.mlp.net.3.batch_norm.weight tensor([0.5597, 0.5627, 0.5587, 0.5630, 0.5631, 0.5588, 0.5611, 0.5621, 0.5617,
        0.5605, 0.5627, 0.5595, 0.5598, 0.5615, 0.5589, 0.5620, 0.5594, 0.5611,
        0.5607, 0.5598, 0.5592, 0.5640, 0.5610, 0.5616, 0.5590, 0.5588, 0.5587,
        0.5608, 0.5601, 0.5621, 0.5612, 0.5586, 0.5620, 0.5622, 0.5587, 0.5590,
        0.5601, 0.5631, 0.5605, 0.5609, 0.5600, 0.5607, 0.5618, 0.5590, 0.5593,
        0.5594, 0.5589, 0.5593, 0.5597, 0.5586, 0.5601, 0.5612, 0.5609, 0.5598,
        0.5633, 0.5600, 0.5603, 0.5602, 0.5597, 0.5613, 0.5615, 0.5586, 0.5590,
        0.5595, 0.5595, 0.5620, 0.5610, 0.5601, 0.5603, 0.5613, 0.5586, 0.5623,
        0.5593, 0.5631, 0.5601, 0.5595, 0.5614, 0.5610, 0.5607, 0.5620, 0.5615,
        0.5612, 0.5589, 0.5600, 0.5619, 0.5616, 0.5618, 0.5588, 0.5598, 0.5602,
        0.5596, 0.5624, 0.5616, 0.5605, 0.5589, 0.5602, 0.5590, 0.5607, 0.5597,
        0.5637, 0.5604, 0.5618, 0.5613, 0.5623, 0.5599, 0.5590, 0.5623, 0.5624,
        0.5592, 0.5621, 0.5592, 0.5614, 0.5609, 0.5602, 0.5612, 0.5613, 0.5600,
        0.5628, 0.5600, 0.5615, 0.5590, 0.5638, 0.5587, 0.5599, 0.5627, 0.5617,
        0.5589, 0.5623, 0.5590, 0.5603, 0.5633, 0.5591, 0.5607, 0.5596, 0.5608,
        0.5587, 0.5598, 0.5610, 0.5621, 0.5608, 0.5598, 0.5594, 0.5586, 0.5610,
        0.5601, 0.5627, 0.5613, 0.5610, 0.5592, 0.5623, 0.5609, 0.5598, 0.5603,
        0.5596, 0.5621, 0.5614, 0.5589, 0.5592, 0.5605, 0.5590, 0.5613, 0.5590,
        0.5598, 0.5599, 0.5630, 0.5622, 0.5593, 0.5603, 0.5610, 0.5605, 0.5637,
        0.5598, 0.5591, 0.5592, 0.5627, 0.5628, 0.5591, 0.5598, 0.5640, 0.5595,
        0.5630, 0.5596, 0.5593, 0.5592, 0.5631, 0.5607, 0.5590, 0.5604, 0.5622,
        0.5635, 0.5586, 0.5638, 0.5615, 0.5596, 0.5614, 0.5594, 0.5588, 0.5590,
        0.5634, 0.5612, 0.5588, 0.5618, 0.5604, 0.5608, 0.5613, 0.5620, 0.5619,
        0.5601, 0.5621, 0.5595, 0.5619, 0.5586, 0.5590, 0.5585, 0.5588, 0.5605,
        0.5589, 0.5610, 0.5635, 0.5613, 0.5620, 0.5627, 0.5621, 0.5603, 0.5600,
        0.5612, 0.5595, 0.5595, 0.5627, 0.5600, 0.5596, 0.5609, 0.5594, 0.5617,
        0.5599, 0.5610, 0.5625, 0.5623, 0.5635, 0.5613, 0.5624, 0.5592, 0.5607,
        0.5628, 0.5591, 0.5609, 0.5630, 0.5603, 0.5609, 0.5605, 0.5613, 0.5589,
        0.5625, 0.5594, 0.5622, 0.5593])
net.mlp.net.3.batch_norm.bias tensor([ 4.7635e-05,  1.9824e-04,  4.3688e-05,  1.0959e-04,  1.6211e-04,
         9.1253e-06, -5.1611e-05,  1.2643e-04, -5.9964e-05,  5.6716e-06,
        -4.2098e-05,  3.7782e-05, -1.5970e-04,  1.6753e-04,  1.1081e-05,
         4.5233e-05, -2.8367e-05, -3.7954e-05, -4.9899e-05,  6.2989e-05,
         9.9401e-05,  9.3309e-05,  4.5869e-05,  7.0547e-05,  1.0582e-04,
        -4.3122e-05, -1.6224e-05,  2.3756e-05,  1.0041e-03,  6.5435e-05,
        -6.3750e-04, -8.3325e-04,  5.4364e-05,  4.4839e-04, -2.2168e-05,
         1.3222e-05, -1.1831e-05,  3.2063e-04,  5.4356e-06, -7.7122e-05,
         5.7715e-06, -2.7656e-03,  3.8355e-05,  5.6387e-05,  8.9290e-06,
         2.2156e-05, -1.6345e-04, -3.9161e-04, -6.1554e-05,  1.0257e-04,
         1.1846e-05, -7.9622e-05,  4.6322e-05, -7.9123e-05,  2.6735e-04,
         4.1644e-04,  4.5304e-06,  2.3376e-05,  1.9543e-05,  6.1267e-05,
         9.6246e-05, -6.2528e-05,  1.3992e-05,  3.2176e-05, -4.5639e-05,
         4.9943e-05,  4.3531e-05,  6.5416e-05,  2.1564e-05,  9.9342e-05,
        -2.3771e-05,  4.5970e-05,  4.8567e-05, -1.1902e-04,  8.7524e-06,
        -1.5980e-05,  4.1886e-05,  1.1845e-04,  5.2441e-05,  4.4661e-05,
         3.7202e-05,  5.5531e-05, -2.1349e-05,  3.7980e-04, -3.6958e-05,
        -1.1372e-04, -4.8671e-05,  1.1811e-05, -8.0344e-06,  7.4838e-05,
        -3.3916e-05,  8.0293e-05,  1.0551e-04, -2.0270e-06, -1.7168e-05,
        -2.8578e-05,  2.0824e-04,  1.1123e-04, -8.1863e-05, -1.8861e-04,
         1.9742e-05,  1.1957e-04, -1.1412e-05,  3.1381e-04,  3.4863e-04,
         2.7547e-05,  1.0314e-04,  1.1941e-04,  5.1497e-05,  7.0823e-05,
        -1.3687e-05,  1.7104e-04,  1.5779e-04, -4.6338e-06,  1.9057e-04,
         3.5929e-05,  9.6628e-05,  2.5907e-04,  3.2693e-05,  8.5758e-05,
         4.6098e-05,  2.3603e-04, -2.2258e-05,  4.6718e-06,  7.4246e-05,
         5.4660e-05,  4.3148e-05,  4.5544e-05,  9.3586e-06,  3.9236e-05,
        -5.7688e-05,  1.1536e-04, -7.2766e-06, -1.7739e-04, -2.2162e-05,
        -1.3798e-05,  5.1975e-05,  2.1962e-04, -2.0276e-04,  2.0425e-05,
         3.8906e-05,  2.2780e-05, -2.4843e-05, -3.8613e-05,  1.9976e-05,
         4.0371e-05, -7.0346e-05, -3.1975e-05,  2.8078e-05,  4.8304e-05,
        -6.9516e-04, -5.8970e-06, -5.9931e-05,  1.8295e-04,  5.8810e-05,
         3.8144e-05, -1.0328e-05, -1.0675e-05,  4.5117e-06,  1.0657e-04,
         7.6674e-07,  1.0105e-05,  2.3462e-05,  4.7305e-05, -5.9299e-05,
        -5.8886e-05, -2.5017e-04,  9.6927e-06, -3.2749e-05,  1.1421e-04,
        -4.7952e-05,  2.2740e-05,  2.1595e-03,  8.6540e-06,  8.9305e-05,
         6.0956e-05,  2.7453e-05,  1.6187e-05, -6.7273e-05,  1.7648e-04,
         4.3919e-05, -1.8076e-04, -1.7599e-05,  7.3767e-05,  7.9581e-05,
        -6.6640e-05,  1.9448e-05,  4.5644e-06,  4.6737e-05,  4.0244e-05,
         5.0542e-05, -1.5006e-04,  2.6915e-03,  2.4201e-05, -4.1141e-05,
        -1.4269e-05,  1.5854e-05, -6.6886e-06,  1.0360e-04,  4.0753e-05,
         4.5924e-05, -7.0628e-05,  2.1976e-04, -2.6223e-04,  3.8978e-06,
         7.2914e-04,  1.0126e-04,  4.4459e-05,  5.9689e-05,  1.2755e-04,
         1.0063e-04,  1.1897e-05, -2.2812e-05,  1.0563e-05,  4.7284e-05,
         1.6706e-05,  1.1906e-04,  3.1549e-06, -6.8042e-04,  4.2885e-05,
         4.1723e-05,  9.4817e-05, -3.8622e-05,  1.7685e-05,  1.7707e-04,
         9.2026e-07,  9.0277e-05, -8.5471e-04, -8.0292e-05,  1.0581e-05,
         4.5955e-05,  5.4064e-05,  8.9252e-06, -4.5824e-05,  1.1113e-05,
         2.9115e-05, -6.3760e-05,  9.5589e-05,  7.4495e-05,  3.9355e-05,
         4.0948e-05,  2.8778e-05, -7.7769e-06,  4.0595e-05,  9.1356e-04,
         5.8763e-05, -4.5265e-05,  5.6336e-05, -4.2690e-05,  4.9108e-05,
         3.8796e-05,  2.0368e-05,  4.8260e-05, -4.2368e-05,  5.5176e-05,
         2.7444e-05])
net.mlp.net.3.batch_norm.running_mean tensor([0.0912, 0.1005, 0.1293, 0.1272, 0.1051, 0.1058, 0.1305, 0.1438, 0.1362,
        0.1166, 0.1074, 0.1024, 0.1040, 0.1482, 0.1109, 0.0975, 0.0829, 0.1235,
        0.1269, 0.1357, 0.0896, 0.0846, 0.1104, 0.1192, 0.1271, 0.1027, 0.1042,
        0.1488, 0.1074, 0.0903, 0.1119, 0.0907, 0.1199, 0.1133, 0.1166, 0.1127,
        0.1177, 0.0943, 0.1121, 0.0981, 0.1543, 0.0960, 0.1371, 0.1278, 0.1350,
        0.1089, 0.1370, 0.1137, 0.1297, 0.1223, 0.1453, 0.1390, 0.1501, 0.1207,
        0.1138, 0.1256, 0.1236, 0.1416, 0.1005, 0.1055, 0.1005, 0.0992, 0.0902,
        0.1237, 0.1210, 0.1156, 0.0979, 0.1052, 0.0907, 0.1299, 0.1162, 0.1203,
        0.1141, 0.1025, 0.0919, 0.1029, 0.1342, 0.1188, 0.1147, 0.1142, 0.1124,
        0.0925, 0.1191, 0.1186, 0.1541, 0.1440, 0.0897, 0.1169, 0.0933, 0.1207,
        0.1110, 0.1275, 0.1128, 0.1076, 0.1193, 0.1139, 0.0954, 0.1246, 0.1133,
        0.1225, 0.1052, 0.0999, 0.1310, 0.1043, 0.1322, 0.0960, 0.1246, 0.1117,
        0.1376, 0.1123, 0.1106, 0.1213, 0.1002, 0.1190, 0.1130, 0.1324, 0.1071,
        0.1160, 0.1007, 0.1178, 0.1069, 0.1048, 0.1158, 0.1300, 0.1234, 0.1141,
        0.1563, 0.1014, 0.1337, 0.1069, 0.1264, 0.1043, 0.1279, 0.1238, 0.1423,
        0.0904, 0.1582, 0.1170, 0.1126, 0.1114, 0.1087, 0.1337, 0.1074, 0.1560,
        0.0944, 0.0948, 0.1273, 0.1272, 0.1231, 0.1023, 0.1341, 0.1335, 0.1149,
        0.1045, 0.1234, 0.1125, 0.0888, 0.1049, 0.1038, 0.1083, 0.1385, 0.1144,
        0.0875, 0.1219, 0.1106, 0.0918, 0.1059, 0.1199, 0.1615, 0.1124, 0.1586,
        0.1090, 0.1249, 0.1273, 0.1042, 0.1014, 0.1034, 0.1235, 0.1238, 0.1078,
        0.1130, 0.1070, 0.1123, 0.0976, 0.1164, 0.1375, 0.1173, 0.1237, 0.1059,
        0.0987, 0.1233, 0.1124, 0.1206, 0.1479, 0.1098, 0.1105, 0.1053, 0.1094,
        0.0969, 0.1216, 0.1250, 0.1249, 0.1346, 0.1023, 0.1010, 0.0931, 0.1102,
        0.1129, 0.1215, 0.1156, 0.1238, 0.0980, 0.1082, 0.1062, 0.1018, 0.1315,
        0.1243, 0.1169, 0.1107, 0.1340, 0.1042, 0.1183, 0.1358, 0.1109, 0.1014,
        0.1171, 0.1307, 0.1250, 0.1113, 0.1347, 0.1118, 0.0831, 0.1121, 0.1319,
        0.1407, 0.1181, 0.1179, 0.0954, 0.0932, 0.1115, 0.1127, 0.0944, 0.1006,
        0.1181, 0.1129, 0.1076, 0.1214, 0.1081, 0.1160, 0.1086, 0.1293, 0.0910,
        0.0921, 0.1451, 0.1193, 0.0888])
net.mlp.net.3.batch_norm.running_var tensor([0.7131, 0.7344, 0.7770, 0.7900, 0.7442, 0.7392, 0.7473, 0.9116, 0.8278,
        0.7422, 0.7394, 0.7450, 0.7230, 0.8645, 0.7319, 0.7529, 0.7234, 0.7769,
        0.7419, 0.8351, 0.7160, 0.7208, 0.8608, 0.8697, 0.7470, 0.7275, 0.7213,
        0.8680, 0.7326, 0.7066, 0.7299, 0.7407, 0.7605, 0.7573, 0.7966, 0.7743,
        0.7385, 0.7326, 0.7525, 0.7485, 0.9233, 0.7245, 0.9086, 0.7570, 0.7737,
        0.7521, 0.7677, 0.7467, 0.7542, 0.7535, 0.8012, 0.7668, 0.8374, 0.7683,
        0.7809, 0.7898, 0.8093, 0.9314, 0.7268, 0.7512, 0.7400, 0.7213, 0.7209,
        0.7786, 0.7531, 0.7614, 0.7211, 0.7649, 0.7337, 0.7591, 0.7538, 0.7917,
        0.7333, 0.7729, 0.7506, 0.7488, 0.8922, 0.7627, 0.7592, 0.7596, 0.7922,
        0.7237, 0.7543, 0.8805, 0.7847, 0.7703, 0.7117, 0.7394, 0.7113, 0.7731,
        0.7706, 0.7625, 0.7813, 0.8168, 0.7259, 0.7320, 0.7694, 0.7746, 0.7334,
        0.7831, 0.7259, 0.7396, 0.7647, 0.7318, 0.7621, 0.7212, 0.7307, 0.8534,
        0.7999, 0.7586, 0.7402, 0.7717, 0.7766, 0.7986, 0.7812, 0.7912, 0.7443,
        0.7507, 0.7460, 0.7761, 0.7381, 0.7461, 0.7650, 0.8009, 0.7941, 0.7428,
        0.8325, 0.7382, 0.7696, 0.7626, 0.7530, 0.7576, 0.7660, 0.7206, 0.7451,
        0.7182, 0.9822, 0.8045, 0.7380, 0.8946, 0.7386, 0.8240, 0.7676, 0.7852,
        0.7462, 0.7340, 0.7791, 0.7541, 0.7918, 0.7765, 0.7783, 0.8475, 0.7468,
        0.7649, 0.8090, 0.7881, 0.7183, 0.7401, 0.7439, 0.7256, 0.7827, 0.7698,
        0.7194, 0.8080, 0.7192, 0.7238, 0.7185, 0.7654, 0.8192, 0.7707, 0.8117,
        0.7557, 0.7703, 0.7301, 0.7403, 0.7525, 0.7229, 0.8027, 0.8150, 0.7449,
        0.7734, 0.7296, 0.7395, 0.7320, 0.7441, 0.7539, 0.7425, 0.9344, 0.7468,
        0.7272, 0.7602, 0.7334, 0.7386, 0.8318, 0.7539, 0.7467, 0.7304, 0.7304,
        0.7322, 0.8346, 0.7456, 0.8009, 0.8431, 0.7295, 0.7229, 0.7224, 0.7691,
        0.7596, 0.7888, 0.7823, 0.8846, 0.7179, 0.7629, 0.7374, 0.7214, 0.7967,
        0.7560, 0.7514, 0.7454, 0.8182, 0.7356, 0.7555, 0.7707, 0.7542, 0.7300,
        0.7983, 0.8602, 0.7812, 0.7506, 0.7738, 0.7616, 0.7349, 0.8384, 0.7658,
        0.8536, 0.8097, 0.7380, 0.7415, 0.7282, 0.7988, 0.7417, 0.7504, 0.7229,
        0.7800, 0.8030, 0.7626, 0.7336, 0.7476, 0.7265, 0.7493, 0.8856, 0.7179,
        0.7573, 0.7656, 0.8068, 0.7411])
net.mlp.net.3.batch_norm.num_batches_tracked tensor(4)
net.mlp.net.4.weight tensor([[ 0.0117, -0.0053,  0.0130, -0.0102, -0.0071,  0.0321,  0.0169, -0.0076,
          0.0135,  0.0287,  0.0329,  0.0137, -0.0030, -0.0043,  0.0300, -0.0284,
         -0.0159,  0.0240, -0.0098,  0.0092,  0.0061, -0.0138, -0.0212, -0.0123,
          0.0055, -0.0129, -0.0254,  0.0171,  0.0009, -0.0134,  0.0009,  0.0009,
          0.0075, -0.0025, -0.0207,  0.0271, -0.0252, -0.0041,  0.0312,  0.0081,
          0.0331,  0.0017, -0.0319,  0.0105,  0.0286,  0.0193, -0.0030, -0.0009,
         -0.0094,  0.0055,  0.0246,  0.0114,  0.0105, -0.0079, -0.0047,  0.0011,
          0.0336,  0.0193,  0.0193, -0.0120, -0.0081, -0.0094,  0.0263,  0.0161,
         -0.0127, -0.0186,  0.0103,  0.0084,  0.0197, -0.0079, -0.0198, -0.0292,
          0.0107,  0.0092,  0.0288, -0.0215, -0.0244, -0.0055, -0.0130, -0.0286,
         -0.0316,  0.0077, -0.0211,  0.0015,  0.0350, -0.0041, -0.0078,  0.0291,
         -0.0312,  0.0072, -0.0149, -0.0137, -0.0069, -0.0266, -0.0242, -0.0151,
          0.0023, -0.0045, -0.0073,  0.0067,  0.0194, -0.0070, -0.0199, -0.0032,
          0.0017,  0.0178, -0.0081, -0.0079,  0.0112, -0.0143, -0.0262,  0.0036,
          0.0039, -0.0285, -0.0032, -0.0326,  0.0056, -0.0045,  0.0139, -0.0091,
          0.0119, -0.0059, -0.0209,  0.0334, -0.0154, -0.0202,  0.0131, -0.0288,
          0.0323,  0.0118,  0.0225,  0.0051, -0.0268, -0.0029, -0.0183, -0.0268,
          0.0112, -0.0018,  0.0041,  0.0163,  0.0137,  0.0200, -0.0196,  0.0251,
          0.0207, -0.0361, -0.0057, -0.0160,  0.0172, -0.0247,  0.0009, -0.0250,
          0.0093,  0.0033, -0.0191, -0.0275, -0.0306, -0.0301,  0.0311,  0.0051,
         -0.0319,  0.0303,  0.0166,  0.0116,  0.0218,  0.0144, -0.0017,  0.0260,
         -0.0157,  0.0050,  0.0295,  0.0191,  0.0006,  0.0276, -0.0120, -0.0196,
          0.0190,  0.0202,  0.0202,  0.0030, -0.0341, -0.0029, -0.0229,  0.0085,
         -0.0157, -0.0079,  0.0225,  0.0324,  0.0082, -0.0360,  0.0113,  0.0086,
         -0.0024,  0.0187,  0.0258, -0.0244,  0.0256, -0.0324, -0.0109, -0.0244,
          0.0123,  0.0115,  0.0032,  0.0012,  0.0280, -0.0018, -0.0083,  0.0118,
         -0.0187,  0.0049, -0.0091,  0.0294, -0.0187,  0.0306,  0.0123,  0.0205,
          0.0045,  0.0326,  0.0029, -0.0276, -0.0274, -0.0109, -0.0094,  0.0212,
          0.0028,  0.0330,  0.0068,  0.0003,  0.0133,  0.0284,  0.0119, -0.0135,
          0.0314,  0.0245,  0.0253,  0.0132,  0.0184, -0.0109, -0.0169, -0.0254,
         -0.0324,  0.0171, -0.0276, -0.0342, -0.0002, -0.0113,  0.0302,  0.0104,
         -0.0112, -0.0133, -0.0270,  0.0221, -0.0260, -0.0114, -0.0187,  0.0184]])
