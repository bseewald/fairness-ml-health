Weights: 
embeddings.embeddings.0.weight tensor([[ 0.0915,  0.2623],
        [ 0.1126, -0.2180],
        [-0.1256,  0.0784],
        [ 0.2490,  0.0326]])
embeddings.embeddings.1.weight tensor([[-0.2482, -0.1928],
        [-0.1595,  0.1520],
        [-0.1602,  0.2007],
        [-0.0765, -0.0839],
        [ 0.0599,  0.1400]])
embeddings.embeddings.2.weight tensor([[-0.0662,  0.1270, -0.1864],
        [-0.2396,  0.2896, -0.1705],
        [-0.2147,  0.2334, -0.2898],
        [-0.0119,  0.0465,  0.0742],
        [ 0.0208,  0.0965,  0.1556],
        [-0.1163, -0.0835, -0.1982]])
embeddings.embeddings.3.weight tensor([[-0.0233, -0.1805],
        [ 0.3949,  0.2750],
        [ 0.2540, -0.1595],
        [-0.2913, -0.1776]])
embeddings.embeddings.4.weight tensor([[ 0.0673,  0.2777],
        [-0.0937,  0.1502],
        [ 0.2300, -0.2810],
        [ 0.0707, -0.0455]])
mlp.net.0.linear.weight tensor([[-0.3780,  0.0571,  0.0713,  ..., -0.2010, -0.1257,  0.1431],
        [-0.0212,  0.0215, -0.0894,  ..., -0.0560,  0.2478, -0.2714],
        [-0.0314, -0.0462, -0.0245,  ...,  0.0783,  0.3611,  0.0075],
        ...,
        [-0.1506,  0.2218, -0.1694,  ..., -0.1478, -0.0422,  0.2089],
        [-0.0083, -0.0504,  0.2180,  ...,  0.2332, -0.1966,  0.0520],
        [ 0.0516, -0.1224,  0.0801,  ...,  0.0525, -0.2287,  0.0185]])
mlp.net.0.linear.bias tensor([ 0.0005,  0.0946, -0.0660, -0.0238,  0.0095,  0.0894,  0.1116,  0.0900,
        -0.0231,  0.0206,  0.0575,  0.1086, -0.1665, -0.0388, -0.1481,  0.1672,
         0.0452, -0.0684,  0.0530,  0.0896,  0.0844,  0.1613,  0.1398,  0.0092,
        -0.0057, -0.0707, -0.0614, -0.0074,  0.0136,  0.0222,  0.0130, -0.0552,
         0.0126,  0.1364,  0.1351, -0.1616, -0.1101, -0.0533,  0.0404, -0.0251,
        -0.0104,  0.0140,  0.0680,  0.0470,  0.1639, -0.1019, -0.0568,  0.0173,
        -0.0462, -0.1965, -0.0981,  0.1209,  0.0597,  0.1570, -0.0575,  0.0302,
         0.0582,  0.0829,  0.0609,  0.1162, -0.0713,  0.0907,  0.0004,  0.0307,
        -0.0897,  0.0076,  0.0334, -0.1221, -0.1111, -0.1267, -0.0366, -0.0178,
         0.0430,  0.0806,  0.1691,  0.1233,  0.0086,  0.0545, -0.0357,  0.0571,
         0.0960,  0.0817,  0.1133, -0.0128, -0.0449, -0.0213, -0.0218,  0.0918,
         0.0611,  0.0560,  0.0714,  0.1962,  0.0985, -0.0437,  0.0338,  0.0106,
        -0.0185, -0.0087, -0.0087,  0.0300, -0.0800, -0.1200,  0.0932, -0.0413,
        -0.0336,  0.0147, -0.1176,  0.0740, -0.0225, -0.0276,  0.1190,  0.0034,
        -0.1263, -0.0069,  0.0040,  0.0290, -0.0574, -0.0170,  0.2039,  0.0059,
        -0.0026,  0.0089, -0.1508,  0.0677,  0.0900, -0.1000,  0.0666, -0.0883])
mlp.net.0.batch_norm.weight tensor([0.3835, 0.4830, 0.4234, 0.5507, 0.3812, 0.5505, 0.5126, 0.4621, 0.4782,
        0.4732, 0.4543, 0.5157, 0.4409, 0.4303, 0.4935, 0.4001, 0.3723, 0.4146,
        0.4621, 0.4938, 0.3700, 0.4761, 0.4638, 0.4036, 0.4895, 0.4768, 0.4757,
        0.4145, 0.4525, 0.4909, 0.4504, 0.3785, 0.4987, 0.5159, 0.4801, 0.4884,
        0.4521, 0.4854, 0.4369, 0.4840, 0.4222, 0.4311, 0.4826, 0.5163, 0.4057,
        0.5019, 0.4587, 0.4168, 0.4981, 0.4579, 0.4686, 0.4544, 0.4563, 0.5144,
        0.3834, 0.4760, 0.4585, 0.5177, 0.4845, 0.4517, 0.5186, 0.5119, 0.5474,
        0.4270, 0.4380, 0.4174, 0.4694, 0.4695, 0.4494, 0.4742, 0.5180, 0.4460,
        0.4323, 0.4168, 0.5169, 0.4684, 0.5471, 0.5184, 0.5172, 0.4982, 0.5766,
        0.4547, 0.4809, 0.4990, 0.4778, 0.4189, 0.4587, 0.5191, 0.4885, 0.3626,
        0.4786, 0.4223, 0.4809, 0.5514, 0.5537, 0.4688, 0.5085, 0.4762, 0.4611,
        0.5399, 0.4945, 0.4873, 0.3844, 0.4144, 0.4340, 0.4281, 0.4562, 0.5156,
        0.4861, 0.4347, 0.4360, 0.4469, 0.4259, 0.5625, 0.4634, 0.4184, 0.4642,
        0.5643, 0.4483, 0.4550, 0.4224, 0.5019, 0.4031, 0.4676, 0.4280, 0.5530,
        0.5478, 0.4901])
mlp.net.0.batch_norm.bias tensor([-0.0235, -0.1065,  0.1126,  0.0691,  0.0305,  0.0311, -0.1375, -0.0191,
        -0.0822, -0.0172, -0.0057,  0.0756, -0.0585, -0.0940, -0.0283,  0.0597,
         0.0556, -0.0267,  0.0088,  0.0864, -0.0594, -0.0251,  0.0995, -0.0437,
         0.0724,  0.0787, -0.0298,  0.0119,  0.0425, -0.0649, -0.1465, -0.0838,
         0.0277,  0.0569, -0.0362, -0.0111, -0.0900,  0.0613, -0.0473, -0.0987,
         0.0422,  0.0829, -0.0072, -0.0229,  0.0028, -0.1016, -0.0408, -0.0506,
        -0.0074, -0.0485, -0.0455,  0.0846, -0.0063,  0.0272, -0.1292, -0.0306,
        -0.0184,  0.0801, -0.0917, -0.0894,  0.0929, -0.0650,  0.0231,  0.0141,
        -0.0219,  0.1038,  0.0035,  0.0890,  0.0346, -0.0074,  0.1378,  0.0606,
        -0.0890,  0.0832,  0.1052,  0.0616, -0.0451, -0.0154,  0.0212, -0.0531,
        -0.0030, -0.0990,  0.0485,  0.0190,  0.0096,  0.0667, -0.1075, -0.0133,
         0.0648, -0.0453, -0.0222,  0.0141,  0.1240, -0.0393, -0.0747,  0.0131,
        -0.0317,  0.0819,  0.0002, -0.0310, -0.0310, -0.0972,  0.0445,  0.1396,
        -0.0584, -0.0442, -0.0060, -0.0804, -0.1176, -0.0947, -0.0284, -0.0771,
        -0.0450, -0.1202,  0.0503,  0.0249, -0.0280, -0.0843, -0.0169,  0.0331,
         0.0163, -0.0477,  0.0689,  0.0427,  0.0317,  0.0412,  0.0280, -0.0260])
mlp.net.0.batch_norm.running_mean tensor([1.6608e-02, 4.6220e-01, 8.9326e-02, 1.9529e-01, 6.2632e-02, 8.7844e-02,
        2.1465e-01, 2.3308e-01, 1.5540e-01, 2.2436e-01, 1.0235e-01, 1.6487e-01,
        3.4117e-02, 1.2652e-01, 4.5544e-03, 3.3970e-01, 3.5081e-02, 1.0674e-01,
        1.7206e-03, 1.0783e-01, 1.9278e-01, 2.6771e-01, 5.8166e-01, 4.5843e-01,
        2.2313e-01, 1.4183e-02, 1.6948e-03, 3.1725e-01, 1.1132e-01, 8.4131e-04,
        6.7853e-02, 7.9524e-03, 8.7777e-02, 1.2132e-01, 1.1876e-01, 1.5430e-04,
        2.3663e-05, 2.8133e-10, 4.0848e-02, 1.1121e-01, 8.4416e-02, 9.0590e-02,
        5.9687e-02, 2.4966e-02, 6.7977e-01, 1.6199e-01, 1.4352e-05, 1.5028e-01,
        2.4230e-01, 5.9541e-04, 5.8004e-02, 4.2231e-01, 1.3762e-01, 3.0444e-01,
        9.7839e-02, 1.2260e-01, 4.8822e-02, 2.2824e-01, 7.5568e-02, 4.2086e-01,
        9.9939e-03, 5.5520e-02, 1.8268e-02, 3.5947e-01, 4.5528e-07, 1.2536e-01,
        4.9888e-01, 1.9677e-02, 2.2987e-05, 1.0848e-05, 3.3270e-01, 1.8440e-01,
        2.2766e-02, 1.3397e-02, 4.6403e-01, 4.3362e-01, 3.6643e-02, 1.8116e-02,
        6.6327e-04, 2.1125e-01, 6.7872e-03, 2.9207e-01, 3.8152e-01, 6.3904e-02,
        2.0168e-04, 1.6474e-01, 7.2348e-03, 1.1540e-02, 4.8972e-02, 4.0584e-02,
        3.6821e-03, 5.0777e-01, 1.2665e-01, 2.7846e-01, 3.1444e-03, 2.3292e-01,
        2.3370e-01, 6.9654e-02, 3.7623e-03, 8.4588e-02, 4.6977e-02, 2.5481e-03,
        2.4911e-01, 3.5154e-01, 3.4749e-02, 1.8703e-08, 2.0733e-02, 7.0275e-02,
        8.1291e-04, 2.0730e-01, 1.7862e-01, 2.8648e-01, 1.0284e-08, 3.5819e-01,
        3.6831e-02, 9.5971e-03, 3.7405e-01, 5.3617e-01, 8.8065e-01, 6.5104e-02,
        3.6181e-01, 2.6539e-02, 5.0156e-02, 4.4153e-01, 6.4120e-02, 2.9990e-02,
        2.2305e-01, 2.8938e-02])
mlp.net.0.batch_norm.running_var tensor([2.4899e-03, 1.8632e-02, 7.8984e-03, 2.5190e-02, 1.1129e-02, 7.2254e-03,
        1.9055e-02, 2.9988e-02, 3.2783e-02, 4.4583e-02, 1.1990e-02, 2.5180e-02,
        5.2522e-03, 1.8218e-02, 7.2931e-04, 5.6361e-02, 5.1449e-03, 1.4549e-02,
        2.2555e-04, 1.8185e-02, 2.4967e-02, 1.5323e-02, 4.2320e-02, 3.2975e-02,
        1.8763e-02, 1.6563e-03, 2.1851e-04, 3.9025e-02, 2.2873e-02, 9.6397e-05,
        1.4284e-02, 1.2109e-03, 1.8141e-02, 8.2631e-03, 1.9900e-02, 2.0125e-05,
        8.6482e-06, 7.5017e-06, 4.8734e-03, 1.6196e-02, 1.3081e-02, 1.4010e-02,
        6.9134e-03, 4.0271e-03, 3.2418e-02, 3.1201e-02, 8.5411e-06, 2.1804e-02,
        2.3315e-02, 6.2089e-05, 7.1348e-03, 1.5939e-02, 1.5969e-02, 1.4223e-02,
        1.4352e-02, 1.2391e-02, 8.3407e-03, 1.8795e-02, 1.1733e-02, 2.5199e-02,
        1.8490e-03, 1.0557e-02, 2.5080e-03, 3.8036e-02, 7.5517e-06, 9.9749e-03,
        3.3610e-02, 3.4422e-03, 9.0602e-06, 8.5312e-06, 2.4738e-02, 2.4775e-02,
        2.5939e-03, 2.8190e-03, 1.9490e-02, 3.4803e-02, 6.0016e-03, 2.6250e-03,
        9.5418e-05, 3.3520e-02, 1.2300e-03, 2.1688e-02, 3.3639e-02, 6.6239e-03,
        2.6256e-05, 3.8218e-02, 1.2605e-03, 1.5823e-03, 7.0554e-03, 6.8499e-03,
        5.1100e-04, 3.6044e-02, 1.2932e-02, 2.2965e-02, 4.2283e-04, 2.6648e-02,
        2.3338e-02, 1.0320e-02, 5.4544e-04, 1.0674e-02, 6.5560e-03, 2.4435e-04,
        2.0563e-02, 5.6019e-02, 6.5388e-03, 7.5045e-06, 2.2485e-03, 1.3865e-02,
        7.8875e-05, 1.3090e-02, 2.3419e-02, 2.3565e-02, 7.5018e-06, 1.6946e-02,
        4.8673e-03, 2.2496e-03, 3.4898e-02, 1.4374e-02, 1.6256e-01, 1.0536e-02,
        2.8458e-02, 3.2088e-03, 8.6560e-03, 3.4781e-02, 6.8613e-03, 5.1708e-03,
        2.5535e-02, 2.9995e-03])
mlp.net.0.batch_norm.num_batches_tracked tensor(112)
mlp.net.1.linear.weight tensor([[ 0.0013, -0.0056,  0.0584,  ...,  0.0084,  0.0200, -0.0605],
        [-0.0144,  0.0789, -0.0069,  ...,  0.0632,  0.1609, -0.0769],
        [-0.0562, -0.0048,  0.0649,  ...,  0.1119,  0.0364,  0.0938],
        ...,
        [-0.0375,  0.0453, -0.0105,  ...,  0.0393, -0.0460, -0.0961],
        [ 0.0753, -0.0714, -0.0631,  ...,  0.0106,  0.0303,  0.0164],
        [-0.1301,  0.0835,  0.0922,  ...,  0.0278, -0.1241, -0.1426]])
mlp.net.1.linear.bias tensor([ 5.3551e-02,  2.5020e-02,  1.2661e-02, -5.8595e-02,  1.2547e-01,
         5.8543e-02,  5.3315e-02,  1.2374e-01, -1.4227e-02,  3.5917e-02,
         1.9082e-01,  6.8411e-02, -1.2198e-03,  8.0405e-02, -3.8256e-02,
         1.6709e-01, -2.9563e-04,  4.9858e-02,  8.2700e-02,  9.0079e-02,
        -3.5087e-02, -1.5961e-02, -2.2548e-02,  1.7138e-02,  5.9628e-02,
        -4.2514e-03, -1.6794e-05,  3.9505e-02,  1.4222e-02,  7.4701e-02,
         1.1972e-01, -1.9864e-03,  1.2745e-01,  8.1316e-02, -8.3787e-04,
         5.5285e-02,  1.2197e-01,  2.0325e-02, -1.0796e-02,  3.2750e-02,
         4.5620e-02,  5.6471e-02,  1.4315e-01, -2.3725e-02,  1.2437e-01,
        -3.1466e-02,  3.0518e-02,  5.5191e-02,  1.5211e-01, -6.1752e-02,
         1.2302e-01,  1.7160e-02, -8.2151e-03,  9.8982e-02, -1.3785e-02,
        -3.6363e-02,  1.1052e-02,  7.1390e-02,  7.2238e-02,  9.2765e-03,
         1.0975e-01, -4.5074e-02,  7.2418e-02,  1.2211e-01,  3.3187e-02,
         6.3259e-02,  3.5417e-02,  4.0892e-02,  8.2198e-02, -2.5407e-02,
         1.2302e-01,  3.0657e-02,  2.1994e-02,  1.1526e-02,  8.8126e-02,
        -1.4016e-02,  5.4089e-02,  1.3680e-01,  1.1161e-01, -2.3973e-02,
         2.9778e-02, -1.9448e-02,  3.7424e-02,  1.4990e-01,  1.4124e-01,
         3.0801e-02,  5.1572e-02,  1.5450e-01,  8.8537e-02, -5.8812e-02,
         4.4411e-03, -6.3586e-02,  1.3559e-02,  4.4435e-02, -8.2772e-03,
         5.1935e-02,  1.1230e-01,  5.1605e-02,  1.0645e-01, -1.0668e-02,
         2.3327e-02,  8.6312e-02,  2.6741e-02, -1.3253e-02,  4.3782e-02,
        -4.3310e-02,  2.9271e-02,  1.0592e-01,  1.1058e-01,  3.9892e-02,
         1.4053e-01,  3.5803e-02,  6.0869e-03, -2.0997e-02,  4.9967e-02,
         4.5271e-02, -1.7515e-02, -6.7776e-02,  7.7740e-02,  5.0017e-02,
         1.4004e-01,  5.0576e-02,  6.7084e-02,  3.0877e-02, -3.2757e-02,
        -4.4028e-02,  5.3240e-02,  1.3426e-01])
mlp.net.1.batch_norm.weight tensor([0.4257, 0.4758, 0.5471, 0.4384, 0.4509, 0.5391, 0.4870, 0.5923, 0.5121,
        0.4258, 0.5026, 0.5073, 0.4646, 0.4758, 0.5219, 0.4155, 0.5064, 0.5305,
        0.4030, 0.5295, 0.4890, 0.4723, 0.4724, 0.4802, 0.3914, 0.5239, 0.4845,
        0.4341, 0.4664, 0.4993, 0.3786, 0.3837, 0.4663, 0.5288, 0.4033, 0.4622,
        0.5409, 0.5094, 0.4902, 0.4611, 0.4191, 0.4929, 0.5238, 0.5327, 0.6188,
        0.4516, 0.5026, 0.5406, 0.5014, 0.3949, 0.4216, 0.4023, 0.4937, 0.4605,
        0.4576, 0.3643, 0.4421, 0.5989, 0.4789, 0.4482, 0.4490, 0.4335, 0.4639,
        0.5412, 0.4348, 0.4816, 0.4925, 0.5087, 0.4688, 0.4375, 0.4957, 0.4304,
        0.4151, 0.4207, 0.4647, 0.5439, 0.4889, 0.4988, 0.4533, 0.5225, 0.4541,
        0.5302, 0.5501, 0.4725, 0.4252, 0.4607, 0.4877, 0.5119, 0.5438, 0.4632,
        0.4724, 0.4147, 0.4839, 0.4467, 0.4642, 0.4750, 0.5254, 0.4571, 0.4231,
        0.4651, 0.4091, 0.4285, 0.5342, 0.4438, 0.5240, 0.3952, 0.4476, 0.4639,
        0.4165, 0.4460, 0.4373, 0.4258, 0.4301, 0.4482, 0.4780, 0.4717, 0.5163,
        0.4658, 0.4252, 0.4697, 0.4758, 0.4945, 0.4338, 0.5324, 0.4094, 0.5004,
        0.4164, 0.5005])
mlp.net.1.batch_norm.bias tensor([ 0.0546, -0.1890, -0.0905,  0.3453, -0.1430, -0.2011, -0.2169, -0.1757,
        -0.1214, -0.0983, -0.1132, -0.1572,  0.1157,  0.1870, -0.2025, -0.0447,
        -0.1177, -0.1426,  0.0490, -0.0918, -0.1582,  0.0707, -0.2332, -0.0509,
        -0.1725, -0.0617,  0.2077,  0.0287, -0.1601, -0.2055,  0.1506,  0.1291,
        -0.0427, -0.1187,  0.2291,  0.0984, -0.1094,  0.0617, -0.0935, -0.1296,
        -0.1564, -0.0151, -0.1656, -0.0812, -0.0288,  0.1012, -0.0699,  0.1716,
         0.2658, -0.1163,  0.2678, -0.1857, -0.0193, -0.1298, -0.2076, -0.2426,
         0.0820,  0.0298,  0.0101, -0.1893, -0.1560,  0.2379, -0.1669,  0.1063,
         0.2051, -0.2113, -0.0969, -0.1516, -0.1223, -0.1889, -0.2672,  0.0872,
        -0.2012, -0.1298, -0.1407, -0.1462, -0.2615, -0.1681,  0.1005, -0.0240,
         0.0532, -0.0948, -0.2253,  0.1126,  0.0981, -0.1562, -0.1403, -0.0936,
         0.0724, -0.2247, -0.1884, -0.0166,  0.0563, -0.2585,  0.1537, -0.2649,
        -0.1157, -0.1382, -0.0257,  0.2103, -0.1297, -0.2292, -0.0742,  0.1799,
        -0.0703, -0.2030, -0.2576, -0.2148,  0.1592,  0.2107,  0.0828, -0.1918,
        -0.1392, -0.2288, -0.1358, -0.1751, -0.1335, -0.0616, -0.1876,  0.0385,
        -0.1927, -0.1675, -0.1393, -0.1277, -0.2373, -0.0415,  0.0446, -0.0909])
mlp.net.1.batch_norm.running_mean tensor([0.3796, 0.4427, 0.4074, 0.2956, 0.5491, 0.4559, 0.4153, 0.4664, 0.4677,
        0.2797, 0.6627, 0.4428, 0.3297, 0.4242, 0.4025, 0.3986, 0.4401, 0.4403,
        0.3382, 0.3670, 0.4225, 0.2688, 0.3496, 0.3179, 0.2693, 0.3753, 0.3602,
        0.3905, 0.5374, 0.3256, 0.4279, 0.2704, 0.3789, 0.4936, 0.2950, 0.3953,
        0.5336, 0.3880, 0.2534, 0.3522, 0.4216, 0.4099, 0.5839, 0.3582, 0.4896,
        0.2817, 0.4624, 0.3646, 0.4853, 0.3102, 0.3866, 0.4791, 0.4605, 0.4598,
        0.5083, 0.3950, 0.3705, 0.4857, 0.3855, 0.3538, 0.5891, 0.2242, 0.5194,
        0.4659, 0.3698, 0.5626, 0.5249, 0.3903, 0.5378, 0.3637, 0.5884, 0.4882,
        0.5445, 0.3644, 0.4482, 0.4679, 0.4207, 0.5620, 0.4338, 0.2638, 0.3485,
        0.3340, 0.5118, 0.4755, 0.4193, 0.5751, 0.4071, 0.5067, 0.3667, 0.3129,
        0.4759, 0.1989, 0.3328, 0.4147, 0.3523, 0.4340, 0.5416, 0.3685, 0.3646,
        0.2734, 0.4831, 0.5108, 0.4642, 0.3496, 0.4718, 0.3386, 0.4649, 0.5267,
        0.4858, 0.4374, 0.3723, 0.4595, 0.4860, 0.3229, 0.3004, 0.2855, 0.4763,
        0.2612, 0.3888, 0.3906, 0.6371, 0.4328, 0.3127, 0.3372, 0.5092, 0.2629,
        0.3606, 0.5216])
mlp.net.1.batch_norm.running_var tensor([0.3504, 0.3537, 0.4122, 0.2557, 0.4008, 0.5172, 0.3607, 0.5306, 0.5246,
        0.2093, 0.3571, 0.3610, 0.2339, 0.2798, 0.3650, 0.3695, 0.4343, 0.3273,
        0.2395, 0.3016, 0.3783, 0.2331, 0.2113, 0.1875, 0.1499, 0.3858, 0.4050,
        0.3661, 0.4049, 0.3289, 0.4329, 0.1806, 0.3675, 0.5875, 0.2195, 0.3818,
        0.4383, 0.3833, 0.3353, 0.2722, 0.2851, 0.3723, 0.4392, 0.2712, 0.3446,
        0.2516, 0.4381, 0.3975, 0.3041, 0.3022, 0.3595, 0.3843, 0.4446, 0.4726,
        0.4040, 0.3612, 0.3087, 0.3281, 0.3033, 0.2216, 0.4172, 0.1489, 0.3962,
        0.4790, 0.3505, 0.3829, 0.4550, 0.2854, 0.5646, 0.3639, 0.3475, 0.5489,
        0.4442, 0.2296, 0.4639, 0.4610, 0.4019, 0.5149, 0.3497, 0.2243, 0.3006,
        0.2818, 0.3942, 0.4665, 0.2978, 0.4226, 0.2805, 0.5532, 0.5146, 0.1979,
        0.3729, 0.1856, 0.3335, 0.3126, 0.3172, 0.3052, 0.4391, 0.3016, 0.1934,
        0.2641, 0.3243, 0.3855, 0.5266, 0.3416, 0.3363, 0.3419, 0.3531, 0.4178,
        0.3774, 0.4028, 0.2346, 0.3249, 0.3575, 0.2249, 0.2524, 0.2338, 0.4467,
        0.2014, 0.2212, 0.3957, 0.4521, 0.3529, 0.2210, 0.2553, 0.4707, 0.2392,
        0.3357, 0.4713])
mlp.net.1.batch_norm.num_batches_tracked tensor(112)
mlp.net.2.weight tensor([[ 0.0649, -0.0206, -0.1177,  ...,  0.0300,  0.0355, -0.1235],
        [ 0.0286, -0.0843, -0.0852,  ...,  0.0661,  0.0539, -0.1144],
        [ 0.0231, -0.1126, -0.1152,  ..., -0.0920,  0.0371, -0.0580],
        ...,
        [-0.0023,  0.0746,  0.0109,  ...,  0.0007, -0.0312, -0.0058],
        [-0.0136,  0.0863, -0.0043,  ..., -0.0089, -0.0268,  0.0040],
        [-0.0527, -0.0052,  0.0523,  ..., -0.0844, -0.0673, -0.0194]])
mlp.net.2.bias tensor([ 1.3751e-02,  1.8582e-01,  1.4480e-01,  1.5518e-01,  1.5417e-01,
         1.0874e-01,  1.3034e-01,  1.8529e-01,  8.9273e-02,  1.8551e-01,
         1.8009e-01,  1.5501e-01,  2.3093e-01,  1.7131e-01,  1.5748e-01,
         1.9439e-01,  1.5739e-01,  1.8628e-01,  2.3932e-01,  1.7906e-01,
         1.3137e-01,  2.3565e-01,  1.3379e-01,  2.4348e-01,  1.7782e-01,
         1.9208e-01,  1.5829e-01,  1.6466e-01,  1.3706e-01,  3.1193e-02,
         1.1220e-01,  1.5884e-01,  1.9830e-01,  1.3786e-02,  2.4303e-01,
         8.7097e-02,  8.2421e-02,  1.3568e-02,  1.2506e-01,  9.4328e-02,
         1.1728e-01,  1.8513e-01,  4.0579e-02,  7.3744e-02,  6.2532e-02,
         9.6437e-02,  1.5068e-01, -3.4580e-02,  2.0111e-01, -8.4268e-02,
        -6.2675e-02, -1.3082e-01, -6.5509e-02,  1.0010e-01, -2.4072e-02,
        -1.5339e-03,  4.6282e-04, -1.3815e-01, -5.2431e-03,  4.4708e-02,
         4.6792e-02, -6.3335e-06,  1.2896e-01, -1.2201e-01, -6.2172e-02,
        -1.1269e-02,  1.0502e-01, -1.4386e-03,  9.7035e-02,  4.6255e-02,
         8.5891e-02,  3.2941e-02, -5.5135e-02, -1.2659e-01,  1.3237e-03,
        -1.1302e-01, -3.1265e-02, -3.2695e-01, -4.9345e-02, -1.1254e-01,
        -3.4776e-01, -2.4460e-02,  9.6797e-02,  9.3837e-02, -6.4277e-03,
        -1.0178e-01,  9.3343e-02,  1.3149e-03, -7.6205e-02, -3.6970e-02,
        -1.5258e-01,  2.2622e-02,  1.2358e-02, -3.4642e-01, -1.2461e-01,
        -1.4223e-01, -3.5296e-01, -8.3528e-02, -7.1249e-02, -4.7492e-02,
        -2.6794e-01, -1.1201e-01,  1.5157e-02, -2.7034e-01, -3.0366e-01,
        -6.3738e-02, -4.7189e-02, -2.9194e-01, -3.2150e-01, -1.0190e-01,
        -1.2498e-01, -3.0209e-01, -1.2812e-01, -2.9422e-01, -3.1275e-01,
        -1.1599e-01, -2.8901e-01, -3.3009e-01,  1.5567e-02, -2.7553e-01,
        -8.2613e-02, -3.0659e-01, -3.1877e-01, -1.2315e-01, -4.7507e-02,
        -3.4124e-01, -2.5700e-01, -3.1260e-01, -3.0370e-01, -2.6885e-01,
        -3.2951e-01, -7.6369e-02, -3.1825e-01, -1.0816e-01, -2.9335e-01,
        -3.3387e-01, -2.5608e-01, -3.2470e-01, -2.6773e-01, -2.7530e-01,
        -2.9466e-01, -2.7427e-01, -2.6464e-01, -3.2424e-01, -2.9725e-01,
        -3.0402e-01, -2.7567e-01, -1.0404e-01, -3.2221e-01, -3.3864e-01,
        -3.4140e-01, -3.0614e-01, -2.8057e-01, -2.6130e-01, -3.2652e-01,
        -2.9290e-01, -3.2487e-01, -8.8442e-02, -3.2020e-01, -3.2574e-01,
        -2.9267e-01, -2.5279e-01, -3.0271e-01, -2.6432e-01, -2.9356e-01,
        -2.8361e-01, -8.8863e-02, -2.9269e-01, -2.8655e-01, -7.3551e-02,
        -2.9132e-01, -1.0069e-01, -2.9603e-01, -9.9619e-02, -3.2380e-01,
        -3.0657e-01, -3.1369e-01, -2.6835e-01, -3.2607e-01, -3.4228e-01,
        -2.9640e-01, -3.0474e-01, -3.0416e-01, -3.0940e-01, -3.2069e-01,
        -9.6520e-02, -2.5494e-01, -3.2598e-01, -2.5617e-01, -3.1179e-01,
        -3.3430e-01, -3.3388e-01, -2.6526e-01, -3.0461e-01, -2.9274e-01,
        -6.4415e-02, -3.0558e-01, -2.8566e-01, -3.0475e-01, -2.8295e-01,
        -3.4270e-01, -2.8744e-01, -2.4588e-01, -3.3999e-01, -7.8949e-02,
        -3.2342e-01, -2.6544e-01, -3.3488e-01, -2.9939e-01, -3.3403e-01,
        -3.1634e-01, -2.5312e-01, -3.2641e-01, -3.3493e-01, -1.3782e-01,
        -3.2270e-01, -2.9635e-01, -3.2222e-01, -3.0356e-01, -2.5377e-01,
        -3.2130e-01, -2.9403e-01, -2.7564e-01, -3.2212e-01, -2.5834e-01,
        -3.2752e-01, -3.3961e-01, -3.3756e-01, -3.2010e-01, -2.8211e-01,
        -2.9211e-01, -8.1371e-02, -2.6703e-01, -2.8571e-01, -3.2124e-01,
        -2.9622e-01, -3.2188e-01, -2.5405e-01, -2.4785e-01, -2.5825e-01,
        -2.6203e-01, -3.1658e-01, -2.4734e-01, -2.6172e-01, -2.8527e-01,
        -2.7791e-01, -3.0935e-01, -2.9778e-01, -3.2431e-01, -3.0630e-01,
        -6.5894e-02, -3.1241e-01, -2.8534e-01, -2.8871e-01, -2.9101e-01,
        -2.7267e-01, -3.0032e-01, -3.2757e-01, -8.7068e-02, -2.7942e-01,
        -2.8175e-01, -2.6462e-01, -2.7129e-01, -2.7210e-01, -2.7726e-01,
        -2.8346e-01, -2.6330e-01, -3.3301e-01, -2.9345e-01, -3.1801e-01,
        -2.9209e-01, -2.7996e-01, -2.8861e-01, -2.7760e-01, -3.3208e-01,
        -3.2362e-01, -2.8437e-01, -2.7581e-01, -3.2405e-01, -3.0723e-01,
        -3.0557e-01, -2.9060e-01, -2.6597e-01, -3.3058e-01, -2.7930e-01,
        -2.8831e-01, -3.0366e-01, -2.5147e-01, -2.4909e-01, -2.8988e-01,
        -3.3430e-01, -3.1607e-01, -2.9285e-01, -3.1366e-01, -2.7978e-01,
        -2.9646e-01, -2.7141e-01, -3.2661e-01, -2.4832e-01, -3.1407e-01,
        -3.0785e-01, -2.7918e-01, -3.1961e-01, -3.2403e-01, -2.7179e-01,
        -2.7820e-01, -3.1008e-01, -2.8746e-01, -2.9710e-01, -4.1237e-02,
        -2.7651e-01, -2.9238e-01, -3.0835e-01, -2.6236e-01, -2.9698e-01,
        -2.5906e-01, -2.5918e-01, -2.7711e-01, -3.1849e-01, -6.6549e-02,
        -2.7866e-01, -2.9781e-01, -2.8150e-01, -3.0545e-01, -2.7402e-01,
        -2.8752e-01, -3.0229e-01, -2.9749e-01, -3.1000e-01, -2.6346e-01,
        -3.0087e-01, -2.6983e-01, -3.1457e-01, -2.6781e-01, -2.5944e-01,
        -1.1973e-01, -2.6944e-01, -2.8225e-01, -3.1993e-01, -2.5484e-01,
        -2.7311e-01, -3.1975e-01, -3.0360e-01, -3.1251e-01, -2.6450e-01,
        -2.8990e-01, -2.5657e-01, -2.8404e-01, -3.2213e-01, -2.9580e-01,
        -2.8882e-01, -3.1584e-01, -3.1434e-01, -3.2372e-01, -3.0626e-01,
        -1.1711e-01, -3.1307e-01, -2.9037e-01, -2.5209e-01, -2.8814e-01,
        -2.9670e-01, -3.3714e-01, -3.1495e-01, -3.2789e-01, -2.6499e-01,
        -2.9324e-01, -2.8744e-01, -2.3119e-01, -2.6571e-01, -3.2225e-01,
        -2.6050e-01, -2.6731e-01, -3.0989e-01, -2.6824e-01, -2.5454e-01,
        -2.6023e-01, -2.7858e-01, -2.8849e-01, -3.1524e-01, -3.0549e-01,
        -3.3740e-01, -2.9803e-01, -2.4570e-01, -3.2823e-01, -3.0491e-01,
        -2.8443e-01, -2.6979e-01, -3.0246e-01, -2.5577e-01, -3.1907e-01,
        -2.5078e-01, -2.7012e-01, -3.0346e-01, -2.7191e-01, -2.9575e-01,
        -3.3974e-01, -2.5870e-01, -3.1417e-01, -2.5550e-01, -1.0166e-01])
