Weights: 
embeddings.embeddings.0.weight tensor([[ 0.0384, -0.1994],
        [-0.2057,  0.1117],
        [-0.1681,  0.0094],
        [ 0.1275,  0.1833]])
embeddings.embeddings.1.weight tensor([[ 0.1168,  0.0344],
        [ 0.1804, -0.1438],
        [ 0.0668,  0.2034],
        [ 0.0681,  0.0003],
        [ 0.1572,  0.1987]])
embeddings.embeddings.2.weight tensor([[ 0.1490, -0.1030, -0.1263],
        [ 0.1089,  0.0062,  0.1097],
        [-0.0346,  0.0696, -0.1149],
        [-0.0012, -0.0972,  0.0059],
        [ 0.0713,  0.1120, -0.0338],
        [-0.0605,  0.0714,  0.1072]])
embeddings.embeddings.3.weight tensor([[ 0.0694, -0.0415],
        [-0.1174, -0.1518],
        [ 0.1253, -0.0036],
        [ 0.3375, -0.1364]])
embeddings.embeddings.4.weight tensor([[-0.0539, -0.1781],
        [ 0.2768,  0.0023],
        [-0.1046, -0.0426],
        [-0.0114, -0.2030]])
mlp.net.0.linear.weight tensor([[-0.0599, -0.0796, -0.1064,  ...,  0.0697, -0.1084, -0.0827],
        [ 0.0107,  0.0343,  0.1891,  ..., -0.1206,  0.1174, -0.0333],
        [-0.0635,  0.0568,  0.0646,  ..., -0.0690, -0.1877, -0.0513],
        ...,
        [ 0.0411, -0.0222,  0.1665,  ..., -0.0060, -0.1904, -0.2523],
        [-0.0383,  0.1549,  0.2255,  ..., -0.0056,  0.0326,  0.0640],
        [ 0.1805,  0.1156, -0.0831,  ...,  0.1120,  0.0742,  0.0095]])
mlp.net.0.linear.bias tensor([ 0.0172,  0.0754,  0.0618,  0.0170, -0.0668, -0.0055, -0.0002, -0.0153,
        -0.0545, -0.0542,  0.0607, -0.0295,  0.0560, -0.0342, -0.0244,  0.0149,
         0.0179,  0.0122,  0.0310, -0.0413, -0.0373, -0.0396,  0.0099,  0.0397,
        -0.0631,  0.0294, -0.0273, -0.0007,  0.0133, -0.0517,  0.0713, -0.0241,
        -0.0474,  0.0443, -0.0387, -0.0717, -0.0222, -0.0175, -0.0354, -0.0498,
         0.0015,  0.0310, -0.0165, -0.0424,  0.0211,  0.0037,  0.0582,  0.0097,
        -0.0300, -0.0477, -0.0728, -0.0549,  0.0571,  0.0038, -0.0707,  0.0328,
        -0.0111, -0.0420,  0.0183,  0.0150,  0.0112, -0.0083, -0.0239,  0.0679,
        -0.0659, -0.0292,  0.0383,  0.0114, -0.0145, -0.0075,  0.0101, -0.0353,
         0.0515, -0.0786,  0.0712,  0.0306,  0.0155, -0.0661,  0.0002,  0.0566,
         0.0057,  0.0121,  0.0176, -0.0453, -0.0842,  0.0394,  0.0626,  0.0531,
         0.0136, -0.0310, -0.0664,  0.0085, -0.0379, -0.0607, -0.0750,  0.0118,
        -0.0172,  0.0699,  0.0241, -0.0163,  0.0865, -0.0511,  0.0465,  0.0317,
        -0.0802, -0.0120,  0.0141,  0.0224,  0.0122, -0.0773, -0.0200, -0.0336,
         0.0388,  0.0996, -0.0282,  0.0093,  0.0687,  0.0285, -0.0185, -0.0141,
         0.0172, -0.0420, -0.0367,  0.0007,  0.0389,  0.0715, -0.0163, -0.0115])
mlp.net.0.batch_norm.weight tensor([0.3372, 0.2822, 0.3666, 0.2812, 0.3116, 0.3064, 0.2702, 0.2937, 0.2662,
        0.2889, 0.3154, 0.2855, 0.3048, 0.3294, 0.3615, 0.2712, 0.2734, 0.3425,
        0.2863, 0.3417, 0.3042, 0.3392, 0.2924, 0.3348, 0.2679, 0.3769, 0.2756,
        0.3213, 0.3691, 0.3038, 0.3198, 0.3185, 0.2409, 0.3053, 0.3373, 0.2850,
        0.2931, 0.3084, 0.2803, 0.2782, 0.3278, 0.3639, 0.3694, 0.2948, 0.3185,
        0.3137, 0.2727, 0.3358, 0.2962, 0.2861, 0.3185, 0.3173, 0.3274, 0.3194,
        0.3228, 0.3008, 0.2957, 0.3065, 0.2902, 0.2788, 0.3274, 0.2887, 0.2970,
        0.2927, 0.2852, 0.3285, 0.3403, 0.2865, 0.3129, 0.2846, 0.2802, 0.2813,
        0.3518, 0.3230, 0.2852, 0.2745, 0.3214, 0.3117, 0.2868, 0.3083, 0.2937,
        0.2731, 0.2960, 0.2809, 0.3514, 0.2958, 0.3031, 0.3485, 0.3070, 0.3292,
        0.3252, 0.2932, 0.3088, 0.2903, 0.2983, 0.3655, 0.2839, 0.3334, 0.3736,
        0.2996, 0.2770, 0.3263, 0.3125, 0.3100, 0.2738, 0.2748, 0.3584, 0.3278,
        0.2910, 0.3638, 0.2977, 0.3334, 0.3023, 0.3095, 0.3602, 0.2860, 0.3022,
        0.3160, 0.2890, 0.3310, 0.3586, 0.3361, 0.3566, 0.2826, 0.3072, 0.3398,
        0.2823, 0.2885])
mlp.net.0.batch_norm.bias tensor([ 0.0197, -0.0056, -0.0327, -0.0177, -0.0175, -0.0237,  0.0003, -0.0094,
        -0.0130,  0.0053, -0.0084, -0.0024, -0.0094,  0.0048, -0.0268,  0.0206,
         0.0009, -0.0330, -0.0167, -0.0149, -0.0158, -0.0050,  0.0212,  0.0102,
         0.0155,  0.0415,  0.0094,  0.0160, -0.0411, -0.0014, -0.0014, -0.0166,
        -0.0120, -0.0386,  0.0028,  0.0131, -0.0111, -0.0304, -0.0029, -0.0095,
         0.0017,  0.0290,  0.0419, -0.0044, -0.0416,  0.0214,  0.0140,  0.0174,
        -0.0150, -0.0111,  0.0240, -0.0302, -0.0194,  0.0109, -0.0111,  0.0115,
        -0.0066,  0.0018, -0.0338,  0.0082, -0.0190,  0.0040,  0.0127,  0.0046,
         0.0169, -0.0208,  0.0081, -0.0435,  0.0208, -0.0037,  0.0063, -0.0223,
         0.0099,  0.0130,  0.0150, -0.0107,  0.0304,  0.0049,  0.0117, -0.0246,
        -0.0420,  0.0335,  0.0008,  0.0111, -0.0435,  0.0203,  0.0114,  0.0351,
        -0.0365,  0.0128,  0.0004, -0.0018, -0.0443, -0.0255, -0.0341,  0.0284,
         0.0024,  0.0341, -0.0371, -0.0185, -0.0039,  0.0363, -0.0393, -0.0143,
         0.0041, -0.0009, -0.0272,  0.0020, -0.0168,  0.0530,  0.0136, -0.0207,
         0.0189,  0.0133,  0.0412,  0.0156, -0.0104, -0.0116, -0.0125,  0.0110,
        -0.0292, -0.0134,  0.0413,  0.0067,  0.0013, -0.0024, -0.0087, -0.0250])
mlp.net.0.batch_norm.running_mean tensor([3.4577e-02, 2.0605e-01, 1.9553e-01, 1.2843e-03, 1.2101e-02, 1.3429e-01,
        1.2684e-01, 7.6267e-02, 4.4504e-02, 5.4681e-04, 1.0860e-02, 5.7949e-03,
        1.3305e-04, 4.5259e-03, 1.2176e-01, 8.5473e-02, 1.7491e-01, 6.0715e-02,
        1.4522e-02, 1.9915e-02, 2.9819e-02, 5.1700e-02, 1.3322e-01, 5.1639e-02,
        4.5572e-02, 1.4590e-01, 1.5048e-01, 7.0128e-02, 1.0119e-01, 1.0145e-02,
        1.8268e-01, 0.0000e+00, 7.8606e-02, 1.0601e-02, 9.7040e-03, 8.3395e-02,
        1.4800e-03, 4.5798e-03, 2.8492e-02, 2.4025e-01, 1.2893e-02, 2.8766e-02,
        3.4446e-02, 1.5252e-03, 0.0000e+00, 1.9748e-02, 1.9211e-01, 1.2261e-01,
        5.1610e-03, 1.0572e-01, 0.0000e+00, 1.1136e-02, 1.3485e-01, 2.6688e-01,
        5.0538e-02, 2.7720e-03, 1.4512e-01, 2.8275e-02, 1.2000e-01, 1.2507e-01,
        8.5745e-02, 1.1053e-01, 4.1206e-02, 2.7113e-01, 1.3340e-01, 3.3887e-03,
        2.9153e-02, 1.8965e-02, 1.4295e-13, 2.6688e-02, 1.5379e-01, 1.8453e-02,
        9.0004e-02, 4.1715e-02, 1.3747e-02, 1.6950e-01, 1.4107e-01, 8.6329e-05,
        6.5523e-03, 2.1752e-02, 7.6304e-04, 1.4884e-02, 3.5973e-01, 2.1023e-01,
        5.6884e-02, 3.7586e-02, 8.1243e-02, 4.1945e-01, 4.3492e-05, 4.4750e-02,
        2.2047e-01, 1.7442e-05, 3.5748e-05, 4.4345e-03, 2.5092e-04, 1.3479e-01,
        5.8226e-02, 2.7961e-01, 3.3429e-02, 1.6284e-01, 1.7587e-01, 1.7647e-01,
        3.7148e-01, 1.0430e-02, 1.6461e-04, 9.5690e-04, 2.6261e-01, 7.5801e-02,
        2.2206e-03, 3.5835e-02, 1.7290e-01, 3.0079e-01, 2.7793e-01, 3.1694e-01,
        1.2385e-01, 6.4814e-02, 4.0324e-02, 3.5913e-01, 2.0262e-01, 2.2395e-02,
        2.4965e-01, 1.5532e-01, 4.2878e-02, 3.7640e-02, 3.0757e-03, 1.8168e-01,
        4.3735e-02, 5.4139e-02])
mlp.net.0.batch_norm.running_var tensor([2.2168e-03, 2.9628e-02, 5.6733e-03, 1.0734e-04, 1.5441e-03, 7.3289e-03,
        7.9932e-03, 8.2666e-03, 5.0212e-03, 2.2993e-05, 6.3472e-04, 2.4730e-04,
        1.2293e-05, 5.8873e-04, 2.9967e-03, 9.4092e-03, 7.7053e-03, 4.0537e-03,
        1.3956e-03, 1.5536e-03, 3.9710e-03, 2.3600e-03, 9.9009e-03, 5.7144e-03,
        5.2390e-03, 7.0282e-03, 2.1880e-02, 9.0117e-03, 5.3135e-03, 5.8490e-04,
        5.0507e-03, 1.0874e-22, 1.0109e-02, 7.1045e-04, 7.7579e-04, 8.9907e-03,
        1.1869e-04, 4.0630e-04, 2.1958e-03, 1.2532e-02, 1.9766e-03, 7.1386e-04,
        2.0715e-03, 1.0064e-04, 1.0874e-22, 8.0182e-04, 2.9079e-02, 4.0546e-03,
        1.6122e-04, 6.6816e-03, 1.0874e-22, 6.8143e-04, 8.7066e-03, 6.2196e-03,
        5.3129e-03, 4.0758e-04, 1.5920e-02, 2.5894e-03, 8.3360e-03, 8.6736e-03,
        7.7012e-03, 5.9479e-03, 3.2626e-03, 1.0080e-02, 6.3303e-03, 1.2827e-04,
        1.9340e-03, 1.8360e-03, 1.4322e-15, 2.2554e-03, 1.5024e-02, 1.5421e-03,
        6.1963e-03, 3.6546e-03, 1.0749e-03, 1.6122e-02, 5.9994e-03, 7.9136e-06,
        4.5749e-04, 2.8307e-03, 5.9275e-05, 1.1766e-03, 1.4122e-02, 6.4791e-03,
        2.3787e-03, 3.4161e-03, 1.1174e-02, 1.4399e-02, 2.1173e-06, 3.5717e-03,
        8.4186e-03, 3.4741e-07, 2.4213e-06, 5.6298e-04, 6.5627e-06, 3.1689e-03,
        4.8110e-03, 8.0471e-03, 1.2128e-03, 8.2635e-03, 9.5407e-03, 7.3229e-03,
        1.0289e-02, 1.5376e-03, 1.1135e-05, 7.1971e-05, 6.4735e-03, 4.2449e-03,
        1.5455e-04, 2.8706e-03, 1.9768e-02, 1.5151e-02, 6.9779e-03, 2.2050e-02,
        6.2711e-03, 6.9418e-03, 3.1625e-03, 3.0042e-02, 3.9190e-02, 1.3275e-03,
        1.8175e-02, 4.7652e-03, 2.0337e-03, 3.3576e-03, 1.8283e-04, 1.5728e-02,
        3.5684e-03, 5.8079e-03])
mlp.net.0.batch_norm.num_batches_tracked tensor(480)
mlp.net.1.linear.weight tensor([[ 0.0062, -0.0207,  0.0452,  ...,  0.0328,  0.0060, -0.0938],
        [ 0.0497,  0.0009, -0.0776,  ...,  0.0200,  0.0649,  0.0176],
        [ 0.0226,  0.0310,  0.0310,  ...,  0.0712, -0.0088, -0.0327],
        ...,
        [ 0.0361, -0.0270, -0.0796,  ..., -0.0017,  0.0094, -0.0447],
        [ 0.0190,  0.0426,  0.0250,  ..., -0.0550, -0.0471, -0.0159],
        [ 0.0063, -0.0113,  0.0499,  ..., -0.0563,  0.0391,  0.0127]])
mlp.net.1.linear.bias tensor([-0.0231, -0.0045,  0.0632,  0.0215,  0.0026,  0.0181,  0.0224,  0.0197,
         0.0497,  0.0194, -0.0026,  0.0404,  0.0502,  0.0315,  0.0334,  0.0218,
         0.0517,  0.0207,  0.0189,  0.0515,  0.0390, -0.0013,  0.0665,  0.0061,
        -0.0166,  0.0407,  0.0351,  0.0562,  0.0314,  0.0046,  0.0143, -0.0014,
         0.0390,  0.0179,  0.0236,  0.0639,  0.0158,  0.0393,  0.0122,  0.0439,
         0.0159, -0.0047,  0.0229,  0.0550,  0.0455,  0.0529, -0.0012,  0.0356,
         0.0247,  0.0566,  0.0227,  0.0315,  0.0120,  0.0051,  0.0468,  0.0225,
         0.0310,  0.0359,  0.0437,  0.0249,  0.0563,  0.0467,  0.0659,  0.0111,
         0.0638,  0.0020, -0.0154,  0.0383,  0.0425,  0.0496,  0.0093,  0.0162,
         0.0452,  0.0317,  0.0454,  0.0249,  0.0369,  0.0173,  0.0367,  0.0320,
         0.0167,  0.0512,  0.0420,  0.0199,  0.0242,  0.0450,  0.0547,  0.0436,
         0.0752,  0.0518,  0.0450, -0.0039,  0.0156,  0.0092,  0.0032,  0.0019,
         0.0093,  0.0262,  0.0034,  0.0018, -0.0077,  0.0333,  0.0712, -0.0187,
         0.0475,  0.0558,  0.0079,  0.0247,  0.0316,  0.0511,  0.0434,  0.0419,
         0.0455, -0.0052, -0.0073,  0.0611,  0.0172,  0.0420, -0.0159,  0.0238,
         0.0494,  0.0079,  0.0436, -0.0052,  0.0138,  0.0547,  0.0426,  0.0154])
mlp.net.1.batch_norm.weight tensor([0.3307, 0.3746, 0.3943, 0.3578, 0.3849, 0.3630, 0.3948, 0.3293, 0.3720,
        0.3521, 0.3493, 0.4055, 0.3564, 0.3990, 0.3622, 0.3934, 0.3977, 0.3482,
        0.3652, 0.3912, 0.3823, 0.3144, 0.3963, 0.3658, 0.3522, 0.3852, 0.3633,
        0.3685, 0.3696, 0.3704, 0.3791, 0.3777, 0.4031, 0.3959, 0.3451, 0.4092,
        0.3712, 0.3757, 0.3893, 0.3770, 0.3645, 0.3921, 0.3672, 0.3792, 0.3729,
        0.3450, 0.3225, 0.3673, 0.3646, 0.4031, 0.3577, 0.3415, 0.3597, 0.3488,
        0.3433, 0.3893, 0.3980, 0.3435, 0.3711, 0.3550, 0.3941, 0.4016, 0.4011,
        0.3627, 0.3740, 0.3334, 0.3474, 0.3644, 0.3769, 0.3762, 0.3425, 0.3593,
        0.3985, 0.3528, 0.3832, 0.3730, 0.3216, 0.3256, 0.3652, 0.4049, 0.3696,
        0.3716, 0.3958, 0.3769, 0.3762, 0.3708, 0.4012, 0.3931, 0.3683, 0.3986,
        0.3995, 0.3575, 0.3907, 0.3448, 0.3697, 0.3675, 0.3562, 0.3867, 0.3727,
        0.4080, 0.3572, 0.3580, 0.4193, 0.3255, 0.3657, 0.3763, 0.3867, 0.3298,
        0.3300, 0.3420, 0.3955, 0.3541, 0.3632, 0.3597, 0.3470, 0.3779, 0.4018,
        0.3830, 0.3512, 0.3265, 0.3952, 0.3655, 0.3702, 0.3645, 0.3591, 0.3973,
        0.3945, 0.3604])
mlp.net.1.batch_norm.bias tensor([-0.0580, -0.1016, -0.1153,  0.1012,  0.1072, -0.1071, -0.1197, -0.0117,
        -0.0780,  0.1030, -0.0948, -0.0973,  0.0957, -0.1230,  0.1014, -0.1253,
        -0.1128,  0.1123, -0.1139, -0.1006, -0.1071,  0.0713, -0.1152,  0.0906,
        -0.0948, -0.1059, -0.0942, -0.0996, -0.0970,  0.1110, -0.1095, -0.0989,
        -0.1126, -0.1062,  0.0758, -0.1059, -0.1031,  0.0815, -0.1209, -0.1009,
        -0.0702, -0.1183, -0.1032,  0.1130,  0.1110,  0.0812, -0.0363,  0.0984,
         0.1045, -0.1180, -0.1055,  0.1010, -0.0754,  0.0987,  0.1053, -0.0973,
        -0.1126,  0.1015,  0.1359,  0.0833, -0.1169, -0.1191, -0.0982, -0.1052,
         0.0994,  0.0829,  0.0624,  0.0971,  0.1015, -0.1187,  0.1001, -0.1096,
        -0.1057,  0.0763, -0.1203, -0.1204, -0.0640, -0.0073,  0.1191, -0.1154,
         0.1054,  0.0931, -0.1081, -0.1059, -0.1088,  0.1035, -0.1030, -0.1131,
         0.1105, -0.1143, -0.1121, -0.0801,  0.0829,  0.1053, -0.1022, -0.0891,
        -0.1083, -0.1228, -0.1150, -0.1279, -0.1152,  0.0802, -0.1206, -0.0664,
         0.1061,  0.0919, -0.1177,  0.0569, -0.0393, -0.0659, -0.1116,  0.0915,
         0.1044, -0.0897, -0.0991,  0.1026, -0.1087,  0.1043,  0.0872, -0.0144,
        -0.1051,  0.1127, -0.1017,  0.0922, -0.0892, -0.1169, -0.1155,  0.1067])
mlp.net.1.batch_norm.running_mean tensor([0.0996, 0.1473, 0.1853, 0.1248, 0.1115, 0.1210, 0.1714, 0.0905, 0.1612,
        0.1292, 0.1381, 0.1847, 0.1282, 0.1765, 0.1213, 0.1489, 0.1601, 0.1066,
        0.1409, 0.1771, 0.1525, 0.1046, 0.1828, 0.1316, 0.0974, 0.1501, 0.1743,
        0.1542, 0.1461, 0.1044, 0.1729, 0.1272, 0.1717, 0.1653, 0.1396, 0.1695,
        0.1353, 0.1368, 0.1146, 0.1498, 0.1541, 0.1566, 0.1331, 0.1533, 0.1435,
        0.1410, 0.0842, 0.1259, 0.1200, 0.1941, 0.1269, 0.1020, 0.1189, 0.1009,
        0.1422, 0.1309, 0.1581, 0.1261, 0.1393, 0.1161, 0.1769, 0.1784, 0.1876,
        0.1412, 0.1647, 0.1026, 0.0857, 0.1414, 0.1448, 0.1642, 0.0930, 0.0918,
        0.1586, 0.1295, 0.1783, 0.1311, 0.1073, 0.1064, 0.1258, 0.1754, 0.1075,
        0.1533, 0.1959, 0.1200, 0.1354, 0.1519, 0.1653, 0.1739, 0.1650, 0.1670,
        0.1669, 0.1095, 0.1199, 0.0995, 0.1566, 0.1030, 0.1144, 0.1540, 0.1250,
        0.1598, 0.1259, 0.1212, 0.2182, 0.0910, 0.1266, 0.1489, 0.1449, 0.0998,
        0.1152, 0.1457, 0.1617, 0.1423, 0.1220, 0.1419, 0.1114, 0.1400, 0.1738,
        0.1431, 0.0955, 0.0925, 0.1595, 0.1241, 0.1617, 0.1143, 0.1351, 0.1653,
        0.1532, 0.1374])
mlp.net.1.batch_norm.running_var tensor([0.0332, 0.0431, 0.0438, 0.0347, 0.0270, 0.0293, 0.0448, 0.0196, 0.0370,
        0.0435, 0.0412, 0.0504, 0.0280, 0.0483, 0.0304, 0.0299, 0.0358, 0.0263,
        0.0361, 0.0515, 0.0393, 0.0244, 0.0443, 0.0386, 0.0264, 0.0317, 0.0489,
        0.0389, 0.0403, 0.0239, 0.0455, 0.0305, 0.0397, 0.0413, 0.0357, 0.0340,
        0.0293, 0.0387, 0.0334, 0.0386, 0.0383, 0.0489, 0.0327, 0.0439, 0.0354,
        0.0373, 0.0268, 0.0346, 0.0296, 0.0549, 0.0314, 0.0184, 0.0268, 0.0243,
        0.0385, 0.0292, 0.0468, 0.0303, 0.0332, 0.0298, 0.0398, 0.0451, 0.0468,
        0.0403, 0.0468, 0.0273, 0.0186, 0.0370, 0.0375, 0.0416, 0.0203, 0.0180,
        0.0348, 0.0309, 0.0482, 0.0359, 0.0198, 0.0262, 0.0274, 0.0446, 0.0311,
        0.0408, 0.0573, 0.0325, 0.0431, 0.0411, 0.0335, 0.0452, 0.0496, 0.0379,
        0.0450, 0.0275, 0.0324, 0.0258, 0.0448, 0.0325, 0.0246, 0.0418, 0.0315,
        0.0451, 0.0360, 0.0279, 0.0589, 0.0181, 0.0332, 0.0409, 0.0354, 0.0215,
        0.0247, 0.0360, 0.0422, 0.0384, 0.0299, 0.0378, 0.0293, 0.0392, 0.0482,
        0.0432, 0.0226, 0.0224, 0.0415, 0.0358, 0.0451, 0.0323, 0.0402, 0.0407,
        0.0379, 0.0431])
mlp.net.1.batch_norm.num_batches_tracked tensor(480)
mlp.net.2.weight tensor([[-0.0472, -0.0559, -0.1025,  ..., -0.0725, -0.0986,  0.0737],
        [-0.0425, -0.0978, -0.0939,  ..., -0.1140, -0.0848,  0.0783],
        [-0.0160, -0.0767, -0.1028,  ..., -0.0754, -0.0847,  0.0444],
        ...,
        [-0.0151,  0.0744,  0.0827,  ...,  0.0673,  0.0662, -0.0203],
        [ 0.0165,  0.0719,  0.0463,  ...,  0.0766,  0.0342, -0.0460],
        [ 0.0274,  0.0512,  0.0265,  ...,  0.0291,  0.0257, -0.0539]])
mlp.net.2.bias tensor([ 1.4998e-01,  1.5848e-01,  1.1462e-01,  9.7964e-02,  6.5105e-02,
         5.7062e-02,  7.8260e-02,  4.5644e-02,  5.3354e-02,  3.7803e-02,
         4.3837e-02,  6.3437e-02,  3.9270e-02,  3.1341e-02,  2.3636e-02,
         4.1317e-02,  5.2037e-02,  4.9213e-02,  2.3660e-02,  1.1328e-02,
         6.0661e-03,  4.7250e-02,  4.1221e-02,  1.5803e-02,  3.4936e-02,
         3.6008e-02,  1.2024e-02, -2.4254e-06,  4.7488e-03,  2.0181e-03,
         4.3219e-03, -3.4339e-05, -8.4346e-04, -3.9636e-02,  1.2965e-02,
        -2.0576e-02, -6.5297e-03, -8.6213e-02, -2.9182e-02,  1.9809e-02,
        -4.7071e-03,  3.7712e-03, -1.5217e-02, -7.4165e-02, -5.2479e-02,
        -6.5670e-02, -4.8225e-02, -9.2575e-02,  7.1499e-03, -8.2665e-02,
        -1.0635e-01, -9.0669e-02, -8.8517e-02, -3.2322e-02, -3.2111e-02,
        -7.8207e-02, -1.6298e-02, -8.8598e-02, -5.5977e-02, -3.7948e-02,
        -1.0691e-01, -5.4071e-02, -3.8076e-02, -6.0787e-02, -1.1068e-01,
        -1.1486e-01, -5.4985e-02, -7.4936e-02, -2.8786e-02, -3.8146e-02,
        -4.8827e-02, -3.6309e-02, -8.6424e-02, -1.3203e-01, -1.3917e-01,
        -9.0708e-02, -1.0526e-01, -1.4886e-01, -1.2363e-01, -9.1429e-02,
        -1.8500e-01, -9.0110e-02, -6.9128e-02, -8.6448e-02, -7.6011e-02,
        -9.4528e-02, -6.3224e-02, -7.4931e-02, -8.9011e-02, -6.3335e-02,
        -1.2263e-01, -3.2257e-02, -9.3764e-02, -1.7408e-01, -1.2979e-01,
        -6.4970e-02, -1.2708e-01, -1.2499e-01, -1.1746e-01, -7.9345e-02,
        -1.1922e-01, -1.4510e-01, -6.8807e-02, -1.5112e-01, -1.5912e-01,
        -9.3447e-02, -8.2613e-02, -1.2598e-01, -1.1748e-01, -1.3462e-01,
        -1.0157e-01, -1.6089e-01, -1.2670e-01, -1.6046e-01, -1.6189e-01,
        -1.8229e-01, -1.2972e-01, -1.6899e-01, -9.0715e-02, -1.3987e-01,
        -1.1052e-01, -1.6312e-01, -1.6632e-01, -8.4602e-02, -1.6121e-01,
        -1.0691e-01, -1.2304e-01, -1.2362e-01, -1.5483e-01, -7.4915e-02,
        -1.7635e-01, -9.7366e-02, -1.6502e-01, -1.0555e-01, -1.4813e-01,
        -1.5323e-01, -1.0043e-01, -1.5173e-01, -1.5558e-01, -1.2622e-01,
        -1.4346e-01, -1.5019e-01, -1.2363e-01, -1.7520e-01, -1.7132e-01,
        -1.3728e-01, -1.5573e-01, -1.0616e-01, -1.8080e-01, -7.8802e-02,
        -1.2940e-01, -1.3822e-01, -1.7534e-01, -1.5137e-01, -1.6067e-01,
        -1.6563e-01, -1.3865e-01, -1.1495e-01, -9.8624e-02, -1.6645e-01,
        -1.4872e-01, -1.2138e-01, -1.7474e-01, -1.5132e-01, -1.6151e-01,
        -1.6748e-01, -1.0072e-01, -1.4171e-01, -1.3723e-01, -1.1420e-01,
        -1.7212e-01, -1.3290e-01, -1.2770e-01, -1.3802e-01, -1.3124e-01,
        -1.4796e-01, -1.2562e-01, -1.2770e-01, -1.5709e-01, -1.7243e-01,
        -1.3059e-01, -1.5201e-01, -1.7158e-01, -1.3371e-01, -1.2380e-01,
        -1.3936e-01, -1.5341e-01, -1.5923e-01, -1.7304e-01, -1.6032e-01,
        -1.5919e-01, -1.7101e-01, -1.5342e-01, -1.7087e-01, -1.5831e-01,
        -1.7398e-01, -1.4440e-01, -1.6248e-01, -1.2012e-01, -1.5505e-01,
        -1.6643e-01, -1.1595e-01, -1.2755e-01, -1.2760e-01, -1.1343e-01,
        -1.3094e-01, -1.5082e-01, -1.5292e-01, -1.6158e-01, -1.3257e-01,
        -1.3952e-01, -1.5034e-01, -1.4058e-01, -1.1870e-01, -1.0042e-01,
        -1.5121e-01, -1.4385e-01, -1.7724e-01, -1.3286e-01, -1.6870e-01,
        -1.3056e-01, -1.5835e-01, -1.7645e-01, -1.6744e-01, -1.7013e-01,
        -1.4477e-01, -1.4282e-01, -1.6304e-01, -1.4327e-01, -1.3081e-01,
        -1.6695e-01, -7.9089e-02, -1.3851e-01, -1.2878e-01, -1.2310e-01,
        -1.5656e-01, -1.6711e-01, -1.7480e-01, -1.7773e-01, -1.3719e-01,
        -1.3326e-01, -1.2904e-01, -1.5256e-01, -1.2930e-01, -1.5823e-01,
        -1.7040e-01, -1.2550e-01, -1.7856e-01, -1.6785e-01, -1.7449e-01,
        -9.9669e-02, -1.5283e-01, -1.6975e-01, -1.2842e-01, -1.2228e-01,
        -1.2834e-01, -1.5216e-01, -1.5330e-01, -9.4610e-02, -1.4593e-01,
        -1.5090e-01, -1.3313e-01, -1.6943e-01, -1.6647e-01, -1.3997e-01,
        -1.4525e-01, -1.4907e-01, -1.5199e-01, -1.2773e-01, -1.4836e-01,
        -1.6520e-01, -1.5644e-01, -1.5194e-01, -1.2777e-01, -1.3524e-01,
        -1.7716e-01, -1.6446e-01, -1.4782e-01, -1.2466e-01, -1.6102e-01,
        -1.4893e-01, -1.6695e-01, -1.3407e-01, -1.4608e-01, -1.6353e-01,
        -1.3927e-01, -1.2882e-01, -1.4346e-01, -1.4271e-01, -1.8500e-01,
        -1.3604e-01, -1.4772e-01, -1.2898e-01, -1.3479e-01, -1.5407e-01,
        -1.5352e-01, -1.3930e-01, -1.6794e-01, -1.5757e-01, -1.7057e-01,
        -1.5833e-01, -1.7705e-01, -1.3709e-01, -1.5387e-01, -1.6139e-01,
        -1.4573e-01, -1.3491e-01, -1.4327e-01, -1.2162e-01, -1.3357e-01,
        -1.5429e-01, -1.2889e-01, -1.5140e-01, -1.4007e-01, -1.3033e-01,
        -1.2487e-01, -1.3953e-01, -1.5445e-01, -1.2325e-01, -9.3211e-02,
        -1.5716e-01, -1.7733e-01, -1.6379e-01, -1.7150e-01, -1.7171e-01,
        -1.7251e-01, -1.4817e-01, -1.5340e-01, -1.2885e-01, -1.5295e-01,
        -1.6493e-01, -1.4035e-01, -1.3797e-01, -1.3838e-01, -1.2559e-01,
        -1.1256e-01, -1.7014e-01, -1.6979e-01, -1.4813e-01, -1.3122e-01,
        -1.2882e-01, -1.4196e-01, -1.7230e-01, -1.5165e-01, -1.6492e-01,
        -1.3467e-01, -1.0569e-01, -1.7202e-01, -1.3466e-01, -1.6464e-01,
        -1.7235e-01, -1.8037e-01, -1.3993e-01, -1.5055e-01, -1.7072e-01,
        -8.5620e-02, -1.4537e-01, -1.5657e-01, -1.2729e-01, -1.6604e-01,
        -1.5944e-01, -1.6208e-01, -1.3144e-01, -1.3345e-01, -1.2833e-01,
        -1.5885e-01, -1.5576e-01, -1.5103e-01, -1.4009e-01, -1.4380e-01,
        -1.4537e-01, -1.6711e-01, -1.4369e-01, -1.2780e-01, -1.2257e-01,
        -1.5675e-01, -1.3765e-01, -1.7257e-01, -1.3995e-01, -1.3603e-01,
        -1.5702e-01, -1.6313e-01, -1.3009e-01, -1.3639e-01, -1.7803e-01,
        -1.4280e-01, -1.4634e-01, -1.7156e-01, -1.5980e-01, -1.3740e-01,
        -1.2115e-01, -1.6925e-01, -1.3678e-01, -1.7486e-01, -1.6125e-01,
        -1.5734e-01, -1.2763e-01, -1.4924e-01, -1.6553e-01, -1.2882e-01])
