Weights: 
embeddings.embeddings.0.weight tensor([[-0.0422,  0.0361],
        [ 0.0157,  0.0364],
        [ 0.0114,  0.0188],
        [-0.0048,  0.0354]])
embeddings.embeddings.1.weight tensor([[ 0.0092, -0.0431],
        [-0.0388, -0.0102],
        [ 0.0248, -0.0022],
        [-0.0006, -0.0203],
        [-0.0112, -0.0397]])
embeddings.embeddings.2.weight tensor([[ 0.0096,  0.0004,  0.0213],
        [ 0.0026,  0.0219,  0.0150],
        [ 0.0368, -0.0289, -0.0313],
        [ 0.0099, -0.0339,  0.0266],
        [-0.0247, -0.0288, -0.0089],
        [ 0.0051, -0.0359, -0.0076]])
embeddings.embeddings.3.weight tensor([[-0.0392, -0.0091],
        [-0.0854,  0.0742],
        [-0.0432,  0.0426],
        [ 0.0267,  0.0213]])
embeddings.embeddings.4.weight tensor([[ 0.0380,  0.0024],
        [ 0.0119,  0.0182],
        [-0.0584,  0.0523],
        [ 0.0074, -0.0373]])
mlp.net.0.linear.weight tensor([[-0.0291,  0.0044,  0.0093,  ...,  0.0072, -0.0328, -0.0156],
        [-0.0342,  0.0596, -0.0046,  ..., -0.0105,  0.0197, -0.0353],
        [ 0.0124, -0.0273, -0.0110,  ...,  0.0329,  0.0195, -0.0036],
        ...,
        [ 0.0232,  0.0383, -0.0067,  ..., -0.0432, -0.0500, -0.0140],
        [-0.0351, -0.0157, -0.0540,  ...,  0.0737,  0.0072, -0.0770],
        [ 0.0429, -0.0166,  0.0163,  ...,  0.0451, -0.0503,  0.0169]])
mlp.net.0.linear.bias tensor([-1.2264e-02, -1.6626e-02,  6.4105e-03,  3.4160e-05, -1.2074e-02,
        -1.4020e-02, -1.4417e-02,  7.2181e-03,  1.4743e-02,  1.5529e-03,
         2.0366e-02, -8.1962e-03,  5.3017e-03, -7.7102e-03, -1.1036e-02,
         7.7401e-03,  3.2727e-03,  3.8147e-03, -1.4615e-03, -8.8361e-03,
         8.5646e-03,  1.1235e-02, -9.9081e-03,  5.5643e-03,  9.0052e-03,
         1.3924e-03,  5.2434e-03, -6.8841e-03,  3.7994e-03,  1.7697e-02,
        -8.3153e-03, -1.6971e-02,  1.2366e-02,  1.3700e-02,  3.2054e-03,
         8.6497e-03,  6.0246e-03,  9.4154e-03,  2.3336e-04, -1.4469e-02,
        -6.1613e-03, -8.4894e-03,  1.3989e-02,  1.5775e-02,  9.8672e-03,
        -7.0367e-04, -1.4565e-02,  1.3799e-02, -1.3688e-02,  1.1632e-02,
        -4.5718e-03, -4.6412e-03, -1.5148e-02,  1.0226e-02,  1.1453e-02,
         1.0422e-02, -1.0685e-02, -9.0078e-03, -3.1263e-04, -1.2892e-02,
         1.2300e-02,  8.4159e-04, -1.6636e-02, -1.6888e-02])
mlp.net.0.batch_norm.weight tensor([0.0704, 0.0816, 0.0845, 0.0797, 0.0820, 0.0723, 0.0957, 0.0684, 0.0803,
        0.0847, 0.0718, 0.0793, 0.1202, 0.0867, 0.0759, 0.0746, 0.0734, 0.0789,
        0.0734, 0.0766, 0.0822, 0.0765, 0.0653, 0.0849, 0.0809, 0.0833, 0.0703,
        0.0842, 0.1055, 0.0797, 0.0885, 0.0839, 0.0854, 0.0843, 0.0694, 0.0776,
        0.0846, 0.0846, 0.0688, 0.0739, 0.0795, 0.0912, 0.0765, 0.0630, 0.0792,
        0.0872, 0.0830, 0.0834, 0.0743, 0.0814, 0.0773, 0.0797, 0.0735, 0.0651,
        0.0789, 0.0841, 0.0863, 0.1000, 0.0744, 0.0797, 0.0772, 0.0743, 0.0719,
        0.0708])
mlp.net.0.batch_norm.bias tensor([-3.2015e-03, -1.3991e-02,  7.6346e-03,  9.9330e-03, -9.4122e-03,
        -2.5102e-03,  2.2024e-02,  1.5758e-02,  7.5679e-03, -1.5734e-02,
        -4.2572e-03,  1.9275e-02,  1.9061e-02, -6.9264e-03,  3.4993e-03,
         1.2461e-02, -3.1478e-03,  4.8561e-03, -9.6706e-03,  2.7086e-04,
        -2.1793e-03, -1.1092e-02, -2.1266e-03, -1.5678e-03,  2.1199e-02,
        -1.2476e-02,  6.2065e-03, -6.2460e-03,  3.3670e-03,  8.7502e-04,
        -3.6871e-03, -5.3336e-03, -2.0297e-03,  1.6380e-02, -8.4786e-03,
        -2.2040e-02,  1.4602e-02,  1.4486e-02, -3.8134e-03, -1.4585e-02,
        -5.4101e-03, -1.0933e-02,  2.6218e-03, -1.1301e-02, -1.0962e-02,
         8.4563e-03,  2.2044e-03,  1.2491e-02, -1.2427e-02,  7.4122e-03,
         1.3707e-03,  2.3352e-03,  2.5304e-03, -1.5441e-02, -5.7702e-03,
         1.1450e-02,  1.1808e-02, -1.8104e-02, -1.7804e-02,  4.8877e-03,
         1.3670e-02, -5.3440e-03,  8.5617e-03, -6.3167e-05])
mlp.net.0.batch_norm.running_mean tensor([8.4036e-04, 3.8029e-05, 3.7900e-02, 7.0413e-02, 1.7903e-02, 1.0487e-03,
        3.4685e-03, 1.4220e-03, 6.1662e-02, 2.4222e-02, 9.5788e-03, 2.6895e-05,
        9.4651e-03, 4.1386e-03, 1.2157e-02, 4.8368e-02, 3.2677e-05, 9.2156e-03,
        2.5887e-02, 1.8871e-03, 3.8745e-03, 3.0168e-02, 2.1537e-02, 4.0281e-02,
        4.4095e-02, 7.8632e-02, 3.4190e-02, 2.6729e-03, 5.7996e-03, 6.7089e-02,
        2.2713e-02, 4.0332e-02, 1.5340e-02, 1.2009e-02, 5.5449e-03, 5.2770e-02,
        5.7400e-02, 4.8352e-02, 1.5775e-03, 2.5412e-05, 2.1223e-02, 1.3196e-02,
        3.1505e-02, 4.4826e-03, 2.3867e-02, 1.5062e-02, 2.5308e-02, 7.3715e-02,
        1.1135e-02, 1.1752e-02, 1.3697e-02, 5.3334e-02, 5.0565e-03, 7.6508e-03,
        1.8351e-02, 1.6163e-02, 1.6212e-05, 2.7307e-02, 1.7276e-04, 3.0999e-04,
        6.7100e-02, 3.7178e-02, 1.7063e-02, 2.9730e-04])
mlp.net.0.batch_norm.running_var tensor([1.5189e-05, 6.9251e-07, 3.6868e-04, 1.4156e-03, 2.1344e-04, 2.3888e-05,
        2.5972e-05, 3.6856e-05, 2.9976e-04, 2.4599e-04, 1.6896e-04, 9.5429e-08,
        2.2199e-05, 4.2578e-05, 1.9181e-04, 1.5075e-03, 5.7941e-07, 1.5795e-04,
        1.0141e-03, 2.3465e-05, 6.2726e-05, 6.6376e-04, 5.5456e-04, 8.2409e-04,
        2.5208e-04, 1.0135e-03, 3.3390e-04, 1.5877e-05, 1.2609e-05, 5.2203e-04,
        1.0776e-04, 4.5431e-04, 1.3111e-04, 2.3665e-04, 6.7357e-05, 8.5437e-04,
        1.1103e-03, 4.0038e-04, 3.4271e-05, 8.7841e-08, 3.8822e-04, 5.2270e-05,
        6.1582e-04, 1.1017e-04, 2.0129e-04, 2.5174e-04, 2.2222e-04, 7.5542e-04,
        3.0182e-04, 2.1252e-04, 3.2977e-04, 6.8827e-04, 8.7659e-05, 1.0291e-04,
        3.6478e-04, 2.6701e-04, 1.5898e-07, 1.5660e-04, 2.4911e-06, 5.3101e-06,
        5.0597e-04, 4.5257e-04, 5.2374e-04, 7.2826e-06])
mlp.net.0.batch_norm.num_batches_tracked tensor(1856)
mlp.net.1.linear.weight tensor([[-0.0150,  0.0229, -0.0003,  ...,  0.0063,  0.0245,  0.0092],
        [-0.0180,  0.0096,  0.0010,  ..., -0.0041,  0.0146,  0.0042],
        [-0.0130, -0.0135, -0.0282,  ...,  0.0145,  0.0081,  0.0064],
        ...,
        [-0.0036, -0.0007,  0.0215,  ..., -0.0050,  0.0134, -0.0202],
        [ 0.0027, -0.0235,  0.0091,  ...,  0.0266,  0.0036, -0.0022],
        [-0.0125, -0.0069, -0.0467,  ..., -0.0169, -0.0020, -0.0038]])
mlp.net.1.linear.bias tensor([ 0.0123,  0.0054,  0.0095,  0.0169,  0.0022,  0.0097,  0.0176,  0.0061,
         0.0107,  0.0041,  0.0145,  0.0112,  0.0092,  0.0036,  0.0169,  0.0062,
        -0.0037,  0.0108,  0.0014,  0.0113,  0.0081,  0.0137, -0.0002,  0.0102,
         0.0085,  0.0100,  0.0117,  0.0181,  0.0162,  0.0122,  0.0112,  0.0111,
         0.0068,  0.0027,  0.0077,  0.0133,  0.0186,  0.0138,  0.0150,  0.0061,
         0.0148,  0.0048,  0.0122,  0.0127,  0.0128,  0.0047,  0.0132,  0.0109,
         0.0210,  0.0168,  0.0082,  0.0050,  0.0112,  0.0147,  0.0099,  0.0087,
         0.0163,  0.0086,  0.0072,  0.0122,  0.0008,  0.0183, -0.0075,  0.0061])
mlp.net.1.batch_norm.weight tensor([0.1214, 0.1267, 0.1250, 0.1247, 0.1144, 0.1185, 0.1226, 0.1238, 0.1224,
        0.1251, 0.1255, 0.1260, 0.1182, 0.1216, 0.1259, 0.1208, 0.1225, 0.1236,
        0.1122, 0.1250, 0.1201, 0.1296, 0.1138, 0.1229, 0.1251, 0.1157, 0.1283,
        0.1261, 0.1273, 0.1266, 0.1222, 0.1241, 0.1254, 0.1178, 0.1225, 0.1246,
        0.1238, 0.1268, 0.1281, 0.1265, 0.1227, 0.1176, 0.1236, 0.1249, 0.1280,
        0.1216, 0.1279, 0.1215, 0.1255, 0.1236, 0.1213, 0.1249, 0.1206, 0.1251,
        0.1259, 0.1248, 0.1244, 0.1254, 0.1269, 0.1255, 0.1273, 0.1266, 0.1199,
        0.1252])
mlp.net.1.batch_norm.bias tensor([ 0.0431,  0.0496,  0.0462, -0.0459,  0.0432, -0.0419, -0.0481, -0.0494,
         0.0451,  0.0470, -0.0490, -0.0472,  0.0483,  0.0432, -0.0491,  0.0428,
        -0.0498, -0.0448,  0.0291, -0.0484, -0.0483, -0.0497,  0.0495, -0.0495,
         0.0482,  0.0387, -0.0498, -0.0486, -0.0383, -0.0498, -0.0463,  0.0448,
         0.0485,  0.0497,  0.0481, -0.0443, -0.0479, -0.0476, -0.0495,  0.0478,
        -0.0496, -0.0421,  0.0473, -0.0454, -0.0477,  0.0488,  0.0494,  0.0485,
        -0.0463, -0.0502, -0.0487,  0.0334, -0.0499, -0.0495,  0.0501,  0.0507,
        -0.0485,  0.0500,  0.0487, -0.0497,  0.0498, -0.0496, -0.0361,  0.0494])
mlp.net.1.batch_norm.running_mean tensor([0.0099, 0.0062, 0.0088, 0.0195, 0.0045, 0.0129, 0.0213, 0.0120, 0.0082,
        0.0062, 0.0182, 0.0158, 0.0084, 0.0046, 0.0218, 0.0065, 0.0062, 0.0142,
        0.0039, 0.0159, 0.0119, 0.0170, 0.0037, 0.0155, 0.0087, 0.0071, 0.0164,
        0.0208, 0.0193, 0.0164, 0.0131, 0.0093, 0.0071, 0.0050, 0.0071, 0.0147,
        0.0210, 0.0183, 0.0194, 0.0063, 0.0189, 0.0094, 0.0105, 0.0172, 0.0173,
        0.0064, 0.0095, 0.0099, 0.0263, 0.0198, 0.0109, 0.0061, 0.0145, 0.0176,
        0.0087, 0.0086, 0.0195, 0.0083, 0.0072, 0.0161, 0.0059, 0.0221, 0.0025,
        0.0066])
mlp.net.1.batch_norm.running_var tensor([7.6827e-05, 5.6464e-05, 6.2315e-05, 9.9953e-05, 4.2759e-05, 5.9174e-05,
        8.2136e-05, 6.4569e-05, 6.7394e-05, 6.8972e-05, 8.1743e-05, 6.6856e-05,
        6.6120e-05, 5.3203e-05, 1.0482e-04, 5.9865e-05, 6.3045e-05, 6.4617e-05,
        3.7887e-05, 6.3307e-05, 7.8492e-05, 8.1650e-05, 3.7048e-05, 8.3468e-05,
        9.6799e-05, 5.0608e-05, 6.9092e-05, 9.3430e-05, 6.6450e-05, 6.6506e-05,
        5.9484e-05, 8.3523e-05, 6.3104e-05, 3.9987e-05, 6.6834e-05, 5.0183e-05,
        8.5426e-05, 7.8774e-05, 8.9337e-05, 5.8784e-05, 8.1494e-05, 5.0803e-05,
        1.1158e-04, 6.6667e-05, 6.8372e-05, 5.9705e-05, 1.0350e-04, 1.0801e-04,
        1.1992e-04, 8.5392e-05, 7.5225e-05, 4.8107e-05, 6.7856e-05, 7.5484e-05,
        6.2384e-05, 6.2931e-05, 1.0449e-04, 8.1745e-05, 7.4678e-05, 6.6122e-05,
        5.4145e-05, 9.1773e-05, 4.8736e-05, 6.1614e-05])
mlp.net.1.batch_norm.num_batches_tracked tensor(1856)
mlp.net.2.weight tensor([[ 0.0241,  0.0397,  0.0167,  ..., -0.0275, -0.0209,  0.0311],
        [ 0.0168,  0.0272,  0.0186,  ..., -0.0325, -0.0084,  0.0254],
        [ 0.0195,  0.0282,  0.0163,  ..., -0.0440, -0.0368,  0.0298],
        ...,
        [-0.0341, -0.0505, -0.0409,  ...,  0.0408, -0.0026, -0.0434],
        [-0.0331, -0.0453, -0.0358,  ...,  0.0321,  0.0107, -0.0433],
        [ 0.0040, -0.0306,  0.0062,  ...,  0.0281,  0.0120, -0.0248]])
mlp.net.2.bias tensor([-4.6479e-02,  2.4835e-02,  2.9215e-02,  3.2855e-02,  3.3024e-02,
         4.0632e-02,  3.6552e-02,  2.2136e-02,  1.7851e-02,  1.9628e-02,
         2.7472e-02,  2.9980e-02,  3.3225e-02,  1.5611e-02,  2.8007e-02,
         2.4924e-02,  3.1441e-02,  2.0808e-02,  1.0270e-02,  3.0112e-02,
         1.2297e-02,  1.7382e-02,  2.1408e-02,  2.1283e-02,  1.7696e-02,
         2.2923e-02,  2.1261e-02,  2.6052e-02,  2.7539e-02,  1.2650e-02,
         1.9894e-02,  2.2221e-02,  2.6742e-02,  2.0587e-03,  1.8951e-02,
         1.8928e-02,  1.1305e-02,  1.4135e-02,  2.8192e-02,  1.3570e-02,
         6.2303e-03,  2.1474e-02,  2.5960e-02,  1.0026e-02,  6.7375e-03,
        -3.3554e-03,  1.6285e-02,  6.8815e-03,  1.0150e-02, -1.5204e-02,
        -1.3348e-02, -2.4084e-02,  4.4350e-03,  1.6512e-02, -2.1811e-03,
         9.8240e-03,  9.0678e-03,  3.0159e-03,  4.9236e-03,  4.7303e-03,
        -5.8169e-03, -6.7786e-03,  1.1062e-02, -4.1362e-03, -8.1569e-03,
        -2.6910e-02,  7.8516e-03,  4.2630e-03,  1.1681e-02,  5.4437e-03,
        -1.7303e-05,  4.0880e-03, -8.5162e-03, -2.0004e-02,  2.9754e-03,
        -3.1373e-02, -1.2430e-02, -4.7530e-02, -1.5722e-02,  2.3291e-04,
        -4.1861e-02, -4.6438e-03, -8.2522e-03, -1.1610e-02, -1.0980e-02,
        -4.8661e-02,  7.4273e-03, -6.9046e-03, -1.6935e-02, -5.6911e-03,
        -1.4827e-02, -1.5168e-02, -1.1966e-02, -5.6067e-02, -1.9955e-02,
        -1.4727e-02, -5.4436e-02, -4.9522e-02, -1.3888e-02, -4.7479e-03,
        -5.0838e-02, -6.3385e-03, -7.1615e-03, -4.2143e-02, -3.9593e-02,
        -2.5986e-02, -2.2852e-02, -1.4941e-02, -2.3507e-02, -1.4745e-02,
        -2.4891e-02, -5.5564e-02, -1.9281e-02, -4.3967e-02, -3.8060e-02,
        -2.9845e-02, -4.4116e-02, -5.1404e-02, -3.7263e-02, -5.1032e-02,
        -8.4163e-03, -4.4616e-02, -5.2705e-02, -1.0727e-02, -1.1116e-02,
        -1.5768e-02, -5.6981e-02, -5.5977e-02, -4.3778e-02, -2.4524e-02,
        -4.9425e-02, -2.3879e-02, -3.7534e-02, -1.1729e-02, -3.7555e-02,
        -4.2660e-02, -4.2218e-02, -4.8410e-02, -5.4600e-02, -4.8530e-02,
        -5.1219e-02, -4.1898e-02, -4.8578e-02, -4.5180e-02, -4.6586e-02,
        -3.9192e-02, -4.0708e-02, -1.7834e-02, -1.4504e-02, -2.4032e-02,
        -3.8914e-02, -4.2332e-02, -4.0139e-02, -5.4858e-02, -4.5648e-02,
        -5.4690e-02, -5.3032e-02, -1.1995e-02, -2.7645e-02, -4.4677e-02,
        -4.6175e-02, -4.6175e-02, -4.3803e-02, -3.8555e-02, -5.6808e-02,
        -4.6061e-02, -1.5249e-02, -4.7402e-02, -3.8452e-02, -4.6901e-02,
        -4.9241e-02, -2.8962e-02, -3.9903e-02, -1.1041e-02, -5.4195e-02,
        -4.0585e-02, -5.1214e-02, -2.7128e-02, -5.5752e-02, -5.7332e-02,
        -3.8731e-02, -4.5280e-02, -4.8950e-02, -3.7887e-02, -4.7491e-02,
        -1.3271e-02, -4.9829e-02, -3.9069e-02, -3.6781e-02, -3.8779e-02,
        -5.7352e-02, -4.2459e-02, -4.4491e-02, -5.1590e-02, -4.5450e-02,
        -4.7454e-02, -4.3218e-02, -4.1170e-02, -3.6934e-02, -5.6387e-02,
        -3.9898e-02, -1.0126e-02, -5.0642e-02, -5.6517e-02, -1.2652e-02,
        -5.4900e-02, -4.6758e-02, -5.1373e-02, -4.6246e-02, -5.3282e-02,
        -5.3115e-02, -4.4492e-02, -4.2516e-02, -1.9359e-02, -4.3930e-02,
        -5.6904e-02, -4.1021e-02, -4.0631e-02, -5.7201e-02, -3.8967e-02,
        -4.9517e-02, -5.2257e-02, -3.9318e-02, -5.2513e-02, -4.9531e-02,
        -5.2796e-02, -5.4568e-02, -4.5386e-02, -4.4167e-02, -3.8570e-02,
        -5.4002e-02, -1.8964e-02, -5.1776e-02, -5.4486e-02, -5.4905e-02,
        -4.8298e-02, -3.8704e-02, -4.4901e-02, -4.1579e-02, -4.6063e-02,
        -3.8945e-02, -3.8318e-02, -4.6988e-02, -3.7841e-02, -4.9871e-02,
        -4.0009e-02, -5.0063e-02, -5.4529e-02, -3.8410e-02, -4.5605e-02,
        -1.0757e-02, -5.4837e-02, -5.7343e-02, -5.3468e-02, -4.4745e-02,
        -3.7082e-02, -4.8999e-02, -5.0754e-02, -1.2225e-02, -3.8545e-02,
        -4.3676e-02, -2.5327e-02, -4.4032e-02, -5.3056e-02, -4.4071e-02,
        -3.9475e-02, -4.5680e-02, -5.3786e-02, -4.7329e-02, -4.5690e-02,
        -4.4546e-02, -4.0722e-02, -4.0222e-02, -5.7243e-02, -5.7191e-02,
        -5.2261e-02, -4.7146e-02, -5.5679e-02, -5.1996e-02, -5.4039e-02,
        -4.4789e-02, -5.5365e-02, -4.3607e-02, -4.2174e-02, -4.2090e-02,
        -4.5803e-02, -4.8107e-02, -4.6528e-02, -4.0086e-02, -5.2870e-02,
        -5.5379e-02, -4.2182e-02, -4.9641e-02, -4.2026e-02, -4.4458e-02,
        -5.2053e-02, -5.1112e-02, -5.0249e-02, -5.6051e-02, -3.8512e-02,
        -4.4108e-02, -5.3716e-02, -4.2060e-02, -4.7495e-02, -4.3088e-02,
        -4.9508e-02, -5.2906e-02, -4.2189e-02, -5.2947e-02, -2.2209e-02,
        -5.3835e-02, -5.1243e-02, -5.6803e-02, -4.3530e-02, -4.7560e-02,
        -5.6899e-02, -4.6217e-02, -4.7888e-02, -5.5925e-02, -2.2354e-02,
        -4.7170e-02, -5.3454e-02, -4.7576e-02, -5.2481e-02, -4.0668e-02,
        -4.4271e-02, -3.8219e-02, -4.4266e-02, -3.7433e-02, -5.6168e-02,
        -3.8154e-02, -5.4286e-02, -5.2765e-02, -4.2739e-02, -3.9429e-02,
        -8.3677e-03, -5.4544e-02, -4.5477e-02, -5.2988e-02, -4.9084e-02,
        -4.9412e-02, -4.3843e-02, -5.0443e-02, -4.9064e-02, -4.3962e-02,
        -5.6775e-02, -5.1409e-02, -4.3295e-02, -3.9540e-02, -4.4664e-02,
        -4.3250e-02, -3.9546e-02, -5.5699e-02, -4.7195e-02, -4.4590e-02,
        -1.1524e-02, -4.4556e-02, -4.3440e-02, -4.7186e-02, -5.6330e-02,
        -4.8657e-02, -3.9432e-02, -3.8554e-02, -3.7602e-02, -3.8690e-02,
        -4.6034e-02, -5.3341e-02, -4.7296e-02, -4.9478e-02, -4.1370e-02,
        -5.5309e-02, -4.3035e-02, -5.5370e-02, -4.0953e-02, -3.7101e-02,
        -4.4304e-02, -5.3368e-02, -3.7509e-02, -3.9466e-02, -4.5996e-02,
        -3.8379e-02, -4.8958e-02, -5.5010e-02, -5.0529e-02, -5.4579e-02,
        -5.3694e-02, -4.3675e-02, -4.5844e-02, -4.4305e-02, -3.9036e-02,
        -3.7427e-02, -5.3868e-02, -4.8498e-02, -5.0509e-02, -4.5483e-02,
        -5.6589e-02, -4.9143e-02, -4.6050e-02, -5.1969e-02, -1.2608e-02])
