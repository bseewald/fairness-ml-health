Weights: 
embeddings.embeddings.0.weight tensor([[ 0.1392, -0.0076],
        [-0.0019, -0.1621],
        [ 0.2119, -0.2121],
        [ 0.0318,  0.0815]])
embeddings.embeddings.1.weight tensor([[ 0.0066,  0.2315],
        [ 0.0044, -0.0498],
        [ 0.0643,  0.0862],
        [ 0.2127, -0.1011],
        [ 0.0539, -0.2375]])
embeddings.embeddings.2.weight tensor([[-0.0184, -0.1113, -0.0199],
        [-0.0625, -0.0304, -0.1463],
        [-0.0913,  0.0989,  0.1728],
        [ 0.1527,  0.1268, -0.1070],
        [-0.1434, -0.0671, -0.1589],
        [-0.1252,  0.1296, -0.2247]])
embeddings.embeddings.3.weight tensor([[-0.0653,  0.0632],
        [ 0.2777, -0.1334],
        [-0.0480, -0.1632],
        [-0.1159,  0.3044]])
embeddings.embeddings.4.weight tensor([[ 0.1058,  0.1045],
        [-0.3182,  0.2770],
        [ 0.1156, -0.1565],
        [ 0.0395,  0.0599]])
mlp.net.0.linear.weight tensor([[-0.2155,  0.0966, -0.2565,  ...,  0.0434, -0.1410, -0.0859],
        [-0.0481, -0.0132, -0.1043,  ...,  0.1567,  0.2802, -0.1221],
        [-0.1836,  0.2701, -0.1154,  ...,  0.1389, -0.0072, -0.0961],
        ...,
        [ 0.3078,  0.1135,  0.0537,  ..., -0.4044, -0.0148, -0.1882],
        [ 0.1094,  0.0523, -0.2188,  ...,  0.1683,  0.1855, -0.1957],
        [ 0.1091, -0.0524,  0.1959,  ..., -0.1502,  0.1811,  0.0672]])
mlp.net.0.linear.bias tensor([ 0.0587,  0.0550, -0.0704, -0.0142,  0.1441,  0.0395,  0.0505,  0.0638,
         0.0453, -0.0673, -0.1094,  0.1278, -0.0032,  0.0707, -0.0959,  0.0377,
        -0.0003,  0.0698,  0.0143,  0.0675,  0.0801, -0.0207,  0.0597, -0.0214,
         0.0637, -0.0420,  0.1005,  0.0962,  0.0573,  0.0648, -0.1361, -0.0646,
         0.0005,  0.0620,  0.0073,  0.0751,  0.0396,  0.0315, -0.0888, -0.0379,
        -0.0881, -0.0137,  0.0775, -0.0798, -0.0164, -0.0204,  0.0529, -0.0474,
        -0.1018, -0.0197,  0.1042, -0.0179, -0.0344,  0.1192,  0.0651, -0.1490,
         0.0008,  0.0131, -0.0173, -0.0467,  0.1038, -0.0261, -0.0108, -0.0945])
mlp.net.0.batch_norm.weight tensor([0.4657, 0.4642, 0.3026, 0.4044, 0.3193, 0.3720, 0.3934, 0.3250, 0.3763,
        0.2888, 0.4457, 0.4907, 0.3092, 0.2833, 0.4824, 0.3464, 0.3420, 0.4344,
        0.4926, 0.4562, 0.4516, 0.4021, 0.4532, 0.4554, 0.3998, 0.4774, 0.3771,
        0.4951, 0.3347, 0.3599, 0.3209, 0.4594, 0.4085, 0.4012, 0.4486, 0.4343,
        0.3376, 0.3144, 0.3617, 0.4158, 0.4399, 0.3978, 0.3568, 0.5049, 0.3247,
        0.3638, 0.4547, 0.4002, 0.3601, 0.3971, 0.4203, 0.4069, 0.3604, 0.4520,
        0.3571, 0.3608, 0.4393, 0.3088, 0.3563, 0.4420, 0.4037, 0.4106, 0.3778,
        0.4722])
mlp.net.0.batch_norm.bias tensor([-0.0887, -0.1247, -0.0727,  0.0016, -0.0581,  0.0732,  0.1348, -0.0157,
         0.0667,  0.0573,  0.0655,  0.1133,  0.0260,  0.0154, -0.1335, -0.0186,
         0.0004, -0.0971, -0.0985,  0.0353,  0.0885, -0.0364, -0.1632,  0.0448,
         0.0211,  0.0795, -0.0027,  0.1020,  0.0373, -0.0981, -0.0189, -0.0004,
         0.0530,  0.1335,  0.1146,  0.0090, -0.0372, -0.0712, -0.0353,  0.1053,
         0.0783, -0.0646, -0.1069, -0.0799,  0.0656, -0.0533,  0.0609, -0.0060,
        -0.0761, -0.1223, -0.1070, -0.0239, -0.0172,  0.1056, -0.0274,  0.1018,
        -0.1090,  0.0476,  0.0886, -0.0202,  0.1290, -0.0159,  0.0851, -0.0746])
mlp.net.0.batch_norm.running_mean tensor([2.1975e-03, 2.2521e-01, 2.0734e-02, 6.2353e-03, 3.3646e-01, 3.8884e-01,
        3.7891e-01, 1.0361e-01, 3.1010e-03, 1.0716e-01, 1.6317e-01, 3.7325e-01,
        2.1024e-01, 1.0650e-02, 5.2479e-02, 8.3840e-02, 1.2120e-01, 5.0050e-01,
        6.8046e-02, 1.6600e-02, 3.3779e-01, 7.1547e-01, 1.3511e-01, 8.5246e-04,
        3.8810e-01, 3.2543e-02, 2.4381e-02, 1.0617e-01, 3.6219e-01, 3.1048e-01,
        2.1882e-01, 2.2925e-01, 1.0782e-02, 7.9026e-02, 1.8193e-02, 5.4375e-02,
        8.5946e-04, 2.1592e-02, 3.6678e-03, 4.2605e-03, 1.4062e-01, 9.8565e-05,
        5.1650e-01, 3.5120e-01, 2.5456e-02, 1.5049e-06, 1.3095e-02, 3.0805e-01,
        1.1384e-04, 1.9245e-01, 3.5191e-01, 1.1414e-03, 1.0992e-01, 2.4106e-01,
        4.9630e-02, 4.4486e-01, 2.4875e-01, 2.1687e-02, 2.7879e-02, 1.2466e-02,
        3.6060e-01, 4.1057e-02, 2.6908e-03, 2.1852e-03])
mlp.net.0.batch_norm.running_var tensor([0.0011, 0.0165, 0.0038, 0.0017, 0.0195, 0.0187, 0.0180, 0.0129, 0.0012,
        0.0096, 0.0197, 0.0189, 0.0228, 0.0016, 0.0054, 0.0158, 0.0127, 0.0187,
        0.0071, 0.0029, 0.0208, 0.0461, 0.0123, 0.0009, 0.0426, 0.0052, 0.0043,
        0.0161, 0.0156, 0.0195, 0.0243, 0.0211, 0.0027, 0.0105, 0.0045, 0.0068,
        0.0009, 0.0035, 0.0012, 0.0012, 0.0116, 0.0008, 0.0310, 0.0227, 0.0046,
        0.0008, 0.0032, 0.0149, 0.0008, 0.0356, 0.0262, 0.0009, 0.0148, 0.0128,
        0.0072, 0.0415, 0.0291, 0.0044, 0.0035, 0.0022, 0.0276, 0.0083, 0.0012,
        0.0009])
mlp.net.0.batch_norm.num_batches_tracked tensor(68)
mlp.net.1.linear.weight tensor([[-0.0604,  0.0448, -0.0511,  ...,  0.0057,  0.0593,  0.1656],
        [-0.0656,  0.0110, -0.1591,  ..., -0.0726, -0.1498, -0.1419],
        [-0.0867,  0.0235, -0.0477,  ..., -0.0214,  0.1035, -0.1748],
        ...,
        [ 0.0601,  0.0137, -0.0238,  ..., -0.0273, -0.0127, -0.1151],
        [-0.1713,  0.1699, -0.1836,  ..., -0.1374, -0.1959,  0.0670],
        [-0.0712,  0.0650,  0.0453,  ..., -0.1788, -0.0470, -0.0613]])
mlp.net.1.linear.bias tensor([ 0.1433,  0.0087,  0.0857,  0.1610,  0.0932,  0.1456,  0.0479,  0.0912,
         0.1843, -0.0301,  0.1021,  0.1281,  0.0828,  0.0507,  0.0282,  0.1561,
         0.0403,  0.1377,  0.0335, -0.0364,  0.1450,  0.0504,  0.0485,  0.1264,
         0.1240,  0.1988,  0.0906,  0.0657,  0.0138,  0.1180, -0.0027,  0.0368,
         0.0982,  0.0731,  0.1275,  0.1184,  0.0301,  0.0425,  0.1264,  0.1505,
         0.1411,  0.1211,  0.1873,  0.0479,  0.0311,  0.0995,  0.1097,  0.1287,
         0.0880,  0.0984,  0.1042,  0.1676,  0.1231,  0.1532,  0.0025,  0.0382,
         0.1099,  0.0333, -0.0318,  0.0091,  0.1222,  0.0993,  0.0550,  0.0521])
mlp.net.1.batch_norm.weight tensor([0.5290, 0.4764, 0.4732, 0.4728, 0.4563, 0.4553, 0.4375, 0.4261, 0.5230,
        0.4021, 0.5107, 0.4711, 0.4744, 0.4806, 0.4915, 0.5134, 0.4547, 0.5401,
        0.5001, 0.4888, 0.4876, 0.5389, 0.4476, 0.4441, 0.4829, 0.4914, 0.5160,
        0.4639, 0.4622, 0.4780, 0.3929, 0.4598, 0.4819, 0.4863, 0.4919, 0.5077,
        0.4436, 0.4410, 0.4774, 0.4917, 0.4893, 0.4806, 0.4590, 0.4520, 0.5629,
        0.5183, 0.5072, 0.4649, 0.4769, 0.4726, 0.4865, 0.4706, 0.4669, 0.4712,
        0.4670, 0.4497, 0.5431, 0.5105, 0.4291, 0.5087, 0.4938, 0.5069, 0.4561,
        0.5074])
mlp.net.1.batch_norm.bias tensor([ 0.0732,  0.1060, -0.1584, -0.1289, -0.1712, -0.1539, -0.1420, -0.1400,
        -0.1614, -0.2023, -0.1509, -0.1386, -0.1585,  0.1363, -0.1419, -0.1691,
         0.1138, -0.1072, -0.1405, -0.0700, -0.1411, -0.0811, -0.1154,  0.1361,
        -0.1502, -0.1463, -0.1283,  0.1516, -0.1406, -0.1624, -0.0385,  0.1555,
         0.1541, -0.1456, -0.1731, -0.1643,  0.1234,  0.1099, -0.1485, -0.1408,
        -0.1560, -0.1679, -0.1436, -0.1513,  0.0706, -0.0846, -0.1562, -0.1292,
        -0.1528, -0.0833, -0.1678, -0.1584, -0.1015, -0.0959, -0.1595, -0.1697,
        -0.1669,  0.1157,  0.1435, -0.0101, -0.1690, -0.1945,  0.0684,  0.1496])
mlp.net.1.batch_norm.running_mean tensor([0.2077, 0.2624, 0.3052, 0.4845, 0.3768, 0.4495, 0.3433, 0.3431, 0.6086,
        0.3144, 0.4721, 0.3479, 0.3903, 0.2399, 0.3214, 0.5430, 0.3135, 0.3147,
        0.3692, 0.2029, 0.5192, 0.3348, 0.2508, 0.2994, 0.4089, 0.5498, 0.4564,
        0.2457, 0.2675, 0.4187, 0.2027, 0.2575, 0.2619, 0.3353, 0.4507, 0.4107,
        0.2555, 0.2404, 0.3686, 0.4427, 0.4368, 0.4976, 0.4373, 0.4518, 0.2921,
        0.3550, 0.4505, 0.4414, 0.4129, 0.3540, 0.3282, 0.4075, 0.2194, 0.4623,
        0.2925, 0.2466, 0.4335, 0.2291, 0.1220, 0.2693, 0.4752, 0.3764, 0.3127,
        0.2706])
mlp.net.1.batch_norm.running_var tensor([0.0752, 0.2331, 0.1501, 0.2855, 0.2320, 0.2688, 0.1985, 0.1519, 0.3491,
        0.1618, 0.3037, 0.1355, 0.2167, 0.1799, 0.1697, 0.3004, 0.2912, 0.1821,
        0.2968, 0.1483, 0.3152, 0.1969, 0.1185, 0.2333, 0.2098, 0.3293, 0.2877,
        0.1847, 0.2577, 0.2575, 0.0714, 0.2057, 0.1747, 0.1634, 0.2064, 0.1902,
        0.2174, 0.1982, 0.1699, 0.2013, 0.2215, 0.2784, 0.2344, 0.2800, 0.1482,
        0.2019, 0.3026, 0.2011, 0.2075, 0.2173, 0.2627, 0.1903, 0.1287, 0.2051,
        0.1896, 0.1126, 0.3336, 0.1706, 0.0873, 0.1970, 0.2809, 0.1927, 0.3083,
        0.2433])
mlp.net.1.batch_norm.num_batches_tracked tensor(68)
mlp.net.2.weight tensor([[ 0.0721,  0.1128, -0.0768,  ..., -0.1239,  0.1405,  0.1807],
        [ 0.0171,  0.1639, -0.0894,  ..., -0.1736,  0.1318,  0.1641],
        [-0.0033,  0.1636, -0.1505,  ..., -0.0681,  0.1238,  0.1482],
        ...,
        [-0.0373, -0.1270,  0.1067,  ...,  0.1127, -0.0748, -0.0433],
        [-0.0517, -0.1090,  0.0986,  ...,  0.1257, -0.0909, -0.1738],
        [-0.1121, -0.0494,  0.0159,  ...,  0.0147, -0.0765, -0.0458]])
mlp.net.2.bias tensor([ 0.0425,  0.1858,  0.1782,  0.1700,  0.0972,  0.1546,  0.0487,  0.1301,
         0.1152,  0.1487,  0.1148,  0.0410,  0.0889,  0.1609,  0.1631,  0.0762,
         0.1499,  0.1306,  0.1491,  0.2207,  0.1473,  0.1532,  0.0749,  0.2045,
         0.1462,  0.1731,  0.1412,  0.1599,  0.0746,  0.1218,  0.1194,  0.1925,
         0.0790,  0.1464, -0.0603,  0.2024,  0.1057,  0.1320,  0.0403, -0.0171,
         0.0843, -0.0500,  0.0435,  0.1217,  0.1509, -0.0507,  0.1457,  0.2279,
         0.0054, -0.0395,  0.1361, -0.1101,  0.0847, -0.1699,  0.1112, -0.0906,
        -0.1481, -0.0850, -0.1158,  0.1125, -0.0328,  0.1205, -0.1425, -0.1034,
        -0.0129,  0.0431,  0.0010, -0.0779,  0.0080,  0.0195,  0.0810, -0.0754,
        -0.1287,  0.0059, -0.0053,  0.0296, -0.1174,  0.1182, -0.0067,  0.1970,
         0.0004, -0.0249, -0.1252, -0.0520, -0.2240, -0.0906, -0.2693, -0.2539,
        -0.0222, -0.0510, -0.1976, -0.1173,  0.0591, -0.0300,  0.0036, -0.2326,
        -0.0886,  0.1085, -0.0410, -0.0783, -0.0919, -0.1109, -0.1269,  0.0542,
        -0.1208, -0.1953, -0.1470,  0.0397, -0.2528, -0.0610, -0.0801, -0.1094,
        -0.0912, -0.2122,  0.0816, -0.0142, -0.1839, -0.2596, -0.2166, -0.2181,
        -0.1571, -0.1303, -0.1523, -0.0710, -0.1480, -0.1798, -0.1960, -0.1009,
        -0.2650, -0.1058, -0.1801, -0.1727, -0.2347, -0.0111, -0.2023, -0.2164,
        -0.2067, -0.2642, -0.1981, -0.1687, -0.1313, -0.0788, -0.2425, -0.2209,
        -0.2446, -0.2303, -0.1010, -0.0613, -0.2303, -0.2205, -0.2007, -0.2167,
        -0.2640, -0.1795, -0.2526, -0.1713, -0.2616, -0.2652, -0.1675, -0.1969,
        -0.1906, -0.2342, -0.2549, -0.2481, -0.2089, -0.2145, -0.1534, -0.1255,
        -0.0846, -0.2120, -0.1713, -0.1613, -0.2101, -0.2577, -0.1629, -0.2377,
        -0.1179, -0.0911, -0.0984, -0.2343, -0.2097, -0.2553, -0.2420, -0.2363,
        -0.1933, -0.1827, -0.2473, -0.1153, -0.2050, -0.1635, -0.2233, -0.1722,
        -0.0827, -0.2326, -0.1999, -0.2081, -0.1684, -0.2386, -0.1831, -0.1561,
        -0.2303, -0.1626, -0.1705, -0.1818, -0.1655, -0.1792, -0.1680, -0.1737,
        -0.1963, -0.1798, -0.2288, -0.2337, -0.2445, -0.1864, -0.1952, -0.1977,
        -0.1887, -0.2141, -0.2563, -0.2496, -0.1434, -0.2410, -0.2250, -0.2194,
        -0.1728, -0.1816, -0.1132, -0.2109, -0.2136, -0.2589, -0.1050, -0.2414,
        -0.2261, -0.2210, -0.2337, -0.2393, -0.1934, -0.1754, -0.1833, -0.1652,
        -0.2532, -0.1293, -0.2233, -0.2459, -0.2353, -0.2592, -0.1737, -0.1683,
        -0.1573, -0.1750, -0.1915, -0.2189, -0.1889, -0.2410, -0.2511, -0.2116,
        -0.1912, -0.2356, -0.1701, -0.1805, -0.1097, -0.2365, -0.1747, -0.2499,
        -0.1584, -0.1835, -0.2589, -0.2361, -0.2312, -0.1727, -0.2127, -0.1627,
        -0.1577, -0.2025, -0.2097, -0.2418, -0.2448, -0.2393, -0.1836, -0.1709,
        -0.1660, -0.2328, -0.2620, -0.2313, -0.2308, -0.1585, -0.2152, -0.1684,
        -0.2496, -0.1720, -0.2504, -0.0906, -0.1711, -0.2110, -0.2327, -0.2280,
        -0.2301, -0.2385, -0.2358, -0.2144, -0.1713, -0.2392, -0.2158, -0.1782,
        -0.2580, -0.1791, -0.1758, -0.2221, -0.1532, -0.2067, -0.1765, -0.1634,
        -0.2194, -0.2366, -0.1826, -0.2177, -0.2412, -0.1826, -0.2061, -0.2159,
        -0.1701, -0.1638, -0.1924, -0.2424, -0.1648, -0.2139, -0.2075, -0.1923,
        -0.2544, -0.2340, -0.1555, -0.1697, -0.1997, -0.2483, -0.2543, -0.2525,
        -0.1854, -0.2169, -0.1554, -0.2303, -0.2109, -0.2348, -0.2489, -0.2229,
        -0.1836, -0.1795, -0.1654, -0.1775, -0.0635, -0.1613, -0.2193, -0.2350,
        -0.2002, -0.2341, -0.1943, -0.1754, -0.2105, -0.1998, -0.1948, -0.2393,
        -0.0660, -0.2077, -0.2076, -0.2029, -0.2389, -0.1994, -0.2293, -0.2415,
        -0.1851, -0.1899, -0.1985, -0.2432, -0.1701, -0.1740, -0.1668, -0.1761,
        -0.2392, -0.2522, -0.1216, -0.1949, -0.1974, -0.2236, -0.2400, -0.1706,
        -0.1721, -0.1816, -0.1515, -0.1643, -0.2475, -0.2087, -0.2019, -0.1920,
        -0.2325, -0.1665, -0.1976, -0.2071, -0.2206, -0.1611, -0.2479, -0.0540])
