Weights: 
embeddings.embeddings.0.weight tensor([[-0.0899,  0.1208],
        [-0.0078, -0.0145],
        [-0.1051,  0.0515],
        [-0.0071,  0.1911]])
embeddings.embeddings.1.weight tensor([[-0.0601, -0.0251],
        [ 0.2761, -0.0308],
        [-0.0382,  0.0822],
        [ 0.1328, -0.0758],
        [-0.0218, -0.0912]])
embeddings.embeddings.2.weight tensor([[-0.0811, -0.0307,  0.0816],
        [ 0.0082, -0.0680,  0.0118],
        [-0.1245, -0.1658, -0.0668],
        [-0.0074, -0.1092,  0.1105],
        [ 0.0043,  0.0460,  0.0589],
        [ 0.0657,  0.0760,  0.0112]])
embeddings.embeddings.3.weight tensor([[ 0.1329,  0.0756],
        [ 0.1534, -0.0841],
        [-0.0241,  0.1526],
        [-0.3435,  0.1040]])
embeddings.embeddings.4.weight tensor([[-0.1222,  0.1406],
        [-0.2173, -0.2619],
        [-0.1809,  0.2374],
        [ 0.0263, -0.1115]])
mlp.net.0.linear.weight tensor([[-0.0048, -0.0142, -0.0197,  ...,  0.0775,  0.1048,  0.1409],
        [-0.0562,  0.0934, -0.0229,  ...,  0.1620,  0.0534,  0.0076],
        [ 0.1134, -0.0157,  0.0031,  ...,  0.1566, -0.0100, -0.1335],
        ...,
        [-0.0087,  0.0621, -0.0425,  ..., -0.0988, -0.1664,  0.0269],
        [ 0.0784,  0.0282, -0.0350,  ...,  0.0101,  0.0414,  0.0726],
        [ 0.1285, -0.1292, -0.0769,  ..., -0.0753, -0.0791,  0.1315]])
mlp.net.0.linear.bias tensor([-0.0019, -0.0039,  0.0444,  0.0215, -0.0265,  0.0922,  0.0023, -0.0247,
        -0.0187,  0.0678,  0.0269, -0.0291,  0.0354, -0.0104, -0.0036, -0.0349,
        -0.0190, -0.0779, -0.0417,  0.0045,  0.0146,  0.0542, -0.0460,  0.0447,
         0.0882, -0.0494, -0.0411, -0.0683, -0.0419,  0.0116,  0.0301,  0.0111,
        -0.0064,  0.0383,  0.0356, -0.0791, -0.0403, -0.0740,  0.0212, -0.0752,
        -0.0170,  0.0091, -0.0838,  0.0767, -0.0530,  0.0370,  0.0029,  0.0019,
         0.0265, -0.0102,  0.0565, -0.0949,  0.0450, -0.0440,  0.0847, -0.0402,
        -0.0531,  0.0864, -0.0100,  0.0389, -0.0071,  0.0303, -0.0564,  0.0209])
mlp.net.0.batch_norm.weight tensor([0.3175, 0.2594, 0.2095, 0.2798, 0.2327, 0.2392, 0.2573, 0.2297, 0.2530,
        0.2668, 0.2897, 0.2847, 0.2733, 0.2553, 0.2155, 0.2946, 0.2555, 0.2348,
        0.2906, 0.3066, 0.3308, 0.2823, 0.2994, 0.2985, 0.2833, 0.2452, 0.2075,
        0.2924, 0.2403, 0.2793, 0.2497, 0.2652, 0.3078, 0.2571, 0.3345, 0.2800,
        0.3314, 0.3138, 0.2942, 0.3131, 0.2583, 0.2518, 0.3262, 0.1904, 0.3385,
        0.2830, 0.2852, 0.2110, 0.3166, 0.2778, 0.2811, 0.2683, 0.2938, 0.2673,
        0.2607, 0.2639, 0.2227, 0.2544, 0.3070, 0.2168, 0.3420, 0.2906, 0.2494,
        0.2387])
mlp.net.0.batch_norm.bias tensor([-0.0632, -0.0543, -0.0150,  0.0488, -0.0032,  0.0246,  0.0186,  0.0526,
         0.0466, -0.0168, -0.0585,  0.0216, -0.0541,  0.0297,  0.0181, -0.0597,
        -0.0294, -0.0206,  0.0462,  0.0593,  0.0697,  0.0850, -0.0038, -0.0214,
         0.0612,  0.0164,  0.0201, -0.0560,  0.0205, -0.0243,  0.0420,  0.0331,
         0.0562,  0.0185,  0.0738,  0.0270, -0.0668, -0.0504,  0.0838, -0.0536,
        -0.0658, -0.0083, -0.0698,  0.0107,  0.0435,  0.0482, -0.0290,  0.0216,
        -0.0459,  0.0029,  0.0493, -0.0629,  0.1028, -0.0642, -0.0398,  0.0203,
         0.0230, -0.0203,  0.0787, -0.0327, -0.0488,  0.0425,  0.0236, -0.0150])
mlp.net.0.batch_norm.running_mean tensor([5.6444e-02, 1.1870e-01, 3.6945e-02, 5.2281e-02, 2.2288e-02, 1.9821e-01,
        8.2673e-03, 6.3995e-02, 7.6158e-02, 2.2394e-01, 2.4933e-01, 2.6419e-02,
        9.8233e-02, 4.5935e-02, 2.2114e-01, 2.1632e-02, 1.1203e-02, 4.0586e-03,
        4.1494e-02, 7.8437e-02, 9.9840e-02, 1.1236e-01, 2.9215e-03, 7.5738e-03,
        1.5236e-01, 1.7600e-02, 2.5427e-02, 9.9730e-02, 1.4231e-01, 8.2106e-03,
        9.4202e-03, 4.1232e-03, 1.3344e-01, 3.0168e-02, 5.7317e-02, 1.3108e-03,
        1.0554e-01, 2.2493e-01, 6.4177e-02, 8.4794e-03, 9.4457e-02, 2.5665e-04,
        1.0194e-01, 2.2419e-01, 4.3762e-02, 4.5646e-03, 1.5887e-01, 3.9052e-03,
        3.6109e-01, 2.3827e-02, 4.1154e-02, 5.1659e-02, 5.2842e-02, 6.3611e-02,
        3.4671e-01, 1.9202e-03, 4.4308e-03, 1.8046e-02, 6.8041e-02, 7.1616e-03,
        1.1149e-02, 1.7354e-02, 1.8170e-03, 3.0031e-01])
mlp.net.0.batch_norm.running_var tensor([2.6754e-03, 5.0544e-03, 4.1443e-03, 2.4039e-03, 1.8496e-03, 6.1946e-03,
        4.0922e-04, 4.8763e-03, 3.8890e-03, 1.0296e-02, 1.2501e-02, 2.4302e-03,
        5.3522e-03, 7.1508e-03, 6.5717e-03, 8.3130e-04, 7.2757e-04, 5.8100e-04,
        3.0539e-03, 4.1454e-03, 4.0820e-03, 5.1515e-03, 2.6461e-04, 6.7876e-04,
        9.1155e-03, 1.2042e-03, 1.0739e-03, 3.5505e-03, 1.1031e-02, 3.4776e-04,
        6.0036e-04, 3.6955e-04, 6.9959e-03, 2.5792e-03, 1.4161e-03, 8.0275e-05,
        3.5335e-03, 5.6180e-03, 3.4936e-03, 4.5462e-04, 4.7684e-03, 3.4841e-05,
        3.9468e-03, 3.8550e-02, 2.6891e-03, 2.5628e-04, 3.1315e-03, 4.6392e-04,
        8.2106e-03, 1.3601e-03, 2.2826e-03, 1.4914e-03, 1.7789e-03, 2.7572e-03,
        1.2232e-02, 7.9410e-05, 2.5162e-04, 1.7088e-03, 4.1341e-03, 4.8608e-04,
        5.6466e-04, 9.6149e-04, 4.0349e-05, 1.0383e-02])
mlp.net.0.batch_norm.num_batches_tracked tensor(896)
mlp.net.1.linear.weight tensor([[-0.0918, -0.0193,  0.0583,  ..., -0.0611,  0.0661,  0.0276],
        [-0.0035,  0.0398, -0.0619,  ..., -0.0669, -0.0502,  0.0172],
        [-0.0752, -0.0998, -0.0695,  ..., -0.0054, -0.0541, -0.0031],
        ...,
        [ 0.0814,  0.0239, -0.0386,  ..., -0.0581,  0.0078, -0.0381],
        [ 0.0524, -0.0288, -0.0143,  ..., -0.0089,  0.0146,  0.0507],
        [-0.0105,  0.0068, -0.0369,  ...,  0.0202,  0.0652,  0.0162]])
mlp.net.1.linear.bias tensor([0.0362, 0.0832, 0.0352, 0.0282, 0.0602, 0.0649, 0.0378, 0.0503, 0.0417,
        0.0661, 0.0102, 0.0746, 0.0372, 0.1195, 0.0176, 0.0476, 0.0653, 0.0336,
        0.0374, 0.0516, 0.0560, 0.0550, 0.0394, 0.0213, 0.0802, 0.0442, 0.0521,
        0.0511, 0.0691, 0.0641, 0.0616, 0.0682, 0.1132, 0.0391, 0.0455, 0.0362,
        0.0365, 0.0614, 0.0860, 0.0306, 0.0381, 0.0528, 0.0403, 0.0357, 0.0804,
        0.0781, 0.0321, 0.0347, 0.0354, 0.0880, 0.0293, 0.0810, 0.0454, 0.0496,
        0.0808, 0.0830, 0.0447, 0.0709, 0.0760, 0.0456, 0.0755, 0.0543, 0.0296,
        0.0634])
mlp.net.1.batch_norm.weight tensor([0.3421, 0.3498, 0.3272, 0.2775, 0.3433, 0.3316, 0.3320, 0.3456, 0.3420,
        0.3130, 0.3464, 0.3576, 0.3366, 0.3608, 0.3308, 0.3486, 0.3635, 0.3195,
        0.3336, 0.3366, 0.3145, 0.3557, 0.3605, 0.3521, 0.3372, 0.3415, 0.3350,
        0.3749, 0.3329, 0.3697, 0.3529, 0.3321, 0.3671, 0.3598, 0.3389, 0.3273,
        0.3294, 0.3408, 0.3540, 0.3373, 0.3248, 0.3549, 0.3769, 0.3240, 0.3493,
        0.3284, 0.3723, 0.3560, 0.3481, 0.3590, 0.3560, 0.3602, 0.3322, 0.3564,
        0.3542, 0.3432, 0.3335, 0.3391, 0.3418, 0.3202, 0.3537, 0.3435, 0.3462,
        0.3448])
mlp.net.1.batch_norm.bias tensor([-0.1302,  0.1255, -0.1440,  0.2067, -0.1416, -0.1331,  0.1667,  0.2048,
        -0.1819, -0.1764, -0.1495, -0.1053,  0.1556, -0.0690,  0.1082,  0.1772,
        -0.0699, -0.1847, -0.1214, -0.1269,  0.2325, -0.1246,  0.1525, -0.1184,
        -0.1437, -0.1347,  0.1932,  0.1385, -0.1349, -0.1270,  0.1737, -0.1663,
        -0.1118,  0.1875, -0.1589, -0.1425, -0.1973, -0.0993, -0.1520,  0.1640,
        -0.1678, -0.1261,  0.0492, -0.1914, -0.1428, -0.1275,  0.1343, -0.0928,
        -0.1077, -0.0845, -0.0828, -0.1364,  0.1787,  0.1556, -0.1113,  0.1496,
        -0.1751, -0.1660, -0.1378, -0.1661, -0.1382,  0.2057,  0.1624, -0.1230])
mlp.net.1.batch_norm.running_mean tensor([0.2023, 0.1486, 0.1879, 0.0842, 0.2000, 0.2023, 0.1016, 0.1246, 0.1643,
        0.1759, 0.1382, 0.2154, 0.1007, 0.2351, 0.0891, 0.1331, 0.1842, 0.1614,
        0.1756, 0.1844, 0.1253, 0.2101, 0.1099, 0.1641, 0.2235, 0.1807, 0.1187,
        0.1123, 0.2175, 0.2232, 0.1271, 0.2240, 0.2401, 0.1147, 0.1835, 0.1573,
        0.1700, 0.1997, 0.2407, 0.1186, 0.1842, 0.2031, 0.1058, 0.1545, 0.2061,
        0.1976, 0.1123, 0.1685, 0.1552, 0.2216, 0.1608, 0.2359, 0.1332, 0.1160,
        0.1990, 0.1275, 0.2007, 0.1694, 0.2309, 0.1485, 0.1955, 0.1145, 0.0992,
        0.1978])
mlp.net.1.batch_norm.running_var tensor([0.0594, 0.0544, 0.0508, 0.0143, 0.0531, 0.0492, 0.0283, 0.0457, 0.0416,
        0.0400, 0.0412, 0.0525, 0.0279, 0.0582, 0.0239, 0.0486, 0.0531, 0.0384,
        0.0401, 0.0371, 0.0406, 0.0591, 0.0349, 0.0371, 0.0543, 0.0503, 0.0369,
        0.0340, 0.0531, 0.0611, 0.0422, 0.0602, 0.0533, 0.0383, 0.0480, 0.0401,
        0.0488, 0.0503, 0.0755, 0.0401, 0.0460, 0.0620, 0.0294, 0.0332, 0.0533,
        0.0457, 0.0364, 0.0513, 0.0345, 0.0462, 0.0495, 0.0648, 0.0492, 0.0378,
        0.0446, 0.0355, 0.0591, 0.0280, 0.0598, 0.0443, 0.0368, 0.0412, 0.0290,
        0.0533])
mlp.net.1.batch_norm.num_batches_tracked tensor(896)
mlp.net.2.weight tensor([[-0.0339,  0.0309, -0.0407,  ...,  0.0570,  0.0638, -0.0989],
        [-0.0888,  0.0699, -0.0792,  ...,  0.0669,  0.0458, -0.1018],
        [-0.0719,  0.0734, -0.0915,  ...,  0.0453,  0.0566, -0.0288],
        ...,
        [ 0.0550, -0.0793,  0.0725,  ..., -0.1169, -0.1014,  0.0465],
        [ 0.0510, -0.0956,  0.0597,  ..., -0.1153, -0.0797,  0.0605],
        [-0.0077,  0.0131,  0.0259,  ..., -0.0040, -0.0467,  0.0084]])
mlp.net.2.bias tensor([ 0.1825,  0.2707,  0.2377,  0.2133,  0.1845,  0.2165,  0.1839,  0.1978,
         0.1468,  0.2053,  0.1661,  0.2517,  0.2591,  0.1771,  0.1308,  0.2559,
         0.1813,  0.1715,  0.2645,  0.2111,  0.1383,  0.1940,  0.1604,  0.2327,
         0.1750,  0.1991,  0.2011,  0.1499,  0.1349,  0.1748,  0.1673,  0.1617,
         0.2103,  0.0085,  0.0680,  0.0779,  0.1315,  0.0285,  0.1214,  0.0910,
         0.1016,  0.1186,  0.1924,  0.0027,  0.0268,  0.0626,  0.1070, -0.0885,
         0.0559, -0.1876, -0.0781, -0.1083, -0.1099,  0.0602, -0.0072, -0.0069,
         0.0932, -0.0678, -0.1202,  0.0128,  0.0038, -0.0054,  0.0583, -0.1200,
        -0.1113, -0.2007, -0.0006, -0.0361,  0.0776,  0.0524,  0.0169, -0.0287,
        -0.0906, -0.0834, -0.0373, -0.1432, -0.1203, -0.3334, -0.1240, -0.0523,
        -0.3253, -0.1074,  0.0333, -0.0832, -0.1922, -0.1590, -0.0474, -0.1267,
        -0.1644, -0.0600, -0.1929, -0.0691, -0.0106, -0.2980, -0.1906, -0.1033,
        -0.2956, -0.1871, -0.1004, -0.1101, -0.3100, -0.1091, -0.0254, -0.2995,
        -0.3439, -0.1519,  0.0236, -0.1928, -0.1975, -0.2811, -0.2832, -0.2853,
        -0.3155, -0.2826, -0.3394, -0.3481, -0.2936, -0.3280, -0.0618, -0.3202,
        -0.1610, -0.2908, -0.3342, -0.1650, -0.1611, -0.2813, -0.3475, -0.3112,
        -0.2842, -0.1642, -0.3151, -0.1443, -0.3164, -0.1657, -0.3360, -0.2848,
        -0.1501, -0.3279, -0.3165, -0.3371, -0.3338, -0.3234, -0.1595, -0.2860,
        -0.3309, -0.3241, -0.2960, -0.1503, -0.3260, -0.0080, -0.2855, -0.3006,
        -0.2925, -0.3063, -0.2969, -0.1756, -0.3391, -0.0795, -0.1488, -0.3151,
        -0.2814, -0.3259, -0.3148, -0.2900, -0.3270, -0.2925, -0.3060, -0.2878,
        -0.3365, -0.1642, -0.2795, -0.1973, -0.3152, -0.1687, -0.3156, -0.3157,
        -0.2944, -0.1434, -0.2877, -0.3190, -0.3145, -0.3128, -0.3372, -0.3330,
        -0.3135, -0.1429, -0.3393, -0.3126, -0.2912, -0.2928, -0.3201, -0.3185,
        -0.2827, -0.2859, -0.3053, -0.3135, -0.2950, -0.3024, -0.3324, -0.3344,
        -0.3364, -0.1768, -0.3342, -0.3024, -0.1849, -0.2777, -0.2781, -0.2867,
        -0.2982, -0.2893, -0.3373, -0.2852, -0.2738, -0.1790, -0.1818, -0.3214,
        -0.2896, -0.3424, -0.3000, -0.3260, -0.3168, -0.3329, -0.2801, -0.3064,
        -0.2830, -0.2852, -0.2963, -0.2884, -0.3161, -0.2822, -0.3065, -0.1202,
        -0.3257, -0.2895, -0.3451, -0.3316, -0.2921, -0.3070, -0.2851, -0.3042,
        -0.2876, -0.2801, -0.2912, -0.3003, -0.3024, -0.2875, -0.2840, -0.2862,
        -0.3135, -0.3399, -0.2827, -0.2846, -0.3296, -0.3332, -0.2828, -0.3311,
        -0.3447, -0.3018, -0.3187, -0.3115, -0.3178, -0.1577, -0.3420, -0.3257,
        -0.3464, -0.3256, -0.3037, -0.2798, -0.2887, -0.2847, -0.3091, -0.3408,
        -0.3236, -0.2801, -0.3156, -0.3144, -0.3485, -0.3016, -0.3429, -0.2828,
        -0.3031, -0.2757, -0.2796, -0.3421, -0.3445, -0.3227, -0.3080, -0.2910,
        -0.3230, -0.3192, -0.3261, -0.3070, -0.3370, -0.3195, -0.2808, -0.3301,
        -0.3336, -0.2954, -0.3107, -0.3458, -0.3159, -0.3485, -0.3242, -0.3028,
        -0.3015, -0.3399, -0.2986, -0.3056, -0.2781, -0.1328, -0.3102, -0.3443,
        -0.3106, -0.3304, -0.3367, -0.3470, -0.3085, -0.3368, -0.2757, -0.1290,
        -0.3287, -0.2972, -0.3254, -0.2935, -0.3085, -0.3361, -0.2926, -0.2770,
        -0.2895, -0.3020, -0.2723, -0.3219, -0.3190, -0.3117, -0.3293, -0.2915,
        -0.3308, -0.2889, -0.3257, -0.2791, -0.3098, -0.3072, -0.2972, -0.2966,
        -0.3147, -0.3112, -0.3164, -0.3443, -0.3248, -0.2970, -0.3329, -0.3432,
        -0.3489, -0.3050, -0.3059, -0.2792, -0.3221, -0.3367, -0.2948, -0.3413,
        -0.2920, -0.2758, -0.3290, -0.2796, -0.3199, -0.3435, -0.3379, -0.3103,
        -0.3054, -0.2903, -0.3314, -0.3244, -0.3160, -0.3232, -0.3505, -0.3379,
        -0.3324, -0.3054, -0.2818, -0.3422, -0.3355, -0.2930, -0.3227, -0.3315,
        -0.3245, -0.2792, -0.3213, -0.3278, -0.3097, -0.2936, -0.2862, -0.2813,
        -0.3071, -0.2765, -0.3282, -0.3340, -0.2865, -0.2744, -0.3297, -0.1467])
