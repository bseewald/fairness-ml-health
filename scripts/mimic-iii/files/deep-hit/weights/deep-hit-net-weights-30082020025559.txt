Weights: 
embeddings.embeddings.0.weight tensor([[ 0.1224, -0.3202],
        [-0.2174,  0.3213],
        [-0.5826,  0.4726],
        [-0.2460, -0.3458]])
embeddings.embeddings.1.weight tensor([[ 0.4553,  0.2340],
        [ 0.2888, -0.5479],
        [ 0.3639,  0.3491],
        [-0.0755,  0.1125],
        [ 0.0458, -0.1390]])
embeddings.embeddings.2.weight tensor([[-0.2449, -0.3943, -0.0988],
        [-0.4570,  0.2552, -0.4333],
        [ 0.1628,  0.2527,  0.4858],
        [-0.2171,  0.1347,  0.3728],
        [-0.3034, -0.3669,  0.3183],
        [ 0.0352,  0.0392, -0.0013]])
embeddings.embeddings.3.weight tensor([[-0.1356,  0.3089],
        [-0.1336,  0.6987],
        [ 0.1107,  0.1247],
        [ 0.5788, -0.4342]])
embeddings.embeddings.4.weight tensor([[ 0.4032,  0.3375],
        [-0.5873, -0.3943],
        [ 0.2383,  0.4338],
        [-0.2884,  0.2760]])
mlp.net.0.linear.weight tensor([[-0.0207, -0.2477, -0.0456,  ..., -0.0137,  0.1298,  0.1120],
        [ 0.1663, -0.2718,  0.3443,  ...,  0.2791, -0.1464, -0.4125],
        [-0.1618, -0.1751, -0.3063,  ...,  0.3068, -0.0279,  0.1373],
        ...,
        [-0.2834, -0.4234,  0.7489,  ..., -0.1338,  0.1191,  0.0586],
        [ 0.3574, -0.5656,  0.2507,  ..., -0.0167,  0.3616,  0.6014],
        [-0.4199,  0.0286,  0.2010,  ...,  0.3799,  0.0900, -0.1275]])
mlp.net.0.linear.bias tensor([ 0.0661, -0.0163, -0.1662, -0.0671, -0.1158,  0.0133,  0.0679,  0.0953,
        -0.0280,  0.2637, -0.1345, -0.1277, -0.0849, -0.0918, -0.0030,  0.0765,
         0.2751,  0.0949, -0.1797, -0.1643, -0.1226,  0.1212,  0.1439, -0.2957,
        -0.1763,  0.0598,  0.0771,  0.1944, -0.1127, -0.0041, -0.2017, -0.1204,
         0.1532, -0.2209, -0.1216,  0.0573, -0.0574, -0.0409, -0.1897, -0.2144,
        -0.2581,  0.1330, -0.0023,  0.2528, -0.1364, -0.0740,  0.0957, -0.0436,
        -0.2843,  0.1676,  0.0765, -0.1591,  0.1799,  0.1003,  0.0906,  0.2825,
        -0.1773, -0.2802,  0.3222,  0.0758,  0.0010,  0.0685,  0.2561,  0.0949])
mlp.net.0.batch_norm.weight tensor([0.7387, 1.0230, 0.8918, 1.0358, 0.8144, 0.9218, 1.1012, 0.8670, 0.7412,
        0.9203, 1.0055, 0.9822, 0.8677, 0.9084, 0.9194, 0.9488, 0.9335, 0.9560,
        0.9066, 0.9082, 0.7123, 0.9610, 0.9650, 0.8175, 0.8423, 0.9866, 0.8135,
        0.8806, 0.7935, 0.7367, 0.9604, 0.9733, 0.8351, 1.0092, 0.7821, 1.0300,
        0.8021, 0.8934, 1.0128, 1.0514, 0.9285, 0.7861, 0.8441, 1.1131, 0.8339,
        0.8482, 0.8458, 0.8866, 0.9463, 0.8847, 0.9757, 0.8087, 0.8873, 0.8371,
        0.9376, 0.8022, 0.9043, 0.9263, 0.8143, 1.0934, 0.7901, 0.9222, 0.8955,
        0.9615])
mlp.net.0.batch_norm.bias tensor([-2.0551e-02, -6.6916e-02,  1.5678e-02,  3.9958e-02, -4.2151e-02,
        -5.4471e-05, -1.7903e-02, -7.5830e-03,  3.9365e-04, -5.5658e-02,
        -3.3262e-02,  6.6945e-02, -3.5776e-02,  4.2390e-02,  4.9504e-02,
         6.4118e-02, -2.5017e-02,  2.5706e-02,  8.6859e-02, -4.7747e-02,
         1.1550e-01, -5.1765e-02,  3.0124e-02,  3.1214e-02,  1.2911e-01,
        -6.7863e-02, -7.8595e-02, -1.0703e-01, -1.4670e-01, -6.2601e-02,
         1.2652e-01, -5.9798e-02, -1.2513e-01, -1.9357e-03, -5.5020e-02,
         2.7320e-02, -1.3193e-01,  3.2863e-02,  9.0838e-02,  2.6213e-02,
        -1.6768e-01, -8.9807e-02, -7.1209e-02, -2.4275e-02, -2.0563e-02,
        -1.3854e-01, -1.2301e-01, -5.7219e-02,  6.6376e-02,  3.3883e-02,
         1.5585e-01, -1.2109e-01,  9.5285e-03, -4.3269e-03, -1.0667e-01,
        -1.3227e-01, -4.0910e-02, -3.2400e-02,  2.6679e-02,  5.6901e-02,
        -2.0557e-02, -2.7743e-03, -1.7968e-02, -5.9054e-02])
mlp.net.0.batch_norm.running_mean tensor([9.6087e-02, 8.5004e-02, 1.7844e-04, 2.2445e-01, 3.2550e-01, 5.2491e-01,
        3.0993e-01, 2.6938e-01, 3.0617e-01, 3.8336e-01, 3.5639e-01, 1.2832e-01,
        1.9270e-02, 9.4886e-01, 2.0169e-01, 1.6299e-01, 6.4149e-01, 1.1295e-01,
        1.7794e-01, 5.6046e-08, 5.7741e-03, 1.0678e+00, 1.4643e-01, 5.5717e-05,
        3.6591e-05, 8.2982e-01, 7.9919e-01, 4.8441e-01, 5.3967e-01, 4.5073e-01,
        1.2356e-01, 3.6719e-01, 7.4719e-03, 2.0188e-01, 1.5699e-02, 2.0041e-01,
        2.9389e-02, 9.9711e-01, 1.0618e-01, 5.9558e-02, 6.0608e-01, 1.7567e+00,
        1.9548e-01, 6.1945e-01, 7.9204e-11, 4.9588e-02, 2.4687e-01, 1.9535e-01,
        7.6236e-03, 3.2737e-01, 6.5047e-02, 2.8082e-02, 9.8423e-01, 1.1916e+00,
        1.1936e+00, 5.2141e-01, 5.9481e-05, 4.5828e-04, 1.2846e+00, 1.5201e-03,
        1.1759e+00, 3.1473e-01, 1.5412e+00, 1.9525e-01])
mlp.net.0.batch_norm.running_var tensor([2.5557e-02, 2.7525e-02, 3.2064e-05, 3.1975e-02, 1.2903e-01, 5.6825e-02,
        9.7378e-02, 9.2305e-02, 6.5624e-02, 1.3614e-01, 1.3385e-01, 2.9101e-02,
        7.0206e-03, 1.6832e-01, 6.7842e-02, 5.8509e-02, 1.7362e-01, 3.2363e-02,
        7.6272e-02, 8.9977e-08, 1.1978e-03, 2.7087e-01, 6.1830e-02, 9.9326e-06,
        7.2938e-06, 2.7833e-01, 2.5104e-01, 1.7317e-01, 1.5792e-01, 2.4382e-01,
        3.3691e-02, 7.3684e-02, 1.7163e-03, 6.6275e-02, 3.8232e-03, 9.1315e-02,
        1.3722e-02, 2.4925e-01, 6.5850e-02, 2.1689e-02, 8.6988e-02, 2.2114e-01,
        7.2677e-02, 1.3955e-01, 8.0844e-08, 1.3779e-02, 6.6571e-02, 8.7287e-02,
        2.7573e-03, 1.1355e-01, 4.2041e-02, 9.6760e-03, 1.5488e-01, 2.7127e-01,
        1.3423e-01, 1.0015e-01, 1.0562e-05, 1.1866e-04, 1.6734e-01, 4.2537e-04,
        1.7561e-01, 9.6751e-02, 2.5120e-01, 6.7791e-02])
mlp.net.0.batch_norm.num_batches_tracked tensor(155)
mlp.net.1.linear.weight tensor([[-2.4968e-01,  1.5855e-02,  4.6936e-02,  ..., -2.1310e-01,
         -2.0936e-01, -1.2268e-01],
        [ 5.8659e-02, -3.1093e-02,  4.2591e-01,  ..., -4.5205e-02,
          3.3140e-01,  7.2628e-03],
        [-8.9442e-02, -1.3480e-01, -3.7568e-02,  ...,  1.1089e-03,
         -3.5934e-02, -2.2720e-04],
        ...,
        [-1.4593e-02, -1.6427e-01, -1.1438e-01,  ..., -2.5290e-02,
          1.2595e-01,  1.6005e-01],
        [-8.2701e-02,  1.6372e-01,  1.6747e-01,  ..., -1.2699e-01,
          9.2920e-02, -1.2718e-01],
        [-1.8061e-01,  1.7733e-01, -8.2418e-02,  ..., -1.9897e-01,
         -4.6881e-02, -2.7804e-01]])
mlp.net.1.linear.bias tensor([-0.0898, -0.1076, -0.0510, -0.1883, -0.2292,  0.0622,  0.0320,  0.2073,
        -0.1317,  0.0557, -0.1199,  0.0152,  0.0593, -0.0054, -0.0790,  0.0434,
        -0.0637,  0.1750, -0.0192,  0.1485, -0.0281,  0.0419, -0.0306, -0.0151,
         0.0087, -0.0366,  0.1802,  0.0412,  0.0163, -0.0321,  0.0325,  0.1645,
         0.1598,  0.0090,  0.0686, -0.0349, -0.0663,  0.0210, -0.1382, -0.1158,
         0.1227,  0.0243, -0.1763,  0.0576, -0.1074,  0.0431,  0.0376,  0.0239,
         0.1649,  0.2668,  0.0657,  0.1145, -0.0767,  0.0853, -0.0275,  0.0198,
        -0.1135, -0.0576,  0.0478,  0.1907, -0.1679,  0.0162,  0.1671,  0.0371])
mlp.net.1.batch_norm.weight tensor([0.8021, 1.0074, 0.9938, 1.0819, 0.8796, 0.8810, 1.0302, 0.9100, 0.8886,
        0.9840, 0.9073, 0.7345, 0.8797, 0.9060, 0.8125, 0.9208, 0.8002, 0.9631,
        0.7700, 0.9561, 0.8594, 1.0059, 0.9744, 0.7681, 0.9847, 0.8329, 0.9088,
        0.8974, 0.8547, 0.8713, 0.9167, 0.9807, 0.7571, 0.7876, 1.0152, 0.9393,
        0.8248, 0.8568, 0.8818, 0.8198, 0.8504, 0.8043, 0.9496, 1.0581, 0.9069,
        0.8194, 0.9499, 0.8612, 1.0353, 0.8407, 0.9312, 1.1317, 0.8873, 0.8894,
        0.9669, 0.8965, 0.7670, 0.9276, 1.0911, 0.9509, 1.0496, 0.9385, 0.9133,
        0.9593])
mlp.net.1.batch_norm.bias tensor([ 0.0488, -0.0865,  0.0460, -0.0815, -0.1222,  0.0473, -0.0455,  0.0464,
         0.0372, -0.0752,  0.1466,  0.0225,  0.0120,  0.0134,  0.0796, -0.0673,
        -0.0294, -0.0838,  0.0780, -0.1820, -0.0165,  0.1702, -0.0390, -0.0193,
        -0.0708, -0.0426, -0.1084, -0.0325,  0.1500,  0.0132, -0.1280,  0.0459,
         0.0136,  0.0502,  0.1244, -0.0535, -0.1007, -0.0638,  0.1374, -0.0743,
         0.0322,  0.0420, -0.0037,  0.0120,  0.0134, -0.0253, -0.0816,  0.0750,
        -0.1299, -0.0436, -0.0544, -0.0388,  0.0911, -0.0019, -0.0949, -0.0194,
        -0.0611,  0.0910,  0.1384,  0.0244,  0.0063, -0.0759, -0.0004, -0.0467])
mlp.net.1.batch_norm.running_mean tensor([0.6860, 0.7931, 0.5025, 0.5831, 0.4927, 1.0977, 1.1065, 0.7999, 0.4743,
        0.8538, 0.6448, 0.5951, 0.8463, 0.7186, 0.7041, 0.7387, 0.5900, 1.0761,
        0.8764, 0.9175, 0.6510, 0.9553, 0.9049, 0.5498, 0.7630, 0.8344, 0.8034,
        0.5930, 0.6679, 0.6848, 0.8035, 0.8901, 0.7157, 0.7531, 0.8568, 0.7680,
        0.7061, 0.5140, 0.7199, 1.0472, 0.6961, 0.8479, 0.6832, 0.9343, 0.6623,
        1.0055, 0.8605, 0.7690, 0.8341, 0.8039, 0.8609, 1.0990, 0.5141, 0.7215,
        0.7984, 0.8172, 0.8424, 0.6731, 1.0658, 1.0886, 0.6604, 0.6973, 0.8586,
        1.0154])
mlp.net.1.batch_norm.running_var tensor([0.9647, 1.8011, 0.7262, 1.4425, 1.0663, 2.1620, 2.7966, 1.0250, 0.6323,
        1.7525, 1.2451, 0.8687, 1.8484, 1.1770, 1.5954, 1.3396, 1.1867, 2.1378,
        2.2265, 1.3912, 1.0907, 2.5301, 2.0516, 0.8827, 1.3797, 1.9870, 1.2535,
        0.6221, 1.2036, 1.1098, 1.5601, 1.6178, 1.1784, 1.0021, 1.8125, 1.2477,
        1.1548, 0.6789, 1.4577, 3.4596, 1.0058, 1.6138, 1.1398, 1.7584, 1.1529,
        1.8408, 1.6047, 1.4754, 1.2742, 1.4146, 1.3886, 2.2116, 0.6432, 1.0431,
        1.5967, 1.9378, 1.6470, 1.0137, 2.2960, 2.4897, 1.1533, 1.1961, 1.4756,
        3.2710])
mlp.net.1.batch_norm.num_batches_tracked tensor(155)
mlp.net.2.linear.weight tensor([[ 0.1659, -0.0199, -0.2294,  ...,  0.0299, -0.0108,  0.0948],
        [ 0.0977,  0.3118, -0.1024,  ..., -0.0656,  0.3228,  0.0853],
        [-0.0515,  0.1090, -0.0557,  ..., -0.0543, -0.3553,  0.2085],
        ...,
        [-0.1581,  0.4626,  0.0398,  ...,  0.0565,  0.0904,  0.1118],
        [ 0.1228,  0.0356, -0.2774,  ..., -0.4306,  0.0789, -0.0328],
        [-0.0193,  0.1928,  0.0502,  ..., -0.0984, -0.1448,  0.3254]])
mlp.net.2.linear.bias tensor([ 0.0725,  0.0980, -0.0162,  0.0342, -0.0317,  0.0241, -0.0236, -0.0581,
         0.0272,  0.1221, -0.1765,  0.1438,  0.0255,  0.0225,  0.2979,  0.0280,
         0.0142, -0.0388, -0.0836, -0.0231,  0.0860,  0.0171, -0.0192, -0.0020,
         0.0925, -0.1868, -0.1167, -0.0443,  0.1452, -0.1677,  0.0319,  0.1722,
         0.0731, -0.0179,  0.2161, -0.0264, -0.0977,  0.1389, -0.0806, -0.0929,
         0.0868,  0.0050,  0.0452,  0.0437,  0.1238,  0.2007,  0.2995, -0.0623,
         0.0263,  0.0506,  0.0439,  0.1398,  0.2467,  0.1701, -0.1709, -0.0212,
         0.0385, -0.0768,  0.1220, -0.1437, -0.0128, -0.1502,  0.0841,  0.1390])
mlp.net.2.batch_norm.weight tensor([0.9462, 0.9065, 0.7944, 0.7824, 0.9548, 0.8456, 0.8964, 0.8996, 0.9432,
        0.7639, 0.8947, 0.8900, 1.0468, 0.8331, 1.0492, 1.0610, 0.8712, 1.0329,
        0.9890, 0.9099, 0.9571, 0.8504, 0.9715, 0.7970, 0.9382, 0.8398, 0.9990,
        0.9637, 0.7805, 0.8649, 0.8863, 0.8659, 0.8220, 1.0527, 0.8582, 0.8865,
        0.7971, 0.8955, 0.9642, 0.8709, 0.8472, 0.9093, 0.8140, 1.0113, 0.8581,
        1.0294, 0.8422, 0.9353, 0.9919, 0.9655, 0.7286, 0.9543, 0.8911, 0.9070,
        0.9580, 0.8531, 0.8814, 0.8493, 1.0738, 0.9729, 0.8675, 1.0324, 0.6993,
        1.0922])
mlp.net.2.batch_norm.bias tensor([-1.4461e-01, -2.3386e-02,  6.8981e-02, -1.4706e-02,  5.5186e-02,
         5.9034e-02, -9.4024e-02, -3.0115e-02, -2.9205e-04,  1.7368e-02,
        -1.2285e-02, -2.6523e-02, -1.6599e-01,  1.2980e-01,  8.6840e-02,
        -1.2111e-01,  1.8638e-01, -1.3534e-01,  6.9472e-02, -1.2883e-01,
         5.8727e-02,  1.4209e-02,  2.7942e-02, -4.0132e-02,  6.9385e-02,
         6.3290e-02,  4.7899e-02,  1.2012e-01, -5.1064e-03, -1.2097e-02,
        -2.1226e-04, -6.1372e-02,  9.1336e-03,  4.9103e-02,  7.9103e-02,
         1.1248e-01,  2.6897e-02,  1.0612e-01,  5.9909e-03,  1.6451e-01,
        -5.1314e-02,  9.2551e-02, -1.7698e-01,  7.9637e-02, -1.0691e-02,
         2.1288e-01,  3.3377e-02, -4.5987e-02,  9.4806e-02, -7.7726e-02,
         1.1286e-01,  7.5774e-02,  7.2009e-03, -1.2962e-01, -4.8974e-02,
        -3.0432e-02, -8.3822e-02,  1.4613e-01, -4.6972e-02,  2.4353e-02,
         6.4671e-02,  5.0490e-03,  1.3670e-01, -6.5826e-03])
mlp.net.2.batch_norm.running_mean tensor([0.8555, 0.7143, 0.9478, 0.9498, 0.6797, 0.9994, 0.6746, 0.9226, 0.7457,
        0.7483, 0.8485, 1.0053, 1.0434, 0.9467, 1.6029, 0.8298, 0.7437, 0.8798,
        0.7752, 0.9504, 1.1318, 0.9093, 0.7621, 0.6287, 1.3240, 0.4950, 0.7986,
        0.7798, 1.0339, 0.6432, 0.8499, 0.9387, 0.8268, 0.9803, 1.0144, 0.7555,
        0.7689, 0.8879, 0.7651, 0.5826, 0.8493, 0.6038, 0.6774, 0.9817, 0.9365,
        0.9779, 1.0047, 0.7633, 0.9201, 0.9496, 0.7692, 1.1705, 0.9954, 0.8316,
        0.6642, 0.7964, 1.0663, 0.9225, 1.1784, 0.5975, 0.7680, 0.7591, 0.7984,
        1.0441])
mlp.net.2.batch_norm.running_var tensor([1.7379, 1.6119, 1.9246, 1.5810, 1.3336, 3.3068, 1.6777, 2.6468, 1.7247,
        1.4838, 2.5565, 1.7587, 3.0859, 1.8785, 4.3079, 2.0672, 0.9584, 2.5156,
        1.9578, 1.9883, 2.5276, 1.8777, 1.1675, 0.9527, 2.7267, 0.7297, 2.1389,
        1.3066, 2.5266, 1.8128, 2.4346, 1.9569, 1.3893, 2.5402, 1.6634, 2.3005,
        1.7822, 2.0197, 1.6543, 1.2463, 2.2480, 1.0297, 1.6103, 2.8655, 1.3599,
        1.8487, 1.9233, 2.2767, 3.7510, 1.2695, 1.3461, 2.7585, 1.8787, 1.2444,
        1.7081, 1.5916, 3.1472, 2.5147, 3.7409, 1.0883, 1.1423, 1.8422, 1.1077,
        2.4179])
mlp.net.2.batch_norm.num_batches_tracked tensor(155)
mlp.net.3.linear.weight tensor([[ 0.1405, -0.2278, -0.0392,  ...,  0.0658,  0.0560, -0.3020],
        [ 0.0023,  0.0422,  0.3217,  ...,  0.0198,  0.1022, -0.2031],
        [ 0.0102,  0.1704,  0.0206,  ..., -0.0172, -0.3498, -0.0833],
        ...,
        [-0.0906,  0.1174,  0.1413,  ...,  0.1194, -0.1875,  0.2663],
        [ 0.0037, -0.1186,  0.1712,  ..., -0.1216, -0.0675, -0.2996],
        [-0.0880, -0.0661,  0.1558,  ...,  0.1111,  0.3950,  0.0037]])
mlp.net.3.linear.bias tensor([ 0.2014,  0.0623, -0.0906, -0.1200, -0.0064,  0.2213,  0.0369,  0.0791,
        -0.1077,  0.0977, -0.0787, -0.1847, -0.0759,  0.0766,  0.0399,  0.0443,
        -0.0726,  0.0449,  0.1514, -0.0156, -0.0578,  0.0913, -0.1625, -0.0615,
         0.2227, -0.0759,  0.1699,  0.1135,  0.0700,  0.0355,  0.0039, -0.0365,
         0.1818,  0.1486,  0.1464, -0.1344, -0.1138,  0.1980,  0.1913, -0.0723,
        -0.0420,  0.1365, -0.0997,  0.0605, -0.1344,  0.0184,  0.0415, -0.0591,
         0.0881,  0.0138, -0.0491,  0.1890,  0.0311,  0.1271, -0.0425, -0.0523,
        -0.1865,  0.1534, -0.1480, -0.0397,  0.0028, -0.1803,  0.0112,  0.2823])
mlp.net.3.batch_norm.weight tensor([0.7212, 0.6618, 0.7440, 0.6981, 0.6533, 0.5901, 0.6418, 0.6567, 0.6096,
        0.6331, 0.6118, 0.6925, 0.7533, 0.7225, 0.7111, 0.6414, 0.7217, 0.7147,
        0.6506, 0.6410, 0.6854, 0.6258, 0.7257, 0.6056, 0.6090, 0.5646, 0.6855,
        0.7005, 0.6103, 0.6655, 0.6465, 0.7782, 0.7255, 0.7454, 0.6752, 0.5807,
        0.6374, 0.6745, 0.5959, 0.6429, 0.7365, 0.5993, 0.7068, 0.5853, 0.6795,
        0.6239, 0.7292, 0.6661, 0.5834, 0.6055, 0.6404, 0.5414, 0.6700, 0.5528,
        0.6420, 0.6168, 0.7225, 0.5634, 0.5271, 0.7026, 0.6718, 0.6032, 0.5138,
        0.6961])
mlp.net.3.batch_norm.bias tensor([ 0.1176, -0.2581, -0.2262,  0.1724, -0.3815,  0.1599,  0.1150, -0.3960,
        -0.3173,  0.0133,  0.0176, -0.2737, -0.1805,  0.1328, -0.2828, -0.0779,
        -0.3124, -0.2619, -0.2133, -0.3206,  0.2291, -0.3045, -0.1813, -0.2923,
        -0.3611, -0.1630, -0.2228, -0.1588,  0.2125,  0.0742, -0.0898, -0.1196,
         0.2518, -0.1572, -0.1988,  0.1422, -0.4120, -0.1691,  0.2868, -0.2447,
         0.1756, -0.3364, -0.3840, -0.1465, -0.1797,  0.1345, -0.0761, -0.0109,
         0.0440,  0.3131, -0.2280, -0.2724, -0.3031, -0.3833, -0.3149, -0.1607,
        -0.0280,  0.0799, -0.3403,  0.4140,  0.0727, -0.0218, -0.3738, -0.2328])
mlp.net.3.batch_norm.running_mean tensor([1.0643, 1.0258, 0.7199, 0.6227, 0.6360, 0.9353, 0.7170, 0.7727, 0.7121,
        0.9192, 0.6894, 0.6797, 0.5756, 1.0679, 1.0200, 0.9723, 0.6349, 0.9996,
        0.7996, 0.5949, 0.7927, 0.9270, 0.9099, 0.7485, 1.0687, 0.8116, 1.1619,
        0.9495, 0.6508, 0.5541, 1.1318, 0.6695, 1.1855, 1.2339, 0.9251, 0.7113,
        0.7092, 0.9668, 1.0936, 0.6880, 0.7559, 0.8845, 0.7400, 0.5578, 0.6573,
        1.1613, 0.6921, 0.8302, 0.8599, 0.6076, 0.9184, 0.9414, 0.8264, 0.8220,
        0.7955, 0.7179, 0.9296, 0.8229, 0.5106, 0.8728, 0.9095, 0.9242, 0.4983,
        1.0583])
mlp.net.3.batch_norm.running_var tensor([2.3211, 2.7903, 1.7625, 1.9037, 1.1445, 2.1358, 1.7295, 2.2463, 1.4750,
        1.3330, 1.2417, 1.3093, 1.3208, 4.0841, 2.7301, 1.6168, 1.2466, 2.7888,
        1.0886, 0.8467, 2.1839, 2.8110, 3.0035, 2.1205, 1.5420, 2.3207, 1.5837,
        2.1564, 1.0788, 0.8256, 5.8928, 1.8508, 2.4867, 2.4133, 2.4317, 2.0914,
        2.5590, 2.5683, 1.8784, 1.8336, 1.7053, 1.8587, 1.4575, 0.9952, 1.7058,
        2.0582, 0.8655, 2.9373, 1.8815, 0.7315, 4.0307, 1.1902, 2.2938, 0.8856,
        2.4042, 2.7320, 4.0226, 1.6777, 0.7764, 3.5195, 2.0105, 3.7953, 0.6019,
        3.0932])
mlp.net.3.batch_norm.num_batches_tracked tensor(155)
mlp.net.4.weight tensor([[-0.0421,  0.0513,  0.0762,  ..., -0.0004,  0.1459,  0.1172],
        [ 0.1023, -0.1612, -0.0084,  ...,  0.0478, -0.0712,  0.0085],
        [ 0.1371, -0.0794,  0.0847,  ..., -0.1364, -0.0576, -0.1325],
        ...,
        [-0.0686,  0.0870,  0.0492,  ...,  0.0048,  0.0842,  0.0211],
        [-0.0987,  0.1089,  0.0486,  ..., -0.0463,  0.0711, -0.0076],
        [-0.0188, -0.0026, -0.0127,  ...,  0.0148,  0.1100, -0.0528]])
mlp.net.4.bias tensor([-7.0839e-01,  2.8016e-01,  1.2596e-01,  1.7559e-01,  1.2952e-01,
         2.0838e-01,  7.8385e-02,  2.7285e-01,  1.7390e-01,  1.7234e-01,
         2.0324e-01,  3.4076e-01,  2.8500e-01,  8.9164e-02,  2.2301e-01,
         1.0948e-01,  2.1505e-01,  1.7815e-01,  3.3363e-01,  2.1774e-01,
         1.6957e-01,  1.3125e-01,  2.5582e-01,  2.4932e-01,  2.2682e-01,
         7.7220e-02,  1.3708e-01,  2.3364e-01,  5.0562e-02,  1.8390e-02,
         4.9188e-02,  2.2405e-01,  1.6228e-01,  4.9993e-02,  5.1865e-02,
         5.3397e-02,  2.3433e-02, -5.3957e-02,  1.7704e-01,  5.9920e-02,
        -8.6295e-02,  1.2850e-01,  2.4772e-01, -1.2155e-02, -9.4701e-03,
        -4.7816e-02,  1.9828e-03, -6.2344e-02,  1.6838e-01, -1.7561e-01,
        -1.7797e-01, -9.7112e-02,  5.9026e-02, -3.5569e-02, -3.0665e-02,
         1.1301e-01,  2.2237e-02, -2.0236e-01, -6.4223e-02,  6.8435e-02,
        -6.6271e-02, -1.2111e-01,  1.6393e-01, -8.5628e-02, -1.3860e-01,
        -2.3070e-01,  5.2963e-02,  7.3142e-02, -8.6676e-03,  1.6004e-02,
         2.1396e-02,  1.8582e-02, -2.3624e-01, -5.4438e-02, -2.0775e-02,
        -2.4421e-01, -1.3722e-01, -5.0876e-01, -1.2511e-01,  7.5261e-02,
        -5.4236e-01,  5.8004e-02, -4.5959e-02,  7.4466e-02, -2.2556e-01,
        -1.4187e-01, -1.2504e-01, -1.3326e-01, -1.0769e-01, -5.8728e-02,
        -6.0277e-01,  2.8448e-02, -3.8298e-02, -5.1523e-01, -9.3971e-02,
         6.6991e-04, -5.8100e-01, -1.9105e-01, -2.5776e-02, -1.8486e-02,
        -4.2746e-02, -4.6729e-02, -6.8988e-02, -6.9552e-01, -6.7433e-01,
        -6.3672e-01, -1.5636e-01, -1.0846e-01, -1.5918e-01, -1.9834e-01,
        -5.3840e-01, -5.4414e-01, -1.7902e-01, -5.2675e-01, -5.5790e-01,
        -2.4513e-01, -5.6026e-01, -4.7462e-01, -6.1469e-02, -5.3008e-01,
        -1.7262e-01, -6.4016e-01, -5.8138e-01, -1.8178e-01, -1.9471e-01,
        -6.5545e-01, -6.9262e-01, -5.4330e-01, -6.8449e-01, -1.1311e-01,
        -6.5987e-01, -1.9526e-01, -4.8590e-01, -2.0746e-01, -6.4184e-01,
        -5.1140e-01, -1.2994e-01, -4.7583e-01, -6.1687e-01, -4.9240e-01,
        -4.8629e-01, -5.1547e-01, -7.3983e-02, -4.8354e-01, -6.6055e-01,
        -6.1947e-01, -6.6344e-01, -6.1964e-01, -8.9286e-02, -6.7486e-01,
        -5.9213e-01, -6.2064e-01, -6.1100e-01, -5.0262e-01, -4.8858e-01,
        -5.8249e-01, -5.5108e-01, -6.8241e-01, -7.4796e-02, -4.9238e-01,
        -6.5046e-01, -6.7295e-01, -5.9789e-01, -5.0921e-01, -5.4399e-01,
        -6.0081e-01, -6.7922e-02, -5.6775e-01, -5.6562e-01, -5.7904e-01,
        -5.0777e-01, -4.8253e-01, -4.9101e-01, -1.5896e-01, -6.6519e-01,
        -5.4943e-01, -6.7308e-01, -7.0054e-02, -6.4252e-01, -5.0008e-01,
        -6.6953e-01, -4.7077e-01, -6.0709e-01, -5.9850e-01, -5.4834e-01,
        -1.3460e-01, -5.8247e-01, -4.9859e-01, -6.5945e-01, -6.5615e-01,
        -4.5260e-01, -4.6419e-01, -5.8641e-01, -5.2038e-01, -6.5268e-01,
        -1.4057e-01, -6.5270e-01, -6.2704e-01, -6.5067e-01, -5.7467e-01,
        -6.4631e-01, -4.7775e-01, -6.4888e-01, -6.5285e-01, -4.5063e-02,
        -6.4176e-01, -6.1343e-01, -4.9686e-01, -5.3052e-01, -4.7895e-01,
        -5.4559e-01, -6.1499e-01, -6.5196e-01, -1.3683e-01, -5.2121e-01,
        -5.0196e-01, -6.4645e-01, -5.8765e-01, -5.7332e-01, -5.0805e-01,
        -5.8570e-01, -6.2243e-01, -6.0399e-01, -5.1283e-01, -6.5628e-01,
        -4.2971e-01, -4.4204e-01, -5.2590e-01, -5.4300e-01, -6.5670e-01,
        -5.3250e-01,  7.5501e-03, -6.3898e-01, -6.0014e-01, -6.2275e-01,
        -6.4145e-01, -5.2456e-01, -4.7703e-01, -5.8415e-01, -5.3499e-01,
        -5.6738e-01, -5.6580e-01, -6.0462e-01, -6.3272e-01, -5.0548e-01,
        -6.5277e-01, -4.9236e-01, -5.3100e-01, -5.7079e-01, -5.4716e-01,
         1.5239e-02, -5.7662e-01, -4.7813e-01, -5.7354e-01, -6.3368e-01,
        -5.0005e-01, -5.4495e-01, -6.2503e-01, -7.7435e-02, -5.2479e-01,
        -5.7409e-01, -8.2716e-02, -4.5064e-01, -5.5436e-01, -6.7810e-01,
        -5.7879e-01, -5.6513e-01, -6.1745e-01, -6.3746e-01, -4.9295e-01,
        -5.7027e-01, -4.2678e-01, -6.6494e-01, -6.1410e-01, -5.8025e-01,
        -5.2012e-01, -5.5110e-01, -6.1735e-01, -4.4921e-01, -5.6343e-01,
        -5.4415e-01, -6.5840e-01, -5.3222e-01, -6.0076e-01, -6.5364e-01,
        -5.5871e-01, -5.9810e-01, -5.3024e-01, -5.6388e-01, -4.5810e-01,
        -6.1133e-01, -5.6167e-01, -5.3720e-01, -5.4917e-01, -5.7538e-01,
        -4.8600e-01, -5.2636e-01, -4.4946e-01, -6.1038e-01, -5.0748e-01,
        -5.6543e-01, -5.6585e-01, -4.8693e-01, -6.5070e-01, -4.4773e-01,
        -4.5717e-01, -4.8545e-01, -5.2159e-01, -5.3120e-01, -1.5893e-01,
        -5.2480e-01, -6.3132e-01, -4.9322e-01, -6.0982e-01, -5.2361e-01,
        -4.3795e-01, -6.2170e-01, -5.9777e-01, -4.3576e-01, -1.5526e-01,
        -4.8258e-01, -4.4610e-01, -5.9425e-01, -6.1045e-01, -4.0877e-01,
        -6.1316e-01, -4.5854e-01, -4.6524e-01, -5.2124e-01, -6.4462e-01,
        -6.3567e-01, -5.7199e-01, -6.7337e-01, -5.8648e-01, -6.4774e-01,
        -1.6014e-01, -6.2017e-01, -4.4911e-01, -4.3915e-01, -4.5731e-01,
        -5.6598e-01, -6.2136e-01, -4.8341e-01, -4.3188e-01, -4.8694e-01,
        -5.8408e-01, -5.7917e-01, -5.8870e-01, -5.2686e-01, -5.3241e-01,
        -4.6216e-01, -5.9376e-01, -5.8907e-01, -6.0950e-01, -6.4943e-01,
        -1.8168e-01, -6.4431e-01, -5.0153e-01, -4.6589e-01, -5.2938e-01,
        -4.4681e-01, -5.6654e-01, -4.9648e-01, -6.3744e-01, -5.2647e-01,
        -5.4623e-01, -4.4134e-01, -6.5307e-01, -5.0512e-01, -4.7925e-01,
        -6.0794e-01, -5.5172e-01, -6.2976e-01, -5.4922e-01, -5.1001e-01,
        -6.1985e-01, -5.0327e-01, -6.3705e-01, -4.3901e-01, -6.1041e-01,
        -5.8343e-01, -5.3172e-01, -5.4706e-01, -5.9238e-01, -4.5891e-01,
        -6.3937e-01, -5.2092e-01, -5.9668e-01, -5.0455e-01, -6.3247e-01,
        -4.9391e-01, -5.1011e-01, -4.7120e-01, -6.1220e-01, -5.2699e-01,
        -6.6090e-01, -4.4058e-01, -6.1476e-01, -4.6902e-01, -1.1144e-01])
