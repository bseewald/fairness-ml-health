Weights: 
embeddings.embeddings.0.weight tensor([[-0.1146,  0.1267],
        [ 0.2504,  0.2014],
        [-0.1967, -0.0419],
        [ 0.0134,  0.0525]])
embeddings.embeddings.1.weight tensor([[-0.2982, -0.1569],
        [ 0.0739,  0.1631],
        [ 0.0448,  0.2849],
        [ 0.1121,  0.2171],
        [-0.1708, -0.0936]])
embeddings.embeddings.2.weight tensor([[ 0.2067, -0.0871,  0.0064],
        [ 0.0823, -0.1843, -0.2004],
        [-0.0011, -0.1511,  0.1663],
        [-0.1426, -0.0258, -0.0998],
        [ 0.0415, -0.0121,  0.2525],
        [ 0.0795, -0.0941,  0.0315]])
embeddings.embeddings.3.weight tensor([[-0.1167,  0.2465],
        [ 0.3047,  0.3019],
        [ 0.0025, -0.1490],
        [-0.4910, -0.3266]])
embeddings.embeddings.4.weight tensor([[-0.1503, -0.1733],
        [ 0.2931, -0.3659],
        [ 0.0602,  0.1924],
        [-0.2713,  0.0632]])
mlp.net.0.linear.weight tensor([[ 0.0613, -0.2187, -0.0702,  ...,  0.0611,  0.1406,  0.0061],
        [ 0.0164, -0.1375,  0.0137,  ..., -0.1552, -0.0833,  0.4693],
        [ 0.0653, -0.1361, -0.1017,  ...,  0.0602, -0.1149,  0.0583],
        ...,
        [-0.2448, -0.0466,  0.3031,  ...,  0.0879,  0.2595, -0.1598],
        [-0.0005,  0.0401,  0.1035,  ..., -0.0394, -0.1578,  0.0273],
        [-0.0711,  0.1072, -0.3046,  ..., -0.0791,  0.1205,  0.0185]])
mlp.net.0.linear.bias tensor([-0.0079,  0.0515,  0.0712, -0.0864,  0.1018,  0.0279,  0.0758,  0.0112,
        -0.0273,  0.0420,  0.0642,  0.0657, -0.0039,  0.0426, -0.0231, -0.0502,
         0.0274, -0.0226,  0.1102,  0.0109, -0.0289, -0.0635,  0.0436, -0.1176,
        -0.1103,  0.0127, -0.0700, -0.0213, -0.0779, -0.0745,  0.1108, -0.0440,
         0.1063, -0.0396,  0.0477,  0.0034,  0.1049, -0.0448,  0.1048, -0.1041,
         0.1021,  0.0634, -0.0499,  0.1189, -0.0869,  0.1009,  0.0499, -0.0831,
        -0.0942,  0.0451, -0.0119,  0.0032,  0.0720, -0.0373, -0.0017, -0.0075,
         0.0131,  0.1011, -0.0685, -0.1023, -0.0423, -0.0809,  0.0834, -0.0132])
mlp.net.0.batch_norm.weight tensor([0.4131, 0.5147, 0.4527, 0.4016, 0.4861, 0.3465, 0.4949, 0.4196, 0.4140,
        0.4675, 0.4217, 0.4557, 0.4445, 0.4570, 0.3681, 0.4065, 0.4538, 0.4075,
        0.4135, 0.4469, 0.4561, 0.4307, 0.4325, 0.3935, 0.4495, 0.5036, 0.4246,
        0.4899, 0.4656, 0.5017, 0.4266, 0.4409, 0.4692, 0.5350, 0.4335, 0.3930,
        0.4214, 0.5713, 0.4519, 0.3673, 0.4052, 0.4748, 0.4692, 0.3768, 0.4884,
        0.4229, 0.4024, 0.4838, 0.5112, 0.4272, 0.4929, 0.4684, 0.5166, 0.4382,
        0.4984, 0.4378, 0.4793, 0.4661, 0.4001, 0.4920, 0.5080, 0.4649, 0.4474,
        0.5161])
mlp.net.0.batch_norm.bias tensor([ 0.0512, -0.0651, -0.0243,  0.0003, -0.0902,  0.0285,  0.0008, -0.0450,
        -0.0561, -0.0215, -0.0181,  0.0501,  0.0588,  0.0600, -0.0027,  0.0059,
         0.0042,  0.0040, -0.0010, -0.0091,  0.0387,  0.0339,  0.0151,  0.0149,
        -0.0217, -0.0480, -0.0016, -0.0616, -0.0036,  0.0330,  0.0403, -0.0208,
        -0.0211, -0.0513,  0.0201, -0.0007, -0.0721, -0.0480, -0.0408, -0.0031,
        -0.0285, -0.0519,  0.0364, -0.0207,  0.0544,  0.0162, -0.0110,  0.0322,
         0.0522, -0.0249,  0.0574, -0.0086, -0.0186,  0.0191, -0.0244, -0.0598,
         0.0137,  0.0546, -0.0122,  0.0864,  0.0211,  0.0551, -0.1012, -0.0438])
mlp.net.0.batch_norm.running_mean tensor([4.3758e-02, 3.7751e-01, 2.7047e-01, 3.8383e-01, 4.9590e-01, 6.8998e-02,
        1.7614e-01, 2.0620e-01, 2.3706e-02, 1.9837e-01, 6.9832e-02, 2.5798e-02,
        1.4828e-01, 1.4186e-01, 1.9397e-01, 1.3517e-01, 1.2367e-02, 4.5418e-02,
        1.0703e-01, 6.7517e-03, 1.0531e-01, 7.0389e-02, 3.3234e-02, 8.5838e-05,
        1.4457e-01, 3.0278e-01, 5.8758e-02, 5.6918e-02, 2.1431e-01, 1.4705e-02,
        9.5455e-01, 1.3591e-01, 3.7198e-02, 2.6290e-01, 4.9659e-02, 1.1976e-01,
        6.7558e-02, 2.0511e-01, 2.4574e-01, 7.9823e-02, 2.3891e-02, 3.6696e-02,
        2.5401e-03, 9.2453e-02, 2.7572e-01, 1.6981e-01, 7.8375e-02, 1.1266e-01,
        1.4898e-01, 1.1126e-01, 7.3871e-02, 1.2510e-02, 3.6358e-01, 1.8452e-01,
        3.8174e-03, 3.1701e-01, 6.9471e-02, 1.6873e-01, 8.1659e-02, 5.5612e-02,
        8.2543e-02, 1.9760e-02, 2.9326e-01, 1.5249e-02])
mlp.net.0.batch_norm.running_var tensor([6.2389e-03, 1.6651e-02, 8.3534e-03, 2.2576e-02, 4.4598e-02, 9.8009e-03,
        2.9762e-02, 3.2047e-02, 2.8426e-03, 3.1207e-02, 1.2722e-02, 3.5329e-03,
        2.6663e-02, 1.4931e-02, 3.8515e-02, 3.0177e-02, 2.3418e-03, 6.6983e-03,
        1.4769e-02, 8.4267e-04, 1.1295e-02, 1.0688e-02, 5.5986e-03, 5.5607e-06,
        1.0547e-02, 1.7953e-02, 8.4816e-03, 6.3269e-03, 3.0698e-02, 1.6142e-03,
        4.1531e-02, 2.4548e-02, 2.6302e-03, 1.4180e-02, 4.1006e-03, 2.7813e-02,
        1.0547e-02, 9.7438e-03, 2.6083e-02, 1.3815e-02, 2.9475e-03, 6.2148e-03,
        5.5274e-04, 1.9175e-02, 3.6198e-02, 1.3106e-02, 1.2438e-02, 1.5912e-02,
        1.4785e-02, 2.2369e-02, 9.0796e-03, 1.3098e-03, 1.6877e-02, 1.7461e-02,
        4.5653e-04, 4.6360e-02, 9.7058e-03, 3.2863e-02, 6.0636e-03, 4.9181e-03,
        8.0922e-03, 2.7706e-03, 1.1481e-02, 1.5679e-03])
mlp.net.0.batch_norm.num_batches_tracked tensor(2867)
mlp.net.1.linear.weight tensor([[-0.0428,  0.1357,  0.1184,  ..., -0.0146,  0.0916, -0.0879],
        [ 0.0289, -0.1088,  0.0548,  ..., -0.0199,  0.0820,  0.1217],
        [-0.0285,  0.1022,  0.1074,  ...,  0.1019, -0.0317,  0.0998],
        ...,
        [ 0.0444, -0.0368, -0.1688,  ...,  0.1506,  0.1119, -0.0560],
        [-0.0862,  0.1045,  0.1121,  ...,  0.0642, -0.0400, -0.0411],
        [ 0.0845, -0.0610,  0.1090,  ...,  0.0031, -0.1209, -0.0791]])
mlp.net.1.linear.bias tensor([ 0.0215,  0.0530, -0.0791,  0.0438, -0.0143,  0.0216,  0.0476,  0.0134,
         0.0206, -0.0326,  0.0262, -0.0637, -0.0211,  0.0842,  0.0959,  0.0171,
         0.0797, -0.0219, -0.0659,  0.0027,  0.1496, -0.0552,  0.1113, -0.0577,
         0.1352,  0.0904, -0.0913,  0.0152, -0.0044,  0.0325,  0.0245,  0.1497,
         0.0843, -0.0665, -0.0452,  0.0709, -0.0169, -0.0326,  0.0353,  0.0899,
        -0.0498, -0.0514, -0.0379,  0.0349,  0.0180,  0.0088,  0.1284,  0.0212,
         0.0185, -0.0044,  0.1454,  0.0013,  0.0593, -0.0324,  0.0351,  0.0656,
        -0.0098,  0.0483, -0.0237,  0.0394,  0.1263,  0.0612,  0.0201, -0.0557])
mlp.net.1.batch_norm.weight tensor([0.4947, 0.4296, 0.4672, 0.4743, 0.4073, 0.4422, 0.3877, 0.4447, 0.3310,
        0.4267, 0.4183, 0.4647, 0.4591, 0.4153, 0.5123, 0.4296, 0.4922, 0.4141,
        0.4431, 0.5576, 0.4693, 0.5090, 0.4941, 0.4444, 0.4362, 0.4502, 0.4046,
        0.4501, 0.3480, 0.4742, 0.4992, 0.5274, 0.4758, 0.4456, 0.4110, 0.4979,
        0.4648, 0.4163, 0.4169, 0.4889, 0.3881, 0.3937, 0.4388, 0.4780, 0.5142,
        0.4467, 0.3825, 0.4662, 0.4351, 0.4845, 0.4849, 0.4103, 0.5031, 0.4674,
        0.4326, 0.4393, 0.3948, 0.4111, 0.4583, 0.4704, 0.4606, 0.4490, 0.4586,
        0.4605])
mlp.net.1.batch_norm.bias tensor([-8.1126e-02, -1.0811e-02,  5.5331e-02,  1.1753e-02,  7.9801e-02,
        -3.4489e-03, -1.6137e-02,  6.6840e-02, -5.5998e-03, -1.4537e-02,
        -4.4519e-02,  3.5870e-02,  1.0885e-02,  6.1219e-02, -2.6491e-02,
         5.9971e-05,  3.4865e-02,  6.1493e-02, -2.6034e-02,  4.5930e-02,
         1.0003e-01,  4.6163e-02,  5.8847e-02,  4.4596e-02,  7.5405e-02,
         2.3679e-03,  9.2859e-02, -5.6041e-02,  4.3348e-02, -1.7832e-02,
         5.6311e-02,  6.6416e-02,  6.5940e-02, -2.2589e-03,  1.7819e-02,
         4.2703e-02,  2.9052e-02, -1.6107e-02, -8.0330e-02,  2.6778e-02,
        -4.7247e-02,  3.9641e-02,  1.2508e-02,  4.4700e-02,  1.0642e-02,
         3.5481e-02, -4.0653e-02,  2.7528e-02,  5.4068e-02,  2.5121e-02,
         8.1977e-02, -3.7412e-02,  3.3989e-02, -6.5509e-02, -1.3925e-02,
         2.8590e-02, -3.6732e-02, -2.9824e-02,  9.1509e-03,  6.0102e-02,
         3.7172e-02,  1.8054e-02,  1.7014e-02,  6.6142e-02])
mlp.net.1.batch_norm.running_mean tensor([0.2407, 0.2250, 0.1251, 0.2402, 0.2908, 0.2884, 0.2082, 0.2624, 0.2225,
        0.2225, 0.2326, 0.1190, 0.2041, 0.3559, 0.3351, 0.2793, 0.3108, 0.2065,
        0.2161, 0.2689, 0.4085, 0.2327, 0.3536, 0.1637, 0.3877, 0.2813, 0.1293,
        0.2108, 0.2195, 0.2569, 0.2851, 0.2894, 0.3485, 0.2583, 0.1515, 0.3288,
        0.1811, 0.2060, 0.2158, 0.3480, 0.1852, 0.1648, 0.2026, 0.3277, 0.2438,
        0.2613, 0.2917, 0.2855, 0.3563, 0.2303, 0.3490, 0.2571, 0.3683, 0.1597,
        0.2599, 0.2468, 0.2180, 0.2698, 0.2198, 0.2647, 0.3481, 0.3450, 0.2204,
        0.2724])
mlp.net.1.batch_norm.running_var tensor([0.1365, 0.1767, 0.0433, 0.1064, 0.2056, 0.2160, 0.1045, 0.1641, 0.1011,
        0.1307, 0.1201, 0.0513, 0.1177, 0.2178, 0.2810, 0.1629, 0.1802, 0.1119,
        0.1265, 0.1472, 0.2424, 0.1396, 0.2598, 0.0857, 0.2181, 0.1477, 0.0756,
        0.1057, 0.1147, 0.1597, 0.1384, 0.1408, 0.1509, 0.1583, 0.0771, 0.1826,
        0.1202, 0.1064, 0.1185, 0.1945, 0.0998, 0.0539, 0.1145, 0.2010, 0.1878,
        0.1419, 0.2000, 0.1670, 0.2518, 0.1134, 0.1421, 0.1642, 0.2303, 0.0721,
        0.1527, 0.1128, 0.1315, 0.1965, 0.1247, 0.1588, 0.1888, 0.2407, 0.0939,
        0.1820])
mlp.net.1.batch_norm.num_batches_tracked tensor(2867)
mlp.net.2.linear.weight tensor([[ 0.0938, -0.0471, -0.0186,  ...,  0.0005,  0.0469, -0.0541],
        [ 0.0608,  0.0319,  0.0459,  ..., -0.0929,  0.1269,  0.1348],
        [-0.0590, -0.1161, -0.0988,  ..., -0.0333,  0.1700, -0.0007],
        ...,
        [-0.0568,  0.1258,  0.0296,  ...,  0.0125,  0.0335, -0.0170],
        [ 0.0875, -0.0788, -0.1719,  ..., -0.1143, -0.0657,  0.1166],
        [-0.0025,  0.0154,  0.0401,  ..., -0.0129,  0.0541, -0.1515]])
mlp.net.2.linear.bias tensor([ 0.0103,  0.0543,  0.0850,  0.0909,  0.0796,  0.0830, -0.0550,  0.0321,
         0.0437, -0.0253, -0.0373,  0.1045,  0.0819,  0.0141,  0.0836,  0.0779,
         0.0736,  0.0160,  0.0244, -0.0229,  0.0100,  0.1098, -0.0048,  0.0832,
         0.0471,  0.1505, -0.0601,  0.1304, -0.0180,  0.1125,  0.0017, -0.0193,
         0.0655,  0.1461,  0.1062, -0.0470,  0.0028,  0.0706,  0.0191, -0.0276,
         0.0839, -0.0194,  0.0755,  0.0536,  0.0366,  0.0649, -0.0226,  0.0465,
         0.0740, -0.0024, -0.0003,  0.0461,  0.1446,  0.0862,  0.0651, -0.0398,
         0.1255, -0.0169, -0.0210,  0.0014,  0.1020,  0.0206,  0.0076,  0.0860])
mlp.net.2.batch_norm.weight tensor([0.5060, 0.4591, 0.5075, 0.4674, 0.4167, 0.4394, 0.4037, 0.4547, 0.4931,
        0.4796, 0.4577, 0.4672, 0.4314, 0.4347, 0.4774, 0.4222, 0.4821, 0.3948,
        0.4456, 0.3513, 0.4858, 0.5090, 0.4423, 0.4462, 0.3860, 0.4569, 0.3731,
        0.4156, 0.4058, 0.4931, 0.4517, 0.4336, 0.4782, 0.4389, 0.4921, 0.3984,
        0.4110, 0.4495, 0.4079, 0.3950, 0.5039, 0.5054, 0.4677, 0.4350, 0.4153,
        0.4428, 0.4281, 0.4308, 0.4557, 0.4005, 0.4393, 0.4466, 0.4767, 0.4629,
        0.4829, 0.4311, 0.4912, 0.4338, 0.4280, 0.4159, 0.4519, 0.4513, 0.4276,
        0.4808])
mlp.net.2.batch_norm.bias tensor([-0.1012, -0.0497,  0.0211,  0.0044, -0.0296,  0.1319, -0.0930,  0.0275,
         0.0432, -0.0982, -0.0323,  0.0555,  0.0726,  0.0179, -0.0819,  0.0286,
        -0.0524,  0.1001,  0.0314,  0.0540, -0.0603, -0.0549, -0.0151,  0.0574,
        -0.0442,  0.0506, -0.0591,  0.0123, -0.0952,  0.0604, -0.0349, -0.0122,
        -0.0553,  0.0093,  0.1126,  0.0355,  0.0049,  0.0898, -0.0589,  0.0054,
         0.0465,  0.0209, -0.0428, -0.0042,  0.0601, -0.0241,  0.0508, -0.0583,
         0.0367,  0.0322,  0.0244,  0.0639,  0.0587,  0.0567,  0.0545,  0.0130,
         0.0627,  0.0397,  0.0584,  0.0340,  0.0664,  0.0240,  0.0360,  0.0444])
mlp.net.2.batch_norm.running_mean tensor([0.3630, 0.2567, 0.3124, 0.3033, 0.2378, 0.4421, 0.2090, 0.2479, 0.3210,
        0.2720, 0.1594, 0.3577, 0.3104, 0.3771, 0.3054, 0.2447, 0.4318, 0.2281,
        0.2889, 0.1527, 0.2591, 0.3546, 0.2087, 0.3123, 0.2474, 0.3620, 0.1933,
        0.3174, 0.1723, 0.3154, 0.2439, 0.2331, 0.3161, 0.3420, 0.3222, 0.1701,
        0.2407, 0.2688, 0.2135, 0.1588, 0.3146, 0.2445, 0.3461, 0.2469, 0.2853,
        0.2737, 0.2557, 0.2623, 0.2656, 0.2232, 0.2264, 0.3592, 0.4705, 0.3397,
        0.2949, 0.1655, 0.4110, 0.2254, 0.2347, 0.2538, 0.2784, 0.2399, 0.2663,
        0.2650])
mlp.net.2.batch_norm.running_var tensor([0.2701, 0.1436, 0.1748, 0.2112, 0.1129, 0.3491, 0.0961, 0.0973, 0.2349,
        0.1796, 0.0825, 0.2284, 0.1348, 0.3796, 0.1970, 0.1163, 0.3725, 0.1229,
        0.3043, 0.0646, 0.1601, 0.2711, 0.1266, 0.1879, 0.1502, 0.2085, 0.1391,
        0.2020, 0.1063, 0.1779, 0.1298, 0.1400, 0.2236, 0.1472, 0.2164, 0.0829,
        0.1708, 0.1549, 0.0925, 0.0835, 0.1857, 0.2195, 0.2260, 0.1661, 0.1786,
        0.1525, 0.1517, 0.1613, 0.1417, 0.1398, 0.1266, 0.3141, 0.3068, 0.2125,
        0.2645, 0.1140, 0.3672, 0.1546, 0.1258, 0.2128, 0.2430, 0.1073, 0.2133,
        0.1612])
mlp.net.2.batch_norm.num_batches_tracked tensor(2867)
mlp.net.3.linear.weight tensor([[ 0.0856,  0.0507, -0.0497,  ..., -0.1508, -0.1473, -0.0920],
        [-0.1934, -0.0514,  0.0197,  ...,  0.0224, -0.0604, -0.0359],
        [ 0.0413,  0.0367, -0.0338,  ...,  0.0424,  0.1044, -0.0829],
        ...,
        [-0.0360, -0.1628,  0.0015,  ..., -0.0430,  0.1304,  0.0393],
        [ 0.1500, -0.0798,  0.0362,  ...,  0.0357, -0.0362, -0.0291],
        [-0.0258, -0.0922,  0.0424,  ...,  0.0986, -0.0628, -0.0442]])
mlp.net.3.linear.bias tensor([-0.0040,  0.0042,  0.1311,  0.0919,  0.0048, -0.0093,  0.0609,  0.0924,
         0.0533,  0.0446,  0.0262,  0.0796,  0.0198,  0.0477,  0.0206,  0.0337,
         0.0437,  0.0204,  0.1160, -0.0100,  0.0826, -0.0335,  0.1368,  0.0290,
         0.0721,  0.0557,  0.1084,  0.0921,  0.1149, -0.0043,  0.1610,  0.1387,
        -0.0081,  0.1456, -0.0888,  0.1239,  0.0704, -0.0400,  0.1014,  0.0215,
         0.1238,  0.1182,  0.0812,  0.1068,  0.0544,  0.1223,  0.0657,  0.0543,
         0.0812,  0.0042, -0.0025,  0.0041, -0.0399, -0.0041,  0.1023, -0.0350,
         0.1286,  0.0798, -0.0226,  0.0271,  0.1217,  0.1104, -0.0030,  0.0745])
mlp.net.3.batch_norm.weight tensor([0.4211, 0.3632, 0.3890, 0.3961, 0.3685, 0.3813, 0.5091, 0.4206, 0.4469,
        0.3523, 0.3937, 0.4751, 0.3788, 0.3901, 0.2965, 0.3328, 0.3660, 0.4196,
        0.4065, 0.3567, 0.3698, 0.4399, 0.4203, 0.2848, 0.3636, 0.4769, 0.3612,
        0.3778, 0.4217, 0.4167, 0.4184, 0.4306, 0.4256, 0.4161, 0.3508, 0.3391,
        0.3325, 0.2813, 0.5036, 0.3141, 0.4273, 0.3097, 0.4613, 0.3286, 0.3363,
        0.4376, 0.4450, 0.3920, 0.4221, 0.3763, 0.3675, 0.3145, 0.4293, 0.2985,
        0.4824, 0.3289, 0.4682, 0.4749, 0.2856, 0.3687, 0.4040, 0.4296, 0.2878,
        0.4113])
mlp.net.3.batch_norm.bias tensor([ 0.0907, -0.2996, -0.2091, -0.1766, -0.3155, -0.2263,  0.1083, -0.1291,
        -0.0358, -0.2679,  0.2070, -0.1140,  0.0194, -0.2042, -0.3389, -0.2907,
        -0.2059,  0.2474, -0.1573,  0.2206, -0.2448, -0.0539, -0.0953, -0.3464,
        -0.3390,  0.1404, -0.2699, -0.2250,  0.1388, -0.1630, -0.2408, -0.2191,
        -0.1196,  0.1911,  0.2119, -0.3339, -0.2713, -0.3590, -0.0726, -0.2740,
        -0.0816, -0.3814, -0.0642, -0.3542, -0.2605, -0.1373, -0.0636, -0.2050,
         0.1580, -0.1594, -0.2246, -0.2321, -0.0675, -0.1327,  0.0637, -0.2587,
        -0.0978, -0.0954, -0.3910, -0.0448,  0.1069, -0.1559, -0.4145, -0.0474])
mlp.net.3.batch_norm.running_mean tensor([0.2667, 0.2635, 0.4202, 0.3754, 0.3350, 0.3741, 0.4780, 0.4319, 0.4118,
        0.3966, 0.3409, 0.4206, 0.2565, 0.2584, 0.1757, 0.2963, 0.3806, 0.3579,
        0.4144, 0.1751, 0.3377, 0.1974, 0.3547, 0.1955, 0.3326, 0.4327, 0.3589,
        0.3358, 0.3307, 0.3668, 0.3519, 0.3177, 0.3407, 0.4004, 0.1620, 0.4403,
        0.2710, 0.2484, 0.3841, 0.2270, 0.4823, 0.3000, 0.4259, 0.3671, 0.3151,
        0.3460, 0.4775, 0.3701, 0.3873, 0.2942, 0.3242, 0.2633, 0.2080, 0.1922,
        0.3411, 0.2173, 0.4938, 0.3881, 0.2568, 0.3877, 0.4226, 0.4389, 0.1626,
        0.3432])
mlp.net.3.batch_norm.running_var tensor([0.1586, 0.1179, 0.2895, 0.2605, 0.2067, 0.4055, 0.3763, 0.4037, 0.3659,
        0.3989, 0.2791, 0.2261, 0.1455, 0.1930, 0.1076, 0.2418, 0.2556, 0.2964,
        0.1915, 0.1048, 0.1425, 0.1074, 0.1336, 0.0930, 0.2094, 0.4395, 0.1791,
        0.1951, 0.2480, 0.3285, 0.1947, 0.2104, 0.3327, 0.3298, 0.0869, 0.2531,
        0.1607, 0.2091, 0.1519, 0.1227, 0.4149, 0.0984, 0.3342, 0.1725, 0.2302,
        0.1610, 0.4511, 0.3109, 0.2773, 0.2332, 0.3875, 0.1858, 0.1223, 0.0887,
        0.1674, 0.1454, 0.3553, 0.2117, 0.0995, 0.3944, 0.2447, 0.3591, 0.0717,
        0.2193])
mlp.net.3.batch_norm.num_batches_tracked tensor(2867)
mlp.net.4.weight tensor([[ 0.0006,  0.0657,  0.0522,  ..., -0.0512,  0.1358, -0.0628],
        [ 0.0210, -0.0454, -0.0525,  ..., -0.0597, -0.0192, -0.0744],
        [ 0.0273, -0.0521, -0.0722,  ..., -0.0907,  0.0385, -0.0740],
        ...,
        [-0.0559,  0.0701,  0.0585,  ...,  0.0086,  0.0910,  0.0032],
        [-0.0467,  0.0740,  0.0587,  ...,  0.0035,  0.0955,  0.0065],
        [-0.0943,  0.0098,  0.0347,  ...,  0.0318,  0.0180,  0.0079]])
mlp.net.4.bias tensor([-5.3892e-01,  4.1375e-01,  3.4788e-01,  3.1071e-01,  3.5909e-01,
         3.3388e-01,  3.0906e-01,  3.1839e-01,  2.0209e-01,  3.8229e-01,
         2.9868e-01,  2.7589e-01,  3.7770e-01,  2.2353e-01,  2.3718e-01,
         3.7655e-01,  2.0230e-01,  3.3931e-01,  2.6365e-01,  1.9732e-01,
         1.7935e-01,  2.5440e-01,  2.8422e-01,  3.0013e-01,  2.2895e-01,
         1.4285e-01,  2.3147e-01,  1.9004e-01,  1.6960e-01,  2.0538e-01,
         2.1936e-01,  1.6320e-01,  1.7834e-01,  3.8314e-02,  1.4136e-01,
        -4.6854e-02,  9.7805e-02,  1.0377e-01,  1.6927e-01,  1.2391e-01,
         9.1466e-02,  1.8202e-01,  1.3967e-01, -3.5283e-02,  6.3724e-02,
        -2.2627e-02,  4.3203e-02, -9.4071e-02,  1.2474e-01, -2.9134e-01,
        -1.6342e-01, -9.4265e-02, -4.9553e-02,  3.7899e-02, -2.5680e-02,
        -2.5365e-02,  6.8916e-02, -5.5336e-03, -1.1847e-01,  8.0940e-03,
         1.9782e-02, -6.1836e-02,  5.2985e-02, -1.5692e-01, -2.5999e-01,
        -2.3837e-01,  1.2076e-01, -6.0188e-02,  7.3699e-02,  5.8325e-02,
         2.2608e-02, -1.8090e-02, -4.6142e-02, -9.6112e-02, -2.3313e-01,
        -1.1230e+00, -2.2562e-01, -1.1189e+00, -2.1091e-01, -2.3272e-02,
        -1.0319e+00, -6.6143e-02,  1.0367e-01, -2.4343e-01, -2.2911e-01,
        -1.1048e+00, -8.3716e-03, -8.2359e-02, -1.1106e+00, -4.9638e-02,
        -2.2131e-01,  3.4970e-02,  2.6761e-02, -1.1341e+00, -2.1064e-01,
        -5.6216e-06, -1.0678e+00, -1.8209e-01, -6.4711e-02, -1.1546e-01,
        -2.3250e-01, -1.6675e-01, -5.5303e-02, -1.0504e+00, -1.1245e+00,
        -2.1920e-01, -5.9288e-02, -2.2783e-01, -1.8978e-01, -2.2339e-01,
        -2.0358e-01, -1.1514e+00, -1.1399e+00, -1.1121e+00, -1.0931e+00,
        -2.0454e-01, -1.1285e+00, -1.0982e+00, -4.2335e-02, -1.1202e+00,
        -1.1131e+00, -1.1500e+00, -1.0579e+00, -1.8797e-01, -1.0640e+00,
        -2.2221e-01, -1.1292e+00, -1.0511e+00, -1.0762e+00, -1.7450e-01,
        -1.0984e+00, -1.8663e-01, -1.0733e+00, -1.5844e-01, -1.0569e+00,
        -1.0980e+00, -1.9077e-01, -1.0386e+00, -1.0781e+00, -1.0931e+00,
        -1.0997e+00, -1.0793e+00, -2.1446e-01, -1.0664e+00, -9.9181e-01,
        -1.0448e+00, -1.0618e+00, -1.7634e-01, -1.6711e-01, -1.4627e-01,
        -1.0459e+00, -1.0450e+00, -1.0827e+00, -1.0392e+00, -1.1117e+00,
        -1.1039e+00, -1.0252e+00, -3.5321e-02, -1.5374e-01, -1.1086e+00,
        -1.0332e+00, -1.0373e+00, -1.0486e+00, -1.0643e+00, -1.1257e+00,
        -1.0519e+00, -2.2765e-01, -1.0616e+00, -1.1295e+00, -1.1230e+00,
        -1.0759e+00, -1.8846e-01, -1.1180e+00, -1.3331e-01, -1.0998e+00,
        -1.0938e+00, -1.0981e+00, -1.9094e-01, -1.0562e+00, -1.0391e+00,
        -1.0395e+00, -1.0265e+00, -1.1148e+00, -1.0826e+00, -1.0562e+00,
        -2.0116e-01, -9.9615e-01, -1.0013e+00, -1.0325e+00, -1.0044e+00,
        -1.0002e+00, -1.0119e+00, -1.0786e+00, -1.0791e+00, -1.0592e+00,
        -1.5574e-01, -1.0974e+00, -1.0944e+00, -1.0221e+00, -1.0663e+00,
        -1.0294e+00, -1.0062e+00, -1.0928e+00, -1.1155e+00, -1.5566e-01,
        -1.1326e+00, -1.1069e+00, -1.0499e+00, -1.0165e+00, -1.1021e+00,
        -1.0886e+00, -1.0969e+00, -1.0326e+00, -1.5649e-01, -1.8993e-01,
        -1.0592e+00, -1.0076e+00, -1.0950e+00, -1.0980e+00, -1.0639e+00,
        -1.0328e+00, -1.0668e+00, -1.1037e+00, -9.9254e-01, -1.0213e+00,
        -9.8344e-01, -1.0056e+00, -1.0359e+00, -1.0195e+00, -1.0188e+00,
        -1.0230e+00, -1.6351e-01, -1.0605e+00, -9.9426e-01, -1.0788e+00,
        -1.0472e+00, -1.0277e+00, -1.0872e+00, -1.0543e+00, -1.0156e+00,
        -1.0698e+00, -1.0962e+00, -9.8950e-01, -1.0260e+00, -1.0286e+00,
        -1.0481e+00, -1.0234e+00, -1.0740e+00, -1.0766e+00, -1.0242e+00,
        -1.9747e-01, -1.0779e+00, -1.0078e+00, -1.0194e+00, -1.0087e+00,
        -1.1185e+00, -1.0720e+00, -1.0222e+00, -1.7195e-01, -1.0657e+00,
        -1.0590e+00, -1.6084e-01, -1.0620e+00, -1.1095e+00, -1.0751e+00,
        -9.3681e-01, -1.0664e+00, -1.0780e+00, -1.0050e+00, -1.0934e+00,
        -1.0158e+00, -1.0465e+00, -1.0001e+00, -1.0433e+00, -9.8460e-01,
        -1.0725e+00, -1.0493e+00, -1.0909e+00, -1.0385e+00, -1.0184e+00,
        -1.0079e+00, -1.0267e+00, -1.0800e+00, -1.0656e+00, -1.0877e+00,
        -1.1019e+00, -1.0051e+00, -9.9456e-01, -1.0605e+00, -1.0655e+00,
        -1.0304e+00, -1.0381e+00, -9.6750e-01, -1.0173e+00, -1.1118e+00,
        -1.0977e+00, -1.0805e+00, -1.0344e+00, -1.1055e+00, -1.0847e+00,
        -1.0627e+00, -1.1152e+00, -1.1042e+00, -1.0566e+00, -9.8835e-01,
        -1.0429e+00, -1.0764e+00, -1.0563e+00, -1.0368e+00, -1.0589e+00,
        -1.0433e+00, -1.0509e+00, -1.0559e+00, -1.1227e+00, -1.0522e+00,
        -1.0947e+00, -1.0339e+00, -1.0353e+00, -1.0824e+00, -1.6593e-01,
        -1.0541e+00, -1.0031e+00, -1.0559e+00, -1.1127e+00, -1.1145e+00,
        -1.0269e+00, -1.0300e+00, -1.0658e+00, -1.0897e+00, -1.0464e+00,
        -1.0171e+00, -1.1050e+00, -1.0330e+00, -1.0693e+00, -9.9992e-01,
        -1.4017e-01, -1.0036e+00, -1.0481e+00, -1.0770e+00, -1.0143e+00,
        -1.0554e+00, -1.0875e+00, -1.0718e+00, -9.9098e-01, -1.0996e+00,
        -1.0605e+00, -1.0068e+00, -1.0976e+00, -1.0448e+00, -1.0800e+00,
        -1.0668e+00, -1.0388e+00, -1.0732e+00, -1.0869e+00, -1.0324e+00,
        -1.0923e+00, -1.0457e+00, -1.0521e+00, -1.0578e+00, -1.0901e+00,
        -1.1165e+00, -1.0777e+00, -9.9944e-01, -9.6124e-01, -1.0835e+00,
        -1.0226e+00, -1.0970e+00, -1.0211e+00, -1.0175e+00, -1.0317e+00,
        -1.0664e+00, -1.0753e+00, -1.1070e+00, -1.0170e+00, -1.0816e+00,
        -1.0387e+00, -1.1174e+00, -1.0898e+00, -1.1215e+00, -1.0936e+00,
        -1.0163e+00, -1.0439e+00, -1.1058e+00, -1.0944e+00, -1.0563e+00,
        -1.0723e+00, -1.0054e+00, -1.0803e+00, -1.1225e+00, -1.0367e+00,
        -1.0364e+00, -1.1125e+00, -1.1041e+00, -1.0553e+00, -1.0140e+00,
        -1.0164e+00, -9.6759e-01, -1.0253e+00, -1.0770e+00, -1.6090e-01])
