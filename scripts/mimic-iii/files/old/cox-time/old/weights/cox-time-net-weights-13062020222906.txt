Weights: 
net.embeddings.embeddings.0.weight tensor([[ 0.0284,  0.0335],
        [ 0.1305,  0.1480],
        [ 0.2320, -0.2554],
        [-0.1385, -0.1817]])
net.embeddings.embeddings.1.weight tensor([[ 0.1999, -0.1060],
        [-0.0852, -0.0824],
        [ 0.0178, -0.1973],
        [ 0.3179, -0.0436],
        [ 0.1197,  0.1454]])
net.embeddings.embeddings.2.weight tensor([[ 0.1680, -0.0288,  0.0036],
        [ 0.1102,  0.1787, -0.0619],
        [-0.1359, -0.0386, -0.0989],
        [ 0.0239,  0.0896,  0.0873],
        [ 0.0230, -0.1162,  0.0356],
        [-0.2338,  0.0742,  0.1126]])
net.embeddings.embeddings.3.weight tensor([[ 0.0494, -0.1624],
        [-0.2835, -0.3723],
        [-0.1695, -0.1154],
        [ 0.1128,  0.0158]])
net.embeddings.embeddings.4.weight tensor([[-0.0045,  0.1887],
        [-0.2979,  0.0534],
        [ 0.2329, -0.2128],
        [-0.0239, -0.2506]])
net.mlp.net.0.linear.weight tensor([[ 0.1120,  0.1139,  0.0171,  ...,  0.0640, -0.0681,  0.0715],
        [ 0.0580, -0.0495, -0.2309,  ...,  0.1811, -0.2506,  0.0466],
        [ 0.0107,  0.2185,  0.0913,  ..., -0.0660,  0.1125, -0.1012],
        ...,
        [-0.3882,  0.0616,  0.0552,  ...,  0.0615,  0.0726,  0.0233],
        [ 0.0836, -0.1279,  0.0015,  ..., -0.1137,  0.1594, -0.1270],
        [ 0.0038, -0.0474, -0.2271,  ..., -0.1932,  0.1694,  0.0273]])
net.mlp.net.0.linear.bias tensor([ 0.0539, -0.1069,  0.0254, -0.0745, -0.0059,  0.0777, -0.1150, -0.0524,
         0.0397,  0.0075, -0.0785, -0.0014, -0.0279, -0.0604, -0.0349, -0.0347,
        -0.0280,  0.1007,  0.0277, -0.0712, -0.0721, -0.1205, -0.0512,  0.0878,
        -0.0786, -0.0874,  0.0425, -0.0399,  0.0416, -0.0916,  0.0517, -0.0208,
        -0.0518,  0.0263,  0.0141, -0.0688,  0.0149,  0.0776,  0.0073, -0.0222,
         0.0444, -0.0292, -0.0308, -0.0878,  0.0292,  0.0439,  0.0931, -0.0144,
        -0.0874, -0.0247, -0.0737,  0.1550, -0.0671, -0.0256, -0.0118,  0.0451,
         0.0152, -0.0902,  0.0430, -0.0445,  0.1333, -0.0593,  0.0563,  0.0758,
        -0.0857, -0.0012, -0.0093, -0.1350, -0.0218, -0.0362, -0.0027,  0.0447,
         0.0404, -0.1739, -0.0748,  0.0257, -0.0003,  0.0107, -0.0163,  0.0474,
         0.0405, -0.0424, -0.0299,  0.0258, -0.0205, -0.0391, -0.0726,  0.0697,
        -0.0823,  0.0515,  0.0910, -0.0367, -0.0179,  0.0452,  0.0218,  0.0374,
        -0.0139, -0.0051, -0.0273,  0.0977, -0.0373,  0.0588, -0.0278, -0.0617,
        -0.0977, -0.0186, -0.0252, -0.0300,  0.0357,  0.0009, -0.0753, -0.0559,
        -0.1248,  0.0092, -0.0224, -0.0178,  0.0268, -0.0332, -0.1064,  0.0161,
         0.1070,  0.0505,  0.0344,  0.0309, -0.0381,  0.0508, -0.1190, -0.0797,
        -0.0784, -0.0265,  0.0544, -0.0520, -0.0882, -0.0510,  0.0354, -0.1062,
         0.1274, -0.0100,  0.0126,  0.0161, -0.0729,  0.0337, -0.0792,  0.0148,
        -0.1322,  0.0513,  0.0145,  0.0946, -0.1586, -0.1097,  0.0840, -0.0206,
         0.0155,  0.1453,  0.0442,  0.0055, -0.0422,  0.0006, -0.0531, -0.0363,
         0.0554, -0.0268, -0.0382,  0.0072, -0.0503, -0.0959, -0.0339,  0.0068,
         0.0284, -0.0317,  0.0579,  0.0007,  0.0164, -0.0740,  0.0661, -0.1180,
        -0.0770, -0.1278, -0.0312,  0.0237,  0.0318, -0.0673, -0.0884,  0.0164,
        -0.0085, -0.0385, -0.0287,  0.1119,  0.0061, -0.0752, -0.0161,  0.0387,
        -0.0499, -0.0102,  0.1511, -0.0031, -0.0726,  0.0082, -0.0648, -0.1501,
         0.1217, -0.1001, -0.0484,  0.0347, -0.0818, -0.1079,  0.0705,  0.0567,
         0.0350, -0.0484, -0.0600,  0.0666,  0.0184, -0.0496,  0.0012,  0.0647,
         0.0117, -0.0632,  0.0254,  0.0556,  0.0047,  0.0319,  0.0335, -0.0587,
        -0.0669,  0.0435,  0.0261,  0.0235,  0.0128, -0.0058,  0.0091,  0.0752,
        -0.0999, -0.0251,  0.1260,  0.1066,  0.0139,  0.0005,  0.0624,  0.1134,
        -0.0857,  0.0571, -0.0159,  0.0101,  0.0643,  0.0793,  0.0126, -0.0687,
        -0.0146,  0.0559, -0.0213,  0.0611,  0.0364, -0.0234,  0.0722,  0.0322])
net.mlp.net.0.batch_norm.weight tensor([0.3721, 0.4423, 0.3064, 0.3264, 0.2993, 0.3864, 0.4189, 0.3973, 0.2724,
        0.3943, 0.4677, 0.3498, 0.4013, 0.3318, 0.3594, 0.3867, 0.3092, 0.2596,
        0.3331, 0.3592, 0.3368, 0.3878, 0.3883, 0.3407, 0.3537, 0.3847, 0.4146,
        0.3966, 0.3418, 0.3156, 0.3325, 0.3307, 0.4011, 0.2835, 0.4356, 0.3382,
        0.3579, 0.2870, 0.3271, 0.3023, 0.3561, 0.2402, 0.3104, 0.2678, 0.2894,
        0.3574, 0.3201, 0.3370, 0.3251, 0.3079, 0.3023, 0.3110, 0.3670, 0.3483,
        0.2637, 0.3231, 0.2881, 0.2882, 0.3442, 0.3582, 0.3847, 0.2885, 0.2542,
        0.3503, 0.3386, 0.2826, 0.3097, 0.4530, 0.2880, 0.3136, 0.2570, 0.3657,
        0.3933, 0.3373, 0.2644, 0.3205, 0.3518, 0.2837, 0.3028, 0.2836, 0.2584,
        0.3678, 0.3272, 0.3490, 0.2514, 0.3175, 0.3576, 0.3728, 0.3428, 0.3945,
        0.3218, 0.2694, 0.3663, 0.2811, 0.4362, 0.3554, 0.3346, 0.3759, 0.3335,
        0.3488, 0.3624, 0.3126, 0.3495, 0.3247, 0.2944, 0.3188, 0.3822, 0.3402,
        0.3378, 0.3813, 0.3181, 0.2975, 0.2806, 0.3210, 0.3408, 0.3290, 0.2493,
        0.2877, 0.3066, 0.3352, 0.3208, 0.2889, 0.3321, 0.3394, 0.3210, 0.3208,
        0.3718, 0.3318, 0.4056, 0.2908, 0.4145, 0.3725, 0.3081, 0.3932, 0.4299,
        0.4120, 0.2915, 0.3578, 0.3926, 0.2623, 0.2906, 0.3500, 0.4554, 0.3832,
        0.3952, 0.2882, 0.4194, 0.3640, 0.3524, 0.3236, 0.2818, 0.3340, 0.4188,
        0.2124, 0.3394, 0.3597, 0.3025, 0.3325, 0.3089, 0.3328, 0.2980, 0.2817,
        0.3055, 0.3785, 0.4412, 0.3388, 0.3377, 0.3375, 0.2553, 0.2952, 0.3457,
        0.2783, 0.3100, 0.2862, 0.3614, 0.3828, 0.3206, 0.3938, 0.3320, 0.2799,
        0.4251, 0.3079, 0.2801, 0.3023, 0.3398, 0.3276, 0.3553, 0.4033, 0.3332,
        0.3541, 0.3181, 0.3432, 0.2900, 0.3891, 0.3118, 0.4343, 0.3219, 0.2974,
        0.3787, 0.3227, 0.3289, 0.2703, 0.3741, 0.3771, 0.3474, 0.2733, 0.3609,
        0.2747, 0.3172, 0.3863, 0.3894, 0.3127, 0.4193, 0.3376, 0.3340, 0.2957,
        0.3233, 0.3551, 0.2752, 0.3041, 0.3023, 0.2501, 0.3524, 0.3430, 0.3016,
        0.4253, 0.3922, 0.3171, 0.2865, 0.2991, 0.2995, 0.3421, 0.3771, 0.2983,
        0.3917, 0.2388, 0.2064, 0.3142, 0.3749, 0.3668, 0.3241, 0.3242, 0.3006,
        0.3492, 0.3433, 0.2929, 0.3342, 0.3440, 0.2889, 0.3279, 0.3277, 0.3083,
        0.3529, 0.3025, 0.3663, 0.3489])
net.mlp.net.0.batch_norm.bias tensor([ 9.8288e-02, -1.3050e-02, -2.5972e-02,  1.2910e-01,  2.3919e-02,
        -4.3029e-02,  1.7712e-02,  4.8607e-02,  2.4790e-03, -3.7082e-02,
        -1.9013e-02, -2.7128e-02, -2.0337e-02, -5.1299e-02, -3.8361e-02,
        -1.0941e-02, -5.8820e-03, -9.6427e-02, -1.4290e-02,  2.4787e-02,
         4.4168e-02, -1.0269e-01,  4.7833e-02, -5.8724e-02,  9.1862e-02,
        -4.8632e-02, -3.8094e-02,  2.0313e-04, -1.2779e-02, -2.8238e-02,
        -3.4491e-02, -8.6201e-02, -3.8576e-02,  2.2130e-02,  4.8969e-02,
        -5.4115e-02,  5.5348e-02,  6.3948e-02, -6.0186e-02,  1.3166e-02,
         5.0814e-02, -4.4649e-02,  2.4767e-02,  4.6864e-03, -8.2017e-02,
         1.0203e-02,  2.8715e-02, -3.6840e-02,  1.7331e-02,  5.0847e-02,
         7.4306e-02, -1.2410e-02, -2.5903e-02, -2.1095e-02,  4.8401e-02,
        -2.7722e-02, -2.5608e-02, -4.6457e-03,  9.2121e-03,  1.2947e-02,
        -9.0566e-04,  5.7912e-02, -9.8866e-02, -5.0428e-02,  5.2933e-02,
         3.7774e-02, -2.2113e-02,  1.1740e-02,  8.9539e-03,  1.0554e-01,
         1.6354e-03,  2.5117e-02, -4.6015e-02, -4.5532e-02,  2.7298e-02,
        -3.2414e-02,  4.2122e-02, -5.5185e-02,  9.4745e-02,  4.4415e-03,
        -6.1015e-02,  3.4267e-03, -2.2101e-02,  6.2034e-03,  5.3194e-02,
        -3.5741e-02, -2.4759e-03,  2.3924e-03, -9.3512e-03, -6.4490e-02,
         8.2218e-02, -4.1697e-02, -9.6046e-03, -8.6940e-02,  6.3637e-02,
        -4.4564e-02,  3.5840e-03, -2.8403e-02,  1.8929e-02, -7.5473e-02,
         9.7335e-03,  2.8703e-03,  1.6990e-02, -1.0170e-02,  1.6390e-02,
        -1.2545e-02,  2.9703e-02,  6.7113e-03,  1.8289e-02,  1.0003e-02,
        -3.9723e-02,  2.2985e-02,  2.7389e-02, -4.4772e-02, -4.0051e-02,
         6.6084e-02,  1.9561e-02, -3.1412e-02, -2.3054e-02,  6.3324e-02,
        -1.3759e-02,  7.0202e-03, -4.1960e-02, -2.6234e-02,  6.7086e-02,
         7.0373e-03,  5.1409e-05, -3.4417e-02, -1.1518e-01, -1.7378e-02,
        -1.0413e-02,  4.9585e-03,  9.2722e-03,  4.3289e-02,  2.4899e-02,
         2.6546e-02,  4.4826e-03, -1.1731e-02, -1.9248e-02,  4.9254e-02,
        -7.8332e-04, -5.1929e-03, -1.0327e-02,  2.7218e-02, -3.2639e-02,
        -2.0966e-02, -1.5201e-01, -3.2186e-02,  3.5450e-02,  5.7951e-02,
        -1.5854e-02,  1.5044e-02, -3.9481e-02,  2.9907e-03, -2.2947e-02,
        -6.8243e-02, -2.5529e-02, -8.1176e-02, -6.8612e-02,  1.3717e-02,
        -3.7452e-02,  4.3255e-02,  5.6688e-02,  9.2271e-02,  4.8750e-02,
        -5.5892e-02, -1.1528e-02, -6.5933e-03, -5.8710e-03, -5.1414e-03,
        -1.5211e-02,  6.7261e-03, -4.4265e-02,  1.0819e-02, -8.2897e-03,
         3.4619e-02,  3.5798e-02,  1.2286e-02, -3.6698e-02, -3.9783e-02,
         3.1790e-02, -4.9771e-04,  1.0145e-01, -5.6757e-03,  1.7635e-03,
        -4.2131e-02, -5.0368e-03,  8.3793e-03,  1.0064e-01, -1.4233e-02,
         1.1007e-01, -1.5213e-02,  3.6432e-02, -7.4239e-02,  3.4424e-02,
         6.1536e-02, -1.7723e-02, -1.8060e-02,  7.4641e-03,  3.8193e-02,
        -2.9626e-02, -4.4668e-03, -2.4606e-02, -3.4847e-02, -9.1374e-04,
        -5.0222e-03, -1.2605e-02,  4.8071e-02,  9.8756e-03, -8.2244e-03,
        -1.1688e-02,  3.6843e-02,  4.2862e-02, -7.0002e-02, -2.5433e-02,
         1.4153e-02,  7.7994e-02,  6.5068e-02, -6.1239e-02,  6.6547e-02,
        -1.9759e-02, -5.6716e-03, -4.2744e-04, -5.6702e-02, -3.7671e-02,
         8.3624e-03,  6.0420e-02, -8.1212e-02,  2.4529e-02,  4.9273e-02,
         7.5467e-02,  3.9332e-02,  1.6849e-02,  3.4190e-03,  1.7439e-02,
         3.6874e-02, -8.6580e-02, -1.2596e-01, -3.4277e-02, -2.7772e-02,
        -5.8565e-02, -4.6526e-02,  4.2994e-02, -3.0008e-02, -5.8996e-03,
         3.1625e-02, -4.3535e-02,  5.1103e-02,  5.4546e-03,  5.3607e-02,
         3.5777e-02, -6.6965e-02,  5.8212e-02,  4.3847e-02,  1.2818e-01,
        -6.1336e-03])
net.mlp.net.0.batch_norm.running_mean tensor([5.1880e-02, 2.4510e-03, 1.9937e-01, 1.4408e-02, 4.1678e-03, 1.3060e-01,
        1.4583e-03, 2.5887e-01, 1.3091e-01, 1.4050e-01, 2.9239e-02, 2.4639e-01,
        7.5016e-02, 2.3357e-02, 2.7232e-01, 4.7011e-04, 1.6380e-02, 1.0431e-01,
        3.0048e-01, 5.5157e-02, 1.8985e-01, 7.5943e-02, 1.0059e-01, 6.2958e-01,
        1.8450e-01, 3.2229e-03, 2.2505e-02, 1.1722e-01, 2.8847e-01, 9.6898e-02,
        2.8705e-01, 1.6911e-01, 1.7012e-01, 2.5053e-02, 2.0737e-01, 7.6390e-03,
        4.3845e-02, 1.8319e-01, 9.9919e-02, 2.4653e-03, 1.0269e-01, 1.3703e-01,
        1.2234e-01, 1.8061e-04, 6.0090e-03, 5.3101e-02, 1.7664e-01, 2.4465e-02,
        5.2706e-06, 5.0142e-02, 7.1086e-02, 4.6193e-01, 2.0928e-02, 2.1036e-03,
        2.4854e-01, 7.2500e-02, 2.7055e-01, 6.4942e-04, 8.4926e-02, 5.5261e-04,
        3.8977e-01, 1.0791e-01, 3.3112e-01, 3.1466e-01, 2.7516e-05, 3.0095e-01,
        1.5155e-01, 2.9748e-03, 4.4285e-01, 2.4583e-03, 1.1533e-01, 4.6678e-01,
        2.9450e-02, 7.9643e-03, 8.9612e-02, 1.7233e-01, 6.4614e-02, 1.4354e-01,
        1.3150e-02, 1.9045e-01, 1.9799e-01, 2.7951e-02, 2.0582e-01, 1.4015e-02,
        1.3467e-01, 2.1188e-01, 9.9558e-02, 5.6456e-01, 3.8209e-02, 1.0251e-01,
        2.6917e-01, 4.9705e-02, 2.6792e-01, 1.9811e-01, 4.3510e-02, 7.6716e-02,
        4.1114e-01, 4.3756e-03, 4.7093e-02, 3.3120e-01, 2.9585e-02, 3.4731e-01,
        6.0057e-03, 7.1496e-02, 1.8067e-02, 3.8980e-03, 5.8709e-02, 1.7503e-01,
        3.0138e-01, 1.0358e-01, 1.1865e-02, 9.9156e-02, 4.8452e-02, 6.3845e-02,
        1.8732e-01, 1.3505e-01, 1.6297e-01, 3.9022e-02, 1.1346e-02, 6.6696e-02,
        1.1255e-01, 4.3948e-01, 1.4776e-01, 2.9090e-03, 6.9064e-03, 8.4812e-02,
        7.4458e-04, 4.3200e-03, 1.8748e-02, 2.8190e-01, 4.6007e-01, 5.1778e-02,
        7.3452e-02, 6.7155e-03, 5.7750e-03, 1.0678e-01, 2.6078e-01, 3.4262e-02,
        3.9117e-02, 2.5472e-01, 8.3209e-03, 2.6584e-03, 3.6693e-03, 4.8212e-03,
        5.1245e-03, 1.9065e-01, 1.3689e-02, 5.4511e-02, 1.1335e-03, 5.3998e-02,
        4.5047e-01, 4.6372e-02, 5.6814e-02, 4.1124e-01, 2.2517e-01, 9.9755e-02,
        1.1389e-02, 3.4627e-02, 1.0541e-02, 2.0639e-03, 2.3880e-01, 1.5017e-01,
        2.8171e-01, 2.1942e-01, 1.8414e-02, 2.9485e-01, 2.7682e-02, 2.3438e-01,
        5.8414e-02, 1.2217e-01, 7.9960e-02, 1.8206e-01, 1.0836e-01, 1.1166e-02,
        2.3412e-01, 1.9454e-01, 5.6377e-03, 5.0644e-04, 4.3868e-03, 3.4472e-02,
        1.7449e-01, 3.8160e-02, 6.0068e-03, 2.9142e-01, 3.1482e-01, 2.1684e-02,
        4.9126e-02, 8.3923e-02, 3.6824e-02, 5.5278e-03, 1.2470e-02, 4.0685e-01,
        2.3017e-04, 1.3041e-01, 3.1097e-01, 1.6550e-02, 7.2183e-02, 4.0100e-01,
        7.0111e-03, 3.2225e-06, 3.2296e-01, 3.1651e-03, 4.4214e-05, 2.2785e-03,
        8.4869e-02, 2.3120e-01, 1.1574e-01, 2.5746e-01, 9.5711e-02, 2.3165e-01,
        1.3732e-01, 2.9315e-01, 1.2646e-02, 2.4127e-04, 8.9163e-02, 2.1423e-01,
        6.4642e-03, 5.8427e-05, 7.3111e-02, 3.3660e-01, 8.8089e-02, 5.9715e-01,
        2.6150e-02, 2.0333e-03, 7.8300e-02, 1.0901e-03, 1.6891e-01, 1.1795e-01,
        1.6483e-01, 7.2612e-02, 1.4029e-02, 3.0934e-01, 3.3950e-04, 2.4279e-02,
        3.3766e-02, 3.3961e-01, 2.5939e-01, 9.0755e-02, 2.0028e-01, 4.1268e-01,
        1.3103e-03, 1.4403e-01, 4.2121e-02, 5.3679e-02, 5.6128e-02, 2.2660e-01,
        4.6319e-02, 8.2868e-03, 2.0505e-01, 9.0743e-02, 3.1294e-01, 5.5150e-02,
        3.9186e-02, 6.7867e-02, 5.7176e-01, 6.2456e-03])
net.mlp.net.0.batch_norm.running_var tensor([1.3845e-02, 4.2485e-04, 1.7528e-02, 4.2858e-03, 1.7377e-03, 1.0841e-02,
        1.6758e-04, 3.0338e-02, 1.8680e-02, 2.3040e-02, 3.3632e-03, 5.5373e-02,
        1.6367e-02, 8.0970e-03, 4.4699e-02, 4.3892e-05, 6.1358e-03, 1.3486e-02,
        5.3187e-02, 8.4652e-03, 2.5974e-02, 8.9724e-03, 2.7462e-02, 4.6246e-02,
        1.9799e-02, 3.3266e-04, 2.6481e-03, 1.4761e-02, 4.2477e-02, 5.1718e-03,
        2.0019e-02, 1.3564e-02, 2.7739e-02, 3.5060e-03, 5.5818e-02, 1.5074e-03,
        1.4287e-02, 2.7284e-02, 1.2309e-02, 3.1098e-04, 1.3302e-02, 1.4883e-02,
        8.0615e-02, 5.6159e-05, 1.0215e-03, 7.2897e-03, 4.7424e-02, 1.8742e-03,
        9.4249e-06, 1.1701e-02, 1.2397e-02, 5.1954e-02, 5.9909e-03, 2.0396e-04,
        1.0151e-01, 1.1335e-02, 1.5031e-02, 7.4239e-05, 8.9751e-03, 5.6932e-05,
        1.5898e-02, 1.1426e-02, 1.3606e-02, 4.4377e-02, 1.1088e-05, 8.5315e-02,
        1.4503e-02, 3.8254e-04, 3.0933e-02, 2.8224e-04, 5.6344e-02, 3.4414e-02,
        5.0514e-03, 9.1172e-04, 1.8381e-02, 4.4442e-02, 3.0318e-02, 1.2124e-02,
        3.8472e-03, 3.0237e-02, 2.3244e-02, 3.6400e-03, 2.8439e-02, 3.8607e-03,
        2.8003e-02, 3.8970e-02, 9.4334e-03, 3.9503e-02, 2.9233e-02, 1.4961e-02,
        2.4168e-02, 6.3840e-03, 3.7668e-02, 2.2176e-02, 2.0075e-02, 7.6461e-03,
        7.8385e-02, 4.7938e-04, 3.7515e-03, 2.1611e-02, 7.2624e-03, 3.4209e-02,
        2.8572e-03, 2.9508e-02, 1.3274e-02, 9.4463e-04, 2.2698e-02, 7.0295e-02,
        6.1630e-02, 8.2322e-03, 3.4454e-03, 1.2687e-02, 6.6175e-03, 4.0728e-02,
        1.8213e-02, 1.6708e-02, 1.9871e-02, 1.8746e-02, 1.4599e-03, 4.4252e-02,
        6.0353e-02, 3.0633e-02, 1.3678e-02, 4.3614e-04, 1.2046e-03, 6.0425e-03,
        1.0763e-04, 1.5832e-03, 2.0386e-03, 2.3106e-02, 2.6970e-02, 2.6506e-02,
        4.0965e-02, 2.1542e-03, 7.9659e-04, 2.7849e-02, 2.8831e-02, 5.8367e-03,
        6.4010e-03, 3.3166e-02, 9.6813e-04, 5.2234e-04, 3.6964e-04, 7.0708e-04,
        7.5063e-04, 2.3023e-02, 1.6737e-03, 6.9488e-03, 1.4807e-04, 1.0458e-02,
        6.6287e-02, 3.0810e-02, 8.2603e-03, 2.9317e-02, 1.9978e-02, 1.4069e-02,
        1.4910e-03, 3.8530e-03, 3.3372e-03, 2.5600e-04, 2.0214e-02, 1.6930e-02,
        2.9503e-02, 1.0936e-02, 2.8501e-03, 3.5154e-02, 4.7910e-03, 1.4016e-02,
        8.5119e-03, 1.8204e-02, 8.5158e-03, 2.0980e-02, 1.2875e-02, 1.7724e-03,
        2.6302e-02, 4.8016e-02, 8.2524e-04, 5.4512e-05, 5.1972e-04, 2.5749e-02,
        1.0750e-02, 3.9569e-02, 1.8456e-03, 1.1264e-02, 1.9614e-02, 4.2325e-03,
        4.3983e-03, 7.2435e-03, 1.8072e-02, 5.8385e-04, 4.5883e-03, 6.2355e-02,
        3.1837e-05, 1.9401e-02, 1.2591e-02, 1.4199e-03, 8.0088e-03, 3.6523e-02,
        1.0577e-03, 9.6144e-06, 1.6169e-02, 3.3452e-04, 1.2393e-05, 3.3835e-04,
        8.0098e-03, 2.3468e-02, 1.7423e-02, 1.9419e-02, 1.6544e-02, 2.5233e-02,
        1.4801e-02, 3.7992e-02, 1.1540e-03, 3.4868e-05, 1.5020e-02, 1.8363e-02,
        2.0017e-03, 1.4864e-05, 9.1277e-03, 1.7433e-02, 2.6085e-02, 3.1060e-02,
        3.9343e-03, 3.3833e-04, 9.8735e-03, 1.1261e-04, 1.2324e-02, 1.1523e-02,
        1.7616e-02, 7.0983e-02, 7.8949e-03, 2.3345e-02, 4.8867e-05, 1.2343e-02,
        5.3038e-03, 2.7444e-02, 3.2887e-02, 1.9791e-02, 5.7471e-02, 3.9540e-02,
        1.4687e-04, 2.0917e-02, 3.7963e-02, 1.9899e-02, 5.9859e-03, 1.8766e-02,
        6.6453e-03, 1.5659e-03, 1.5385e-02, 4.4817e-03, 2.8327e-02, 9.1171e-03,
        2.3734e-02, 3.0749e-02, 2.6628e-02, 9.1053e-04])
net.mlp.net.0.batch_norm.num_batches_tracked tensor(110)
net.mlp.net.1.linear.weight tensor([[-0.0545, -0.0212,  0.0179,  ..., -0.0155, -0.0520, -0.0507],
        [ 0.1292, -0.0206,  0.1452,  ..., -0.0309, -0.0379,  0.0142],
        [-0.0177, -0.0254, -0.0334,  ...,  0.0277, -0.1062,  0.0738],
        ...,
        [-0.0108,  0.0169,  0.0118,  ...,  0.0405,  0.0216, -0.0438],
        [ 0.0397, -0.0488,  0.0257,  ..., -0.0312, -0.0399, -0.0046],
        [ 0.0335,  0.0101,  0.0593,  ...,  0.0296,  0.0369,  0.0029]])
net.mlp.net.1.linear.bias tensor([-0.0130,  0.0089,  0.0029,  0.0088, -0.0524,  0.0457, -0.1213,  0.0266,
        -0.1079, -0.0272, -0.1356,  0.0280, -0.0007, -0.0540, -0.1220,  0.0160,
         0.0333, -0.0425, -0.0224, -0.0199,  0.0305, -0.0169, -0.1110, -0.0031,
         0.0074,  0.0441, -0.0038, -0.0046, -0.1165,  0.0055,  0.0399, -0.0512,
        -0.0144, -0.0205, -0.0867, -0.0457, -0.0169, -0.0722,  0.0374,  0.0508,
         0.0657, -0.0660,  0.0003, -0.0009, -0.0143,  0.0168, -0.0178,  0.0650,
        -0.0938,  0.0459,  0.0500,  0.0941,  0.0135,  0.0080, -0.0121,  0.0482,
         0.0175,  0.0019, -0.0568,  0.0206,  0.0654, -0.0043, -0.0142, -0.1055,
        -0.1006, -0.0372, -0.0187, -0.0237,  0.0312, -0.0418, -0.0381, -0.0340,
        -0.0399,  0.0166,  0.0728, -0.1531, -0.0469,  0.0223, -0.0294, -0.0213,
         0.0177, -0.0529, -0.0298, -0.0205,  0.0370, -0.0121,  0.0569,  0.0489,
        -0.0370, -0.0272,  0.0239,  0.0404, -0.0611, -0.0152, -0.0490,  0.0076,
        -0.0643, -0.0756,  0.1425,  0.0025,  0.0006, -0.0249, -0.0544, -0.0549,
        -0.0928, -0.0298, -0.1240,  0.0479, -0.0139,  0.0654, -0.0300,  0.0304,
         0.0286, -0.0644,  0.0052, -0.0271, -0.0536, -0.0957, -0.0380, -0.0943,
        -0.0588, -0.0566, -0.0913, -0.0594, -0.0608, -0.0388, -0.0177, -0.0467,
        -0.0660,  0.0207, -0.1315, -0.0828,  0.0035,  0.0444, -0.0097, -0.0494,
        -0.0508,  0.0129,  0.0335,  0.0113,  0.0322,  0.0592, -0.0291,  0.0047,
        -0.0238,  0.0552,  0.0255, -0.0306,  0.0405, -0.0612, -0.0134,  0.0129,
         0.0596,  0.0518, -0.0508, -0.0065,  0.0323,  0.0092, -0.0154, -0.0169,
        -0.0744,  0.0076, -0.0884,  0.0365, -0.0466, -0.0916, -0.0597, -0.0621,
        -0.0400,  0.0556, -0.0343, -0.0334,  0.0014,  0.0224, -0.0122, -0.0114,
        -0.0552,  0.0467,  0.0038, -0.1150, -0.0389, -0.0031,  0.0084, -0.0383,
        -0.0305,  0.0337, -0.0351, -0.0539, -0.0415,  0.0350,  0.0634, -0.0631,
        -0.0115, -0.0332,  0.0291,  0.0067, -0.0257, -0.0421, -0.0484, -0.0242,
        -0.0479,  0.0126,  0.0455, -0.0563, -0.0372,  0.0500, -0.0506,  0.0180,
         0.0142,  0.0255,  0.0306, -0.0948, -0.0513, -0.0430,  0.0250, -0.0667,
        -0.0126,  0.0255,  0.0718, -0.0785, -0.0017, -0.0255, -0.0472,  0.0695,
         0.0059, -0.0584, -0.0535,  0.0498,  0.0056,  0.0694, -0.1179,  0.1227,
        -0.0900, -0.0659, -0.0192,  0.0863,  0.0834, -0.0095, -0.0016, -0.0117,
        -0.1031,  0.0451, -0.0319, -0.0745,  0.0088, -0.0455, -0.0897,  0.0015,
        -0.0781, -0.0228,  0.0408, -0.0309,  0.0467, -0.0324,  0.0131,  0.0620])
net.mlp.net.1.batch_norm.weight tensor([0.3314, 0.3825, 0.3474, 0.3405, 0.3313, 0.4298, 0.3170, 0.3607, 0.3214,
        0.3488, 0.3236, 0.3900, 0.2667, 0.3283, 0.3153, 0.2893, 0.3101, 0.3169,
        0.4196, 0.3033, 0.3110, 0.3321, 0.4112, 0.2887, 0.3945, 0.2994, 0.3140,
        0.2820, 0.3761, 0.3315, 0.2867, 0.3654, 0.2661, 0.3644, 0.4306, 0.2809,
        0.3805, 0.2777, 0.3617, 0.2970, 0.3407, 0.3277, 0.3621, 0.3519, 0.3680,
        0.2925, 0.2475, 0.4234, 0.3396, 0.3517, 0.3860, 0.3346, 0.2849, 0.3200,
        0.2634, 0.3286, 0.3397, 0.3626, 0.3384, 0.3428, 0.3494, 0.3218, 0.3035,
        0.3308, 0.3175, 0.2942, 0.3173, 0.2827, 0.3187, 0.3648, 0.3267, 0.3611,
        0.3594, 0.3710, 0.3586, 0.2807, 0.3751, 0.3332, 0.3522, 0.3433, 0.3464,
        0.3735, 0.3956, 0.3389, 0.3217, 0.2954, 0.4385, 0.3905, 0.3491, 0.3521,
        0.3273, 0.3572, 0.3501, 0.2702, 0.3303, 0.3925, 0.3659, 0.3363, 0.2837,
        0.2864, 0.3236, 0.2999, 0.2896, 0.3980, 0.3242, 0.3701, 0.3209, 0.4131,
        0.3235, 0.3051, 0.3357, 0.3060, 0.2634, 0.3705, 0.3141, 0.2921, 0.3177,
        0.3261, 0.2820, 0.2834, 0.2992, 0.3234, 0.3290, 0.3316, 0.3621, 0.2567,
        0.3079, 0.3323, 0.3713, 0.2698, 0.3742, 0.3121, 0.3605, 0.3161, 0.3963,
        0.3820, 0.3667, 0.3147, 0.3331, 0.2886, 0.3055, 0.4253, 0.3342, 0.3791,
        0.3189, 0.4053, 0.3706, 0.3118, 0.3303, 0.3628, 0.4106, 0.3628, 0.3531,
        0.3889, 0.2874, 0.3005, 0.3275, 0.2865, 0.3054, 0.3472, 0.3404, 0.2155,
        0.3258, 0.3344, 0.3014, 0.3768, 0.4062, 0.3375, 0.3250, 0.3356, 0.3027,
        0.4009, 0.3521, 0.3342, 0.3291, 0.3496, 0.2582, 0.3048, 0.3943, 0.3373,
        0.4279, 0.3728, 0.3206, 0.3934, 0.3350, 0.3367, 0.2802, 0.3433, 0.2784,
        0.2796, 0.3733, 0.3474, 0.3282, 0.3421, 0.3136, 0.3567, 0.3316, 0.3330,
        0.3372, 0.3138, 0.2988, 0.3156, 0.2961, 0.3191, 0.3075, 0.2781, 0.3814,
        0.3208, 0.3065, 0.2548, 0.3896, 0.3794, 0.3067, 0.3687, 0.4036, 0.4542,
        0.2879, 0.3199, 0.3547, 0.2960, 0.3400, 0.2992, 0.3978, 0.3517, 0.3056,
        0.3327, 0.3293, 0.3134, 0.2929, 0.2832, 0.3496, 0.3349, 0.3583, 0.3710,
        0.3033, 0.3122, 0.3193, 0.3124, 0.3502, 0.4232, 0.3991, 0.3154, 0.3950,
        0.3207, 0.3912, 0.3848, 0.3340, 0.3570, 0.3628, 0.2948, 0.3932, 0.3445,
        0.3320, 0.2938, 0.3867, 0.3631])
net.mlp.net.1.batch_norm.bias tensor([ 0.0174,  0.0304, -0.0622, -0.0601, -0.0674,  0.0310,  0.0812,  0.0577,
         0.0118, -0.0172,  0.0294, -0.0189,  0.0476, -0.0160,  0.0156,  0.0568,
         0.0416,  0.0313,  0.0960, -0.0002,  0.0100,  0.0160,  0.0193, -0.0150,
        -0.0154,  0.0315, -0.0337,  0.1040, -0.0402, -0.0637,  0.0570, -0.0009,
         0.0094, -0.0280,  0.0081,  0.0589,  0.0223,  0.0266,  0.0143,  0.0261,
        -0.0129,  0.0466, -0.0287,  0.0283,  0.0297, -0.0053,  0.0671,  0.0050,
        -0.0284, -0.0170,  0.0394,  0.0932,  0.0437, -0.0714, -0.0167,  0.0260,
        -0.0175,  0.0084,  0.0491,  0.0226,  0.1158,  0.0216,  0.0390, -0.0135,
        -0.0124, -0.0683,  0.0611,  0.0375, -0.0769,  0.0334, -0.0104, -0.0013,
        -0.0226,  0.0255, -0.0293,  0.0515, -0.0535,  0.0634,  0.0083, -0.0032,
         0.0666, -0.1341,  0.0417,  0.0724, -0.0267, -0.0555,  0.0320, -0.0487,
         0.0177, -0.0283,  0.0577,  0.0399, -0.0885,  0.0849, -0.0338, -0.0301,
        -0.0800,  0.0916, -0.0116, -0.0053,  0.0319, -0.0251, -0.0745,  0.0786,
        -0.0817,  0.0231,  0.0538, -0.0016,  0.0104, -0.0217, -0.0137, -0.0038,
         0.0032,  0.0003, -0.0065, -0.0698,  0.0134,  0.0080, -0.0174, -0.0148,
         0.0421, -0.0077, -0.0110, -0.0128,  0.1168, -0.0033,  0.0402,  0.0123,
        -0.0129, -0.0938,  0.0115,  0.0047, -0.0125, -0.0012, -0.0420, -0.0534,
         0.0507, -0.0867, -0.0233, -0.0093, -0.0251, -0.0397, -0.0255, -0.0100,
         0.0297,  0.0284, -0.0551, -0.0327, -0.0595, -0.0183,  0.0503, -0.0335,
        -0.0582, -0.0121,  0.0144, -0.0137,  0.0235,  0.0859,  0.0366,  0.0245,
        -0.0640, -0.0102, -0.0384,  0.0260,  0.0506, -0.1058, -0.0024,  0.0289,
        -0.0017,  0.0194, -0.0573, -0.1051,  0.0249,  0.0278,  0.0399,  0.0279,
         0.0178,  0.0314,  0.0067, -0.0050, -0.0201, -0.0033,  0.0084,  0.0070,
         0.0110,  0.0226,  0.0460, -0.0524, -0.0043,  0.0027,  0.0023,  0.0042,
        -0.0862, -0.0269, -0.0820, -0.0499, -0.0147, -0.0035, -0.0431,  0.0386,
         0.0375,  0.0152,  0.0730,  0.0168, -0.0806, -0.0099,  0.0422,  0.0145,
         0.0212, -0.0307, -0.0391, -0.0076,  0.0879,  0.0122,  0.0520, -0.0142,
         0.0208, -0.0314, -0.0440,  0.0477,  0.0335,  0.0329, -0.0298, -0.0161,
        -0.0032, -0.0350,  0.0212, -0.0689,  0.0093, -0.0559,  0.0705,  0.0577,
         0.0353,  0.0158, -0.0221,  0.0295,  0.0033,  0.0292,  0.0266, -0.0759,
         0.0194, -0.0242, -0.0867, -0.0223, -0.0248, -0.0399, -0.0395,  0.0550,
         0.0521,  0.0602,  0.0445, -0.0506, -0.0211, -0.0186,  0.0164, -0.0113])
net.mlp.net.1.batch_norm.running_mean tensor([0.1900, 0.1889, 0.2743, 0.2450, 0.1161, 0.2561, 0.1255, 0.2233, 0.1667,
        0.2092, 0.1087, 0.3343, 0.1905, 0.1870, 0.1654, 0.1861, 0.2240, 0.2080,
        0.1989, 0.1526, 0.1958, 0.2240, 0.1531, 0.1781, 0.2293, 0.2454, 0.1843,
        0.2221, 0.1139, 0.2261, 0.2187, 0.1354, 0.2263, 0.2604, 0.1777, 0.1255,
        0.2095, 0.1396, 0.2308, 0.3309, 0.3883, 0.1518, 0.2691, 0.1902, 0.2104,
        0.2033, 0.2404, 0.3234, 0.1243, 0.2644, 0.2143, 0.3241, 0.1947, 0.3011,
        0.1466, 0.2629, 0.2425, 0.2909, 0.1542, 0.2299, 0.2535, 0.2208, 0.2292,
        0.1459, 0.1820, 0.1794, 0.1429, 0.1680, 0.2714, 0.1627, 0.1724, 0.1843,
        0.1677, 0.2238, 0.2329, 0.1230, 0.2357, 0.2848, 0.1187, 0.2150, 0.2215,
        0.2251, 0.2137, 0.1987, 0.2984, 0.2222, 0.3005, 0.1752, 0.1664, 0.2443,
        0.2638, 0.3251, 0.2350, 0.2230, 0.1819, 0.2190, 0.2010, 0.1692, 0.3278,
        0.1805, 0.2567, 0.1507, 0.1099, 0.1515, 0.1516, 0.2147, 0.0942, 0.3728,
        0.1789, 0.2376, 0.2046, 0.2153, 0.2457, 0.1807, 0.2159, 0.1908, 0.1794,
        0.1451, 0.1545, 0.1448, 0.2727, 0.2728, 0.1293, 0.1347, 0.2150, 0.1663,
        0.2608, 0.1377, 0.2358, 0.2660, 0.1399, 0.1711, 0.2855, 0.2056, 0.1956,
        0.2195, 0.2089, 0.1864, 0.2821, 0.1716, 0.2567, 0.2585, 0.2144, 0.2794,
        0.2495, 0.3057, 0.2219, 0.1908, 0.2515, 0.2153, 0.2343, 0.1895, 0.3976,
        0.2112, 0.2482, 0.2259, 0.2013, 0.2806, 0.1649, 0.1815, 0.2045, 0.2201,
        0.1297, 0.1943, 0.1489, 0.1456, 0.3054, 0.2308, 0.2604, 0.2162, 0.1594,
        0.2179, 0.2436, 0.1860, 0.2807, 0.1918, 0.1745, 0.2496, 0.1865, 0.1092,
        0.2522, 0.2033, 0.1541, 0.1355, 0.2060, 0.1780, 0.1526, 0.1048, 0.2036,
        0.1927, 0.3627, 0.1522, 0.1965, 0.2734, 0.1524, 0.2916, 0.1995, 0.2348,
        0.1939, 0.1690, 0.1734, 0.2133, 0.1830, 0.1811, 0.2715, 0.2263, 0.2396,
        0.2399, 0.2209, 0.2286, 0.2754, 0.1208, 0.1045, 0.1809, 0.2211, 0.2113,
        0.2719, 0.2313, 0.2641, 0.1441, 0.1982, 0.1221, 0.2408, 0.3566, 0.2302,
        0.1956, 0.1810, 0.2310, 0.2160, 0.2114, 0.1520, 0.3743, 0.1869, 0.1964,
        0.2018, 0.2794, 0.2541, 0.1826, 0.2237, 0.3117, 0.1841, 0.1992, 0.2042,
        0.1557, 0.2066, 0.2442, 0.2077, 0.2008, 0.1095, 0.2329, 0.1834, 0.1626,
        0.2791, 0.2840, 0.2977, 0.2366])
net.mlp.net.1.batch_norm.running_var tensor([0.1554, 0.1209, 0.1763, 0.2322, 0.0705, 0.1607, 0.0802, 0.0996, 0.2080,
        0.3358, 0.0578, 0.1853, 0.0671, 0.0831, 0.0886, 0.1840, 0.0987, 0.1100,
        0.1151, 0.0518, 0.0902, 0.1464, 0.2044, 0.0718, 0.1520, 0.1831, 0.0855,
        0.2526, 0.0788, 0.1857, 0.0661, 0.2141, 0.2359, 0.1110, 0.0944, 0.1334,
        0.2247, 0.0734, 0.0842, 0.2475, 0.9084, 0.0687, 0.1233, 0.1506, 0.1296,
        0.1903, 0.4034, 0.1458, 0.0935, 0.1776, 0.1405, 0.1503, 0.0955, 0.3383,
        0.0832, 0.1567, 0.1341, 0.2937, 0.0693, 0.0853, 0.0990, 0.1826, 0.0749,
        0.1917, 0.0798, 0.0743, 0.0510, 0.0541, 0.1314, 0.0731, 0.2918, 0.1157,
        0.1157, 0.2118, 0.1242, 0.0837, 0.1607, 0.1060, 0.1217, 0.1172, 0.1253,
        0.2791, 0.1374, 0.0769, 0.1688, 0.2227, 0.2095, 0.0838, 0.1045, 0.3693,
        0.1065, 0.4982, 0.3211, 0.0961, 0.1167, 0.1110, 0.1101, 0.1186, 0.1867,
        0.1307, 0.3948, 0.0556, 0.0496, 0.1000, 0.1022, 0.2147, 0.0495, 0.2171,
        0.1235, 0.1483, 0.1318, 0.1007, 0.0998, 0.1126, 0.1237, 0.1018, 0.1245,
        0.0720, 0.0642, 0.0875, 0.6262, 0.1740, 0.0515, 0.0726, 0.1315, 0.0787,
        0.1219, 0.2373, 0.1377, 0.4916, 0.0849, 0.0703, 0.1253, 0.0732, 0.1028,
        0.1380, 0.0925, 0.0975, 0.3117, 0.0708, 0.3715, 0.1852, 0.0807, 0.2154,
        0.2846, 0.2295, 0.1329, 0.1912, 0.0934, 0.1024, 0.1320, 0.0739, 0.2246,
        0.1384, 0.1299, 0.4353, 0.1928, 0.3449, 0.0676, 0.1254, 0.1040, 0.1680,
        0.0692, 0.0848, 0.0712, 0.1048, 0.1853, 0.4048, 0.2786, 0.1164, 0.0718,
        0.1647, 0.3286, 0.1362, 0.3613, 0.0959, 0.2420, 0.2709, 0.1255, 0.0441,
        0.3851, 0.0922, 0.0733, 0.0794, 0.1824, 0.1211, 0.2187, 0.0406, 0.1075,
        0.0746, 0.2023, 0.0699, 0.0661, 0.3561, 0.0651, 0.4037, 0.0834, 0.1353,
        0.1245, 0.1040, 0.1268, 0.2148, 0.0953, 0.2382, 0.1504, 0.1403, 0.1752,
        0.1081, 0.0842, 0.1449, 0.1302, 0.0698, 0.0664, 0.1053, 0.1415, 0.1817,
        0.2112, 0.1720, 0.1347, 0.0850, 0.1471, 0.2759, 0.2960, 0.5843, 0.0845,
        0.1387, 0.0757, 0.2638, 0.2617, 0.0857, 0.1173, 0.1475, 0.0917, 0.1199,
        0.1769, 0.1072, 0.1652, 0.1081, 0.1120, 0.3983, 0.0845, 0.0859, 0.1797,
        0.0590, 0.1657, 0.2020, 0.0893, 0.1182, 0.0680, 0.2066, 0.0855, 0.0674,
        0.1181, 0.3041, 0.2288, 0.0906])
net.mlp.net.1.batch_norm.num_batches_tracked tensor(110)
net.mlp.net.2.linear.weight tensor([[ 0.0597,  0.0056,  0.1024,  ..., -0.0062,  0.0030, -0.0227],
        [ 0.0092,  0.0711, -0.0285,  ..., -0.0499, -0.0111, -0.0487],
        [ 0.0275, -0.0004, -0.0276,  ..., -0.0256,  0.0018,  0.0053],
        ...,
        [ 0.0339, -0.0059, -0.0363,  ..., -0.0322,  0.0457, -0.0174],
        [ 0.0467, -0.0177,  0.0900,  ..., -0.0190, -0.0523, -0.0510],
        [-0.0076, -0.0267, -0.0335,  ..., -0.0172, -0.0433, -0.0038]])
net.mlp.net.2.linear.bias tensor([-0.0630, -0.0745, -0.0385,  0.0606, -0.0304,  0.0246, -0.0444,  0.0280,
         0.0492, -0.0464, -0.0555,  0.1005, -0.0500,  0.0269,  0.0003, -0.0152,
        -0.0875,  0.1075,  0.0187,  0.0382,  0.0546, -0.1226, -0.1260, -0.0358,
         0.0871,  0.0103,  0.0043, -0.0395, -0.0844,  0.0107, -0.0145, -0.0154,
        -0.0560,  0.0115, -0.0213,  0.0188, -0.0039,  0.0508,  0.0234, -0.0278,
         0.0193, -0.0871,  0.0449, -0.0563,  0.1109, -0.0081,  0.0175, -0.0318,
        -0.0940,  0.0678, -0.0566,  0.0083, -0.0655, -0.0724, -0.0581, -0.0281,
        -0.0644,  0.0062,  0.0404, -0.0193, -0.0672,  0.0211,  0.0068, -0.0197,
        -0.0143,  0.0143, -0.0035, -0.0887, -0.0300, -0.0158, -0.0273, -0.0777,
        -0.0105,  0.0437,  0.0175,  0.0137,  0.0035, -0.0242, -0.0688, -0.0364,
        -0.0348, -0.0228, -0.0970,  0.0549,  0.0352, -0.0139, -0.0720, -0.0268,
        -0.0335, -0.0492,  0.0136,  0.0315,  0.0569, -0.0189, -0.0512,  0.1005,
        -0.0233, -0.0644,  0.0160,  0.0485,  0.0006,  0.0731,  0.0449, -0.0644,
        -0.0808, -0.0481, -0.0341,  0.0814, -0.0052, -0.0344,  0.0180,  0.0172,
        -0.0324,  0.0488, -0.0661, -0.0113, -0.0661,  0.0244, -0.0958, -0.0038,
         0.0324,  0.0459,  0.0381,  0.0010, -0.0458, -0.0655, -0.0151, -0.0030,
         0.0228,  0.0495, -0.0372, -0.0291,  0.0096, -0.0384, -0.0954, -0.0875,
         0.0383, -0.0097,  0.0277, -0.0758, -0.0120, -0.0564, -0.0044, -0.0209,
        -0.0552, -0.0784, -0.0095, -0.0578,  0.0163,  0.0025, -0.0230,  0.0255,
        -0.0229,  0.0221, -0.0189, -0.0476, -0.0594,  0.0076, -0.0118, -0.0843,
         0.0419,  0.0028,  0.0429, -0.0357, -0.1342, -0.0486, -0.0708, -0.0488,
        -0.0320,  0.0438, -0.0384,  0.0774, -0.0378,  0.0273, -0.0288,  0.0017,
        -0.0469, -0.1125, -0.0238, -0.0326,  0.0326, -0.0120, -0.0050,  0.0034,
        -0.0559, -0.1018, -0.0120,  0.0228, -0.0190, -0.0058, -0.0611,  0.0249,
         0.0171,  0.0029, -0.0309,  0.0160,  0.0114, -0.0164,  0.0037, -0.0710,
        -0.0304,  0.0030,  0.0728, -0.0201, -0.0114,  0.0146, -0.0288,  0.0488,
         0.0351,  0.0320, -0.0209, -0.0453, -0.0238,  0.0410, -0.0110, -0.0195,
        -0.0005,  0.0837, -0.0534,  0.0788, -0.0441, -0.0238,  0.0510, -0.0044,
         0.1075, -0.0396, -0.0411,  0.0034, -0.0395,  0.0261, -0.0181, -0.0376,
        -0.0543,  0.0570,  0.0238,  0.0186, -0.0476,  0.0485,  0.0109, -0.0968,
         0.0328, -0.0080,  0.0120,  0.0071, -0.0347, -0.0832,  0.0466, -0.0497,
        -0.0626, -0.0420, -0.0245, -0.0711, -0.0425, -0.0133, -0.0858, -0.0295])
net.mlp.net.2.batch_norm.weight tensor([0.3127, 0.3731, 0.3158, 0.4243, 0.3339, 0.3204, 0.3402, 0.3174, 0.3600,
        0.2969, 0.3664, 0.3008, 0.3548, 0.2795, 0.3428, 0.3923, 0.3139, 0.3437,
        0.2659, 0.3478, 0.3230, 0.3537, 0.3196, 0.3656, 0.2917, 0.3464, 0.3765,
        0.2968, 0.2877, 0.2914, 0.3023, 0.3345, 0.3290, 0.3631, 0.3424, 0.3238,
        0.3406, 0.3304, 0.3143, 0.3542, 0.3707, 0.3442, 0.3212, 0.3201, 0.3449,
        0.4384, 0.3285, 0.3420, 0.3102, 0.3960, 0.3153, 0.3582, 0.3505, 0.3096,
        0.3378, 0.3524, 0.3523, 0.3314, 0.3690, 0.3480, 0.3623, 0.3021, 0.3559,
        0.3080, 0.3320, 0.3257, 0.3954, 0.3983, 0.4014, 0.3541, 0.3219, 0.3115,
        0.3567, 0.2708, 0.3377, 0.3836, 0.3912, 0.4285, 0.3820, 0.3341, 0.3338,
        0.3431, 0.4395, 0.3125, 0.3572, 0.3761, 0.3632, 0.2760, 0.3100, 0.2971,
        0.3097, 0.2898, 0.2700, 0.2913, 0.3681, 0.3487, 0.3090, 0.2994, 0.3252,
        0.3988, 0.2718, 0.3711, 0.3579, 0.3686, 0.3115, 0.3096, 0.2766, 0.3312,
        0.3010, 0.3132, 0.3546, 0.3661, 0.3773, 0.2673, 0.3166, 0.3609, 0.3868,
        0.3248, 0.3380, 0.4311, 0.3153, 0.3388, 0.3053, 0.2625, 0.3988, 0.3163,
        0.3539, 0.3034, 0.3247, 0.3843, 0.3061, 0.3565, 0.3587, 0.3051, 0.3691,
        0.2979, 0.3663, 0.3874, 0.3928, 0.3294, 0.3443, 0.2840, 0.2937, 0.3345,
        0.3591, 0.3018, 0.3747, 0.3494, 0.3145, 0.2912, 0.4316, 0.3284, 0.3108,
        0.3423, 0.3382, 0.3999, 0.3569, 0.3583, 0.3523, 0.3451, 0.3457, 0.3624,
        0.3212, 0.3500, 0.3963, 0.3381, 0.3375, 0.3124, 0.3450, 0.2985, 0.2888,
        0.3483, 0.3041, 0.3689, 0.3105, 0.3303, 0.3052, 0.3515, 0.3093, 0.3451,
        0.3236, 0.3588, 0.3988, 0.3075, 0.4319, 0.3204, 0.3133, 0.3357, 0.3101,
        0.2765, 0.3484, 0.3772, 0.3149, 0.3619, 0.3471, 0.3060, 0.2882, 0.4009,
        0.3209, 0.3871, 0.3563, 0.4014, 0.3096, 0.3464, 0.3058, 0.3070, 0.3351,
        0.3466, 0.3562, 0.3540, 0.3080, 0.2919, 0.3884, 0.3512, 0.4003, 0.2877,
        0.3586, 0.3408, 0.2867, 0.3648, 0.3244, 0.3669, 0.4104, 0.3253, 0.3610,
        0.3238, 0.3565, 0.3620, 0.3551, 0.4296, 0.3639, 0.2944, 0.3726, 0.2533,
        0.3084, 0.3350, 0.3279, 0.2897, 0.3180, 0.3419, 0.3795, 0.2826, 0.3228,
        0.2985, 0.3820, 0.3374, 0.2558, 0.3500, 0.3185, 0.3339, 0.3471, 0.3511,
        0.3161, 0.4107, 0.3319, 0.2948])
net.mlp.net.2.batch_norm.bias tensor([ 2.6302e-03,  1.1790e-02,  6.9678e-02, -1.0096e-01, -4.1382e-02,
         1.7613e-03, -2.0058e-02, -2.3517e-02,  1.4342e-02, -2.3722e-02,
        -4.9932e-02, -1.3461e-02,  8.4427e-02, -2.1337e-02,  4.7544e-02,
        -5.4981e-02, -1.2639e-02,  8.6003e-02, -6.1419e-02,  4.7328e-02,
         1.7903e-02, -4.1642e-02, -1.2064e-02, -2.6842e-02,  3.5184e-02,
        -2.7622e-02, -1.6597e-02, -5.1290e-02,  1.6897e-02,  1.0744e-02,
        -5.7669e-02, -9.7106e-02,  3.8906e-04, -1.2021e-02, -4.3968e-02,
        -4.5867e-02,  6.5221e-04, -4.3236e-02, -7.1286e-02, -3.1534e-02,
         5.5024e-02, -1.0790e-03, -7.6300e-02, -1.6259e-02,  5.3617e-02,
         9.2478e-02, -2.9126e-02,  5.3592e-02,  9.9088e-04, -1.4495e-03,
         1.1526e-02,  1.0188e-01, -1.7937e-02,  2.5578e-02, -9.6473e-03,
        -5.3130e-02, -2.6567e-02,  4.2863e-02, -3.0745e-02,  5.6807e-02,
         4.6947e-02,  3.9169e-02, -1.0863e-01,  5.8031e-02, -5.9564e-02,
         8.7576e-03,  7.0571e-02, -2.7362e-02,  1.4392e-02,  2.3838e-02,
        -4.3289e-02, -1.1309e-03, -1.5810e-02,  1.3059e-02,  5.9525e-02,
        -1.1604e-02, -1.0512e-03, -4.3463e-02, -8.2112e-02,  3.1210e-03,
        -3.6911e-02, -2.1544e-02,  3.3461e-02, -2.0621e-02,  5.1022e-03,
        -1.7365e-03, -1.7732e-02, -3.0634e-02, -7.0056e-02, -4.9340e-02,
        -1.1025e-02,  9.9126e-05, -1.7121e-02,  8.4516e-02, -3.8420e-02,
        -3.1706e-02, -2.0871e-02, -3.5788e-02, -3.6516e-02, -5.1131e-02,
        -3.1790e-02,  1.0008e-02, -9.8450e-02,  2.0865e-02, -6.4487e-02,
         5.2455e-03, -8.4184e-02,  6.9897e-02, -1.6821e-02,  6.3579e-02,
        -1.9424e-02, -1.6079e-02,  1.8563e-02, -1.5211e-02,  3.0911e-02,
        -5.4488e-02,  1.5494e-02, -1.0767e-02,  4.8773e-04,  1.8043e-02,
        -2.4936e-02, -1.9889e-03,  1.2524e-02, -1.1406e-02, -2.9370e-02,
        -8.1546e-02,  1.9965e-02,  1.4590e-02, -8.0499e-02,  3.6248e-02,
        -2.4142e-02,  1.2985e-02, -3.8987e-02, -1.6445e-02,  3.7229e-02,
        -2.8699e-02, -1.1582e-01,  3.5642e-02,  5.3275e-02,  1.5922e-02,
         2.7014e-02,  1.8617e-02,  2.7929e-02, -1.6418e-02,  1.2687e-02,
         1.1454e-02, -4.0174e-02, -4.8397e-02, -1.3713e-02,  1.2147e-02,
        -3.6155e-02, -1.0283e-02,  3.5103e-02,  4.2696e-02, -4.5168e-02,
         8.6136e-03, -4.9540e-02, -3.7978e-02, -8.8273e-02,  1.4087e-03,
        -7.2829e-02,  3.5375e-02,  3.7254e-04, -8.0252e-02,  6.0259e-02,
         3.0675e-02,  2.1326e-02,  3.4185e-02,  1.4227e-02, -4.8292e-02,
         2.0078e-02, -1.2403e-02, -4.9137e-02,  5.2503e-02, -3.6768e-02,
        -2.8640e-03,  2.8039e-02,  1.5716e-02,  4.4977e-02, -7.7742e-02,
         5.2792e-02,  7.3880e-02,  1.2402e-02,  2.0920e-02, -6.7400e-03,
        -1.0010e-01,  3.6690e-03,  3.1508e-03, -3.5163e-02,  6.2814e-02,
         5.4907e-02, -3.0679e-02,  8.1630e-02, -7.4034e-02, -1.0005e-01,
        -3.0741e-02, -9.6235e-03, -4.7400e-02, -4.0567e-02, -5.7297e-02,
        -2.2009e-02, -2.4186e-02,  1.6887e-02, -1.3118e-02,  3.3043e-02,
        -1.6553e-02,  3.0074e-02, -1.6753e-02,  4.2072e-03, -3.9007e-02,
         8.9815e-03,  2.2497e-03,  1.0773e-02, -4.1444e-03,  1.0343e-01,
         5.5360e-02,  1.9430e-02, -9.6031e-02,  5.7464e-02,  1.6889e-02,
         2.0948e-02, -5.7149e-02,  6.5254e-03,  2.0854e-03, -1.3416e-02,
        -9.9584e-03, -4.5461e-03, -8.5933e-02,  7.4436e-02, -6.6778e-03,
        -4.7127e-02, -1.4701e-02,  9.6452e-02,  3.3150e-02,  8.5220e-02,
         2.8632e-02, -5.8913e-02,  3.7209e-02, -9.0531e-03, -4.8897e-04,
         3.7362e-03,  2.6399e-02, -1.7082e-03,  7.1696e-02, -2.9744e-02,
         1.2718e-02, -1.1991e-02,  4.9634e-02,  2.6138e-02, -7.8699e-02,
         2.9915e-02,  1.5572e-02,  2.1335e-02, -5.7554e-02,  9.3919e-02,
        -3.5818e-02])
net.mlp.net.2.batch_norm.running_mean tensor([0.1421, 0.0977, 0.1999, 0.2398, 0.2425, 0.2054, 0.1901, 0.2113, 0.2983,
        0.1308, 0.1963, 0.3077, 0.2778, 0.2329, 0.1802, 0.1918, 0.2144, 0.4125,
        0.1741, 0.2786, 0.2170, 0.0980, 0.0852, 0.2119, 0.3290, 0.2034, 0.2423,
        0.1460, 0.1211, 0.1560, 0.2096, 0.2062, 0.2483, 0.3159, 0.1711, 0.1989,
        0.2041, 0.2312, 0.2491, 0.1325, 0.2612, 0.1487, 0.2733, 0.1356, 0.3885,
        0.3523, 0.1936, 0.1109, 0.0894, 0.3847, 0.2092, 0.2297, 0.1937, 0.2289,
        0.1372, 0.2035, 0.1743, 0.2377, 0.2757, 0.2110, 0.1696, 0.1938, 0.2098,
        0.2472, 0.1454, 0.1721, 0.2476, 0.2143, 0.2242, 0.2228, 0.1754, 0.1616,
        0.2474, 0.2650, 0.1765, 0.2613, 0.1852, 0.2006, 0.2125, 0.1691, 0.1445,
        0.2801, 0.1713, 0.2120, 0.3110, 0.2164, 0.1333, 0.2506, 0.1815, 0.1623,
        0.2330, 0.2737, 0.2183, 0.1286, 0.2923, 0.2460, 0.1709, 0.1088, 0.2059,
        0.2115, 0.1633, 0.3581, 0.2329, 0.2557, 0.1471, 0.2540, 0.1710, 0.2941,
        0.2057, 0.2218, 0.2421, 0.2936, 0.2301, 0.2355, 0.1300, 0.2152, 0.1523,
        0.2845, 0.1432, 0.3186, 0.3081, 0.3721, 0.2260, 0.1886, 0.1891, 0.1549,
        0.2691, 0.2272, 0.1946, 0.3488, 0.1798, 0.2811, 0.1980, 0.1983, 0.1372,
        0.0937, 0.1975, 0.2395, 0.2232, 0.1940, 0.1550, 0.1521, 0.1615, 0.1783,
        0.1397, 0.1454, 0.2026, 0.1475, 0.2266, 0.1848, 0.2688, 0.1576, 0.2338,
        0.2608, 0.2031, 0.2076, 0.1530, 0.2078, 0.3045, 0.1972, 0.2500, 0.3446,
        0.3317, 0.2726, 0.1525, 0.1717, 0.2364, 0.1370, 0.2028, 0.2061, 0.1229,
        0.2870, 0.2093, 0.2248, 0.1500, 0.2328, 0.1260, 0.1163, 0.2050, 0.2513,
        0.2296, 0.1766, 0.3324, 0.2750, 0.1667, 0.1161, 0.1865, 0.2568, 0.1487,
        0.1674, 0.1984, 0.2193, 0.1899, 0.2690, 0.3279, 0.1574, 0.2206, 0.2544,
        0.2133, 0.2207, 0.1989, 0.1988, 0.2820, 0.2052, 0.2170, 0.3167, 0.1710,
        0.4257, 0.2476, 0.2646, 0.1574, 0.1736, 0.2262, 0.2134, 0.3051, 0.1614,
        0.1391, 0.2145, 0.1183, 0.1999, 0.1818, 0.2797, 0.3543, 0.1245, 0.2310,
        0.1551, 0.1514, 0.1764, 0.2067, 0.1817, 0.2447, 0.2339, 0.2064, 0.2699,
        0.2653, 0.1556, 0.2289, 0.2502, 0.2666, 0.1742, 0.3104, 0.1588, 0.1802,
        0.1850, 0.1913, 0.1580, 0.1615, 0.2034, 0.2122, 0.2065, 0.2115, 0.1527,
        0.1955, 0.2001, 0.1756, 0.1638])
net.mlp.net.2.batch_norm.running_var tensor([0.1077, 0.0949, 0.1122, 0.2240, 0.2748, 0.2018, 0.4406, 0.2332, 0.2317,
        0.1766, 0.1645, 0.0941, 0.3633, 0.1092, 0.1906, 0.2533, 0.1257, 0.3040,
        0.1834, 0.2079, 0.1567, 0.1654, 0.0303, 0.1098, 0.1724, 0.1903, 0.1529,
        0.1322, 0.0454, 0.1068, 0.1445, 0.1683, 0.1402, 0.2550, 0.2074, 0.3036,
        0.1496, 0.1084, 0.1883, 0.0483, 0.2622, 0.1845, 0.1420, 0.2873, 0.4073,
        0.1872, 0.1931, 0.0572, 0.0383, 0.3704, 0.2089, 0.1060, 0.2454, 0.1573,
        0.0870, 0.1583, 0.2008, 0.1930, 0.2647, 0.1329, 0.1584, 0.1519, 0.1117,
        0.1808, 0.1451, 0.0785, 0.1126, 0.1306, 0.1078, 0.2466, 0.2282, 0.1016,
        0.1489, 0.0794, 0.0570, 0.1478, 0.1348, 0.1879, 0.1608, 0.3418, 0.1963,
        0.1635, 0.1429, 0.1743, 0.1965, 0.4198, 0.0963, 0.2265, 0.0663, 0.3577,
        0.1831, 0.1134, 0.0570, 0.0741, 0.1769, 0.1790, 0.0620, 0.1128, 0.1014,
        0.1603, 0.0515, 0.2892, 0.1200, 0.2432, 0.0887, 0.2140, 0.1230, 0.1142,
        0.0598, 0.1711, 0.2012, 0.2403, 0.0843, 0.1013, 0.1477, 0.1427, 0.2632,
        0.1277, 0.2348, 0.3723, 0.2435, 1.0674, 0.1730, 0.0719, 0.1787, 0.1132,
        0.0934, 0.1265, 0.1595, 0.3601, 0.0495, 0.1759, 0.1114, 0.2016, 0.1199,
        0.0844, 0.1509, 0.3392, 0.1364, 0.1008, 0.0501, 0.0979, 0.0605, 0.1297,
        0.1001, 0.0941, 0.0813, 0.1716, 0.2063, 0.1213, 0.2469, 0.1653, 0.1642,
        0.1285, 0.0954, 0.2929, 0.0645, 0.1528, 0.1291, 0.1208, 0.1206, 0.3732,
        0.1348, 0.1248, 0.1737, 0.0880, 0.7075, 0.2080, 0.0984, 0.0721, 0.0931,
        0.0940, 0.0790, 0.1657, 0.2159, 0.2119, 0.0391, 0.0900, 0.1470, 0.1400,
        0.1077, 0.0497, 0.3232, 0.2568, 0.2842, 0.1430, 0.2691, 0.2369, 0.2118,
        0.1174, 0.1640, 0.1868, 0.1432, 0.2566, 0.3629, 0.1428, 0.0727, 0.1124,
        0.0922, 0.3331, 0.0762, 0.1363, 0.1247, 0.1112, 0.0842, 0.2798, 0.0517,
        0.3645, 0.1736, 0.1289, 0.0443, 0.2425, 0.2155, 0.0782, 0.3453, 0.1511,
        0.0708, 0.1675, 0.0658, 0.1120, 0.3220, 0.1464, 0.3813, 0.0463, 0.0849,
        0.1463, 0.0833, 0.2056, 0.1698, 0.0909, 0.2335, 0.1606, 0.2769, 0.0991,
        0.4199, 0.1653, 0.1310, 0.1541, 0.2960, 0.1158, 0.2291, 0.0934, 0.0962,
        0.0651, 0.0682, 0.1333, 0.0372, 0.0941, 0.1152, 0.1433, 0.0856, 0.1799,
        0.1898, 0.1245, 0.0887, 0.0525])
net.mlp.net.2.batch_norm.num_batches_tracked tensor(110)
net.mlp.net.3.linear.weight tensor([[ 0.0487, -0.0002,  0.0038,  ...,  0.0151, -0.0845, -0.0339],
        [ 0.0045,  0.0141, -0.0386,  ..., -0.0620, -0.0244,  0.0816],
        [-0.0381, -0.0241, -0.0354,  ..., -0.0137,  0.0313, -0.1111],
        ...,
        [ 0.0131,  0.0169,  0.0272,  ...,  0.0189, -0.0014,  0.0438],
        [ 0.0525, -0.0198, -0.0016,  ...,  0.0511,  0.0364,  0.0013],
        [ 0.0227,  0.0494, -0.0501,  ...,  0.0349,  0.0105, -0.1155]])
net.mlp.net.3.linear.bias tensor([-0.0116, -0.0481,  0.0418, -0.0403,  0.0104,  0.0448, -0.0246, -0.0356,
         0.0607,  0.0132, -0.0748,  0.0207, -0.1183,  0.0029, -0.0693,  0.0354,
        -0.0329,  0.0065,  0.0730, -0.0413, -0.0014, -0.0172,  0.0351, -0.0306,
        -0.0552,  0.0158,  0.0564,  0.0388, -0.0459, -0.0208, -0.0319,  0.0659,
        -0.0229, -0.0140,  0.0325, -0.0369, -0.0426, -0.0510,  0.0365, -0.0664,
        -0.0793,  0.0176, -0.0221, -0.0077,  0.0706, -0.0249, -0.0224,  0.0102,
         0.0003, -0.0327,  0.0006, -0.0303, -0.0569,  0.0610,  0.0253, -0.0559,
        -0.0314,  0.0600,  0.0225, -0.0187,  0.0284,  0.0037, -0.0233,  0.0615,
         0.0401, -0.0114, -0.0858, -0.0158, -0.1269,  0.0050, -0.0361,  0.0132,
        -0.0636,  0.0558, -0.0469,  0.0081, -0.0033, -0.0004, -0.0619,  0.0026,
         0.0334, -0.0390, -0.0526,  0.0313, -0.0044,  0.0349, -0.0658,  0.0076,
         0.0465,  0.0172,  0.0296, -0.0590,  0.0576,  0.0235,  0.0876, -0.0237,
        -0.0365, -0.0632,  0.0222,  0.0134, -0.0589, -0.0667, -0.0703, -0.0484,
        -0.0581,  0.0315,  0.0306,  0.0287, -0.0288,  0.0511, -0.0766, -0.0665,
         0.0223, -0.0461,  0.0309, -0.0494, -0.0499, -0.0570,  0.0043,  0.0118,
         0.0633, -0.0150, -0.0761,  0.0027, -0.0383, -0.0316,  0.0006, -0.0391,
         0.0161, -0.0261,  0.0595,  0.0043,  0.0093,  0.0619, -0.0235, -0.0021,
         0.0514,  0.0266,  0.0529,  0.0005,  0.0067, -0.0301,  0.0103,  0.0397,
        -0.0126, -0.0101, -0.0363, -0.0210,  0.0293, -0.0068, -0.0127,  0.0268,
         0.0503, -0.0578, -0.0059,  0.0956,  0.0308, -0.1082,  0.0144, -0.0372,
        -0.0064, -0.0665, -0.0486,  0.0461, -0.0324, -0.0269,  0.0341, -0.0044,
         0.0309, -0.0167,  0.0531, -0.1409, -0.0418,  0.0005,  0.0062,  0.0470,
        -0.1181, -0.0424,  0.0210,  0.0703,  0.0207,  0.0271, -0.0655, -0.0302,
        -0.0608, -0.0522, -0.0088,  0.0108, -0.0234,  0.0036, -0.0153,  0.0313,
        -0.0146, -0.1066, -0.0328, -0.0796,  0.0312, -0.0440, -0.1007,  0.0332,
        -0.0143,  0.0927, -0.1016,  0.0088,  0.0052,  0.0005, -0.0029,  0.0125,
        -0.0359,  0.0385, -0.0151,  0.0265, -0.0348,  0.0154, -0.0554, -0.0603,
        -0.0121, -0.0344, -0.0154, -0.0810, -0.0214, -0.0664, -0.0303,  0.0460,
         0.0199,  0.0290,  0.0894, -0.0495,  0.0614, -0.0162,  0.0206, -0.0471,
         0.1033,  0.0169,  0.0349, -0.0298, -0.0188, -0.0229, -0.0011,  0.0246,
         0.0175,  0.0421, -0.0292,  0.0056, -0.0591, -0.0237, -0.0025, -0.0391,
         0.0049, -0.0106, -0.0063,  0.0388,  0.0182,  0.0561, -0.0015, -0.0333])
net.mlp.net.3.batch_norm.weight tensor([0.3354, 0.2118, 0.2474, 0.3312, 0.2795, 0.3426, 0.2801, 0.2740, 0.3049,
        0.3072, 0.2700, 0.2977, 0.3036, 0.2970, 0.3072, 0.3061, 0.3173, 0.3515,
        0.2673, 0.2703, 0.3429, 0.3017, 0.2769, 0.2837, 0.2209, 0.2813, 0.2947,
        0.3157, 0.2977, 0.3307, 0.2932, 0.3210, 0.3170, 0.3469, 0.3202, 0.2854,
        0.2783, 0.2635, 0.2903, 0.3262, 0.3252, 0.3187, 0.2869, 0.3812, 0.3463,
        0.3031, 0.2501, 0.2553, 0.2881, 0.2845, 0.2153, 0.2737, 0.2552, 0.3359,
        0.3398, 0.2873, 0.2631, 0.3167, 0.2816, 0.3399, 0.2941, 0.3513, 0.3128,
        0.2835, 0.3384, 0.3367, 0.3140, 0.3027, 0.2925, 0.2459, 0.2387, 0.2976,
        0.2960, 0.3388, 0.2906, 0.3481, 0.3181, 0.2431, 0.3289, 0.3775, 0.2816,
        0.3216, 0.3155, 0.3095, 0.3142, 0.3014, 0.2906, 0.3160, 0.3370, 0.3053,
        0.2460, 0.2884, 0.3464, 0.2784, 0.3472, 0.3246, 0.2644, 0.2364, 0.3366,
        0.2276, 0.2565, 0.3077, 0.3712, 0.3580, 0.3364, 0.3251, 0.2617, 0.3347,
        0.2996, 0.3688, 0.3197, 0.3203, 0.2647, 0.3362, 0.3597, 0.2885, 0.3122,
        0.3310, 0.2797, 0.3692, 0.3204, 0.2832, 0.3312, 0.3214, 0.3295, 0.3066,
        0.3182, 0.3399, 0.2341, 0.3121, 0.3133, 0.3470, 0.3279, 0.3221, 0.3036,
        0.2945, 0.3579, 0.3136, 0.3223, 0.3131, 0.2799, 0.2960, 0.3336, 0.3003,
        0.2895, 0.2932, 0.2818, 0.2573, 0.3527, 0.1934, 0.3367, 0.3055, 0.2885,
        0.2654, 0.3125, 0.3236, 0.3463, 0.2405, 0.2958, 0.3255, 0.2750, 0.2866,
        0.3011, 0.3066, 0.3372, 0.3286, 0.3463, 0.3445, 0.2839, 0.3082, 0.3684,
        0.2927, 0.3010, 0.2797, 0.3040, 0.3344, 0.3264, 0.2602, 0.3527, 0.3463,
        0.2296, 0.3162, 0.3671, 0.3030, 0.2738, 0.2897, 0.2827, 0.3281, 0.2971,
        0.3183, 0.3307, 0.3385, 0.2903, 0.3049, 0.3080, 0.2731, 0.2938, 0.2593,
        0.2773, 0.3625, 0.2788, 0.2989, 0.3546, 0.2421, 0.2253, 0.2840, 0.3096,
        0.3596, 0.2641, 0.2861, 0.3107, 0.2947, 0.3291, 0.3377, 0.3050, 0.3099,
        0.3165, 0.2900, 0.2950, 0.3183, 0.3103, 0.3162, 0.2791, 0.3300, 0.3185,
        0.3146, 0.3517, 0.3045, 0.3470, 0.2616, 0.2622, 0.2893, 0.3161, 0.3121,
        0.3441, 0.2355, 0.2602, 0.3040, 0.3130, 0.3195, 0.2991, 0.2743, 0.2895,
        0.3414, 0.3043, 0.3305, 0.2700, 0.2973, 0.2857, 0.2902, 0.3186, 0.3224,
        0.3033, 0.3270, 0.2948, 0.3569])
net.mlp.net.3.batch_norm.bias tensor([ 0.0604, -0.0335,  0.0146,  0.0461,  0.0454,  0.0386, -0.0132,  0.0163,
        -0.0312,  0.0138, -0.0731, -0.1083, -0.0993,  0.0548, -0.0601,  0.0007,
        -0.0181,  0.0770,  0.0034, -0.0290,  0.0726, -0.0466,  0.0312,  0.0031,
         0.1106,  0.0313, -0.0229, -0.0477, -0.0058, -0.0276,  0.0352,  0.0249,
         0.0049,  0.0326, -0.0428,  0.0219,  0.0351, -0.0123,  0.0436, -0.1088,
        -0.0480, -0.0299,  0.0850,  0.0863, -0.0304,  0.0425,  0.0703,  0.0086,
         0.0218,  0.0505,  0.0238,  0.0496,  0.0811,  0.0686,  0.0229, -0.0302,
        -0.0193, -0.0538, -0.0033, -0.0161, -0.0276,  0.0062, -0.0044,  0.0167,
        -0.0721, -0.0210, -0.0918,  0.0114, -0.0175,  0.0448,  0.0261,  0.0628,
         0.0683, -0.0233,  0.0296, -0.0370,  0.0425,  0.0113,  0.0473, -0.1242,
        -0.0380,  0.0006,  0.0942, -0.0169, -0.0236,  0.0173,  0.0442,  0.0013,
         0.0403,  0.0222,  0.0039, -0.0119, -0.0623,  0.0021,  0.0633,  0.0340,
         0.0100, -0.0038,  0.0058,  0.0556, -0.0044, -0.0313, -0.1076, -0.0536,
         0.0920, -0.0671, -0.0862,  0.0348, -0.0846, -0.0250, -0.0730, -0.0585,
         0.0423, -0.1031, -0.0035, -0.0276,  0.0871,  0.0145, -0.0294,  0.0435,
        -0.0306,  0.0364, -0.0538,  0.0723,  0.0141,  0.1381,  0.0098, -0.0296,
         0.0041,  0.0499,  0.0086,  0.0245,  0.1130, -0.0228, -0.0453,  0.0326,
         0.0880,  0.0806, -0.0472, -0.0051, -0.0123,  0.0318, -0.0099,  0.0136,
         0.0181,  0.0213,  0.0287,  0.0197, -0.0064, -0.0565,  0.0064, -0.1135,
        -0.1463, -0.0859,  0.1113, -0.0251,  0.0175,  0.0376,  0.0300,  0.0420,
         0.0058,  0.0129, -0.0030, -0.0318, -0.0365,  0.0013,  0.0030,  0.0308,
        -0.0273, -0.0275, -0.0070,  0.0473, -0.0723, -0.0751, -0.0473,  0.0183,
        -0.0351,  0.0438, -0.0215, -0.0187, -0.0009, -0.0485, -0.1205,  0.0313,
         0.0046,  0.0090,  0.0357, -0.0714,  0.0103,  0.0271, -0.0023,  0.0356,
         0.0048,  0.0161,  0.0296,  0.0191,  0.0219, -0.0149,  0.0254,  0.0619,
        -0.0021,  0.0925, -0.0392,  0.0187,  0.0220,  0.0747, -0.0535, -0.0415,
        -0.0081,  0.0046, -0.0494, -0.0792,  0.0406, -0.0505,  0.0673, -0.0394,
         0.0467, -0.0143,  0.0117, -0.0043,  0.0326, -0.0216,  0.0297,  0.0535,
        -0.0597, -0.0274,  0.0158,  0.0044, -0.0145,  0.0219, -0.0434, -0.0521,
        -0.0414, -0.0462,  0.0837, -0.0151,  0.0786,  0.0011, -0.0194,  0.0579,
         0.0177, -0.0304,  0.0598, -0.0214, -0.0271,  0.0081,  0.0086, -0.0057,
         0.0437,  0.0283,  0.0165,  0.0219,  0.0155,  0.0026, -0.0084, -0.1045])
net.mlp.net.3.batch_norm.running_mean tensor([0.1574, 0.1096, 0.1587, 0.1353, 0.1682, 0.4174, 0.2854, 0.1391, 0.2075,
        0.1706, 0.2126, 0.2036, 0.1790, 0.2334, 0.2954, 0.3113, 0.2234, 0.3784,
        0.3537, 0.1176, 0.3947, 0.2321, 0.3679, 0.3260, 0.1502, 0.2139, 0.3306,
        0.4699, 0.1118, 0.3992, 0.1487, 0.4681, 0.2505, 0.2970, 0.2910, 0.2154,
        0.2227, 0.2353, 0.2027, 0.1615, 0.2346, 0.2560, 0.1998, 0.2692, 0.3358,
        0.2481, 0.1699, 0.2991, 0.2031, 0.2486, 0.1449, 0.2164, 0.1832, 0.2359,
        0.3346, 0.1160, 0.1983, 0.3656, 0.1377, 0.3001, 0.2014, 0.2138, 0.1850,
        0.3789, 0.4086, 0.2292, 0.1210, 0.1070, 0.1342, 0.1752, 0.2592, 0.4314,
        0.1966, 0.2787, 0.2053, 0.2728, 0.2357, 0.0886, 0.2390, 0.3801, 0.2743,
        0.2677, 0.1449, 0.4405, 0.1348, 0.4074, 0.2625, 0.2053, 0.3079, 0.3009,
        0.2854, 0.0858, 0.3286, 0.1070, 0.4465, 0.2222, 0.2280, 0.1471, 0.2663,
        0.1847, 0.2188, 0.2056, 0.1243, 0.3050, 0.3313, 0.3363, 0.1684, 0.3180,
        0.1885, 0.2759, 0.1466, 0.2134, 0.1993, 0.2205, 0.3983, 0.1044, 0.1632,
        0.2438, 0.2239, 0.2896, 0.3445, 0.1719, 0.1906, 0.2013, 0.3007, 0.2562,
        0.3037, 0.3723, 0.2037, 0.1718, 0.3600, 0.3390, 0.3479, 0.2534, 0.1584,
        0.1790, 0.3783, 0.2065, 0.3356, 0.2387, 0.1768, 0.2616, 0.3336, 0.1870,
        0.1830, 0.2253, 0.2237, 0.2419, 0.2642, 0.2299, 0.2283, 0.3770, 0.2187,
        0.1062, 0.3661, 0.6190, 0.4209, 0.1563, 0.2402, 0.2008, 0.1586, 0.0902,
        0.1197, 0.2831, 0.1597, 0.1575, 0.2801, 0.4130, 0.1989, 0.2313, 0.2171,
        0.2213, 0.1805, 0.2005, 0.2564, 0.2511, 0.2278, 0.1221, 0.3835, 0.2849,
        0.2826, 0.3315, 0.2861, 0.1797, 0.1749, 0.1550, 0.1457, 0.4231, 0.1085,
        0.2784, 0.3594, 0.4964, 0.2401, 0.1378, 0.1853, 0.1751, 0.2919, 0.1480,
        0.0720, 0.3746, 0.2029, 0.3678, 0.0889, 0.2837, 0.1903, 0.3455, 0.3342,
        0.2545, 0.2277, 0.2640, 0.2489, 0.3649, 0.1780, 0.2721, 0.1538, 0.2154,
        0.2390, 0.1552, 0.2000, 0.1719, 0.2134, 0.1219, 0.2054, 0.3097, 0.4813,
        0.3045, 0.3972, 0.1785, 0.4215, 0.1398, 0.2571, 0.2185, 0.5408, 0.3700,
        0.3547, 0.2777, 0.1703, 0.1874, 0.2594, 0.2099, 0.2178, 0.1770, 0.1959,
        0.3217, 0.1070, 0.2525, 0.2081, 0.1485, 0.2334, 0.2275, 0.3567, 0.3177,
        0.2123, 0.2369, 0.3315, 0.2525])
net.mlp.net.3.batch_norm.running_var tensor([0.2455, 0.1339, 0.1131, 0.1072, 0.0433, 0.2130, 0.2102, 0.1350, 0.0817,
        0.0416, 0.3382, 0.1972, 0.5725, 0.1896, 0.1463, 0.4341, 0.2613, 0.5575,
        0.1340, 0.1711, 0.3454, 0.1101, 0.2153, 0.2688, 0.1090, 0.1179, 0.2027,
        0.3240, 0.1772, 0.2646, 0.1288, 0.2881, 0.5456, 0.2012, 0.2384, 0.2645,
        0.2803, 0.2360, 0.0655, 0.2490, 0.3484, 0.4566, 0.1475, 0.1034, 0.1753,
        0.1380, 0.2309, 0.1249, 0.2532, 0.5941, 0.2312, 0.4536, 0.2276, 0.0794,
        0.3734, 0.0745, 0.1362, 0.1339, 0.1146, 0.3053, 0.0690, 0.1849, 0.0913,
        0.4296, 0.1676, 0.2199, 0.1433, 0.0285, 0.2295, 0.2945, 0.5085, 0.2610,
        0.1557, 0.3028, 0.1142, 0.3816, 0.2536, 0.0308, 0.3096, 0.6552, 0.1507,
        0.3100, 0.1984, 0.3115, 0.0971, 0.2350, 0.1866, 0.0821, 0.2010, 0.3534,
        0.1807, 0.1017, 0.1601, 0.0748, 0.3467, 0.3368, 0.3767, 0.3276, 0.1818,
        0.1394, 0.4139, 0.2853, 0.1558, 0.3763, 0.2491, 0.1578, 0.2729, 0.4136,
        0.1971, 0.1194, 0.1350, 0.4695, 0.0866, 0.4251, 0.5099, 0.0361, 0.1469,
        0.1357, 0.1168, 0.4163, 0.3933, 0.2328, 0.3032, 0.4171, 0.1959, 0.7612,
        0.4174, 0.2575, 0.0788, 0.2083, 0.1902, 0.2728, 1.0101, 0.1269, 0.1575,
        0.4083, 0.2341, 0.3283, 0.4399, 0.3353, 0.1976, 0.3710, 0.1801, 0.2508,
        0.2018, 0.2701, 0.1361, 0.1132, 0.1503, 0.2144, 0.2725, 0.5071, 0.2649,
        0.1143, 0.1880, 0.3968, 0.6212, 0.2141, 0.1831, 0.1905, 0.0341, 0.0402,
        0.1159, 0.2793, 0.2980, 0.2420, 0.2785, 0.2911, 0.0333, 0.6447, 0.1201,
        0.1461, 0.2042, 0.2329, 0.1483, 0.2856, 0.6740, 0.0299, 0.5261, 0.1966,
        0.3525, 0.6511, 0.1427, 0.3500, 0.4171, 0.3403, 0.0525, 0.3909, 0.0394,
        0.2705, 0.1613, 1.0131, 0.3004, 0.1368, 0.4668, 0.2232, 0.1252, 0.1081,
        0.0974, 0.4737, 0.3600, 0.1521, 0.0732, 0.3760, 0.0427, 0.1791, 0.2926,
        0.3500, 0.5811, 0.4847, 0.2468, 0.4412, 0.1157, 0.2540, 0.2397, 0.2721,
        0.4225, 0.2577, 0.2864, 0.1466, 0.1850, 0.1274, 0.3387, 0.4949, 0.8692,
        0.1235, 0.5808, 0.2707, 0.1966, 0.2858, 0.2843, 0.3145, 0.8094, 0.2414,
        0.4101, 0.3287, 0.0542, 0.2098, 0.3905, 0.3109, 0.2258, 0.0434, 0.2885,
        0.1881, 0.0569, 0.3249, 0.2795, 0.3266, 0.1190, 0.3046, 0.5493, 0.1527,
        0.1878, 0.2757, 0.1904, 0.1155])
net.mlp.net.3.batch_norm.num_batches_tracked tensor(110)
net.mlp.net.4.weight tensor([[-2.8634e-02,  1.5612e-04,  6.0552e-04, -2.5198e-02, -1.0971e-02,
          3.6355e-02, -1.3382e-02, -7.0471e-03, -6.4787e-03, -2.5501e-02,
         -6.0766e-03, -2.4399e-02,  5.9368e-04,  5.6474e-03,  1.8760e-02,
          1.1448e-03,  1.8714e-02, -4.2322e-02,  1.3396e-02, -7.2388e-03,
          2.2452e-02,  2.2517e-02, -7.1899e-03,  9.7120e-03,  6.2565e-03,
         -1.9464e-03,  1.7960e-02,  2.2189e-02,  4.6620e-03,  2.9803e-02,
          8.4801e-03,  2.6351e-02,  2.5783e-02,  3.6269e-02, -2.6720e-02,
          6.3304e-04, -3.0156e-02, -4.4221e-03, -8.5479e-03, -3.2095e-02,
         -2.3379e-02,  2.1834e-02, -2.6465e-03,  5.3067e-02,  4.0027e-02,
          2.8466e-03, -8.6554e-03,  2.0821e-02, -9.8974e-03, -2.7357e-04,
          7.4672e-03,  2.8165e-03, -9.7274e-03,  3.5301e-02, -3.4168e-02,
         -9.8739e-03, -6.5696e-03,  2.0367e-02, -5.5897e-03, -3.0515e-02,
         -3.8440e-03, -4.7435e-02,  1.2991e-02,  4.4756e-03,  3.1808e-02,
          2.5981e-02, -2.1157e-02,  1.8412e-02, -2.5736e-02, -2.3210e-04,
         -1.2968e-02,  2.2322e-02, -2.1738e-02, -3.2515e-02,  8.5389e-03,
         -3.7747e-02, -2.3670e-02,  3.1180e-03, -2.2257e-02, -5.4266e-02,
         -1.3019e-02, -1.9837e-02, -1.3891e-02,  2.5282e-02, -1.1127e-02,
          2.4916e-02, -4.2251e-03,  1.5879e-02, -2.2662e-02, -1.9833e-02,
         -9.8291e-03, -9.1777e-03,  3.5685e-02,  1.4541e-03, -3.9869e-02,
         -2.3536e-02,  8.6773e-03, -1.0069e-02, -3.1956e-02,  5.8971e-05,
         -6.2264e-03, -1.7843e-02, -4.5288e-02, -4.1322e-02,  2.8587e-02,
          1.6428e-02,  1.4714e-02, -2.8309e-02,  2.1765e-02,  4.4663e-02,
         -2.9384e-02,  2.4760e-02,  1.0618e-02, -3.9633e-02, -3.7433e-02,
         -5.2350e-04, -1.9041e-02,  2.5309e-02, -1.8475e-02, -4.4516e-02,
         -1.7258e-02,  3.2989e-03, -3.4181e-02, -2.3106e-02,  2.5757e-02,
         -1.1001e-02, -3.1070e-02,  3.3781e-02, -1.4959e-04,  2.7543e-02,
          1.5024e-02,  3.4053e-02,  3.1080e-02, -1.4524e-02,  7.5892e-03,
          1.2629e-02,  4.5332e-02,  1.8712e-02, -2.4988e-02, -3.2589e-02,
         -8.7393e-03, -1.0548e-02,  3.0449e-02,  1.0667e-02, -3.8896e-03,
         -6.9071e-03, -1.6888e-03,  4.2144e-03,  2.9364e-02,  1.0898e-03,
         -2.7363e-02, -2.0823e-02,  2.7211e-02, -1.5993e-02,  2.4643e-02,
          2.5255e-02, -2.7309e-02,  3.7262e-03, -7.0220e-03, -2.5897e-02,
          6.8329e-03,  3.3691e-03, -7.3665e-03,  7.7590e-03, -4.1499e-02,
          2.3961e-02, -3.0753e-02,  4.5528e-02, -2.3769e-02,  1.5794e-02,
         -4.0882e-02,  1.2960e-02, -1.5099e-02, -6.0591e-03,  1.3436e-02,
         -2.7279e-02, -1.7748e-02,  1.0262e-02, -4.3152e-02, -3.3677e-02,
         -1.0860e-02, -2.5525e-02,  5.3673e-02,  1.6999e-02,  1.0719e-02,
         -1.7570e-02,  3.4757e-03,  2.9403e-02,  2.0297e-03, -2.5925e-02,
          2.1565e-02, -2.1863e-02, -2.2388e-02, -2.7003e-02,  2.1779e-02,
          2.8864e-03,  1.8284e-02, -1.9304e-02, -1.2903e-02, -5.0526e-02,
          1.7590e-02,  2.7992e-02,  4.6866e-02, -8.6377e-03,  6.4678e-03,
          7.3556e-03, -2.3719e-02, -3.8040e-02,  2.7655e-03,  2.1899e-02,
         -1.3822e-02, -2.3428e-03,  3.4520e-02, -3.1311e-02, -5.6155e-03,
         -2.0378e-02, -1.5192e-02, -6.5005e-03, -9.9366e-03, -2.4827e-02,
         -3.4551e-02, -5.2146e-03,  4.3021e-03, -2.9033e-02, -2.6213e-02,
          2.3842e-02, -4.4429e-02, -9.1952e-03,  3.7877e-02,  6.0073e-03,
         -9.9459e-03,  1.0144e-02, -2.6020e-02,  2.7800e-02, -4.1004e-02,
         -2.0200e-02, -1.8064e-03, -8.0851e-03, -2.5046e-02, -2.8001e-02,
          1.2840e-02, -2.2733e-03, -1.6572e-02,  3.1162e-02, -1.2978e-02,
         -1.9655e-02, -5.7209e-03,  1.2922e-02,  1.6150e-02,  7.9532e-03,
         -3.1676e-02,  2.1245e-02, -1.4456e-03,  1.2246e-02,  1.8277e-03,
          5.5975e-02]])
