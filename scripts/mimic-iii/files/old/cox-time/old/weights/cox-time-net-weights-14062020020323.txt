Weights: 
net.embeddings.embeddings.0.weight tensor([[ 0.3821,  0.5014],
        [ 0.1571, -0.4292],
        [ 0.2162,  0.4579],
        [ 0.2039, -0.2695]])
net.embeddings.embeddings.1.weight tensor([[-0.0358, -0.0005],
        [ 0.2556,  0.4883],
        [ 0.0049, -0.4038],
        [ 0.3853,  0.3762],
        [ 0.0904,  0.2065]])
net.embeddings.embeddings.2.weight tensor([[ 0.2362, -0.1382, -0.0227],
        [ 0.1337, -0.2730,  0.0925],
        [ 0.3688,  0.2805,  0.1930],
        [ 0.3902,  0.0446,  0.1387],
        [ 0.1258,  0.3906,  0.0769],
        [-0.1677, -0.3050, -0.0778]])
net.embeddings.embeddings.3.weight tensor([[ 0.2081, -0.4225],
        [-0.5281, -0.5787],
        [-0.2820, -0.1916],
        [-0.2275,  0.5372]])
net.embeddings.embeddings.4.weight tensor([[ 0.2034,  0.2254],
        [ 0.2229,  0.2975],
        [ 0.6768, -0.1370],
        [-0.5944, -0.0580]])
net.mlp.net.0.linear.weight tensor([[ 0.1251,  0.2662,  0.1064,  ...,  0.0087, -0.0046,  0.8345],
        [-0.0695, -0.0945, -0.1733,  ..., -0.0771,  0.3979,  0.3984],
        [ 0.0549, -0.1889, -0.4346,  ..., -0.3556, -0.0835,  0.3325],
        ...,
        [-0.1921,  0.0850,  0.4290,  ...,  0.1345,  0.0613, -0.1768],
        [ 0.5725,  0.2396, -0.0994,  ...,  0.0453, -0.0790,  0.0353],
        [ 0.0782,  0.1091, -0.1534,  ..., -0.0333,  0.3695,  0.2832]])
net.mlp.net.0.linear.bias tensor([-0.0602,  0.2034,  0.2074, -0.1095,  0.0143,  0.2169, -0.1015, -0.2312,
        -0.0762,  0.0581,  0.2449,  0.1818,  0.1496, -0.0059, -0.1532,  0.0558,
        -0.0168, -0.0763,  0.1213,  0.2157,  0.1811,  0.0880, -0.0333,  0.1572,
         0.2645, -0.2343, -0.0343,  0.1489,  0.0681, -0.2149,  0.0137, -0.0861,
         0.0817, -0.1603, -0.0582,  0.1686,  0.0663, -0.0988,  0.1726,  0.0653,
         0.0209, -0.1088, -0.1276, -0.0121, -0.1559, -0.0143,  0.1327, -0.2177,
        -0.1570, -0.1214, -0.0727,  0.0075,  0.1331,  0.1438,  0.0148, -0.1639,
        -0.1072,  0.0195, -0.0895, -0.1069,  0.2160, -0.1074,  0.0768,  0.2022,
        -0.1690,  0.1961, -0.2500, -0.0283, -0.0225, -0.2059,  0.0191, -0.0305,
        -0.1216, -0.2105,  0.2589, -0.0866,  0.1247, -0.1161,  0.0896,  0.1854,
        -0.0881, -0.0840,  0.1046, -0.1348,  0.0343,  0.0253, -0.1985,  0.1707,
         0.2017,  0.0749, -0.0036, -0.1517,  0.0358, -0.1518, -0.1129, -0.1146,
        -0.2096,  0.1093, -0.1733,  0.0327, -0.0584, -0.1089,  0.1080, -0.0772,
        -0.0233, -0.1915,  0.0580, -0.0147, -0.1144, -0.1096, -0.1047,  0.1451,
         0.0325, -0.0208, -0.2391, -0.0567,  0.2393,  0.2711, -0.1297,  0.0758,
        -0.2742, -0.2716, -0.1395, -0.0438,  0.2395,  0.1072, -0.0369,  0.1136,
        -0.1438, -0.0816,  0.0651,  0.1070,  0.1854, -0.1711,  0.0398,  0.1915,
        -0.0551, -0.1276, -0.1181,  0.0214,  0.0564,  0.0470,  0.1730,  0.0890,
        -0.1772,  0.1121, -0.1455, -0.2217, -0.0122,  0.1526, -0.0106,  0.1333,
         0.1169, -0.1071, -0.2412, -0.0449,  0.0079,  0.0401, -0.0965,  0.1395,
         0.2360,  0.1124,  0.1163, -0.0102, -0.0737, -0.1535,  0.0807, -0.0311,
         0.2453, -0.1876, -0.1964, -0.0351, -0.0356, -0.2045, -0.1569,  0.1809,
         0.0887, -0.0753, -0.1907, -0.0214, -0.2040,  0.0679,  0.0844, -0.1258,
        -0.0138, -0.0751, -0.1812,  0.0355, -0.2622,  0.0537, -0.0737, -0.1761,
        -0.1441,  0.1718,  0.2735,  0.0666, -0.0980, -0.2418, -0.0538, -0.0631,
        -0.2282, -0.0856,  0.0968,  0.0122, -0.1291, -0.0730, -0.0970,  0.1421,
         0.0403,  0.1708,  0.1650,  0.1239, -0.1818, -0.2307,  0.1338,  0.0987,
         0.1116,  0.0983, -0.0637,  0.0459, -0.1937, -0.0786,  0.0132, -0.1973,
        -0.0052, -0.0880,  0.2055,  0.2331,  0.0018, -0.0571,  0.1039, -0.1663,
        -0.0716, -0.1630, -0.1763,  0.1629,  0.0217,  0.1554,  0.2002,  0.1100,
        -0.0005, -0.2126,  0.1292,  0.0140, -0.0206,  0.2455, -0.0611, -0.0661,
         0.2281,  0.0349, -0.1367, -0.1535,  0.0419,  0.2018,  0.0054,  0.2744])
net.mlp.net.0.batch_norm.weight tensor([0.9083, 0.9018, 1.0021, 0.9764, 0.9435, 0.9501, 0.9055, 0.9091, 0.8397,
        0.8270, 0.8480, 0.9228, 0.9086, 0.8939, 0.9249, 0.9198, 0.9142, 0.8909,
        0.9417, 0.8993, 0.8696, 0.8783, 0.9613, 0.8737, 0.8979, 0.8765, 0.9214,
        0.9849, 0.9326, 0.9332, 0.8311, 1.0271, 1.0132, 0.9175, 0.9654, 0.9577,
        0.9703, 1.0094, 0.9329, 0.9647, 0.9773, 0.9648, 0.9487, 1.0449, 0.7944,
        0.8928, 0.9023, 0.8636, 0.9601, 0.9121, 0.9594, 0.8877, 0.9241, 0.9888,
        0.8243, 0.9039, 0.9115, 0.9341, 0.9384, 0.8755, 0.8354, 0.9597, 0.9923,
        0.9796, 0.9399, 0.8655, 0.9675, 0.8756, 0.9543, 0.9275, 0.8508, 0.9186,
        0.9218, 0.9695, 1.0130, 0.9312, 0.9839, 0.9177, 0.8800, 0.9239, 0.8768,
        0.9763, 0.9596, 0.9793, 0.8621, 0.9563, 0.9391, 0.8650, 0.9715, 0.8743,
        0.9216, 0.9262, 0.8949, 0.8927, 0.9112, 0.9466, 0.9157, 0.8754, 0.9691,
        0.9493, 0.8391, 0.9833, 0.9450, 0.9277, 0.9330, 0.9448, 0.9071, 0.9012,
        0.8977, 0.9386, 0.9293, 0.8707, 0.8990, 0.8700, 0.8625, 0.9402, 0.8962,
        0.9602, 0.8988, 0.9188, 0.9309, 0.9212, 0.9404, 0.9555, 0.9923, 0.9020,
        0.9068, 0.9686, 0.9043, 0.8687, 0.9717, 0.9610, 0.9858, 0.9957, 0.8757,
        0.9587, 0.8497, 0.8785, 1.0274, 1.0101, 0.9388, 0.9528, 1.0191, 0.9776,
        0.9617, 0.8790, 0.9540, 0.8396, 0.8394, 0.8835, 0.8759, 0.9448, 0.9713,
        0.8797, 0.9912, 0.9132, 0.9064, 0.8644, 0.9263, 0.9757, 0.9180, 0.8575,
        0.9237, 0.9527, 0.9053, 0.9397, 0.9211, 0.8768, 0.9853, 0.9487, 0.9121,
        0.8747, 0.9623, 0.9123, 0.9523, 0.9485, 0.8862, 1.0049, 0.9163, 1.0723,
        0.9257, 0.9471, 1.0003, 0.9193, 0.9371, 0.9253, 0.8979, 0.9489, 0.9178,
        0.9713, 0.9767, 0.8800, 0.8953, 0.9037, 0.9911, 0.8990, 0.8756, 0.9025,
        0.9150, 0.9812, 0.9081, 0.9337, 0.9383, 0.8911, 0.9244, 0.8998, 0.9096,
        0.9428, 0.8481, 0.9224, 0.9391, 0.9876, 0.9359, 0.9894, 0.9198, 0.9543,
        0.9382, 0.9174, 0.9228, 0.9721, 1.0374, 0.9243, 0.9692, 0.9068, 0.8483,
        0.8765, 0.8867, 1.0052, 0.8714, 0.8462, 0.9087, 0.9964, 0.9584, 0.8986,
        0.9687, 0.9588, 0.9621, 0.9660, 1.1123, 0.9717, 0.9955, 0.9949, 0.9177,
        0.8481, 0.9187, 0.9924, 0.9437, 0.9415, 0.9616, 0.9583, 0.9435, 0.9157,
        0.8834, 1.0074, 0.9977, 0.9011])
net.mlp.net.0.batch_norm.bias tensor([-2.3145e-02, -2.5489e-02, -4.8335e-02, -5.9869e-02,  1.0306e-02,
        -5.8811e-02,  6.2492e-02, -2.4984e-02,  5.3499e-02,  3.7636e-02,
         3.4178e-02, -3.0154e-02,  6.3695e-03,  4.8255e-02,  7.3760e-02,
         2.1943e-02, -4.0024e-02, -2.5806e-02,  1.2615e-02, -1.6262e-02,
         3.5613e-02,  1.2802e-02,  8.0101e-02,  7.2002e-02, -2.0639e-02,
        -2.3934e-02,  2.6887e-02, -6.7926e-02,  6.3384e-02,  1.8984e-02,
         7.3668e-02, -1.6420e-02,  6.9894e-02,  1.9352e-02,  3.5867e-02,
         1.0381e-02, -4.6218e-02, -1.2252e-01,  2.6180e-02,  5.2408e-02,
        -4.4401e-02, -1.8071e-02,  1.9966e-02, -7.1334e-02, -5.2241e-02,
         1.5229e-02,  7.0967e-02, -4.3396e-03,  7.8090e-02, -4.7692e-03,
         1.7126e-02, -8.5547e-03,  2.5686e-02,  1.3893e-02, -5.6467e-02,
         2.6293e-02,  3.7616e-02,  5.8410e-03,  5.7632e-02,  7.3833e-02,
        -1.2041e-02, -2.5899e-02,  3.9591e-02, -9.2500e-02,  1.1043e-02,
         1.5671e-02, -7.1700e-02, -4.8907e-02,  1.2365e-02, -4.5165e-02,
        -4.5285e-02, -5.8722e-02, -3.4136e-02,  9.2065e-02, -3.3347e-02,
        -6.6971e-02,  4.5664e-02,  5.9967e-02, -1.5692e-03,  3.3413e-02,
        -1.2223e-02,  5.4983e-02, -2.6321e-02,  1.7676e-02,  2.1254e-02,
        -5.0525e-02,  5.2353e-03, -9.3662e-02,  4.0143e-02,  4.7090e-02,
        -1.7316e-02, -6.0872e-02, -2.4784e-02, -1.5907e-02, -1.4841e-02,
         5.0403e-02,  2.0942e-02, -8.6399e-02,  9.2102e-02,  6.5520e-02,
         2.3820e-02, -6.3072e-02,  5.8507e-02, -3.6222e-03, -7.8503e-02,
        -5.2592e-02, -6.2088e-02, -3.7692e-02, -5.6839e-05, -3.3438e-02,
        -5.6635e-02,  2.9822e-02,  5.7931e-04, -3.6677e-02,  3.9643e-02,
         2.1980e-02,  9.3884e-02, -3.8642e-02, -6.0732e-02,  3.1886e-02,
        -1.6828e-02,  3.4500e-02, -1.7203e-02,  4.5818e-02,  1.4339e-02,
         7.4464e-02, -5.7960e-02, -2.5945e-03,  5.1531e-02, -7.1147e-02,
         4.5991e-02,  4.6233e-02, -1.7613e-02,  6.9800e-02,  6.7927e-03,
        -3.5564e-02, -6.2083e-02,  4.4453e-02,  2.4954e-02, -2.4949e-02,
         1.5316e-03,  8.7035e-03,  2.7236e-02,  7.8296e-02, -2.9417e-02,
         4.8667e-02,  4.0713e-02, -1.3960e-02, -3.6359e-03,  8.1375e-02,
         6.3771e-02, -4.4291e-02, -1.7396e-02,  3.8354e-02,  6.6325e-03,
         1.5409e-02,  5.7683e-02, -1.1911e-02,  1.3451e-01, -3.3507e-02,
         1.4914e-02, -2.7160e-02,  1.9119e-02,  1.2393e-03,  3.6183e-02,
         3.0094e-02,  7.8481e-02, -2.8669e-02,  1.8587e-02, -4.1880e-02,
         1.1413e-02, -2.6043e-02, -6.4275e-02, -4.8574e-02,  2.4393e-02,
         3.5878e-03,  1.7934e-02,  1.1520e-01, -4.4393e-02, -4.1865e-02,
        -2.6596e-02, -3.3021e-02, -6.7151e-02,  5.5172e-02, -6.4130e-02,
         9.5804e-02,  1.7293e-02, -1.8616e-03, -8.8008e-02, -5.0381e-02,
         2.8113e-02,  1.2864e-02, -2.4013e-02, -2.6158e-03,  3.4039e-02,
        -1.9063e-02,  5.1147e-02, -2.5337e-02,  2.3736e-02, -1.4533e-02,
        -4.9676e-02, -3.5539e-02, -2.3367e-02,  4.3576e-02, -8.8020e-02,
         1.7691e-02, -8.8886e-02,  4.1753e-02, -2.1701e-02, -8.5994e-02,
         3.9223e-02, -3.5583e-03, -3.5557e-02, -5.4252e-03, -3.8684e-02,
        -6.2849e-02, -2.0410e-02, -1.8903e-02,  7.7676e-03, -1.3780e-02,
         1.2848e-02, -2.5845e-02, -7.8153e-02, -8.3382e-03,  4.1615e-02,
        -6.2042e-02, -6.8089e-03, -1.1373e-02,  3.3538e-02,  1.6575e-02,
        -2.2932e-03, -9.3308e-02,  4.1184e-02, -1.0956e-02, -4.2109e-02,
        -8.4873e-02, -5.6160e-02,  6.4599e-02,  5.6144e-02,  8.2612e-02,
         9.7023e-02,  7.9536e-02,  1.8759e-02, -7.1633e-02, -1.7159e-02,
        -3.2912e-02, -5.2823e-02,  5.5030e-03,  2.3662e-02,  1.0059e-01,
        -8.7719e-03,  5.0015e-02, -1.8977e-02,  3.5674e-02, -1.0900e-02,
        -5.5994e-02])
net.mlp.net.0.batch_norm.running_mean tensor([0.0967, 0.4657, 0.2402, 1.0473, 0.0378, 0.3405, 0.1287, 0.0480, 0.0946,
        0.0575, 0.2478, 1.3407, 0.3496, 0.4678, 0.0898, 0.3971, 0.1018, 0.4046,
        0.7564, 0.3918, 0.9039, 0.1970, 0.0308, 0.0707, 0.4905, 0.0295, 0.0887,
        0.1077, 0.3589, 0.0686, 0.0477, 0.1071, 1.3207, 0.5298, 0.2744, 0.8505,
        0.0200, 0.0040, 0.2009, 0.0261, 0.1725, 0.4830, 0.4643, 0.1862, 1.0783,
        0.1339, 0.5713, 0.0496, 0.4941, 0.2446, 0.1148, 0.2478, 0.8884, 0.2244,
        0.0145, 0.0021, 0.0735, 0.1174, 0.9935, 0.0557, 0.1599, 0.3341, 0.6702,
        0.3910, 0.3011, 0.2863, 0.1484, 0.0059, 0.0432, 0.0709, 0.2331, 0.1015,
        0.3228, 0.0782, 0.2592, 0.1199, 0.8210, 0.1231, 0.0862, 0.8692, 0.4081,
        0.0116, 0.3455, 0.1249, 0.0530, 0.7282, 0.1085, 0.2645, 0.0023, 0.2370,
        0.6750, 0.1175, 0.7536, 0.0224, 0.4761, 0.0396, 0.0285, 1.4060, 0.0179,
        0.0799, 0.3301, 0.0080, 0.1639, 0.2731, 0.1594, 0.0759, 0.0244, 0.0128,
        0.0117, 0.7820, 0.1892, 0.9967, 0.3173, 0.5698, 0.2302, 0.7571, 0.2356,
        1.2040, 0.0288, 0.2319, 0.0700, 0.0052, 0.1561, 0.3903, 0.0083, 0.2753,
        0.0088, 0.1807, 0.1498, 0.1291, 0.3906, 0.2775, 0.6657, 0.0586, 0.2975,
        1.0579, 0.1193, 0.2269, 0.0708, 0.5408, 0.0049, 0.0083, 0.0864, 0.0549,
        0.6137, 1.1421, 0.1090, 0.1000, 0.0170, 0.1221, 0.1054, 0.3509, 0.3471,
        0.0490, 0.0045, 0.0203, 0.4684, 0.4684, 0.0813, 0.8866, 1.0685, 0.6535,
        0.6031, 0.1416, 0.0217, 0.1033, 0.2603, 0.2368, 0.5099, 0.1285, 0.0618,
        0.5362, 0.2388, 0.4293, 0.5320, 0.2704, 0.5653, 0.0339, 0.0031, 0.4993,
        0.1353, 0.5440, 0.0956, 1.0409, 0.6832, 0.0564, 0.2750, 0.9954, 0.0790,
        0.5196, 0.1758, 0.0047, 0.3838, 0.7130, 0.0031, 0.0157, 0.1920, 0.3555,
        0.2326, 0.0509, 0.0824, 0.0885, 1.1236, 0.2491, 0.2435, 0.5355, 0.3177,
        0.1506, 0.1920, 0.1556, 0.4631, 0.2446, 0.1044, 0.2301, 1.3767, 0.7662,
        0.0564, 0.7005, 0.1376, 0.0312, 0.0947, 0.0132, 0.3240, 0.5234, 0.0433,
        0.2374, 0.0633, 0.5001, 0.5252, 0.1024, 0.3528, 0.0543, 0.4391, 0.3933,
        0.0404, 0.5565, 0.0183, 0.2451, 0.1343, 0.2054, 0.8970, 0.4585, 0.2522,
        0.6582, 0.0553, 1.3579, 0.4168, 0.0971, 0.5373, 0.3815, 0.0891, 0.3164,
        0.1559, 0.3874, 0.7332, 0.2874])
net.mlp.net.0.batch_norm.running_var tensor([0.0219, 0.1054, 0.1177, 0.2324, 0.0119, 0.0718, 0.3222, 0.0130, 0.0370,
        0.0187, 0.4534, 0.1818, 0.1260, 0.2128, 0.0389, 0.1594, 0.0516, 0.3022,
        0.1636, 0.1848, 0.1378, 0.1287, 0.0237, 0.0222, 0.1682, 0.0131, 0.0315,
        0.0461, 0.1171, 0.0362, 0.0214, 0.1442, 0.8003, 0.1979, 0.0843, 0.1167,
        0.0094, 0.0032, 0.0942, 0.0133, 0.1828, 1.2072, 0.1644, 0.0632, 0.2369,
        0.0466, 0.2356, 0.0175, 0.3219, 0.4460, 0.0768, 0.1078, 0.4275, 0.0685,
        0.0121, 0.0023, 0.0772, 0.1731, 0.1946, 0.0192, 0.0622, 0.1291, 0.2781,
        0.1044, 0.1147, 0.1034, 0.0874, 0.0054, 0.0219, 0.1104, 0.0803, 0.0250,
        0.0878, 0.1250, 0.1959, 0.0349, 0.5430, 0.1456, 0.0398, 0.2487, 0.1074,
        0.0103, 0.2750, 0.0842, 0.0246, 0.4668, 0.0369, 0.1215, 0.0028, 0.0499,
        0.2428, 0.0485, 0.1409, 0.0122, 0.1614, 0.0164, 0.0425, 0.7175, 0.0079,
        0.0245, 0.1484, 0.0040, 0.0644, 0.1028, 0.0665, 0.0383, 0.0084, 0.0040,
        0.0084, 0.1496, 0.0665, 0.1703, 0.1377, 0.2271, 0.0638, 0.3334, 0.0942,
        0.2994, 0.0105, 0.1017, 0.0679, 0.0033, 0.1456, 0.1470, 0.0059, 0.1174,
        0.0035, 0.3053, 0.0728, 0.0768, 0.2212, 0.0959, 0.1340, 0.0208, 0.1054,
        0.1978, 0.0742, 0.1264, 0.0262, 0.8477, 0.0029, 0.0037, 0.0730, 0.0263,
        0.1045, 0.2433, 0.0393, 0.0253, 0.0120, 0.0277, 0.0306, 0.1440, 0.1674,
        0.0153, 0.0028, 0.0078, 0.0778, 0.6734, 0.0322, 0.2118, 0.1176, 0.4753,
        0.1936, 0.0607, 0.0269, 0.1893, 0.0907, 0.1106, 0.0714, 0.0503, 0.1042,
        0.2232, 0.0790, 0.1501, 0.1519, 0.1298, 0.1323, 0.0164, 0.0025, 0.1650,
        0.0423, 0.2371, 0.0346, 0.2353, 0.2619, 0.0817, 0.1451, 0.1687, 0.0335,
        0.1398, 0.2305, 0.0038, 0.2324, 0.2099, 0.0031, 0.0078, 0.0709, 0.0791,
        0.0940, 0.0204, 0.0178, 0.1349, 0.2798, 0.2003, 0.1212, 0.1578, 0.1053,
        0.0550, 0.0787, 0.0545, 0.1699, 0.0772, 0.1370, 0.0939, 0.1889, 0.1831,
        0.0247, 0.1368, 0.0781, 0.0199, 0.0391, 0.0057, 0.2935, 0.2434, 0.0197,
        0.0805, 0.0433, 0.3134, 0.3069, 0.0688, 0.1559, 0.0210, 0.1700, 0.1521,
        0.0173, 0.1555, 0.0084, 0.3651, 0.0575, 0.0871, 0.1480, 0.1096, 0.1110,
        0.1253, 0.0263, 0.4906, 0.1423, 0.0368, 0.1870, 0.0836, 0.0439, 0.1113,
        0.1872, 0.1316, 0.7926, 0.0955])
net.mlp.net.0.batch_norm.num_batches_tracked tensor(60)
net.mlp.net.1.linear.weight tensor([[-0.0897, -0.0212,  0.0925,  ..., -0.0699,  0.0842, -0.1254],
        [ 0.0011,  0.0645,  0.0505,  ..., -0.0026, -0.0423, -0.0590],
        [-0.0628,  0.0113,  0.1884,  ..., -0.0401,  0.0661, -0.0072],
        ...,
        [-0.0021,  0.1017,  0.1582,  ..., -0.0446, -0.0540,  0.0649],
        [-0.0683,  0.0133,  0.0944,  ...,  0.0769,  0.0905, -0.0087],
        [ 0.0951, -0.0420, -0.0765,  ...,  0.0348, -0.1359, -0.0255]])
net.mlp.net.1.linear.bias tensor([ 1.1166e-01,  1.2296e-01,  1.0659e-02,  3.2296e-02,  2.7543e-02,
         8.6998e-04, -4.5891e-02, -1.7449e-03,  1.7679e-02, -5.8757e-02,
        -9.5740e-02,  2.7814e-02, -1.4959e-01,  1.9914e-03,  4.2208e-02,
         8.5360e-02, -3.4825e-02,  3.0379e-02,  7.1178e-02, -8.9182e-02,
        -4.8194e-02,  2.8331e-02,  1.5006e-02, -2.3405e-02, -2.9194e-03,
         3.7469e-02, -1.4456e-02,  2.9034e-02,  8.4969e-02, -1.0422e-01,
         1.5797e-02,  6.3933e-02,  3.6595e-02,  3.6562e-02, -1.6493e-02,
        -9.3549e-02, -2.9080e-02, -1.3022e-01,  3.3721e-02,  1.8104e-02,
        -1.1307e-01,  9.0542e-02, -9.7409e-03, -7.0642e-02, -2.8194e-02,
         5.6395e-03,  1.2564e-02, -9.2028e-02,  1.5536e-02, -8.1036e-02,
         8.0109e-02,  5.3058e-02, -3.0189e-02, -3.5739e-02, -1.2342e-02,
        -3.3619e-02, -1.0322e-01, -1.3253e-01,  2.4226e-03,  4.6556e-02,
         1.0974e-01, -1.6970e-02, -1.5999e-01,  1.6506e-01, -7.2100e-02,
         8.0897e-02,  4.5744e-02, -1.0310e-01,  8.9131e-02,  1.5470e-02,
         2.7863e-02, -6.6349e-02,  4.0872e-02,  4.4885e-02, -7.1710e-02,
        -3.8412e-03,  5.8512e-02, -7.6164e-02, -4.3946e-02, -5.6698e-03,
        -8.7687e-02,  2.6157e-02,  2.2360e-02, -4.0468e-03,  7.5790e-02,
        -8.4520e-02, -6.7279e-02, -7.0134e-02, -1.0608e-03, -6.0984e-02,
         7.0571e-02, -3.6314e-02,  3.3920e-02, -7.6085e-02,  3.9194e-02,
         1.1294e-02, -5.2488e-02,  1.6577e-02,  5.9851e-03, -7.7957e-02,
        -4.6671e-02,  5.9963e-02, -1.2994e-02, -7.1648e-02, -9.3440e-03,
         3.6039e-02, -4.0447e-02,  2.3376e-02, -1.1368e-01, -1.7793e-02,
         4.8767e-02,  1.0352e-02, -5.4298e-02,  2.8170e-02, -6.0376e-02,
        -1.1273e-01, -1.2304e-01, -2.3127e-02,  3.6135e-02, -1.0401e-02,
         3.9688e-02,  4.0395e-02,  4.0747e-02, -1.1020e-03, -5.5659e-02,
        -5.5156e-02, -3.9350e-02, -1.3809e-01,  2.4711e-02, -4.7258e-02,
        -1.2939e-02, -2.5472e-02, -8.5854e-02, -2.1274e-02,  7.5720e-02,
         1.5990e-03, -1.2042e-02, -4.4583e-02,  5.0595e-03, -3.8869e-02,
         3.8371e-02,  2.4004e-02,  4.0158e-02, -5.7604e-02,  2.4483e-03,
         4.9644e-02, -1.0079e-01,  9.8338e-02,  2.8533e-02,  1.8688e-01,
        -8.0135e-02, -1.2567e-01,  6.1704e-02, -4.4323e-03,  1.0221e-01,
         3.4622e-02,  2.9593e-02,  2.2772e-02, -1.1065e-04, -3.2260e-03,
         4.0711e-02, -7.4570e-02, -7.1999e-02, -1.8836e-02, -2.1015e-02,
         1.9361e-02, -1.0244e-02, -7.3527e-02, -4.0495e-02, -8.6939e-02,
         2.2635e-02,  2.9823e-03, -5.9385e-03, -9.9238e-04, -6.2380e-03,
        -1.2697e-01, -1.1304e-01,  2.4013e-02, -1.1526e-02, -1.0891e-01,
         1.8742e-02,  2.5015e-03, -4.6765e-02, -4.9006e-02,  1.6277e-02,
        -5.3079e-02, -2.0147e-02, -6.1450e-02,  4.1712e-02, -3.3342e-02,
         9.0157e-03, -8.9455e-03,  1.9927e-02,  4.4840e-02, -6.1805e-02,
         4.6210e-02,  4.6229e-02, -4.8065e-02,  9.3333e-02,  1.4597e-01,
        -1.7037e-03, -9.8390e-02,  8.2615e-02,  3.4288e-02,  2.9474e-02,
        -4.5301e-02, -1.4920e-01,  7.3572e-02,  7.0429e-02,  5.2648e-02,
         4.1492e-02, -7.6947e-03,  8.9354e-02, -6.6567e-03, -1.3788e-02,
         3.9009e-03, -7.5414e-02, -6.5014e-02,  7.7469e-02,  6.7182e-02,
         7.4544e-02, -1.9744e-02,  1.8957e-02, -8.5238e-04, -2.2241e-02,
        -4.8647e-02, -2.9768e-02,  1.6426e-02,  4.6883e-03, -4.3625e-02,
         2.1222e-02, -7.5568e-02,  1.1502e-01, -6.1546e-05, -2.5653e-02,
        -6.2420e-02, -2.6239e-02,  9.2003e-03, -2.4064e-02,  2.9650e-02,
         5.4802e-02,  1.7105e-02,  2.0206e-03, -2.0130e-02,  1.1226e-02,
        -4.8618e-02, -2.2564e-02, -8.0753e-02,  4.6018e-02, -4.8298e-02,
         7.8573e-02, -7.3150e-02,  3.0295e-02, -1.6709e-02, -6.9955e-03,
         9.9456e-02])
net.mlp.net.1.batch_norm.weight tensor([0.8581, 0.8836, 0.8532, 0.8612, 0.8688, 0.8575, 0.8897, 0.9014, 0.9210,
        0.8725, 0.8442, 0.8798, 0.8937, 0.8114, 0.8639, 0.8022, 0.8341, 0.9074,
        0.8675, 0.8756, 0.8958, 0.8375, 0.8227, 0.8078, 0.8661, 0.8851, 0.8843,
        0.8432, 0.8208, 0.8808, 0.8608, 0.8257, 0.8568, 0.8299, 0.8536, 0.8747,
        0.8196, 0.8461, 0.8403, 0.9201, 0.8997, 0.7930, 0.8751, 0.8845, 0.8671,
        0.8548, 0.8688, 0.8887, 0.8856, 0.8848, 0.8799, 0.8396, 0.8301, 0.8591,
        0.8681, 0.8964, 0.9111, 0.8426, 0.8743, 0.8295, 0.7657, 0.8792, 0.7755,
        0.8706, 0.9001, 0.8788, 0.8723, 0.8371, 0.8663, 0.8714, 0.8551, 0.8432,
        0.7898, 0.8110, 0.9421, 0.8535, 0.8979, 0.8181, 0.8975, 0.8766, 0.8039,
        0.9312, 0.9065, 0.8183, 0.8512, 0.8732, 0.8585, 0.8737, 0.8478, 0.8836,
        0.9043, 0.8994, 0.9339, 0.8489, 0.8463, 0.8640, 0.8893, 0.8726, 0.7788,
        0.8627, 0.8431, 0.8984, 0.8622, 0.8829, 0.8851, 0.8496, 0.8699, 0.8253,
        0.8667, 0.8668, 0.8631, 0.8526, 0.8637, 0.8597, 0.8105, 0.8234, 0.8490,
        0.8745, 0.8909, 0.8826, 0.8101, 0.8582, 0.8379, 0.7930, 0.8748, 0.8459,
        0.8453, 0.8621, 0.8573, 0.8516, 0.8688, 0.8840, 0.8690, 0.8646, 0.9466,
        0.8735, 0.8346, 0.7469, 0.8568, 0.8607, 0.8697, 0.8554, 0.8203, 0.8732,
        0.8422, 0.8348, 0.8910, 0.8082, 0.8815, 0.8230, 0.8414, 0.8206, 0.8504,
        0.8620, 0.8637, 0.8569, 0.9041, 0.8437, 0.8546, 0.8202, 0.8750, 0.8162,
        0.8351, 0.7964, 0.8337, 0.8796, 0.8459, 0.8269, 0.8902, 0.8708, 0.8160,
        0.8236, 0.8027, 0.8109, 0.8663, 0.8250, 0.8829, 0.9010, 0.9019, 0.8664,
        0.8630, 0.8646, 0.7942, 0.8525, 0.8484, 0.8737, 0.8353, 0.8517, 0.8741,
        0.8900, 0.8608, 0.8464, 0.9268, 0.8421, 0.8995, 0.8926, 0.8465, 0.8025,
        0.8178, 0.9111, 0.8608, 0.8563, 0.8780, 0.8389, 0.8437, 0.8446, 0.8625,
        0.8301, 0.8737, 0.9131, 0.8056, 0.8643, 0.8511, 0.7946, 0.8481, 0.9020,
        0.8648, 0.8770, 0.8356, 0.9006, 0.8713, 0.8506, 0.8770, 0.8723, 0.8646,
        0.8378, 0.8598, 0.8480, 0.8734, 0.8969, 0.8779, 0.8848, 0.9062, 0.8442,
        0.9049, 0.8895, 0.8744, 0.8429, 0.8769, 0.8983, 0.9045, 0.8489, 0.8443,
        0.8311, 0.8497, 0.8653, 0.9069, 0.8353, 0.8316, 0.8849, 0.8365, 0.8433,
        0.8672, 0.8651, 0.8450, 0.8258])
net.mlp.net.1.batch_norm.bias tensor([ 0.0064,  0.0749, -0.0028,  0.0596, -0.0284,  0.0452,  0.0333,  0.0131,
         0.0176, -0.0043, -0.0625, -0.1233, -0.0360,  0.0188,  0.0322, -0.0204,
         0.0093,  0.0403,  0.0059,  0.0615,  0.0177, -0.0521, -0.0574,  0.0225,
        -0.0156, -0.0226,  0.0308, -0.1288, -0.0321,  0.0477, -0.0755, -0.0203,
         0.0454,  0.1130, -0.0147,  0.0865, -0.0327, -0.0161,  0.0902,  0.0552,
        -0.0478, -0.0104,  0.0004, -0.0159,  0.0031,  0.0198, -0.0997,  0.0398,
        -0.0420, -0.0626,  0.0611, -0.0463, -0.0451, -0.0127, -0.0118, -0.0059,
        -0.0405, -0.0426, -0.0553,  0.0915,  0.0259,  0.0214, -0.1589, -0.0373,
        -0.0055,  0.0449,  0.0020,  0.0345,  0.0666,  0.0022, -0.0425, -0.0036,
        -0.0429,  0.0585,  0.0301, -0.0587,  0.0326, -0.0636, -0.0214, -0.0683,
        -0.0286, -0.0900, -0.0780, -0.0116, -0.0243,  0.0597,  0.0275, -0.0178,
         0.0144,  0.0266,  0.0990,  0.0441,  0.0097, -0.0496,  0.0702,  0.0259,
         0.0056,  0.0614, -0.0125, -0.0005,  0.0032,  0.0258,  0.0248, -0.0268,
         0.0319,  0.0308, -0.0026, -0.0077,  0.0186,  0.0226, -0.0075, -0.0126,
        -0.1355, -0.0331, -0.0244,  0.0282,  0.0096, -0.0226,  0.0339, -0.0187,
        -0.0125,  0.0301, -0.0344, -0.0249, -0.0401,  0.0497,  0.0077,  0.0635,
        -0.0474, -0.0243,  0.0364, -0.0480, -0.0487, -0.0097,  0.0017,  0.0120,
         0.0002, -0.0646, -0.0322,  0.0574, -0.0006,  0.0602, -0.0319, -0.0526,
        -0.0716, -0.0623, -0.0476,  0.0517,  0.0477, -0.1695,  0.0062, -0.0301,
        -0.0381,  0.0016,  0.0046, -0.0498,  0.0386, -0.0498, -0.0192,  0.0353,
         0.0187, -0.0490,  0.1101, -0.0579,  0.0088,  0.0412,  0.0440, -0.0460,
        -0.0020,  0.0051,  0.0539, -0.0273,  0.0065,  0.0031,  0.0267,  0.0333,
        -0.0114,  0.0752, -0.0925,  0.0260, -0.0118, -0.0715, -0.0045, -0.0550,
        -0.0417,  0.0581, -0.0277, -0.0542, -0.0728, -0.0767,  0.0746, -0.0010,
        -0.0343,  0.0608,  0.0398, -0.0107,  0.0224, -0.0656, -0.0194,  0.0179,
         0.0037,  0.0048, -0.0661, -0.0869,  0.0492,  0.0687, -0.0013, -0.0875,
         0.1773, -0.0479, -0.0112,  0.0131, -0.0330, -0.0158, -0.0248, -0.0232,
        -0.0078,  0.0686, -0.0348, -0.0068, -0.0199,  0.0357,  0.0111,  0.0092,
        -0.0483,  0.0237, -0.1541, -0.0200,  0.0793, -0.0203,  0.0498,  0.0624,
         0.0542, -0.0209,  0.0149,  0.0020,  0.0116, -0.0303,  0.0544,  0.0590,
         0.0211, -0.0424,  0.0460,  0.0034,  0.0350,  0.0158, -0.0192,  0.0336,
        -0.0426, -0.0135, -0.0006, -0.0781,  0.0760, -0.0457, -0.0703,  0.0752])
net.mlp.net.1.batch_norm.running_mean tensor([0.9870, 1.3919, 1.0939, 0.8989, 1.2706, 0.9171, 0.8768, 1.2629, 1.5480,
        0.9217, 1.2949, 0.9978, 1.1339, 0.9694, 1.0988, 1.1729, 0.8493, 1.1791,
        1.0353, 1.1438, 0.9044, 1.0042, 1.0266, 0.9824, 0.7611, 1.1206, 1.0270,
        0.7689, 0.8979, 0.9211, 0.8577, 1.1637, 1.2840, 1.3973, 1.0099, 0.7458,
        1.1472, 0.8295, 1.1625, 0.9051, 0.8111, 0.9315, 0.8964, 0.8052, 0.9173,
        1.2264, 0.9845, 1.0304, 0.9807, 0.8398, 1.0091, 1.0590, 0.7981, 0.9685,
        0.7974, 0.7246, 0.9334, 0.9778, 0.9311, 1.1019, 1.0244, 0.9943, 0.9389,
        1.0991, 0.8442, 1.6483, 0.8620, 0.8666, 1.1258, 1.1824, 0.9908, 0.8580,
        1.4058, 1.0297, 1.1428, 0.9304, 0.9793, 0.7257, 1.3533, 0.8039, 0.9030,
        0.9702, 1.1280, 1.3292, 1.3730, 1.1689, 1.0518, 0.7879, 1.4459, 1.1148,
        1.1306, 1.0244, 1.0329, 0.8328, 0.8756, 0.8295, 1.0045, 1.1214, 0.9362,
        1.0426, 0.7291, 1.0465, 0.9676, 0.8043, 0.8943, 0.7233, 1.1805, 1.1377,
        0.8959, 0.9040, 1.0404, 0.8775, 1.0082, 1.0098, 0.6464, 0.7924, 1.0119,
        1.0627, 1.1044, 0.9114, 0.8212, 0.9108, 1.2009, 0.9777, 0.9514, 0.8311,
        0.7817, 1.1870, 0.8512, 0.9904, 1.0993, 0.8778, 0.9386, 0.9100, 1.0538,
        1.0125, 1.0290, 0.9139, 0.9539, 0.9949, 1.0125, 1.1752, 0.7974, 0.8732,
        0.8480, 0.9172, 1.2788, 0.9458, 0.9889, 1.1370, 1.0581, 0.9176, 1.0116,
        1.1873, 1.0366, 1.2630, 0.8184, 0.8579, 0.8109, 0.9365, 0.8769, 1.0519,
        0.7295, 0.9565, 1.2043, 1.2978, 1.0837, 0.9804, 1.3344, 1.1089, 0.6958,
        0.8089, 0.9764, 1.0603, 0.9047, 0.8144, 0.8844, 1.1231, 1.0245, 1.0400,
        1.1069, 0.9914, 0.9208, 1.0573, 1.0660, 0.8707, 1.2138, 0.9274, 1.0341,
        1.1017, 1.1891, 1.1551, 1.1406, 0.9542, 1.1148, 1.2023, 0.9401, 1.0966,
        0.9416, 1.0480, 1.1981, 0.8885, 1.2198, 1.0008, 1.0331, 0.6978, 0.9445,
        1.1231, 1.3699, 1.2327, 0.9901, 0.9086, 1.3475, 0.8725, 0.7324, 0.7838,
        0.7589, 0.8582, 0.9636, 0.8731, 1.2311, 0.9135, 1.0330, 1.4533, 1.1859,
        0.8496, 0.8786, 1.0508, 1.1819, 0.9796, 1.4006, 1.0458, 1.1238, 1.0858,
        0.8599, 1.1978, 0.8082, 0.8539, 1.1382, 1.1041, 1.1337, 1.0016, 0.9969,
        0.8446, 0.9088, 0.8886, 1.1120, 1.1057, 1.3146, 0.9953, 0.9462, 0.6073,
        0.9843, 0.9643, 0.8803, 1.0338])
net.mlp.net.1.batch_norm.running_var tensor([ 1.9230,  3.2572,  1.9576,  2.7969,  2.4417,  1.7583,  1.7786,  3.0726,
         4.2027,  1.8474,  3.3903,  5.9654,  2.8650,  4.0619,  2.4621,  6.0126,
         1.6402,  3.1130,  2.1428,  6.4373,  2.4592,  2.5407,  2.8636,  4.6312,
         1.9512,  6.0838,  4.7973,  2.0723,  1.4332,  2.0470,  3.6361,  5.0059,
         6.0052,  3.8333,  3.3705,  1.0822,  8.3177,  2.3904,  5.8359,  3.0877,
         2.7517,  1.4755,  2.5726,  2.6096,  2.0509,  5.6516,  2.7437,  2.5470,
         2.5946,  5.4617,  2.8736,  3.7146,  1.4256,  2.4014,  2.2252,  1.0681,
         2.2395,  2.0097,  1.9026,  3.1326,  2.8021,  6.1123,  3.6587,  2.3705,
         1.6144,  4.4934,  1.6654,  1.9160,  2.0322,  2.1327,  3.2585,  2.9173,
         6.2557,  3.0096,  2.8526,  3.1056,  2.1816,  1.8591,  3.2811,  1.7850,
         3.0525,  2.2361,  2.8615,  7.2854,  2.6323,  3.0716,  2.8055,  1.7001,
         4.1521,  3.5756,  2.2543,  2.0340,  2.3160,  2.2852,  4.5662,  1.9004,
         1.9663,  2.0584,  2.7891,  3.9672,  1.4692,  2.6395,  3.1881,  1.6139,
         3.0033,  1.6604,  9.0854,  3.9043,  1.9484,  1.8054,  2.6078,  1.7943,
         2.1625,  1.9888,  0.9486,  2.1261,  3.6679,  2.3927,  2.5803,  2.9027,
         1.9542,  2.0838,  6.7994,  2.2640,  2.1659,  3.1304,  1.7168,  9.3611,
         1.5570,  2.2063,  5.0893,  3.4865,  2.1329,  1.6960,  2.8763,  2.9518,
         3.1200,  1.8017,  1.6770,  2.0393,  2.3386,  4.7392,  1.2711,  3.7900,
         1.4227,  1.8843,  3.1783,  3.4278,  4.2195,  2.5711,  2.3557,  2.8664,
         2.1167,  2.6959,  2.9149,  3.5786,  1.7804,  2.0878,  1.5084,  2.9338,
         1.7539,  2.8735,  1.3847,  2.5720,  2.5235, 10.9947,  4.8921,  1.9985,
         3.1257,  2.5249,  1.7403,  1.8770,  1.9267,  2.5179,  1.8076,  1.5779,
         2.0711,  2.0774,  4.0138,  2.3247,  2.9498,  1.9919,  2.8946,  4.5398,
         6.7701,  1.9806,  6.0110,  2.0701,  2.5097,  6.4361,  2.4868,  5.2380,
         2.7903,  2.6521,  2.6052,  2.9653,  1.3936,  2.0863,  1.9361,  1.9731,
         4.3856,  5.3214,  2.6510,  3.3888,  3.6289,  2.8323,  2.1660,  4.1527,
        11.2728,  6.1730,  2.5767,  2.0078,  7.4325,  1.7056,  1.3934,  1.3075,
         1.2021,  5.3879,  3.2919,  1.9672,  2.5679,  1.9795,  4.6150,  4.4189,
         7.6415,  1.3497,  1.5895,  2.3799,  3.2159,  2.1046,  3.2909,  2.9339,
         3.1972,  2.2968,  2.3208,  2.8688,  1.8736,  2.8420,  3.2499,  2.4113,
         6.2073,  1.8516,  2.0759,  1.6851,  1.6832,  3.9299,  2.9203,  2.0993,
         3.2224,  3.4930,  5.6207,  1.1012,  1.5550,  3.7963,  1.7217,  2.2064])
net.mlp.net.1.batch_norm.num_batches_tracked tensor(60)
net.mlp.net.2.weight tensor([[ 8.9521e-04,  3.0945e-02,  3.5927e-02, -1.8575e-02, -5.5617e-03,
         -2.7782e-02, -2.5401e-02, -1.8874e-02,  3.2152e-02, -2.0181e-02,
         -4.2509e-03,  2.0152e-02,  1.3284e-03,  1.4886e-02,  4.3363e-03,
          3.2440e-03, -2.2303e-02, -2.7443e-02, -2.7415e-02, -1.5733e-02,
         -1.1419e-02,  5.9557e-04, -2.3614e-02,  8.2902e-03, -1.5514e-02,
         -1.0534e-02,  2.4814e-02,  9.4245e-03, -2.4130e-03,  3.4248e-02,
          4.8635e-03, -5.6384e-03, -1.7342e-02,  8.5393e-04, -1.5397e-02,
          2.5014e-02,  1.6458e-02,  2.1716e-02, -1.3093e-02, -2.5542e-02,
         -3.4507e-02, -6.8755e-04,  1.9924e-02, -9.5887e-04,  3.5593e-02,
          2.0800e-02, -5.8001e-03, -3.1772e-02,  3.8145e-02,  1.8429e-02,
         -3.7678e-02, -4.1551e-03, -6.6310e-03, -9.7553e-03,  1.4449e-02,
          3.7198e-02,  4.5110e-02,  1.2630e-02,  2.8355e-02, -3.0217e-03,
         -1.2810e-02,  1.4542e-02, -1.6440e-03, -6.4073e-03, -1.7310e-02,
          4.5533e-02, -1.2035e-02,  3.4141e-03, -1.7159e-02,  6.9182e-03,
          2.3254e-02,  5.6710e-03,  3.2682e-02,  2.9691e-03, -6.2315e-02,
         -7.5658e-03, -2.4425e-02, -1.0617e-02,  3.3001e-02,  2.2883e-03,
          2.7250e-02, -4.3511e-02, -3.9821e-02,  1.0799e-03,  2.4373e-02,
          3.0661e-04, -3.1138e-03,  2.4190e-02,  2.4732e-02,  1.7852e-02,
          1.6537e-02, -1.4530e-02, -3.7242e-02, -1.4082e-02, -5.5720e-03,
         -3.8142e-03,  4.0418e-02,  1.3146e-02,  1.3316e-02,  1.5710e-02,
         -9.3010e-03,  4.6997e-04, -3.2499e-03, -4.1869e-03,  2.1228e-02,
          1.6437e-03, -8.0102e-03,  8.6517e-03,  2.2517e-02, -5.1613e-03,
         -1.8128e-02, -1.4052e-02, -2.5485e-02,  6.3103e-03,  6.9223e-03,
          2.1662e-02, -7.4752e-03, -1.0615e-02,  3.2558e-02, -2.0369e-02,
         -8.3685e-03,  1.0038e-02,  1.6588e-02, -3.3755e-03, -2.9702e-02,
         -2.4589e-02, -4.4574e-03, -3.9757e-03,  2.0698e-02, -1.6032e-02,
         -9.4855e-03, -5.4421e-04, -9.5744e-03,  3.9996e-05, -5.1344e-02,
          6.0901e-04,  6.6987e-03, -6.2086e-03,  2.5572e-02, -3.2758e-02,
         -7.1686e-03, -1.0113e-03, -2.8986e-03, -4.3004e-03, -2.6830e-02,
         -2.9835e-02,  2.2962e-02, -1.3272e-02, -1.0383e-02, -1.5393e-02,
         -2.1360e-04, -5.1539e-03,  1.8970e-02,  8.8845e-03, -3.0816e-02,
          2.0575e-02, -1.8996e-03, -5.6111e-03,  1.5330e-02, -4.7786e-03,
          2.0723e-02, -1.8414e-02,  4.7710e-03,  4.6838e-02, -3.0873e-03,
         -1.2777e-02, -7.7635e-03,  6.7581e-03,  3.4005e-02,  1.1507e-02,
         -1.1736e-02, -1.4839e-02, -3.5553e-02, -3.4760e-02,  6.2325e-04,
         -1.7557e-02, -8.6511e-04,  2.0216e-02, -5.7203e-02,  8.2465e-04,
         -6.8664e-03,  3.7646e-03,  2.8923e-03, -1.0579e-02, -1.7325e-02,
         -1.4245e-03, -1.9464e-02,  3.9312e-02, -2.7335e-02, -1.3279e-02,
          1.8364e-02, -2.2741e-02, -5.8309e-02,  1.1131e-02, -3.3231e-02,
         -2.1272e-02,  7.5880e-04, -5.5109e-03,  5.9592e-04, -3.8727e-02,
         -2.3356e-02,  6.6710e-03,  1.0179e-02, -6.0631e-04,  1.7995e-02,
          1.8929e-02, -1.0480e-02, -2.1597e-02,  2.3587e-02,  3.7104e-02,
         -1.9419e-02,  2.8918e-02,  6.5315e-03,  1.4031e-02,  9.2284e-03,
          1.3373e-02,  1.0067e-02,  1.5746e-02,  3.2550e-02, -2.2721e-02,
         -7.7373e-03,  2.3536e-02, -1.7814e-02,  5.8778e-03, -9.8957e-03,
          1.4145e-02, -6.2255e-03, -2.2942e-02, -7.9304e-03, -2.8661e-02,
          8.3768e-03,  2.8293e-02, -2.8656e-02,  2.0942e-02, -4.2178e-02,
         -1.3195e-02, -6.9806e-03,  2.6254e-02, -2.7120e-02,  3.4867e-02,
         -2.7820e-02, -2.1819e-02,  9.0078e-03, -2.0337e-02, -8.6799e-05,
         -6.0499e-03, -9.9745e-03, -8.8382e-03, -1.2888e-02,  3.0074e-02,
          1.7365e-02, -2.0304e-02,  2.6235e-02, -2.7057e-02, -7.6264e-03,
         -1.0377e-02]])
