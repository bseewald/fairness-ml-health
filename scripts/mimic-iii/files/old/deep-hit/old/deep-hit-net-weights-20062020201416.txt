Weights: 
embeddings.embeddings.0.weight tensor([[ 0.2925, -0.0560],
        [ 0.2026, -0.1167],
        [ 0.1490,  0.0234],
        [ 0.2066, -0.3036]])
embeddings.embeddings.1.weight tensor([[-0.1747,  0.0895],
        [-0.1112,  0.3203],
        [ 0.0465, -0.1802],
        [-0.0162, -0.0984],
        [ 0.2004, -0.0515]])
embeddings.embeddings.2.weight tensor([[ 0.0214,  0.2599, -0.0522],
        [-0.2310,  0.1436, -0.1020],
        [ 0.1891, -0.1416, -0.0100],
        [-0.0356,  0.1842, -0.0595],
        [ 0.1925,  0.1679, -0.1928],
        [ 0.1097, -0.2351,  0.2209]])
embeddings.embeddings.3.weight tensor([[-0.0558,  0.0654],
        [-0.0426, -0.4141],
        [ 0.3429,  0.2026],
        [-0.1060,  0.1294]])
embeddings.embeddings.4.weight tensor([[-0.1383,  0.1139],
        [ 0.3370,  0.0978],
        [-0.3447, -0.0212],
        [ 0.1553,  0.0412]])
mlp.net.0.linear.weight tensor([[-0.2228,  0.1877,  0.0807,  ..., -0.1247,  0.0507,  0.1068],
        [ 0.1094, -0.2635,  0.0924,  ...,  0.1961, -0.0100, -0.0513],
        [-0.2968,  0.0146,  0.0714,  ...,  0.2878,  0.0884,  0.0893],
        ...,
        [-0.2420, -0.0233,  0.0463,  ..., -0.0800,  0.1092,  0.2240],
        [ 0.0528, -0.3495,  0.0309,  ...,  0.2195,  0.1416,  0.0798],
        [-0.1398,  0.2183,  0.0899,  ..., -0.2034,  0.0635,  0.1119]])
mlp.net.0.linear.bias tensor([ 0.0340,  0.1072,  0.0264,  0.1290,  0.1086, -0.0393, -0.1062, -0.0189,
        -0.0181, -0.0940,  0.0059, -0.0032,  0.1259, -0.0990,  0.0432, -0.0974,
        -0.1284, -0.0728, -0.0654,  0.0404, -0.0190, -0.0460, -0.0764,  0.0942,
        -0.0702,  0.0727, -0.0995, -0.0431, -0.0419, -0.0094, -0.1087, -0.0328,
        -0.0343, -0.0807, -0.0188,  0.0799, -0.0404,  0.1322,  0.0506,  0.0116,
         0.1321, -0.0834, -0.1115,  0.0301,  0.0037, -0.0371,  0.0212, -0.1186,
         0.0044, -0.0867, -0.1167, -0.0398, -0.0380, -0.0632, -0.0393, -0.1226,
         0.0512, -0.0417, -0.0924, -0.0799,  0.0450, -0.0905, -0.0054,  0.1302,
        -0.1024, -0.0722, -0.0826,  0.0879,  0.0451,  0.0559, -0.0097,  0.0434,
        -0.0087, -0.0260, -0.0011,  0.1039, -0.0795,  0.1349, -0.0616, -0.0653,
         0.0198, -0.0231, -0.1055,  0.0263,  0.0775, -0.0967,  0.1105, -0.0981,
        -0.0235,  0.0988, -0.0821, -0.0165,  0.0934,  0.0742, -0.0271,  0.0414,
        -0.0390,  0.1099,  0.0601, -0.0768,  0.0707, -0.0845,  0.1076,  0.0326,
        -0.0233, -0.0385,  0.0863, -0.0487, -0.0175,  0.1182, -0.0754, -0.1097,
         0.0899, -0.0293, -0.0689,  0.0015, -0.0860,  0.0537, -0.0601, -0.1001,
         0.0414, -0.0362,  0.1063, -0.1261,  0.0418,  0.1065, -0.1005,  0.0637])
mlp.net.0.batch_norm.weight tensor([0.5132, 0.5567, 0.5377, 0.5226, 0.5090, 0.5353, 0.5404, 0.5225, 0.5676,
        0.5304, 0.5346, 0.5349, 0.5278, 0.5206, 0.5303, 0.5213, 0.5421, 0.5835,
        0.5960, 0.5786, 0.5278, 0.5606, 0.5110, 0.5453, 0.5464, 0.5552, 0.5201,
        0.5371, 0.5628, 0.5275, 0.5792, 0.5883, 0.5283, 0.5622, 0.5094, 0.5094,
        0.5236, 0.5539, 0.5370, 0.5055, 0.5116, 0.5282, 0.5297, 0.5785, 0.5319,
        0.5997, 0.5340, 0.5345, 0.5270, 0.5563, 0.5712, 0.5407, 0.5451, 0.5351,
        0.5125, 0.5423, 0.5297, 0.5230, 0.5685, 0.5292, 0.5512, 0.5176, 0.5176,
        0.5110, 0.5079, 0.5314, 0.5085, 0.5231, 0.5217, 0.5541, 0.5374, 0.5273,
        0.5331, 0.5884, 0.5347, 0.5778, 0.5122, 0.5374, 0.5541, 0.5605, 0.5219,
        0.5544, 0.5122, 0.5218, 0.5336, 0.5837, 0.5458, 0.5260, 0.5167, 0.5470,
        0.5522, 0.5358, 0.5407, 0.5089, 0.5629, 0.5435, 0.5635, 0.5319, 0.5252,
        0.5616, 0.5364, 0.5823, 0.5653, 0.5528, 0.5400, 0.5163, 0.5300, 0.5382,
        0.5604, 0.5486, 0.5196, 0.5919, 0.5572, 0.5527, 0.5449, 0.5282, 0.5132,
        0.5769, 0.5170, 0.5328, 0.5251, 0.5490, 0.5574, 0.4999, 0.5439, 0.5686,
        0.5033, 0.5603])
mlp.net.0.batch_norm.bias tensor([-0.0201, -0.0189, -0.0152,  0.0213,  0.0243, -0.0180, -0.0097, -0.0148,
        -0.0234,  0.0078,  0.0253,  0.0109, -0.0080,  0.0044, -0.0026, -0.0153,
         0.0101,  0.0287, -0.0458, -0.0319,  0.0141,  0.0307,  0.0229, -0.0090,
         0.0096,  0.0128, -0.0059,  0.0095,  0.0075,  0.0105,  0.0273,  0.0004,
         0.0004,  0.0351, -0.0175, -0.0075, -0.0129, -0.0146,  0.0008,  0.0065,
         0.0196, -0.0153,  0.0201,  0.0226, -0.0050,  0.0222,  0.0133,  0.0268,
         0.0038, -0.0040, -0.0013, -0.0117,  0.0085, -0.0082,  0.0043,  0.0097,
        -0.0016,  0.0075, -0.0208, -0.0029,  0.0057, -0.0214, -0.0083, -0.0011,
         0.0032, -0.0209,  0.0068, -0.0249,  0.0217, -0.0320,  0.0053, -0.0077,
         0.0262,  0.0210,  0.0200,  0.0024,  0.0084,  0.0151,  0.0173,  0.0024,
        -0.0053, -0.0160, -0.0123, -0.0104,  0.0022, -0.0251, -0.0020, -0.0069,
         0.0175, -0.0109,  0.0043, -0.0047,  0.0057,  0.0059,  0.0175,  0.0169,
         0.0089, -0.0242, -0.0047,  0.0166, -0.0118, -0.0203,  0.0258,  0.0223,
         0.0007, -0.0089,  0.0057,  0.0116,  0.0070,  0.0179,  0.0159,  0.0110,
        -0.0125, -0.0243,  0.0054,  0.0235,  0.0009,  0.0157, -0.0053,  0.0075,
        -0.0022,  0.0019, -0.0004,  0.0167, -0.0094,  0.0122,  0.0305,  0.0200])
mlp.net.0.batch_norm.running_mean tensor([5.4645e-02, 4.3438e-01, 2.5907e-01, 7.1003e-02, 9.8345e-02, 1.2164e-03,
        6.4284e-07, 2.1884e-02, 1.3618e-01, 4.7257e-02, 1.5762e-06, 1.5491e-02,
        3.6177e-01, 2.9464e-02, 8.8159e-02, 3.5518e-02, 2.2600e-01, 1.2263e-01,
        2.7183e-01, 1.1386e-01, 1.2855e-01, 4.8149e-01, 3.2311e-01, 6.7264e-01,
        2.7731e-02, 8.9980e-02, 4.2259e-02, 6.0646e-03, 1.0908e-01, 2.0715e-01,
        3.7470e-02, 2.8801e-02, 2.2596e-01, 3.1338e-01, 1.7670e-03, 6.6351e-03,
        4.4029e-02, 3.1107e-02, 5.2433e-03, 7.3886e-02, 3.7681e-01, 6.4365e-01,
        5.9244e-01, 3.9641e-02, 1.3137e-01, 8.9201e-02, 1.2696e-04, 2.7714e-02,
        1.3281e-01, 1.9944e-01, 6.2413e-01, 3.8116e-02, 5.8885e-01, 2.8807e-02,
        1.0046e-01, 1.5470e-02, 3.3948e-02, 8.9086e-03, 2.6474e-01, 4.9026e-02,
        2.0573e-01, 4.3150e-01, 2.4313e-02, 3.6178e-02, 1.4818e-03, 4.0011e-02,
        9.7205e-02, 1.3440e-01, 1.9538e-02, 3.6459e-01, 1.4073e-02, 7.9930e-02,
        1.2821e-01, 4.1046e-02, 1.2794e-02, 1.1805e-02, 3.5425e-01, 1.3531e-01,
        3.9461e-02, 2.5633e-03, 2.1966e-03, 3.2049e-01, 2.0844e-01, 4.9115e-03,
        3.1759e-01, 1.2264e-01, 8.9641e-01, 8.8492e-03, 1.6823e-02, 5.6025e-02,
        4.1791e-03, 3.1673e-02, 5.9341e-02, 4.3789e-01, 1.1589e-01, 2.2876e-01,
        6.3804e-02, 7.1410e-02, 2.8281e-01, 9.1258e-03, 3.0667e-01, 2.8751e-01,
        7.3168e-02, 5.0902e-02, 1.9262e-01, 6.9766e-01, 2.5941e-02, 1.7449e-01,
        6.7569e-02, 3.0711e-02, 5.9462e-02, 5.6793e-02, 1.5977e-01, 9.2341e-02,
        5.0795e-02, 1.0693e-01, 1.4335e-01, 5.9942e-02, 2.0033e-01, 2.2900e-02,
        2.2378e-01, 1.7751e-02, 2.3510e-01, 3.3189e-03, 3.6583e-01, 2.4039e-02,
        1.9914e-02, 3.4507e-01])
mlp.net.0.batch_norm.running_var tensor([9.9512e-03, 3.1587e-02, 3.0057e-02, 6.5980e-03, 1.5802e-02, 1.2894e-04,
        1.2229e-09, 3.4553e-03, 1.4359e-02, 6.9144e-03, 7.6245e-08, 3.4700e-03,
        2.1554e-02, 6.0802e-03, 1.3134e-02, 5.5335e-03, 5.9661e-02, 1.3644e-02,
        2.5079e-02, 1.0540e-02, 2.4369e-02, 7.7522e-02, 2.5169e-02, 2.1132e-02,
        3.9768e-03, 1.6084e-02, 9.5662e-03, 4.0463e-04, 1.4461e-02, 2.0570e-02,
        5.6853e-03, 2.7837e-03, 2.7600e-02, 3.0213e-02, 2.6450e-04, 8.5456e-04,
        6.5485e-03, 5.9507e-03, 7.7791e-04, 1.1140e-02, 2.1413e-02, 5.3577e-02,
        5.9900e-02, 7.0435e-03, 2.3720e-02, 1.3365e-02, 1.0899e-05, 4.3434e-03,
        2.7307e-02, 2.2611e-02, 4.7010e-02, 3.5670e-03, 1.0751e-01, 2.5381e-03,
        1.3903e-02, 3.8505e-03, 5.0130e-03, 7.6615e-04, 3.5056e-02, 1.0087e-02,
        1.4695e-02, 6.9572e-02, 4.2719e-03, 4.3273e-03, 1.8959e-04, 6.6165e-03,
        1.6589e-02, 1.9356e-02, 2.8691e-03, 4.6611e-02, 2.5652e-03, 1.1691e-02,
        1.7811e-02, 7.3626e-03, 1.2326e-03, 1.6536e-03, 3.6775e-02, 3.0685e-02,
        6.8743e-03, 2.7546e-04, 2.4319e-04, 2.7589e-02, 2.4934e-02, 5.4880e-04,
        4.0970e-02, 1.6664e-02, 5.7434e-02, 1.5751e-03, 3.2184e-03, 7.5635e-03,
        4.4899e-04, 8.3378e-03, 1.3209e-02, 4.9616e-02, 2.6143e-02, 4.5996e-02,
        6.8051e-03, 7.1289e-03, 5.3293e-02, 1.5066e-03, 5.7114e-02, 1.8879e-02,
        1.2031e-02, 1.1993e-02, 2.7657e-02, 9.8224e-02, 6.1946e-03, 4.1383e-02,
        1.3228e-02, 6.8318e-03, 1.2849e-02, 9.9385e-03, 1.7871e-02, 1.1358e-02,
        7.9544e-03, 1.9016e-02, 2.2041e-02, 7.7367e-03, 5.1977e-02, 3.7890e-03,
        4.9328e-02, 2.7111e-03, 2.0314e-02, 6.2971e-04, 5.1844e-02, 2.4774e-03,
        2.8467e-03, 2.6816e-02])
mlp.net.0.batch_norm.num_batches_tracked tensor(3978)
mlp.net.1.linear.weight tensor([[ 0.0139,  0.0161, -0.0313,  ..., -0.0440,  0.0428,  0.0436],
        [ 0.0557, -0.0462, -0.0354,  ..., -0.1297,  0.1556,  0.0203],
        [-0.0083, -0.1071,  0.1490,  ..., -0.0417,  0.0885, -0.0400],
        ...,
        [ 0.0202, -0.0112,  0.0822,  ..., -0.0979,  0.0902,  0.0700],
        [-0.0541, -0.0014, -0.0641,  ...,  0.0108,  0.0541, -0.0241],
        [-0.0053,  0.1536, -0.0482,  ..., -0.0252, -0.0397, -0.0464]])
mlp.net.1.linear.bias tensor([ 6.3136e-02, -3.5935e-02,  1.9057e-02, -2.2917e-02,  4.2636e-02,
        -1.0896e-02,  6.1361e-02,  3.4023e-02, -1.3188e-02, -3.6446e-02,
         2.5729e-02,  3.2891e-02,  4.9423e-02, -1.5445e-02, -3.8509e-02,
        -6.6895e-04,  3.2397e-02, -3.2897e-02,  4.0919e-02,  6.2894e-02,
        -2.2856e-02, -1.9026e-02, -2.3586e-02, -3.2624e-03,  3.7159e-02,
         3.5937e-02, -2.7502e-02,  4.2874e-02,  5.5252e-03,  3.4402e-02,
         1.7277e-02,  3.4884e-02, -4.3537e-02,  4.3588e-02, -3.0884e-02,
         2.9461e-03,  1.3868e-02, -2.2120e-02, -1.1185e-02,  3.0829e-02,
        -1.6711e-02, -3.8988e-02,  1.1939e-02, -2.0924e-02, -2.9099e-02,
         1.3355e-02, -4.3973e-02,  2.2877e-02, -2.0558e-02, -1.9764e-02,
         1.5617e-02,  2.3486e-02,  9.1400e-03,  8.6025e-03, -2.2867e-02,
        -4.1235e-02,  3.2205e-02, -1.9000e-02,  2.2269e-02,  7.8390e-03,
        -2.2071e-02, -5.7210e-05, -1.6027e-02, -1.0487e-02, -6.6506e-03,
         5.7598e-03, -4.7555e-03,  4.5653e-03, -1.7702e-02, -3.9885e-02,
         4.2036e-02,  3.5596e-03, -1.7232e-02, -3.9793e-02, -2.7255e-02,
        -2.2257e-02,  5.6500e-02,  5.0294e-02,  1.7652e-02,  4.9070e-02,
         7.8715e-02, -3.4741e-02,  4.1295e-04,  8.3397e-04, -6.6857e-03,
         6.9964e-02, -3.2692e-02, -1.3852e-02,  5.0861e-02,  6.4287e-02,
         3.4762e-03, -7.8815e-03,  3.2332e-02,  2.9742e-02,  1.2508e-02,
         6.0979e-03,  5.4972e-02, -1.1741e-02, -5.5317e-02,  4.3887e-03,
        -1.8332e-02,  3.4955e-02,  6.1170e-02,  4.3820e-02,  6.1662e-02,
        -3.1323e-02, -3.8856e-02,  3.2546e-02, -2.6048e-02, -3.7506e-02,
        -3.4122e-02,  2.1978e-03,  2.2327e-02, -2.1739e-02, -4.9289e-02,
        -3.0342e-02, -3.8231e-02, -3.8938e-02,  1.5705e-02,  3.8299e-02,
        -2.8732e-02,  1.9599e-02, -1.0899e-02,  5.3335e-02,  2.0454e-02,
        -5.2696e-02,  2.0841e-02, -1.1977e-02])
mlp.net.1.batch_norm.weight tensor([0.5988, 0.5898, 0.5611, 0.5736, 0.5863, 0.5698, 0.5875, 0.5978, 0.5857,
        0.5727, 0.6059, 0.5634, 0.5798, 0.5545, 0.5937, 0.6155, 0.5880, 0.5454,
        0.5735, 0.5794, 0.5951, 0.6012, 0.5934, 0.6069, 0.6067, 0.6151, 0.5716,
        0.5716, 0.5427, 0.5386, 0.6105, 0.5700, 0.5856, 0.6106, 0.5921, 0.6002,
        0.5820, 0.5989, 0.5799, 0.5716, 0.5628, 0.5860, 0.5683, 0.5703, 0.5675,
        0.5916, 0.5624, 0.5865, 0.5946, 0.5609, 0.5921, 0.5937, 0.5793, 0.5608,
        0.5947, 0.5599, 0.5524, 0.5876, 0.5831, 0.6098, 0.5719, 0.5781, 0.5944,
        0.6049, 0.6088, 0.5726, 0.6067, 0.5972, 0.5956, 0.5657, 0.5826, 0.5889,
        0.5686, 0.5645, 0.5571, 0.5802, 0.5713, 0.5860, 0.5829, 0.5564, 0.6040,
        0.5624, 0.5378, 0.5849, 0.5739, 0.5875, 0.6048, 0.5623, 0.5624, 0.5560,
        0.5435, 0.5789, 0.5867, 0.5560, 0.5948, 0.5517, 0.5530, 0.5990, 0.5842,
        0.5843, 0.5716, 0.5334, 0.5864, 0.5762, 0.5523, 0.5788, 0.5854, 0.6059,
        0.5843, 0.5587, 0.5810, 0.5815, 0.5675, 0.5906, 0.5565, 0.5904, 0.5834,
        0.5819, 0.6047, 0.5353, 0.5696, 0.6062, 0.5833, 0.5780, 0.5866, 0.5792,
        0.5979, 0.5842])
mlp.net.1.batch_norm.bias tensor([-0.0884,  0.0618, -0.0711, -0.1074, -0.0977,  0.0453,  0.0771, -0.0857,
        -0.0846,  0.0329, -0.0943,  0.1453, -0.0935,  0.1640, -0.0592, -0.0929,
        -0.1155,  0.0747,  0.0838, -0.1058, -0.0566, -0.1134, -0.1027, -0.0778,
        -0.0945, -0.1252,  0.0797, -0.0558,  0.1135,  0.0994, -0.1004, -0.1112,
        -0.0826, -0.1092, -0.0969, -0.0620,  0.0646, -0.0782, -0.0505,  0.0537,
        -0.0868, -0.1026,  0.0296,  0.0915,  0.0619, -0.0796,  0.0761, -0.1057,
        -0.0774,  0.0714, -0.1163, -0.0592,  0.0425,  0.0847, -0.1227, -0.1054,
         0.1011,  0.0889,  0.0667, -0.0833, -0.0306, -0.1045,  0.0828, -0.0718,
        -0.0898, -0.0578,  0.0751, -0.0925,  0.0894,  0.0125,  0.0758,  0.1377,
        -0.0749, -0.0583,  0.1188, -0.0727, -0.0899,  0.0646, -0.0349,  0.0983,
        -0.1165,  0.1048,  0.0919,  0.0596, -0.1091, -0.0888,  0.0480,  0.1086,
         0.1104,  0.1007,  0.0487, -0.0606, -0.0308,  0.0345,  0.0617,  0.0400,
         0.0441, -0.1037, -0.1340, -0.0775,  0.0823,  0.1332, -0.0831, -0.1055,
        -0.1135,  0.0920, -0.0999, -0.0967,  0.0988, -0.0606, -0.0781,  0.0668,
        -0.0779,  0.1027,  0.0327,  0.0758, -0.0365, -0.0643, -0.0670, -0.1564,
         0.0463,  0.0892,  0.0620, -0.0556, -0.1105,  0.0589, -0.0612,  0.0847])
mlp.net.1.batch_norm.running_mean tensor([0.2316, 0.1818, 0.2645, 0.2752, 0.2750, 0.2107, 0.2222, 0.2858, 0.1860,
        0.1854, 0.2088, 0.2121, 0.2918, 0.1976, 0.1791, 0.2300, 0.2878, 0.1568,
        0.1791, 0.3013, 0.1713, 0.2261, 0.2139, 0.2215, 0.2235, 0.3269, 0.2336,
        0.2157, 0.1931, 0.2460, 0.2379, 0.2318, 0.2598, 0.3060, 0.2150, 0.2566,
        0.1894, 0.2492, 0.1834, 0.2034, 0.2335, 0.2236, 0.1995, 0.1503, 0.1801,
        0.2111, 0.1968, 0.2385, 0.2160, 0.1884, 0.2042, 0.2365, 0.1769, 0.1851,
        0.2009, 0.1539, 0.2201, 0.1767, 0.2005, 0.2339, 0.2110, 0.2218, 0.1886,
        0.2350, 0.1957, 0.2280, 0.1663, 0.2686, 0.1904, 0.1456, 0.2698, 0.1900,
        0.1642, 0.1901, 0.1713, 0.1578, 0.2405, 0.2154, 0.1943, 0.2581, 0.2791,
        0.2119, 0.1805, 0.2194, 0.1666, 0.2282, 0.1846, 0.2276, 0.2449, 0.2425,
        0.2032, 0.2080, 0.2013, 0.2200, 0.1792, 0.2305, 0.2517, 0.2294, 0.2452,
        0.2891, 0.1701, 0.2816, 0.2134, 0.2451, 0.2446, 0.1651, 0.1670, 0.3002,
        0.2266, 0.1945, 0.2574, 0.1794, 0.2425, 0.2033, 0.1216, 0.1845, 0.1601,
        0.2119, 0.2155, 0.1826, 0.1885, 0.2036, 0.1740, 0.2065, 0.2022, 0.1600,
        0.2432, 0.1444])
mlp.net.1.batch_norm.running_var tensor([0.0914, 0.0832, 0.1182, 0.1748, 0.1837, 0.0859, 0.0769, 0.1382, 0.0961,
        0.0860, 0.0741, 0.0888, 0.1462, 0.1217, 0.1613, 0.1104, 0.2061, 0.0725,
        0.0611, 0.1474, 0.0964, 0.1117, 0.1124, 0.1075, 0.0996, 0.1837, 0.1256,
        0.0959, 0.0792, 0.1251, 0.1106, 0.1011, 0.1749, 0.1788, 0.0913, 0.1290,
        0.0885, 0.1260, 0.1134, 0.0898, 0.1046, 0.1308, 0.0891, 0.0543, 0.0702,
        0.1071, 0.0878, 0.1094, 0.1077, 0.0734, 0.0870, 0.1370, 0.0749, 0.0809,
        0.1060, 0.0771, 0.0874, 0.0667, 0.0777, 0.1120, 0.1184, 0.1000, 0.0755,
        0.1015, 0.0785, 0.1221, 0.0716, 0.1766, 0.0859, 0.0736, 0.1507, 0.0837,
        0.0684, 0.1202, 0.0714, 0.0615, 0.1086, 0.0827, 0.0754, 0.1361, 0.1272,
        0.1074, 0.0804, 0.1082, 0.0636, 0.1299, 0.0765, 0.1179, 0.1058, 0.1308,
        0.0769, 0.0864, 0.0978, 0.1294, 0.0585, 0.1122, 0.1045, 0.1129, 0.1518,
        0.1834, 0.0624, 0.2076, 0.0708, 0.1093, 0.1059, 0.0703, 0.0633, 0.2145,
        0.1087, 0.1308, 0.2041, 0.0674, 0.1104, 0.0896, 0.0441, 0.0722, 0.0629,
        0.1607, 0.1059, 0.0670, 0.0799, 0.0854, 0.0729, 0.1002, 0.0911, 0.1175,
        0.1760, 0.0541])
mlp.net.1.batch_norm.num_batches_tracked tensor(3978)
mlp.net.2.weight tensor([[ 0.0185,  0.0593,  0.0198,  ..., -0.0366,  0.0028,  0.0053],
        [-0.1105,  0.0541,  0.0123,  ..., -0.0134, -0.0807,  0.0876],
        [-0.0164,  0.0054, -0.0736,  ..., -0.0460, -0.0099,  0.0460],
        ...,
        [ 0.0751, -0.0843,  0.0374,  ..., -0.0323,  0.0094, -0.0574],
        [ 0.0665, -0.0211,  0.0248,  ..., -0.0072,  0.0319, -0.0044],
        [ 0.0291, -0.0802,  0.0286,  ...,  0.0310,  0.0142, -0.0302]])
mlp.net.2.bias tensor([-0.2064,  0.0628,  0.0542,  0.0637,  0.0870,  0.0963,  0.1102,  0.0289,
        -0.0028, -0.0178,  0.0362, -0.0673, -0.0360, -0.0700, -0.0185, -0.1090,
        -0.1118, -0.1207, -0.0773, -0.1485, -0.1496, -0.1299, -0.0709, -0.0745,
        -0.0559, -0.1721, -0.1302, -0.1259, -0.1010, -0.1257, -0.1523, -0.1514,
        -0.1328, -0.1658, -0.1926, -0.1564, -0.0595, -0.1524, -0.1638, -0.1180,
        -0.1389, -0.1657, -0.1369, -0.1374, -0.1909, -0.1060, -0.1964, -0.1818,
        -0.1826, -0.0985])
